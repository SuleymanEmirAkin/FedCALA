GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:2462: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=38, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Visualization saved to evolution_features_['COX2']_clients10.png
Visualization saved to evolution_params_['COX2']_clients10.png
[client 0]	loss_train: 1.0958	loss_val: 1.0456	loss_test: 1.0604	accuracy_train: 0.2553	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 1]	loss_train: 1.7103	loss_val: 1.7832	loss_test: 1.6733	accuracy_train: 0.2424	accuracy_val: 0.2500	accuracy_test: 0.3333
[client 2]	loss_train: 0.2956	loss_val: 0.2930	loss_test: 0.2871	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 3]	loss_train: 0.1645	loss_val: 0.1695	loss_test: 0.5321	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 4]	loss_train: 0.7290	loss_val: 0.7636	loss_test: 0.7290	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 5]	loss_train: 1.7002	loss_val: 1.4634	loss_test: 1.5486	accuracy_train: 0.2333	accuracy_val: 0.2500	accuracy_test: 0.2500
[client 6]	loss_train: 2.3232	loss_val: 2.5500	loss_test: 2.4202	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 7]	loss_train: 0.8147	loss_val: 0.7720	loss_test: 1.0067	accuracy_train: 0.4667	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 8]	loss_train: 1.4031	loss_val: nan	loss_test: 1.0175	accuracy_train: 0.2500	accuracy_val: nan	accuracy_test: 0.5000
[client 9]	loss_train: 1.2038	loss_val: 1.1119	loss_test: 1.2917	accuracy_train: 0.5366	accuracy_val: 0.6000	accuracy_test: 0.5000
curr_round: 0	curr_val_accuracy: nan	curr_test_accuracy: 0.4124
best_round: 0	best_val_accuracy: 0.0000	best_test_accuracy: 0.0000
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Visualization saved to evolution_features_['COX2']_clients10.png
Visualization saved to evolution_params_['COX2']_clients10.png
Round 2 | KL Drift: 0.357998
[client 0]	loss_train: 0.7066	loss_val: 0.7112	loss_test: 0.7060	accuracy_train: 0.2553	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 1]	loss_train: 0.6958	loss_val: 0.6955	loss_test: 0.6952	accuracy_train: 0.2121	accuracy_val: 0.2500	accuracy_test: 0.3333
[client 2]	loss_train: 0.7596	loss_val: 0.7597	loss_test: 0.7597	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 3]	loss_train: 0.7091	loss_val: 0.7071	loss_test: 0.7011	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 4]	loss_train: 0.6960	loss_val: 0.6935	loss_test: 0.6967	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 5]	loss_train: 0.7269	loss_val: 0.7249	loss_test: 0.7248	accuracy_train: 0.2333	accuracy_val: 0.2500	accuracy_test: 0.2500
[client 6]	loss_train: 0.6973	loss_val: 0.6974	loss_test: 0.6981	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 7]	loss_train: 0.6909	loss_val: 0.6956	loss_test: 0.6736	accuracy_train: 0.5333	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 8]	loss_train: 0.7377	loss_val: nan	loss_test: 0.6970	accuracy_train: 0.2500	accuracy_val: nan	accuracy_test: 0.5000
[client 9]	loss_train: 0.6905	loss_val: 0.6786	loss_test: 0.6985	accuracy_train: 0.5366	accuracy_val: 0.6000	accuracy_test: 0.5000
curr_round: 1	curr_val_accuracy: nan	curr_test_accuracy: 0.2458
best_round: 0	best_val_accuracy: 0.0000	best_test_accuracy: 0.0000
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Visualization saved to evolution_features_['COX2']_clients10.png
Visualization saved to evolution_params_['COX2']_clients10.png
Round 3 | KL Drift: 0.000204
[client 0]	loss_train: 0.7034	loss_val: 0.7095	loss_test: 0.7021	accuracy_train: 0.2553	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 1]	loss_train: 0.7224	loss_val: 0.7197	loss_test: 0.7123	accuracy_train: 0.2424	accuracy_val: 0.2500	accuracy_test: 0.3333
[client 2]	loss_train: 0.7428	loss_val: 0.7427	loss_test: 0.7421	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 3]	loss_train: 0.7339	loss_val: 0.7345	loss_test: 0.7145	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 4]	loss_train: 0.6947	loss_val: 0.7010	loss_test: 0.6941	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 5]	loss_train: 0.7307	loss_val: 0.7306	loss_test: 0.7280	accuracy_train: 0.2333	accuracy_val: 0.2500	accuracy_test: 0.2500
[client 6]	loss_train: 0.7241	loss_val: 0.7232	loss_test: 0.7251	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 7]	loss_train: 0.6908	loss_val: 0.6989	loss_test: 0.6673	accuracy_train: 0.5333	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 8]	loss_train: 0.7270	loss_val: nan	loss_test: 0.6958	accuracy_train: 0.2500	accuracy_val: nan	accuracy_test: 0.5000
[client 9]	loss_train: 0.6904	loss_val: 0.6842	loss_test: 0.6937	accuracy_train: 0.5366	accuracy_val: 0.6000	accuracy_test: 0.5000
curr_round: 2	curr_val_accuracy: nan	curr_test_accuracy: 0.2458
best_round: 0	best_val_accuracy: 0.0000	best_test_accuracy: 0.0000
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Visualization saved to evolution_features_['COX2']_clients10.png
Visualization saved to evolution_params_['COX2']_clients10.png
Round 4 | KL Drift: 0.000133
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.
  avg = a.mean(axis, **keepdims_kw)
/cta/users/anajafi/.local/lib/python3.10/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide
  ret = ret.dtype.type(ret / rcount)
/cta/users/anajafi/.local/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
