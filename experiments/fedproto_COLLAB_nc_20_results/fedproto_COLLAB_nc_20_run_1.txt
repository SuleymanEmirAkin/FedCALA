GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1.0179	loss_val: 0.9647	loss_test: 1.0144	accuracy_train: 0.9126	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 1]	loss_train: 1.2568	loss_val: 1.1980	loss_test: 1.2922	accuracy_train: 0.0969	accuracy_val: 0.0625	accuracy_test: 0.2059
[client 2]	loss_train: 1.0943	loss_val: 1.1247	loss_test: 1.0822	accuracy_train: 0.3855	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 3]	loss_train: 1.1175	loss_val: 1.1402	loss_test: 1.1280	accuracy_train: 0.3616	accuracy_val: 0.3000	accuracy_test: 0.3902
[client 4]	loss_train: 1.0709	loss_val: 1.0474	loss_test: 1.1238	accuracy_train: 0.1765	accuracy_val: 0.2381	accuracy_test: 0.1667
[client 5]	loss_train: 1.2839	loss_val: 1.4608	loss_test: 1.3020	accuracy_train: 0.1224	accuracy_val: 0.0556	accuracy_test: 0.1351
[client 6]	loss_train: 1.0528	loss_val: 1.1121	loss_test: 1.0451	accuracy_train: 0.3824	accuracy_val: 0.3182	accuracy_test: 0.3636
[client 7]	loss_train: 1.0100	loss_val: 1.0234	loss_test: 0.9863	accuracy_train: 0.6232	accuracy_val: 0.6111	accuracy_test: 0.6757
[client 8]	loss_train: 1.1098	loss_val: 1.0858	loss_test: 1.1020	accuracy_train: 0.3018	accuracy_val: 0.2778	accuracy_test: 0.3333
[client 9]	loss_train: 1.3563	loss_val: 1.2515	loss_test: 0.9147	accuracy_train: 0.4038	accuracy_val: 0.2857	accuracy_test: 0.7500
[client 10]	loss_train: 1.0730	loss_val: 1.0165	loss_test: 1.0709	accuracy_train: 0.1277	accuracy_val: 0.1765	accuracy_test: 0.0857
[client 11]	loss_train: 1.1273	loss_val: 1.1171	loss_test: 1.1636	accuracy_train: 0.4275	accuracy_val: 0.4688	accuracy_test: 0.3939
[client 12]	loss_train: 1.1299	loss_val: 1.0703	loss_test: 1.1009	accuracy_train: 0.5254	accuracy_val: 0.6667	accuracy_test: 0.2941
[client 13]	loss_train: 1.1419	loss_val: 1.1460	loss_test: 1.1129	accuracy_train: 0.0867	accuracy_val: 0.1200	accuracy_test: 0.1154
[client 14]	loss_train: 0.9890	loss_val: 0.9404	loss_test: 0.9825	accuracy_train: 0.6993	accuracy_val: 0.7647	accuracy_test: 0.7500
[client 15]	loss_train: 1.0505	loss_val: 1.0513	loss_test: 1.0398	accuracy_train: 0.7598	accuracy_val: 0.8400	accuracy_test: 0.6923
[client 16]	loss_train: 0.8218	loss_val: 0.8562	loss_test: 1.0113	accuracy_train: 0.8393	accuracy_val: 0.5000	accuracy_test: 0.6250
[client 17]	loss_train: 0.9069	loss_val: 0.9164	loss_test: 0.8519	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 1.0275	loss_val: 1.0543	loss_test: 1.0026	accuracy_train: 0.5221	accuracy_val: 0.4706	accuracy_test: 0.5143
[client 19]	loss_train: 1.2334	loss_val: 1.1897	loss_test: 1.2236	accuracy_train: 0.0227	accuracy_val: 0.0769	accuracy_test: 0.0000
curr_round: 0	curr_val_accuracy: 0.3614	curr_test_accuracy: 0.3635
best_round: 0	best_val_accuracy: 0.3614	best_test_accuracy: 0.3635
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 56170.1602	loss_val: 56170.1055	loss_test: 56170.1094	accuracy_train: 0.8835	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 24050.3750	loss_val: 24050.3945	loss_test: 24050.3652	accuracy_train: 0.2093	accuracy_val: 0.0625	accuracy_test: 0.2647
[client 2]	loss_train: 38773.6328	loss_val: 38773.6602	loss_test: 38773.6602	accuracy_train: 0.4217	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 21611.6445	loss_val: 21611.6465	loss_test: 21611.6602	accuracy_train: 0.3994	accuracy_val: 0.4000	accuracy_test: 0.3902
[client 4]	loss_train: 8792.6846	loss_val: 8792.6963	loss_test: 8792.6514	accuracy_train: 0.2471	accuracy_val: 0.2381	accuracy_test: 0.3333
[client 5]	loss_train: 6143.4438	loss_val: 6143.4233	loss_test: 6143.4893	accuracy_train: 0.6993	accuracy_val: 0.6389	accuracy_test: 0.7297
[client 6]	loss_train: 38716.4727	loss_val: 38716.5039	loss_test: 38716.4570	accuracy_train: 0.3529	accuracy_val: 0.3182	accuracy_test: 0.3636
[client 7]	loss_train: 11451.3213	loss_val: 11451.3184	loss_test: 11451.2930	accuracy_train: 0.6162	accuracy_val: 0.6389	accuracy_test: 0.6486
[client 8]	loss_train: 75.6348	loss_val: 75.6237	loss_test: 75.6164	accuracy_train: 0.7123	accuracy_val: 0.8056	accuracy_test: 0.7500
[client 9]	loss_train: 66444.2344	loss_val: 66444.1875	loss_test: 66444.0156	accuracy_train: 0.8269	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 3759.2505	loss_val: 3759.2200	loss_test: 3759.2554	accuracy_train: 0.2810	accuracy_val: 0.2353	accuracy_test: 0.2857
[client 11]	loss_train: 79.1348	loss_val: 79.1389	loss_test: 79.1562	accuracy_train: 0.4745	accuracy_val: 0.4688	accuracy_test: 0.4848
[client 12]	loss_train: 27420.5547	loss_val: 27420.5840	loss_test: 27420.5742	accuracy_train: 0.6271	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 47654.4141	loss_val: 47654.4180	loss_test: 47654.3945	accuracy_train: 0.0918	accuracy_val: 0.1200	accuracy_test: 0.1154
[client 14]	loss_train: 13643.9414	loss_val: 13643.9092	loss_test: 13643.9238	accuracy_train: 0.7273	accuracy_val: 0.8235	accuracy_test: 0.7000
[client 15]	loss_train: 78.7067	loss_val: 78.7086	loss_test: 78.6928	accuracy_train: 0.8725	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 16]	loss_train: 17009.4062	loss_val: 17009.4180	loss_test: 17009.5527	accuracy_train: 0.7321	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 12270.7754	loss_val: 12270.7568	loss_test: 12270.6973	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16551.0039	loss_val: 16551.0254	loss_test: 16550.9805	accuracy_train: 0.4449	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 113.5456	loss_val: 113.5152	loss_test: 113.5420	accuracy_train: 0.0324	accuracy_val: 0.1026	accuracy_test: 0.0000
curr_round: 1	curr_val_accuracy: 0.4629	curr_test_accuracy: 0.4718
best_round: 1	best_val_accuracy: 0.4629	best_test_accuracy: 0.4718
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26444.3809	loss_val: 26444.3281	loss_test: 26444.3320	accuracy_train: 0.8835	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 24176.2930	loss_val: 24176.3418	loss_test: 24176.2676	accuracy_train: 0.3682	accuracy_val: 0.3438	accuracy_test: 0.3235
[client 2]	loss_train: 27481.4082	loss_val: 27481.4316	loss_test: 27481.4414	accuracy_train: 0.4578	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 19195.0566	loss_val: 19195.0371	loss_test: 19195.0762	accuracy_train: 0.4214	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7444.7559	loss_val: 7444.7773	loss_test: 7444.7075	accuracy_train: 0.3471	accuracy_val: 0.2381	accuracy_test: 0.5417
[client 5]	loss_train: 5624.1982	loss_val: 5624.1836	loss_test: 5624.2305	accuracy_train: 0.8147	accuracy_val: 0.8611	accuracy_test: 0.8108
[client 6]	loss_train: 32311.6797	loss_val: 32311.6973	loss_test: 32311.6621	accuracy_train: 0.3529	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 7]	loss_train: 12335.4541	loss_val: 12335.4482	loss_test: 12335.4297	accuracy_train: 0.6127	accuracy_val: 0.6389	accuracy_test: 0.6486
[client 8]	loss_train: 124.0541	loss_val: 124.0475	loss_test: 124.0312	accuracy_train: 0.9298	accuracy_val: 1.0000	accuracy_test: 0.9722
[client 9]	loss_train: 52274.2070	loss_val: 52274.1914	loss_test: 52274.0469	accuracy_train: 0.7692	accuracy_val: 0.4286	accuracy_test: 0.7500
[client 10]	loss_train: 4294.3599	loss_val: 4294.3315	loss_test: 4294.3613	accuracy_train: 0.4599	accuracy_val: 0.4118	accuracy_test: 0.4857
[client 11]	loss_train: 99.7642	loss_val: 99.7710	loss_test: 99.7768	accuracy_train: 0.5255	accuracy_val: 0.4688	accuracy_test: 0.5455
[client 12]	loss_train: 19022.5293	loss_val: 19022.5566	loss_test: 19022.5449	accuracy_train: 0.6525	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 45983.3750	loss_val: 45983.3789	loss_test: 45983.3633	accuracy_train: 0.7245	accuracy_val: 0.8000	accuracy_test: 0.7308
[client 14]	loss_train: 9940.7324	loss_val: 9940.7168	loss_test: 9940.7314	accuracy_train: 0.7273	accuracy_val: 0.8235	accuracy_test: 0.7000
[client 15]	loss_train: 97.9554	loss_val: 97.9611	loss_test: 97.9441	accuracy_train: 0.9020	accuracy_val: 0.9200	accuracy_test: 0.9615
[client 16]	loss_train: 9185.0625	loss_val: 9185.0693	loss_test: 9185.1973	accuracy_train: 0.7500	accuracy_val: 0.8750	accuracy_test: 0.5000
[client 17]	loss_train: 10163.4111	loss_val: 10163.3799	loss_test: 10163.3223	accuracy_train: 0.5461	accuracy_val: 0.5882	accuracy_test: 0.5263
[client 18]	loss_train: 12875.2090	loss_val: 12875.2285	loss_test: 12875.1904	accuracy_train: 0.4632	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 181.8362	loss_val: 181.8112	loss_test: 181.8370	accuracy_train: 0.0809	accuracy_val: 0.1026	accuracy_test: 0.0769
curr_round: 2	curr_val_accuracy: 0.5624	curr_test_accuracy: 0.5661
best_round: 2	best_val_accuracy: 0.5624	best_test_accuracy: 0.5661
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20771.9316	loss_val: 20771.8789	loss_test: 20771.8789	accuracy_train: 0.8835	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 26974.0938	loss_val: 26974.1582	loss_test: 26974.0664	accuracy_train: 0.5039	accuracy_val: 0.3438	accuracy_test: 0.5294
[client 2]	loss_train: 21156.7207	loss_val: 21156.7422	loss_test: 21156.7578	accuracy_train: 0.5301	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 3]	loss_train: 19527.9336	loss_val: 19527.9082	loss_test: 19527.9551	accuracy_train: 0.4245	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7293.9839	loss_val: 7294.0142	loss_test: 7293.9272	accuracy_train: 0.5529	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 6042.3530	loss_val: 6042.3472	loss_test: 6042.3799	accuracy_train: 0.8427	accuracy_val: 0.8611	accuracy_test: 0.8378
[client 6]	loss_train: 32836.3086	loss_val: 32836.3125	loss_test: 32836.2930	accuracy_train: 0.3529	accuracy_val: 0.3182	accuracy_test: 0.3636
[client 7]	loss_train: 15089.4551	loss_val: 15089.4395	loss_test: 15089.4316	accuracy_train: 0.6162	accuracy_val: 0.6667	accuracy_test: 0.6486
[client 8]	loss_train: 208.8127	loss_val: 208.8137	loss_test: 208.7890	accuracy_train: 0.9684	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 44283.5430	loss_val: 44283.5664	loss_test: 44283.4414	accuracy_train: 0.7692	accuracy_val: 0.4286	accuracy_test: 0.7500
[client 10]	loss_train: 5010.9038	loss_val: 5010.8721	loss_test: 5010.9067	accuracy_train: 0.5620	accuracy_val: 0.5588	accuracy_test: 0.5429
[client 11]	loss_train: 144.0470	loss_val: 144.0581	loss_test: 144.0557	accuracy_train: 0.5412	accuracy_val: 0.4688	accuracy_test: 0.5758
[client 12]	loss_train: 16436.8672	loss_val: 16436.8945	loss_test: 16436.8809	accuracy_train: 0.6610	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 50928.7266	loss_val: 50928.7305	loss_test: 50928.7188	accuracy_train: 0.8827	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 7327.9321	loss_val: 7327.9351	loss_test: 7327.9414	accuracy_train: 0.7343	accuracy_val: 0.8235	accuracy_test: 0.7000
[client 15]	loss_train: 132.9143	loss_val: 132.9254	loss_test: 132.9091	accuracy_train: 0.9167	accuracy_val: 0.9200	accuracy_test: 0.9615
[client 16]	loss_train: 6714.3750	loss_val: 6714.3921	loss_test: 6714.5054	accuracy_train: 0.7679	accuracy_val: 0.8750	accuracy_test: 0.5000
[client 17]	loss_train: 8902.4141	loss_val: 8902.3770	loss_test: 8902.3213	accuracy_train: 0.5532	accuracy_val: 0.5882	accuracy_test: 0.5263
[client 18]	loss_train: 13364.4746	loss_val: 13364.4961	loss_test: 13364.4619	accuracy_train: 0.4632	accuracy_val: 0.4706	accuracy_test: 0.4286
[client 19]	loss_train: 298.2969	loss_val: 298.2766	loss_test: 298.3032	accuracy_train: 0.4919	accuracy_val: 0.6667	accuracy_test: 0.5641
curr_round: 3	curr_val_accuracy: 0.6344	curr_test_accuracy: 0.6361
best_round: 3	best_val_accuracy: 0.6344	best_test_accuracy: 0.6361
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 18846.5195	loss_val: 18846.4668	loss_test: 18846.4648	accuracy_train: 0.8932	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 30918.2168	loss_val: 30918.2852	loss_test: 30918.1855	accuracy_train: 0.5349	accuracy_val: 0.3750	accuracy_test: 0.5882
[client 2]	loss_train: 20250.8770	loss_val: 20250.8984	loss_test: 20250.9180	accuracy_train: 0.5663	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 3]	loss_train: 19895.3965	loss_val: 19895.3672	loss_test: 19895.4219	accuracy_train: 0.4245	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7160.3008	loss_val: 7160.3369	loss_test: 7160.2407	accuracy_train: 0.6118	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 6883.1392	loss_val: 6883.1431	loss_test: 6883.1587	accuracy_train: 0.8601	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 35098.5234	loss_val: 35098.5117	loss_test: 35098.5039	accuracy_train: 0.3706	accuracy_val: 0.3182	accuracy_test: 0.3636
[client 7]	loss_train: 17564.8086	loss_val: 17564.7793	loss_test: 17564.7812	accuracy_train: 0.6373	accuracy_val: 0.6667	accuracy_test: 0.6757
[client 8]	loss_train: 327.6786	loss_val: 327.6871	loss_test: 327.6571	accuracy_train: 0.9895	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43632.3906	loss_val: 43632.4570	loss_test: 43632.3516	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 5787.4204	loss_val: 5787.3853	loss_test: 5787.4277	accuracy_train: 0.6095	accuracy_val: 0.6176	accuracy_test: 0.5714
[client 11]	loss_train: 208.6116	loss_val: 208.6259	loss_test: 208.6208	accuracy_train: 0.5569	accuracy_val: 0.5000	accuracy_test: 0.6061
[client 12]	loss_train: 15310.8555	loss_val: 15310.8828	loss_test: 15310.8691	accuracy_train: 0.6610	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 57103.6211	loss_val: 57103.6289	loss_test: 57103.6211	accuracy_train: 0.8980	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 6144.5669	loss_val: 6144.5811	loss_test: 6144.5952	accuracy_train: 0.7552	accuracy_val: 0.8235	accuracy_test: 0.7500
[client 15]	loss_train: 181.8270	loss_val: 181.8449	loss_test: 181.8261	accuracy_train: 0.9706	accuracy_val: 0.9200	accuracy_test: 0.9615
[client 16]	loss_train: 5705.1909	loss_val: 5705.2197	loss_test: 5705.3179	accuracy_train: 0.7500	accuracy_val: 0.8750	accuracy_test: 0.5000
[client 17]	loss_train: 8307.8730	loss_val: 8307.8350	loss_test: 8307.7773	accuracy_train: 0.5745	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13626.3682	loss_val: 13626.3896	loss_test: 13626.3652	accuracy_train: 0.4596	accuracy_val: 0.4118	accuracy_test: 0.4571
[client 19]	loss_train: 476.3492	loss_val: 476.3324	loss_test: 476.3601	accuracy_train: 0.8544	accuracy_val: 0.8974	accuracy_test: 0.8205
curr_round: 4	curr_val_accuracy: 0.6623	curr_test_accuracy: 0.6767
best_round: 4	best_val_accuracy: 0.6623	best_test_accuracy: 0.6767
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 19429.1934	loss_val: 19429.1426	loss_test: 19429.1406	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 34903.8320	loss_val: 34903.9102	loss_test: 34903.7930	accuracy_train: 0.6085	accuracy_val: 0.5000	accuracy_test: 0.5882
[client 2]	loss_train: 21641.2129	loss_val: 21641.2383	loss_test: 21641.2578	accuracy_train: 0.5663	accuracy_val: 0.4545	accuracy_test: 0.3636
[client 3]	loss_train: 20530.7051	loss_val: 20530.6777	loss_test: 20530.7363	accuracy_train: 0.4245	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 6849.2861	loss_val: 6849.3252	loss_test: 6849.2212	accuracy_train: 0.6588	accuracy_val: 0.4762	accuracy_test: 0.7083
[client 5]	loss_train: 7931.3716	loss_val: 7931.3696	loss_test: 7931.3926	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 37384.5195	loss_val: 37384.4844	loss_test: 37384.4844	accuracy_train: 0.3588	accuracy_val: 0.3182	accuracy_test: 0.3636
[client 7]	loss_train: 19978.2168	loss_val: 19978.1797	loss_test: 19978.1934	accuracy_train: 0.6479	accuracy_val: 0.6667	accuracy_test: 0.6757
[client 8]	loss_train: 485.5352	loss_val: 485.5523	loss_test: 485.5187	accuracy_train: 0.9965	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 44633.6719	loss_val: 44633.7227	loss_test: 44633.6250	accuracy_train: 0.7692	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 6449.3726	loss_val: 6449.3296	loss_test: 6449.3838	accuracy_train: 0.5730	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 291.8023	loss_val: 291.8200	loss_test: 291.8169	accuracy_train: 0.5647	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 12]	loss_train: 14779.0361	loss_val: 14779.0635	loss_test: 14779.0508	accuracy_train: 0.6610	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 63637.7969	loss_val: 63637.8086	loss_test: 63637.8047	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 6069.2954	loss_val: 6069.3188	loss_test: 6069.3354	accuracy_train: 0.7483	accuracy_val: 0.7059	accuracy_test: 0.7500
[client 15]	loss_train: 247.3901	loss_val: 247.4173	loss_test: 247.3990	accuracy_train: 0.9853	accuracy_val: 0.9200	accuracy_test: 0.9615
[client 16]	loss_train: 5195.9185	loss_val: 5195.9561	loss_test: 5196.0400	accuracy_train: 0.7321	accuracy_val: 0.8750	accuracy_test: 0.5000
[client 17]	loss_train: 7920.3179	loss_val: 7920.2822	loss_test: 7920.2246	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14861.3145	loss_val: 14861.3330	loss_test: 14861.3184	accuracy_train: 0.4375	accuracy_val: 0.4412	accuracy_test: 0.4571
[client 19]	loss_train: 719.6364	loss_val: 719.6264	loss_test: 719.6537	accuracy_train: 0.9320	accuracy_val: 0.9487	accuracy_test: 0.8974
curr_round: 5	curr_val_accuracy: 0.6660	curr_test_accuracy: 0.6865
best_round: 5	best_val_accuracy: 0.6660	best_test_accuracy: 0.6865
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 19514.9004	loss_val: 19514.8516	loss_test: 19514.8477	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 37848.0039	loss_val: 37848.0938	loss_test: 37847.9648	accuracy_train: 0.6512	accuracy_val: 0.5625	accuracy_test: 0.6176
[client 2]	loss_train: 23932.8984	loss_val: 23932.9277	loss_test: 23932.9473	accuracy_train: 0.5904	accuracy_val: 0.4545	accuracy_test: 0.3636
[client 3]	loss_train: 22167.9980	loss_val: 22167.9785	loss_test: 22168.0312	accuracy_train: 0.4245	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 6622.1270	loss_val: 6622.1685	loss_test: 6622.0586	accuracy_train: 0.6412	accuracy_val: 0.6190	accuracy_test: 0.7083
[client 5]	loss_train: 9110.8135	loss_val: 9110.8086	loss_test: 9110.8359	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41523.0664	loss_val: 41523.0117	loss_test: 41523.0156	accuracy_train: 0.3471	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 7]	loss_train: 23070.6328	loss_val: 23070.5918	loss_test: 23070.6113	accuracy_train: 0.6338	accuracy_val: 0.6667	accuracy_test: 0.6486
[client 8]	loss_train: 671.6528	loss_val: 671.6783	loss_test: 671.6425	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45551.6445	loss_val: 45551.6992	loss_test: 45551.6055	accuracy_train: 0.7692	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 7344.3867	loss_val: 7344.3354	loss_test: 7344.4019	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 396.1308	loss_val: 396.1520	loss_test: 396.1471	accuracy_train: 0.5843	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 12]	loss_train: 14947.8965	loss_val: 14947.9238	loss_test: 14947.9102	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 74972.8906	loss_val: 74972.9062	loss_test: 74972.9062	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 6231.9663	loss_val: 6231.9937	loss_test: 6232.0034	accuracy_train: 0.5734	accuracy_val: 0.4118	accuracy_test: 0.5000
[client 15]	loss_train: 329.2196	loss_val: 329.2552	loss_test: 329.2387	accuracy_train: 0.9902	accuracy_val: 0.9600	accuracy_test: 1.0000
[client 16]	loss_train: 5068.9829	loss_val: 5069.0229	loss_test: 5069.1079	accuracy_train: 0.7500	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 7980.4985	loss_val: 7980.4678	loss_test: 7980.4106	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16465.0469	loss_val: 16465.0664	loss_test: 16465.0547	accuracy_train: 0.4118	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1008.3941	loss_val: 1008.3941	loss_test: 1008.4124	accuracy_train: 0.9709	accuracy_val: 0.9744	accuracy_test: 0.9744
curr_round: 6	curr_val_accuracy: 0.6696	curr_test_accuracy: 0.6871
best_round: 6	best_val_accuracy: 0.6696	best_test_accuracy: 0.6871
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 19465.0195	loss_val: 19464.9727	loss_test: 19464.9668	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 41652.6250	loss_val: 41652.7188	loss_test: 41652.5820	accuracy_train: 0.7093	accuracy_val: 0.6562	accuracy_test: 0.6765
[client 2]	loss_train: 26649.6133	loss_val: 26649.6484	loss_test: 26649.6660	accuracy_train: 0.6145	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 25270.1543	loss_val: 25270.1504	loss_test: 25270.1914	accuracy_train: 0.4025	accuracy_val: 0.4000	accuracy_test: 0.3902
[client 4]	loss_train: 6562.6562	loss_val: 6562.6997	loss_test: 6562.5859	accuracy_train: 0.6706	accuracy_val: 0.6190	accuracy_test: 0.7917
[client 5]	loss_train: 10379.5518	loss_val: 10379.5518	loss_test: 10379.5752	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45027.8008	loss_val: 45027.7305	loss_test: 45027.7344	accuracy_train: 0.3471	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 7]	loss_train: 25967.3594	loss_val: 25967.3242	loss_test: 25967.3359	accuracy_train: 0.6585	accuracy_val: 0.7500	accuracy_test: 0.6757
[client 8]	loss_train: 868.0609	loss_val: 868.0886	loss_test: 868.0609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45788.9336	loss_val: 45788.9961	loss_test: 45788.8945	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 8539.1201	loss_val: 8539.0664	loss_test: 8539.1348	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 531.2806	loss_val: 531.3065	loss_test: 531.2959	accuracy_train: 0.6118	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 12]	loss_train: 15284.7012	loss_val: 15284.7295	loss_test: 15284.7168	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 88879.2500	loss_val: 88879.2656	loss_test: 88879.2734	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 6688.6538	loss_val: 6688.6831	loss_test: 6688.6875	accuracy_train: 0.4476	accuracy_val: 0.2353	accuracy_test: 0.4500
[client 15]	loss_train: 425.1116	loss_val: 425.1533	loss_test: 425.1378	accuracy_train: 0.9951	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5003.7515	loss_val: 5003.7964	loss_test: 5003.8779	accuracy_train: 0.8036	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 7985.7881	loss_val: 7985.7671	loss_test: 7985.7085	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17708.8965	loss_val: 17708.9180	loss_test: 17708.9062	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1318.7007	loss_val: 1318.7130	loss_test: 1318.7239	accuracy_train: 0.9903	accuracy_val: 0.9744	accuracy_test: 1.0000
curr_round: 7	curr_val_accuracy: 0.6752	curr_test_accuracy: 0.6965
best_round: 7	best_val_accuracy: 0.6752	best_test_accuracy: 0.6965
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 18967.1680	loss_val: 18967.1250	loss_test: 18967.1172	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 46430.4531	loss_val: 46430.5430	loss_test: 46430.4141	accuracy_train: 0.7984	accuracy_val: 0.8438	accuracy_test: 0.7059
[client 2]	loss_train: 29006.3008	loss_val: 29006.3379	loss_test: 29006.3574	accuracy_train: 0.6145	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 28699.0273	loss_val: 28699.0215	loss_test: 28699.0605	accuracy_train: 0.4025	accuracy_val: 0.4000	accuracy_test: 0.3902
[client 4]	loss_train: 6673.9731	loss_val: 6674.0190	loss_test: 6673.9023	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.7917
[client 5]	loss_train: 11631.3359	loss_val: 11631.3408	loss_test: 11631.3594	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48912.1016	loss_val: 48912.0273	loss_test: 48912.0273	accuracy_train: 0.3471	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 7]	loss_train: 30995.3457	loss_val: 30995.3184	loss_test: 30995.3184	accuracy_train: 0.6655	accuracy_val: 0.7500	accuracy_test: 0.7297
[client 8]	loss_train: 1051.6315	loss_val: 1051.6593	loss_test: 1051.6416	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47616.7266	loss_val: 47616.7969	loss_test: 47616.6875	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 9352.7988	loss_val: 9352.7412	loss_test: 9352.8115	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 694.4745	loss_val: 694.5042	loss_test: 694.4879	accuracy_train: 0.6431	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 12]	loss_train: 15705.0195	loss_val: 15705.0488	loss_test: 15705.0381	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 96925.3203	loss_val: 96925.3359	loss_test: 96925.3594	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 7128.3594	loss_val: 7128.3872	loss_test: 7128.3853	accuracy_train: 0.4126	accuracy_val: 0.2353	accuracy_test: 0.4000
[client 15]	loss_train: 537.6824	loss_val: 537.7262	loss_test: 537.7161	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4942.4399	loss_val: 4942.4902	loss_test: 4942.5674	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 8184.8511	loss_val: 8184.8403	loss_test: 8184.7798	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17991.2012	loss_val: 17991.2227	loss_test: 17991.2070	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1597.5283	loss_val: 1597.5565	loss_test: 1597.5635	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 8	curr_val_accuracy: 0.6873	curr_test_accuracy: 0.7005
best_round: 8	best_val_accuracy: 0.6873	best_test_accuracy: 0.7005
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 18682.7637	loss_val: 18682.7227	loss_test: 18682.7129	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 49400.6367	loss_val: 49400.7266	loss_test: 49400.6055	accuracy_train: 0.8411	accuracy_val: 0.8438	accuracy_test: 0.7353
[client 2]	loss_train: 30808.2441	loss_val: 30808.2891	loss_test: 30808.3086	accuracy_train: 0.6265	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 31780.0879	loss_val: 31780.0781	loss_test: 31780.1191	accuracy_train: 0.4245	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 6904.8945	loss_val: 6904.9443	loss_test: 6904.8223	accuracy_train: 0.7059	accuracy_val: 0.6190	accuracy_test: 0.7917
[client 5]	loss_train: 12335.8623	loss_val: 12335.8721	loss_test: 12335.8867	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 52669.0898	loss_val: 52669.0117	loss_test: 52669.0078	accuracy_train: 0.3529	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 7]	loss_train: 37843.9336	loss_val: 37843.9102	loss_test: 37843.9102	accuracy_train: 0.6690	accuracy_val: 0.7500	accuracy_test: 0.7027
[client 8]	loss_train: 1197.8285	loss_val: 1197.8579	loss_test: 1197.8451	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47022.1875	loss_val: 47022.2656	loss_test: 47022.1523	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 10047.5273	loss_val: 10047.4658	loss_test: 10047.5361	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 889.9181	loss_val: 889.9515	loss_test: 889.9274	accuracy_train: 0.7020	accuracy_val: 0.6250	accuracy_test: 0.6970
[client 12]	loss_train: 16151.5176	loss_val: 16151.5488	loss_test: 16151.5381	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 101124.7734	loss_val: 101124.7891	loss_test: 101124.8203	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 7693.7476	loss_val: 7693.7627	loss_test: 7693.7656	accuracy_train: 0.3916	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 661.8708	loss_val: 661.9142	loss_test: 661.9117	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4992.1729	loss_val: 4992.2251	loss_test: 4992.2993	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 8649.7480	loss_val: 8649.7500	loss_test: 8649.6846	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 18656.4922	loss_val: 18656.5137	loss_test: 18656.5020	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1836.1581	loss_val: 1836.1920	loss_test: 1836.1997	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 9	curr_val_accuracy: 0.7015	curr_test_accuracy: 0.7062
best_round: 9	best_val_accuracy: 0.7015	best_test_accuracy: 0.7062
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 18874.4023	loss_val: 18874.3652	loss_test: 18874.3535	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 50063.8906	loss_val: 50063.9766	loss_test: 50063.8711	accuracy_train: 0.8256	accuracy_val: 0.8750	accuracy_test: 0.7647
[client 2]	loss_train: 33763.3477	loss_val: 33763.3984	loss_test: 33763.4141	accuracy_train: 0.6386	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 33987.6523	loss_val: 33987.6406	loss_test: 33987.6836	accuracy_train: 0.4308	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7332.2529	loss_val: 7332.3076	loss_test: 7332.1812	accuracy_train: 0.6882	accuracy_val: 0.6190	accuracy_test: 0.7917
[client 5]	loss_train: 12984.6074	loss_val: 12984.6191	loss_test: 12984.6318	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 56900.5586	loss_val: 56900.4688	loss_test: 56900.4648	accuracy_train: 0.3588	accuracy_val: 0.4091	accuracy_test: 0.3636
[client 7]	loss_train: 42486.9570	loss_val: 42486.9375	loss_test: 42486.9414	accuracy_train: 0.6725	accuracy_val: 0.7500	accuracy_test: 0.7027
[client 8]	loss_train: 1293.6890	loss_val: 1293.7205	loss_test: 1293.7120	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47629.0039	loss_val: 47629.0859	loss_test: 47628.9688	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 10922.7480	loss_val: 10922.6885	loss_test: 10922.7559	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1102.5514	loss_val: 1102.5880	loss_test: 1102.5536	accuracy_train: 0.7529	accuracy_val: 0.7188	accuracy_test: 0.7879
[client 12]	loss_train: 17821.2656	loss_val: 17821.2988	loss_test: 17821.2871	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 107745.0547	loss_val: 107745.0781	loss_test: 107745.1172	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 8342.7754	loss_val: 8342.7803	loss_test: 8342.7900	accuracy_train: 0.3706	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 789.9969	loss_val: 790.0408	loss_test: 790.0446	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5148.8291	loss_val: 5148.8877	loss_test: 5148.9580	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 9244.4482	loss_val: 9244.4590	loss_test: 9244.3916	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 19385.1621	loss_val: 19385.1836	loss_test: 19385.1777	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1962.7330	loss_val: 1962.7678	loss_test: 1962.7777	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 10	curr_val_accuracy: 0.7134	curr_test_accuracy: 0.7122
best_round: 10	best_val_accuracy: 0.7134	best_test_accuracy: 0.7122
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 19836.8516	loss_val: 19836.8184	loss_test: 19836.8027	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 49604.8438	loss_val: 49604.9297	loss_test: 49604.8320	accuracy_train: 0.7984	accuracy_val: 0.8125	accuracy_test: 0.7941
[client 2]	loss_train: 35651.9297	loss_val: 35651.9922	loss_test: 35652.0039	accuracy_train: 0.6747	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 35053.3906	loss_val: 35053.3789	loss_test: 35053.4258	accuracy_train: 0.4465	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 7630.0181	loss_val: 7630.0767	loss_test: 7629.9492	accuracy_train: 0.6765	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 5]	loss_train: 13022.6270	loss_val: 13022.6416	loss_test: 13022.6514	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 60346.8867	loss_val: 60346.7812	loss_test: 60346.7773	accuracy_train: 0.3647	accuracy_val: 0.4091	accuracy_test: 0.3636
[client 7]	loss_train: 43629.3320	loss_val: 43629.3125	loss_test: 43629.3203	accuracy_train: 0.6796	accuracy_val: 0.8056	accuracy_test: 0.6757
[client 8]	loss_train: 1375.6005	loss_val: 1375.6338	loss_test: 1375.6244	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48008.1992	loss_val: 48008.2852	loss_test: 48008.1641	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 11317.7705	loss_val: 11317.7080	loss_test: 11317.7754	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1331.2896	loss_val: 1331.3317	loss_test: 1331.2861	accuracy_train: 0.8000	accuracy_val: 0.7812	accuracy_test: 0.8485
[client 12]	loss_train: 19063.7871	loss_val: 19063.8223	loss_test: 19063.8105	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 116565.9297	loss_val: 116565.9531	loss_test: 116566.0000	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 8792.7334	loss_val: 8792.7305	loss_test: 8792.7471	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 914.0551	loss_val: 914.1003	loss_test: 914.1068	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5304.1963	loss_val: 5304.2607	loss_test: 5304.3267	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 9961.5518	loss_val: 9961.5703	loss_test: 9961.5020	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 19378.7988	loss_val: 19378.8184	loss_test: 19378.8164	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 2017.3297	loss_val: 2017.3644	loss_test: 2017.3777	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 11	curr_val_accuracy: 0.7153	curr_test_accuracy: 0.7162
best_round: 11	best_val_accuracy: 0.7153	best_test_accuracy: 0.7162
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21637.8438	loss_val: 21637.8145	loss_test: 21637.7969	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 50600.8633	loss_val: 50600.9453	loss_test: 50600.8594	accuracy_train: 0.7674	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 37322.4219	loss_val: 37322.4961	loss_test: 37322.5039	accuracy_train: 0.6988	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 3]	loss_train: 35804.8516	loss_val: 35804.8555	loss_test: 35804.8906	accuracy_train: 0.4403	accuracy_val: 0.4000	accuracy_test: 0.4146
[client 4]	loss_train: 7521.1870	loss_val: 7521.2495	loss_test: 7521.1211	accuracy_train: 0.6824	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 5]	loss_train: 12731.9492	loss_val: 12731.9678	loss_test: 12731.9717	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 63438.3750	loss_val: 63438.2500	loss_test: 63438.2578	accuracy_train: 0.3647	accuracy_val: 0.4091	accuracy_test: 0.3636
[client 7]	loss_train: 45095.6289	loss_val: 45095.6055	loss_test: 45095.6172	accuracy_train: 0.6901	accuracy_val: 0.7500	accuracy_test: 0.6757
[client 8]	loss_train: 1431.9283	loss_val: 1431.9634	loss_test: 1431.9514	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49462.2305	loss_val: 49462.3203	loss_test: 49462.1992	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 11205.4092	loss_val: 11205.3467	loss_test: 11205.4131	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1551.2540	loss_val: 1551.3041	loss_test: 1551.2479	accuracy_train: 0.8196	accuracy_val: 0.7500	accuracy_test: 0.8485
[client 12]	loss_train: 21065.6094	loss_val: 21065.6465	loss_test: 21065.6348	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 131223.9531	loss_val: 131223.9688	loss_test: 131224.0312	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 9378.5371	loss_val: 9378.5215	loss_test: 9378.5537	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1031.1388	loss_val: 1031.1838	loss_test: 1031.1930	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5491.9160	loss_val: 5491.9814	loss_test: 5492.0508	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10943.9014	loss_val: 10943.9258	loss_test: 10943.8535	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 18333.6504	loss_val: 18333.6719	loss_test: 18333.6738	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 2028.0529	loss_val: 2028.0862	loss_test: 2028.1028	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 12	curr_val_accuracy: 0.7093	curr_test_accuracy: 0.7143
best_round: 11	best_val_accuracy: 0.7153	best_test_accuracy: 0.7162
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23156.0547	loss_val: 23156.0332	loss_test: 23156.0137	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 50462.9023	loss_val: 50462.9805	loss_test: 50462.9102	accuracy_train: 0.7674	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 39411.2695	loss_val: 39411.3516	loss_test: 39411.3555	accuracy_train: 0.6988	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 3]	loss_train: 35877.9141	loss_val: 35877.9258	loss_test: 35877.9531	accuracy_train: 0.4560	accuracy_val: 0.3750	accuracy_test: 0.3902
[client 4]	loss_train: 7436.7505	loss_val: 7436.8193	loss_test: 7436.6870	accuracy_train: 0.6824	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 5]	loss_train: 12272.5488	loss_val: 12272.5703	loss_test: 12272.5713	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 65303.4414	loss_val: 65303.3086	loss_test: 65303.3164	accuracy_train: 0.3765	accuracy_val: 0.4091	accuracy_test: 0.4091
[client 7]	loss_train: 46608.4492	loss_val: 46608.4180	loss_test: 46608.4375	accuracy_train: 0.6937	accuracy_val: 0.7778	accuracy_test: 0.7027
[client 8]	loss_train: 1470.8822	loss_val: 1470.9182	loss_test: 1470.9031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50887.7188	loss_val: 50887.8164	loss_test: 50887.6875	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 11070.5801	loss_val: 11070.5166	loss_test: 11070.5820	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1806.6844	loss_val: 1806.7429	loss_test: 1806.6763	accuracy_train: 0.8353	accuracy_val: 0.8125	accuracy_test: 0.8182
[client 12]	loss_train: 22557.3574	loss_val: 22557.3984	loss_test: 22557.3867	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 143644.8438	loss_val: 143644.8750	loss_test: 143644.9375	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 9717.2139	loss_val: 9717.1924	loss_test: 9717.2305	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1134.1707	loss_val: 1134.2129	loss_test: 1134.2257	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5722.5938	loss_val: 5722.6602	loss_test: 5722.7349	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 11469.1885	loss_val: 11469.2188	loss_test: 11469.1455	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17823.0371	loss_val: 17823.0566	loss_test: 17823.0625	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 2030.9626	loss_val: 2030.9946	loss_test: 2031.0157	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 13	curr_val_accuracy: 0.7133	curr_test_accuracy: 0.7143
best_round: 11	best_val_accuracy: 0.7153	best_test_accuracy: 0.7162
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24528.1562	loss_val: 24528.1484	loss_test: 24528.1250	accuracy_train: 0.9223	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 47838.5859	loss_val: 47838.6562	loss_test: 47838.6016	accuracy_train: 0.7791	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 41248.1445	loss_val: 41248.2422	loss_test: 41248.2422	accuracy_train: 0.7108	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 3]	loss_train: 38249.3594	loss_val: 38249.3672	loss_test: 38249.4023	accuracy_train: 0.4591	accuracy_val: 0.4000	accuracy_test: 0.4146
[client 4]	loss_train: 7290.2515	loss_val: 7290.3286	loss_test: 7290.1909	accuracy_train: 0.6824	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 5]	loss_train: 11815.9502	loss_val: 11815.9785	loss_test: 11815.9717	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 67636.2578	loss_val: 67636.1250	loss_test: 67636.1250	accuracy_train: 0.3824	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 47276.2031	loss_val: 47276.1641	loss_test: 47276.1992	accuracy_train: 0.6972	accuracy_val: 0.7222	accuracy_test: 0.7027
[client 8]	loss_train: 1501.2191	loss_val: 1501.2552	loss_test: 1501.2383	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54228.1250	loss_val: 54228.2266	loss_test: 54228.0977	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 11239.0078	loss_val: 11238.9502	loss_test: 11239.0088	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2042.6427	loss_val: 2042.7062	loss_test: 2042.6318	accuracy_train: 0.8431	accuracy_val: 0.7812	accuracy_test: 0.8182
[client 12]	loss_train: 24121.9023	loss_val: 24121.9453	loss_test: 24121.9316	accuracy_train: 0.6610	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 159151.0938	loss_val: 159151.1250	loss_test: 159151.2031	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10259.3281	loss_val: 10259.3076	loss_test: 10259.3477	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1221.8478	loss_val: 1221.8873	loss_test: 1221.9050	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5982.4541	loss_val: 5982.5205	loss_test: 5982.6064	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 11583.2549	loss_val: 11583.2891	loss_test: 11583.2178	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17753.5410	loss_val: 17753.5586	loss_test: 17753.5645	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 2022.5231	loss_val: 2022.5541	loss_test: 2022.5798	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 14	curr_val_accuracy: 0.7133	curr_test_accuracy: 0.7162
best_round: 11	best_val_accuracy: 0.7153	best_test_accuracy: 0.7162
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25646.6074	loss_val: 25646.5938	loss_test: 25646.5664	accuracy_train: 0.9320	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 46249.5430	loss_val: 46249.5977	loss_test: 46249.5664	accuracy_train: 0.7868	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 43993.3203	loss_val: 43993.4336	loss_test: 43993.4219	accuracy_train: 0.7711	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 3]	loss_train: 39995.8438	loss_val: 39995.8477	loss_test: 39995.8906	accuracy_train: 0.4591	accuracy_val: 0.4000	accuracy_test: 0.3902
[client 4]	loss_train: 7299.4585	loss_val: 7299.5435	loss_test: 7299.4028	accuracy_train: 0.6882	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 11551.9473	loss_val: 11551.9795	loss_test: 11551.9678	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 69491.5703	loss_val: 69491.4453	loss_test: 69491.4531	accuracy_train: 0.3941	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 46251.4297	loss_val: 46251.3984	loss_test: 46251.4336	accuracy_train: 0.7042	accuracy_val: 0.7222	accuracy_test: 0.7027
[client 8]	loss_train: 1501.6006	loss_val: 1501.6349	loss_test: 1501.6205	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56975.6289	loss_val: 56975.7422	loss_test: 56975.6055	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11339.7578	loss_val: 11339.7031	loss_test: 11339.7598	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2260.2178	loss_val: 2260.2859	loss_test: 2260.2063	accuracy_train: 0.8353	accuracy_val: 0.7812	accuracy_test: 0.8485
[client 12]	loss_train: 25606.9316	loss_val: 25606.9805	loss_test: 25606.9629	accuracy_train: 0.6610	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 172240.9531	loss_val: 172240.9844	loss_test: 172241.0781	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11033.4824	loss_val: 11033.4609	loss_test: 11033.5039	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1309.3057	loss_val: 1309.3431	loss_test: 1309.3646	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6189.8643	loss_val: 6189.9287	loss_test: 6190.0273	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 11722.9678	loss_val: 11723.0059	loss_test: 11722.9365	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17860.2773	loss_val: 17860.2969	loss_test: 17860.3008	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 2033.0453	loss_val: 2033.0758	loss_test: 2033.1063	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 15	curr_val_accuracy: 0.7114	curr_test_accuracy: 0.7126
best_round: 11	best_val_accuracy: 0.7153	best_test_accuracy: 0.7162
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27030.9902	loss_val: 27030.9785	loss_test: 27030.9473	accuracy_train: 0.9320	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 46307.4570	loss_val: 46307.5039	loss_test: 46307.4883	accuracy_train: 0.7984	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 44905.1797	loss_val: 44905.3125	loss_test: 44905.2930	accuracy_train: 0.7831	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 3]	loss_train: 39228.4023	loss_val: 39228.3984	loss_test: 39228.4492	accuracy_train: 0.4811	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7471.4819	loss_val: 7471.5737	loss_test: 7471.4336	accuracy_train: 0.6824	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 11400.2520	loss_val: 11400.2852	loss_test: 11400.2725	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70713.1016	loss_val: 70712.9922	loss_test: 70712.9922	accuracy_train: 0.4059	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 7]	loss_train: 46755.5664	loss_val: 46755.5430	loss_test: 46755.5742	accuracy_train: 0.7113	accuracy_val: 0.7500	accuracy_test: 0.7027
[client 8]	loss_train: 1482.9229	loss_val: 1482.9551	loss_test: 1482.9451	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60416.4297	loss_val: 60416.5625	loss_test: 60416.4102	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11492.9727	loss_val: 11492.9209	loss_test: 11492.9766	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2400.4612	loss_val: 2400.5327	loss_test: 2400.4497	accuracy_train: 0.8235	accuracy_val: 0.7812	accuracy_test: 0.9394
[client 12]	loss_train: 26474.3594	loss_val: 26474.4102	loss_test: 26474.3926	accuracy_train: 0.6695	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 181083.3594	loss_val: 181083.3906	loss_test: 181083.4844	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11743.7979	loss_val: 11743.7764	loss_test: 11743.8184	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1379.8063	loss_val: 1379.8431	loss_test: 1379.8673	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6374.4512	loss_val: 6374.5151	loss_test: 6374.6255	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 11879.8594	loss_val: 11879.9023	loss_test: 11879.8340	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17802.8965	loss_val: 17802.9141	loss_test: 17802.9219	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 2029.3604	loss_val: 2029.3900	loss_test: 2029.4227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 16	curr_val_accuracy: 0.7174	curr_test_accuracy: 0.7244
best_round: 16	best_val_accuracy: 0.7174	best_test_accuracy: 0.7244
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28371.5508	loss_val: 28371.5449	loss_test: 28371.5098	accuracy_train: 0.9417	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 50697.9531	loss_val: 50697.9883	loss_test: 50697.9961	accuracy_train: 0.8178	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 46152.1953	loss_val: 46152.3516	loss_test: 46152.3203	accuracy_train: 0.7711	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 37774.7070	loss_val: 37774.7031	loss_test: 37774.7617	accuracy_train: 0.4780	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7719.4580	loss_val: 7719.5552	loss_test: 7719.4189	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 11206.2500	loss_val: 11206.2822	loss_test: 11206.2695	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72371.3516	loss_val: 72371.2578	loss_test: 72371.2500	accuracy_train: 0.4059	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 7]	loss_train: 48483.8477	loss_val: 48483.8320	loss_test: 48483.8633	accuracy_train: 0.7042	accuracy_val: 0.7500	accuracy_test: 0.7027
[client 8]	loss_train: 1504.4264	loss_val: 1504.4568	loss_test: 1504.4508	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62921.5664	loss_val: 62921.7266	loss_test: 62921.5508	accuracy_train: 0.8269	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11309.8057	loss_val: 11309.7549	loss_test: 11309.8086	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2535.5298	loss_val: 2535.6042	loss_test: 2535.5178	accuracy_train: 0.8196	accuracy_val: 0.7812	accuracy_test: 0.8788
[client 12]	loss_train: 27136.2500	loss_val: 27136.3066	loss_test: 27136.2871	accuracy_train: 0.6864	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 184651.9062	loss_val: 184651.9531	loss_test: 184652.0469	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12218.1465	loss_val: 12218.1201	loss_test: 12218.1582	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1444.1233	loss_val: 1444.1599	loss_test: 1444.1879	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6574.3965	loss_val: 6574.4624	loss_test: 6574.5801	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 11679.8369	loss_val: 11679.8848	loss_test: 11679.8164	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17082.8711	loss_val: 17082.8867	loss_test: 17082.9004	accuracy_train: 0.4118	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 2025.4496	loss_val: 2025.4790	loss_test: 2025.5114	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 17	curr_val_accuracy: 0.7193	curr_test_accuracy: 0.7187
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29493.3320	loss_val: 29493.3320	loss_test: 29493.2949	accuracy_train: 0.9515	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 54397.6250	loss_val: 54397.6523	loss_test: 54397.6719	accuracy_train: 0.8178	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 48087.8320	loss_val: 48088.0156	loss_test: 48087.9688	accuracy_train: 0.7711	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 36035.5820	loss_val: 36035.5703	loss_test: 36035.6328	accuracy_train: 0.4748	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7714.3936	loss_val: 7714.4966	loss_test: 7714.3633	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 10902.0566	loss_val: 10902.0898	loss_test: 10902.0752	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 73664.6875	loss_val: 73664.6016	loss_test: 73664.5938	accuracy_train: 0.4176	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 49270.6992	loss_val: 49270.6875	loss_test: 49270.7148	accuracy_train: 0.6866	accuracy_val: 0.7500	accuracy_test: 0.7027
[client 8]	loss_train: 1515.1016	loss_val: 1515.1306	loss_test: 1515.1263	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64437.7500	loss_val: 64437.9336	loss_test: 64437.7422	accuracy_train: 0.8269	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11117.1689	loss_val: 11117.1211	loss_test: 11117.1709	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2633.5508	loss_val: 2633.6277	loss_test: 2633.5366	accuracy_train: 0.8000	accuracy_val: 0.7812	accuracy_test: 0.8485
[client 12]	loss_train: 27032.8379	loss_val: 27032.9004	loss_test: 27032.8809	accuracy_train: 0.6864	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 179140.1719	loss_val: 179140.2031	loss_test: 179140.3281	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12703.1855	loss_val: 12703.1592	loss_test: 12703.1924	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1513.6650	loss_val: 1513.7013	loss_test: 1513.7318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6830.9941	loss_val: 6831.0635	loss_test: 6831.1870	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 11599.4268	loss_val: 11599.4795	loss_test: 11599.4141	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16154.8818	loss_val: 16154.8984	loss_test: 16154.9170	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1986.6970	loss_val: 1986.7255	loss_test: 1986.7570	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 18	curr_val_accuracy: 0.7193	curr_test_accuracy: 0.7187
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30831.7793	loss_val: 30831.7812	loss_test: 30831.7441	accuracy_train: 0.9515	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 48078.0938	loss_val: 48078.1133	loss_test: 48078.1445	accuracy_train: 0.8178	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 50499.8359	loss_val: 50500.0430	loss_test: 50499.9844	accuracy_train: 0.7831	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 33237.6211	loss_val: 33237.6094	loss_test: 33237.6719	accuracy_train: 0.4654	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 7695.1094	loss_val: 7695.2188	loss_test: 7695.0889	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 10822.3418	loss_val: 10822.3779	loss_test: 10822.3604	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 75127.4141	loss_val: 75127.3438	loss_test: 75127.3359	accuracy_train: 0.4294	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 48697.3320	loss_val: 48697.3281	loss_test: 48697.3516	accuracy_train: 0.6937	accuracy_val: 0.7222	accuracy_test: 0.7297
[client 8]	loss_train: 1511.5171	loss_val: 1511.5454	loss_test: 1511.5416	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66965.0234	loss_val: 66965.2500	loss_test: 66965.0312	accuracy_train: 0.8462	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11003.8145	loss_val: 11003.7666	loss_test: 11003.8154	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2739.5215	loss_val: 2739.6003	loss_test: 2739.5068	accuracy_train: 0.7765	accuracy_val: 0.7812	accuracy_test: 0.7879
[client 12]	loss_train: 27191.2363	loss_val: 27191.3047	loss_test: 27191.2871	accuracy_train: 0.6864	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 173765.6094	loss_val: 173765.6406	loss_test: 173765.7656	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12788.2832	loss_val: 12788.2598	loss_test: 12788.2871	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1573.5133	loss_val: 1573.5497	loss_test: 1573.5822	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7019.3359	loss_val: 7019.4087	loss_test: 7019.5386	accuracy_train: 0.8214	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 11521.7266	loss_val: 11521.7832	loss_test: 11521.7207	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15511.7178	loss_val: 15511.7363	loss_test: 15511.7588	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1943.2218	loss_val: 1943.2487	loss_test: 1943.2782	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 19	curr_val_accuracy: 0.7173	curr_test_accuracy: 0.7187
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31723.0527	loss_val: 31723.0566	loss_test: 31723.0215	accuracy_train: 0.9612	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 44009.4062	loss_val: 44009.4180	loss_test: 44009.4648	accuracy_train: 0.8295	accuracy_val: 0.8750	accuracy_test: 0.7647
[client 2]	loss_train: 53338.2344	loss_val: 53338.4727	loss_test: 53338.3984	accuracy_train: 0.8193	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 30344.0859	loss_val: 30344.0723	loss_test: 30344.1387	accuracy_train: 0.4497	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7954.5039	loss_val: 7954.6191	loss_test: 7954.4932	accuracy_train: 0.6294	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 10772.2061	loss_val: 10772.2451	loss_test: 10772.2256	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 75136.2266	loss_val: 75136.1641	loss_test: 75136.1562	accuracy_train: 0.4412	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 47219.1836	loss_val: 47219.1797	loss_test: 47219.2031	accuracy_train: 0.6866	accuracy_val: 0.6667	accuracy_test: 0.6757
[client 8]	loss_train: 1500.8036	loss_val: 1500.8314	loss_test: 1500.8285	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66260.4453	loss_val: 66260.7188	loss_test: 66260.4609	accuracy_train: 0.8462	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 10954.2617	loss_val: 10954.2158	loss_test: 10954.2617	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2844.5491	loss_val: 2844.6292	loss_test: 2844.5369	accuracy_train: 0.7412	accuracy_val: 0.7500	accuracy_test: 0.7879
[client 12]	loss_train: 27542.1504	loss_val: 27542.2207	loss_test: 27542.2070	accuracy_train: 0.6864	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 174380.0938	loss_val: 174380.1250	loss_test: 174380.2500	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12972.3408	loss_val: 12972.3193	loss_test: 12972.3447	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1625.6908	loss_val: 1625.7263	loss_test: 1625.7607	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7461.4106	loss_val: 7461.4917	loss_test: 7461.6265	accuracy_train: 0.8393	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 11872.9775	loss_val: 11873.0342	loss_test: 11872.9736	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14912.9033	loss_val: 14912.9248	loss_test: 14912.9531	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1899.2579	loss_val: 1899.2834	loss_test: 1899.3107	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 20	curr_val_accuracy: 0.7133	curr_test_accuracy: 0.7092
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32722.4238	loss_val: 32722.4297	loss_test: 32722.3945	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 43095.5000	loss_val: 43095.5078	loss_test: 43095.5625	accuracy_train: 0.8372	accuracy_val: 0.9062	accuracy_test: 0.7647
[client 2]	loss_train: 56627.0625	loss_val: 56627.3320	loss_test: 56627.2422	accuracy_train: 0.8313	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 28994.6973	loss_val: 28994.6836	loss_test: 28994.7520	accuracy_train: 0.4403	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 8339.3594	loss_val: 8339.4795	loss_test: 8339.3584	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 10803.2627	loss_val: 10803.3047	loss_test: 10803.2832	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 74988.8047	loss_val: 74988.7422	loss_test: 74988.7344	accuracy_train: 0.4471	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 46770.0156	loss_val: 46770.0117	loss_test: 46770.0391	accuracy_train: 0.6690	accuracy_val: 0.6667	accuracy_test: 0.6757
[client 8]	loss_train: 1506.2991	loss_val: 1506.3259	loss_test: 1506.3241	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64058.2930	loss_val: 64058.6172	loss_test: 64058.3125	accuracy_train: 0.8462	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 10904.9033	loss_val: 10904.8584	loss_test: 10904.9014	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2919.3015	loss_val: 2919.3813	loss_test: 2919.2927	accuracy_train: 0.7176	accuracy_val: 0.7188	accuracy_test: 0.7576
[client 12]	loss_train: 27558.3086	loss_val: 27558.3809	loss_test: 27558.3750	accuracy_train: 0.6949	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 173942.1562	loss_val: 173942.2031	loss_test: 173942.3438	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 13394.0059	loss_val: 13393.9873	loss_test: 13394.0107	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1668.1064	loss_val: 1668.1411	loss_test: 1668.1766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7850.2065	loss_val: 7850.2944	loss_test: 7850.4312	accuracy_train: 0.8393	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 12352.2861	loss_val: 12352.3457	loss_test: 12352.2881	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14524.0391	loss_val: 14524.0625	loss_test: 14524.0957	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1850.7543	loss_val: 1850.7786	loss_test: 1850.8046	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 21	curr_val_accuracy: 0.7132	curr_test_accuracy: 0.7072
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34344.9219	loss_val: 34344.9297	loss_test: 34344.8945	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 44213.8867	loss_val: 44213.8906	loss_test: 44213.9570	accuracy_train: 0.8295	accuracy_val: 0.9062	accuracy_test: 0.7353
[client 2]	loss_train: 59419.4492	loss_val: 59419.7422	loss_test: 59419.6484	accuracy_train: 0.8313	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 29479.7832	loss_val: 29479.7715	loss_test: 29479.8379	accuracy_train: 0.4340	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 8726.1514	loss_val: 8726.2773	loss_test: 8726.1572	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 10702.9746	loss_val: 10703.0205	loss_test: 10702.9971	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 74213.7344	loss_val: 74213.6797	loss_test: 74213.6641	accuracy_train: 0.4471	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 47518.9414	loss_val: 47518.9336	loss_test: 47518.9609	accuracy_train: 0.6620	accuracy_val: 0.6111	accuracy_test: 0.6486
[client 8]	loss_train: 1506.9083	loss_val: 1506.9336	loss_test: 1506.9330	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62508.8906	loss_val: 62509.2812	loss_test: 62508.9180	accuracy_train: 0.8462	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 10930.4082	loss_val: 10930.3633	loss_test: 10930.4053	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3013.1963	loss_val: 3013.2737	loss_test: 3013.1921	accuracy_train: 0.6863	accuracy_val: 0.6875	accuracy_test: 0.6970
[client 12]	loss_train: 27919.1973	loss_val: 27919.2715	loss_test: 27919.2754	accuracy_train: 0.6949	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 182317.1094	loss_val: 182317.1562	loss_test: 182317.2969	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 13769.4414	loss_val: 13769.4258	loss_test: 13769.4482	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1702.7979	loss_val: 1702.8319	loss_test: 1702.8676	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8033.8647	loss_val: 8033.9600	loss_test: 8034.0967	accuracy_train: 0.8393	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 12508.0996	loss_val: 12508.1602	loss_test: 12508.1055	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14258.4639	loss_val: 14258.4893	loss_test: 14258.5283	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1833.6187	loss_val: 1833.6415	loss_test: 1833.6671	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 22	curr_val_accuracy: 0.7091	curr_test_accuracy: 0.6995
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34034.4102	loss_val: 34034.4219	loss_test: 34034.3867	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 42244.0352	loss_val: 42244.0391	loss_test: 42244.1094	accuracy_train: 0.8295	accuracy_val: 0.9062	accuracy_test: 0.7353
[client 2]	loss_train: 61678.7695	loss_val: 61679.0859	loss_test: 61678.9883	accuracy_train: 0.8434	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 30131.7812	loss_val: 30131.7754	loss_test: 30131.8340	accuracy_train: 0.4465	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 8980.0186	loss_val: 8980.1533	loss_test: 8980.0342	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 10657.4766	loss_val: 10657.5264	loss_test: 10657.5020	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 74165.8906	loss_val: 74165.8438	loss_test: 74165.8281	accuracy_train: 0.4471	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 48090.6289	loss_val: 48090.6250	loss_test: 48090.6484	accuracy_train: 0.6620	accuracy_val: 0.6111	accuracy_test: 0.6486
[client 8]	loss_train: 1496.8286	loss_val: 1496.8523	loss_test: 1496.8530	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61550.1211	loss_val: 61550.5859	loss_test: 61550.1523	accuracy_train: 0.8654	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10684.8818	loss_val: 10684.8369	loss_test: 10684.8779	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3061.3684	loss_val: 3061.4436	loss_test: 3061.3716	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 29518.0176	loss_val: 29518.0938	loss_test: 29518.1074	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 199919.9531	loss_val: 199920.0000	loss_test: 199920.1406	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 13877.5947	loss_val: 13877.5811	loss_test: 13877.6055	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1704.5679	loss_val: 1704.6013	loss_test: 1704.6371	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8194.2422	loss_val: 8194.3438	loss_test: 8194.4824	accuracy_train: 0.8571	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 12914.4209	loss_val: 12914.4814	loss_test: 12914.4326	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14175.5547	loss_val: 14175.5830	loss_test: 14175.6260	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1808.0359	loss_val: 1808.0577	loss_test: 1808.0835	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 23	curr_val_accuracy: 0.7070	curr_test_accuracy: 0.6993
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33797.9609	loss_val: 33797.9727	loss_test: 33797.9375	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 40035.5117	loss_val: 40035.5117	loss_test: 40035.5938	accuracy_train: 0.8333	accuracy_val: 0.8750	accuracy_test: 0.7353
[client 2]	loss_train: 64030.3594	loss_val: 64030.7031	loss_test: 64030.6016	accuracy_train: 0.8434	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 29002.4102	loss_val: 29002.4062	loss_test: 29002.4629	accuracy_train: 0.4403	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 8766.4668	loss_val: 8766.6104	loss_test: 8766.4922	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 10379.0928	loss_val: 10379.1445	loss_test: 10379.1211	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 74299.5938	loss_val: 74299.5547	loss_test: 74299.5391	accuracy_train: 0.4471	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 47929.5703	loss_val: 47929.5703	loss_test: 47929.5898	accuracy_train: 0.6690	accuracy_val: 0.6111	accuracy_test: 0.6216
[client 8]	loss_train: 1464.0312	loss_val: 1464.0535	loss_test: 1464.0553	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63567.7695	loss_val: 63568.3320	loss_test: 63567.8047	accuracy_train: 0.8846	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10367.7021	loss_val: 10367.6553	loss_test: 10367.6973	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3075.7122	loss_val: 3075.7883	loss_test: 3075.7209	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 30798.0723	loss_val: 30798.1484	loss_test: 30798.1777	accuracy_train: 0.7034	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 198212.6094	loss_val: 198212.6562	loss_test: 198212.8125	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 13889.9863	loss_val: 13889.9746	loss_test: 13890.0010	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1700.2661	loss_val: 1700.2986	loss_test: 1700.3341	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8291.6211	loss_val: 8291.7295	loss_test: 8291.8691	accuracy_train: 0.8571	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 13054.3223	loss_val: 13054.3838	loss_test: 13054.3398	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14069.2256	loss_val: 14069.2539	loss_test: 14069.3008	accuracy_train: 0.4154	accuracy_val: 0.4706	accuracy_test: 0.4286
[client 19]	loss_train: 1783.7512	loss_val: 1783.7717	loss_test: 1783.7977	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 24	curr_val_accuracy: 0.7070	curr_test_accuracy: 0.6954
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33783.7969	loss_val: 33783.8047	loss_test: 33783.7734	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 39831.3711	loss_val: 39831.3711	loss_test: 39831.4570	accuracy_train: 0.8372	accuracy_val: 0.8750	accuracy_test: 0.7353
[client 2]	loss_train: 63802.4883	loss_val: 63802.8555	loss_test: 63802.7578	accuracy_train: 0.8554	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 28229.7871	loss_val: 28229.7832	loss_test: 28229.8379	accuracy_train: 0.4371	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 8195.3340	loss_val: 8195.4844	loss_test: 8195.3721	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 10293.7178	loss_val: 10293.7734	loss_test: 10293.7490	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 74546.0469	loss_val: 74546.0156	loss_test: 74545.9922	accuracy_train: 0.4471	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 47664.8672	loss_val: 47664.8750	loss_test: 47664.8867	accuracy_train: 0.6373	accuracy_val: 0.6111	accuracy_test: 0.5676
[client 8]	loss_train: 1451.0382	loss_val: 1451.0586	loss_test: 1451.0615	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 71714.0391	loss_val: 71714.6641	loss_test: 71714.0781	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10283.0469	loss_val: 10283.0000	loss_test: 10283.0410	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3066.6416	loss_val: 3066.7190	loss_test: 3066.6555	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 31742.6113	loss_val: 31742.6895	loss_test: 31742.7324	accuracy_train: 0.7034	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 187366.0156	loss_val: 187366.0625	loss_test: 187366.2344	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 13638.1387	loss_val: 13638.1279	loss_test: 13638.1602	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1687.4254	loss_val: 1687.4572	loss_test: 1687.4933	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8388.8389	loss_val: 8388.9561	loss_test: 8389.0957	accuracy_train: 0.8750	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 13208.2041	loss_val: 13208.2676	loss_test: 13208.2285	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13957.7852	loss_val: 13957.8154	loss_test: 13957.8633	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1767.0928	loss_val: 1767.1115	loss_test: 1767.1372	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 25	curr_val_accuracy: 0.7071	curr_test_accuracy: 0.6915
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33324.4453	loss_val: 33324.4570	loss_test: 33324.4219	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 39830.0586	loss_val: 39830.0547	loss_test: 39830.1484	accuracy_train: 0.8488	accuracy_val: 0.9062	accuracy_test: 0.7353
[client 2]	loss_train: 63262.1680	loss_val: 63262.5547	loss_test: 63262.4648	accuracy_train: 0.8554	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 27546.3926	loss_val: 27546.3906	loss_test: 27546.4414	accuracy_train: 0.4214	accuracy_val: 0.4000	accuracy_test: 0.3902
[client 4]	loss_train: 7923.0728	loss_val: 7923.2285	loss_test: 7923.1230	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 10483.0752	loss_val: 10483.1338	loss_test: 10483.1123	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 73370.1719	loss_val: 73370.1484	loss_test: 73370.1250	accuracy_train: 0.4529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 47753.1445	loss_val: 47753.1602	loss_test: 47753.1641	accuracy_train: 0.6338	accuracy_val: 0.6111	accuracy_test: 0.5676
[client 8]	loss_train: 1444.2717	loss_val: 1444.2911	loss_test: 1444.2933	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 74255.2500	loss_val: 74255.9844	loss_test: 74255.2969	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10219.0723	loss_val: 10219.0244	loss_test: 10219.0664	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3079.9314	loss_val: 3080.0098	loss_test: 3079.9502	accuracy_train: 0.6510	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 32293.9727	loss_val: 32294.0547	loss_test: 32294.1133	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 179826.0625	loss_val: 179826.1094	loss_test: 179826.2969	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 13406.6719	loss_val: 13406.6621	loss_test: 13406.6973	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1674.3213	loss_val: 1674.3522	loss_test: 1674.3899	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8519.8916	loss_val: 8520.0176	loss_test: 8520.1592	accuracy_train: 0.8750	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 13474.2754	loss_val: 13474.3418	loss_test: 13474.3066	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13329.2842	loss_val: 13329.3164	loss_test: 13329.3652	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1753.2179	loss_val: 1753.2360	loss_test: 1753.2598	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 26	curr_val_accuracy: 0.7051	curr_test_accuracy: 0.6896
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31818.7598	loss_val: 31818.7754	loss_test: 31818.7383	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 39878.4922	loss_val: 39878.4883	loss_test: 39878.5859	accuracy_train: 0.8527	accuracy_val: 0.9062	accuracy_test: 0.7353
[client 2]	loss_train: 62711.8906	loss_val: 62712.2930	loss_test: 62712.2109	accuracy_train: 0.8554	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 26542.1133	loss_val: 26542.1191	loss_test: 26542.1621	accuracy_train: 0.4182	accuracy_val: 0.4000	accuracy_test: 0.3902
[client 4]	loss_train: 7908.9844	loss_val: 7909.1440	loss_test: 7909.0464	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 9585.0869	loss_val: 9585.1484	loss_test: 9585.1270	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 71607.8594	loss_val: 71607.8438	loss_test: 71607.8125	accuracy_train: 0.4588	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 46421.1250	loss_val: 46421.1484	loss_test: 46421.1406	accuracy_train: 0.6232	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1457.7427	loss_val: 1457.7606	loss_test: 1457.7628	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 78278.2266	loss_val: 78279.0859	loss_test: 78278.2734	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10385.5391	loss_val: 10385.4883	loss_test: 10385.5332	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3089.2727	loss_val: 3089.3530	loss_test: 3089.2983	accuracy_train: 0.6510	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 33393.2344	loss_val: 33393.3164	loss_test: 33393.3906	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 173363.6250	loss_val: 173363.6875	loss_test: 173363.8750	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 13767.0469	loss_val: 13767.0361	loss_test: 13767.0703	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1660.9688	loss_val: 1660.9985	loss_test: 1661.0375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8618.4141	loss_val: 8618.5488	loss_test: 8618.6924	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 13567.9668	loss_val: 13568.0342	loss_test: 13568.0059	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12804.0049	loss_val: 12804.0391	loss_test: 12804.0850	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1729.4352	loss_val: 1729.4532	loss_test: 1729.4734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 27	curr_val_accuracy: 0.7033	curr_test_accuracy: 0.6840
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32381.9805	loss_val: 32381.9961	loss_test: 32381.9590	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 37975.1250	loss_val: 37975.1172	loss_test: 37975.2188	accuracy_train: 0.8643	accuracy_val: 0.9062	accuracy_test: 0.7353
[client 2]	loss_train: 63518.6289	loss_val: 63519.0469	loss_test: 63518.9688	accuracy_train: 0.8554	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 27489.7266	loss_val: 27489.7402	loss_test: 27489.7754	accuracy_train: 0.4119	accuracy_val: 0.4000	accuracy_test: 0.3902
[client 4]	loss_train: 7903.2754	loss_val: 7903.4434	loss_test: 7903.3467	accuracy_train: 0.6824	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 9644.0176	loss_val: 9644.0811	loss_test: 9644.0615	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 71722.8281	loss_val: 71722.8203	loss_test: 71722.7812	accuracy_train: 0.4647	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 43873.9727	loss_val: 43873.9961	loss_test: 43873.9922	accuracy_train: 0.6162	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1463.8804	loss_val: 1463.8970	loss_test: 1463.9001	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 82870.6016	loss_val: 82871.6406	loss_test: 82870.6484	accuracy_train: 0.9231	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10304.0928	loss_val: 10304.0439	loss_test: 10304.0879	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3145.5671	loss_val: 3145.6504	loss_test: 3145.6013	accuracy_train: 0.6471	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 34879.6328	loss_val: 34879.7188	loss_test: 34879.8125	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 169133.1406	loss_val: 169133.1875	loss_test: 169133.3906	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 14464.5020	loss_val: 14464.4883	loss_test: 14464.5234	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1643.2781	loss_val: 1643.3071	loss_test: 1643.3457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8800.0674	loss_val: 8800.2129	loss_test: 8800.3594	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 13649.2031	loss_val: 13649.2734	loss_test: 13649.2500	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12679.9785	loss_val: 12680.0146	loss_test: 12680.0605	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1709.5250	loss_val: 1709.5435	loss_test: 1709.5614	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 28	curr_val_accuracy: 0.7033	curr_test_accuracy: 0.6840
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31007.2188	loss_val: 31007.2383	loss_test: 31007.1992	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 36655.5898	loss_val: 36655.5820	loss_test: 36655.6836	accuracy_train: 0.8605	accuracy_val: 0.9062	accuracy_test: 0.7647
[client 2]	loss_train: 65677.5781	loss_val: 65678.0078	loss_test: 65677.9375	accuracy_train: 0.8554	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 28089.6074	loss_val: 28089.6074	loss_test: 28089.6562	accuracy_train: 0.4371	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7830.4028	loss_val: 7830.5752	loss_test: 7830.4839	accuracy_train: 0.6882	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 10180.6436	loss_val: 10180.7100	loss_test: 10180.6934	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70869.4375	loss_val: 70869.4375	loss_test: 70869.3984	accuracy_train: 0.4765	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 43076.3281	loss_val: 43076.3516	loss_test: 43076.3555	accuracy_train: 0.6127	accuracy_val: 0.6111	accuracy_test: 0.5405
[client 8]	loss_train: 1470.8676	loss_val: 1470.8834	loss_test: 1470.8873	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 85967.4609	loss_val: 85968.6875	loss_test: 85967.5156	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9718.6104	loss_val: 9718.5635	loss_test: 9718.6074	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3168.7412	loss_val: 3168.8267	loss_test: 3168.7832	accuracy_train: 0.6471	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 33932.0742	loss_val: 33932.1641	loss_test: 33932.2734	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 169509.5469	loss_val: 169509.6094	loss_test: 169509.7969	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 15076.0508	loss_val: 15076.0361	loss_test: 15076.0703	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1624.2168	loss_val: 1624.2445	loss_test: 1624.2833	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8956.8291	loss_val: 8956.9854	loss_test: 8957.1367	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 13596.1562	loss_val: 13596.2285	loss_test: 13596.2119	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13263.9062	loss_val: 13263.9424	loss_test: 13263.9883	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1686.6244	loss_val: 1686.6433	loss_test: 1686.6595	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 29	curr_val_accuracy: 0.7054	curr_test_accuracy: 0.6877
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30261.1348	loss_val: 30261.1562	loss_test: 30261.1152	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34534.7031	loss_val: 34534.6914	loss_test: 34534.7891	accuracy_train: 0.8527	accuracy_val: 0.9062	accuracy_test: 0.7647
[client 2]	loss_train: 67729.6875	loss_val: 67730.1562	loss_test: 67730.0703	accuracy_train: 0.8554	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 28952.6387	loss_val: 28952.6348	loss_test: 28952.6895	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7938.3999	loss_val: 7938.5698	loss_test: 7938.4917	accuracy_train: 0.6706	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 9925.2393	loss_val: 9925.3096	loss_test: 9925.2969	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70224.4062	loss_val: 70224.4062	loss_test: 70224.3672	accuracy_train: 0.4765	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 42697.5312	loss_val: 42697.5547	loss_test: 42697.5664	accuracy_train: 0.6127	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1472.9985	loss_val: 1473.0148	loss_test: 1473.0187	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 84275.8906	loss_val: 84277.3281	loss_test: 84275.9453	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9714.2090	loss_val: 9714.1602	loss_test: 9714.2051	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3212.8335	loss_val: 3212.9199	loss_test: 3212.8813	accuracy_train: 0.6431	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 33043.9414	loss_val: 33044.0352	loss_test: 33044.1602	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 166545.7344	loss_val: 166545.8125	loss_test: 166546.0000	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 15195.5068	loss_val: 15195.4941	loss_test: 15195.5264	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1616.8805	loss_val: 1616.9069	loss_test: 1616.9460	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9017.4707	loss_val: 9017.6367	loss_test: 9017.7939	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 13532.7656	loss_val: 13532.8389	loss_test: 13532.8291	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14010.2822	loss_val: 14010.3184	loss_test: 14010.3613	accuracy_train: 0.4154	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1664.8110	loss_val: 1664.8306	loss_test: 1664.8463	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 30	curr_val_accuracy: 0.7073	curr_test_accuracy: 0.6875
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29851.5840	loss_val: 29851.6074	loss_test: 29851.5664	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 35940.6797	loss_val: 35940.6719	loss_test: 35940.7656	accuracy_train: 0.8450	accuracy_val: 0.8750	accuracy_test: 0.7941
[client 2]	loss_train: 70559.9844	loss_val: 70560.4844	loss_test: 70560.3828	accuracy_train: 0.8554	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 30037.9883	loss_val: 30037.9824	loss_test: 30038.0391	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 8138.7188	loss_val: 8138.8838	loss_test: 8138.8203	accuracy_train: 0.6588	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 10145.0811	loss_val: 10145.1523	loss_test: 10145.1436	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70272.8281	loss_val: 70272.8281	loss_test: 70272.7891	accuracy_train: 0.4824	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 42125.9727	loss_val: 42125.9922	loss_test: 42126.0039	accuracy_train: 0.6127	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1461.3025	loss_val: 1461.3197	loss_test: 1461.3234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 80730.8047	loss_val: 80732.4844	loss_test: 80730.8672	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 10170.3848	loss_val: 10170.3340	loss_test: 10170.3799	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3229.8032	loss_val: 3229.8901	loss_test: 3229.8538	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 32212.2148	loss_val: 32212.3125	loss_test: 32212.4551	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 162004.2188	loss_val: 162004.2812	loss_test: 162004.4844	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 15262.6240	loss_val: 15262.6152	loss_test: 15262.6455	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1614.2379	loss_val: 1614.2632	loss_test: 1614.3022	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9011.7266	loss_val: 9011.9014	loss_test: 9012.0654	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 13452.9814	loss_val: 13453.0566	loss_test: 13453.0537	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14145.7139	loss_val: 14145.7500	loss_test: 14145.7910	accuracy_train: 0.4118	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1645.3964	loss_val: 1645.4154	loss_test: 1645.4316	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 31	curr_val_accuracy: 0.6973	curr_test_accuracy: 0.6857
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30853.5508	loss_val: 30853.5762	loss_test: 30853.5332	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 35759.0938	loss_val: 35759.0859	loss_test: 35759.1836	accuracy_train: 0.8178	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 72218.1953	loss_val: 72218.7188	loss_test: 72218.6094	accuracy_train: 0.8554	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 31162.3887	loss_val: 31162.3848	loss_test: 31162.4375	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 8434.7715	loss_val: 8434.9307	loss_test: 8434.8789	accuracy_train: 0.6588	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 10588.3164	loss_val: 10588.3896	loss_test: 10588.3838	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70078.1328	loss_val: 70078.1406	loss_test: 70078.1016	accuracy_train: 0.4882	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 42864.2305	loss_val: 42864.2461	loss_test: 42864.2500	accuracy_train: 0.5951	accuracy_val: 0.5833	accuracy_test: 0.4595
[client 8]	loss_train: 1446.1425	loss_val: 1446.1610	loss_test: 1446.1641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 80065.5156	loss_val: 80067.4062	loss_test: 80065.5703	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 10354.8096	loss_val: 10354.7588	loss_test: 10354.8037	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3213.4429	loss_val: 3213.5291	loss_test: 3213.4956	accuracy_train: 0.6392	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 31380.8809	loss_val: 31380.9824	loss_test: 31381.1387	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 163713.5156	loss_val: 163713.5938	loss_test: 163713.7969	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 15168.4268	loss_val: 15168.4199	loss_test: 15168.4492	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1620.6493	loss_val: 1620.6741	loss_test: 1620.7122	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9235.8135	loss_val: 9235.9980	loss_test: 9236.1699	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 14101.8428	loss_val: 14101.9160	loss_test: 14101.9170	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13276.4854	loss_val: 13276.5215	loss_test: 13276.5664	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1628.4434	loss_val: 1628.4611	loss_test: 1628.4789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 32	curr_val_accuracy: 0.6932	curr_test_accuracy: 0.6838
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31126.7246	loss_val: 31126.7539	loss_test: 31126.7070	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 35275.7773	loss_val: 35275.7695	loss_test: 35275.8672	accuracy_train: 0.8101	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 65800.6094	loss_val: 65801.1484	loss_test: 65801.0312	accuracy_train: 0.8675	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 31691.3965	loss_val: 31691.3965	loss_test: 31691.4473	accuracy_train: 0.4214	accuracy_val: 0.4250	accuracy_test: 0.3902
[client 4]	loss_train: 8407.5850	loss_val: 8407.7412	loss_test: 8407.6963	accuracy_train: 0.6529	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 11590.3643	loss_val: 11590.4355	loss_test: 11590.4355	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70221.9844	loss_val: 70222.0000	loss_test: 70221.9609	accuracy_train: 0.4882	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 41750.6328	loss_val: 41750.6484	loss_test: 41750.6484	accuracy_train: 0.5845	accuracy_val: 0.5556	accuracy_test: 0.4595
[client 8]	loss_train: 1446.7802	loss_val: 1446.7992	loss_test: 1446.8014	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 81027.5078	loss_val: 81029.6016	loss_test: 81027.5625	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9766.2246	loss_val: 9766.1729	loss_test: 9766.2178	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3177.9792	loss_val: 3178.0645	loss_test: 3178.0337	accuracy_train: 0.6392	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 30952.5352	loss_val: 30952.6406	loss_test: 30952.8125	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 164544.0469	loss_val: 164544.1250	loss_test: 164544.3281	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 14936.7402	loss_val: 14936.7363	loss_test: 14936.7637	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1629.3016	loss_val: 1629.3265	loss_test: 1629.3628	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9440.5820	loss_val: 9440.7764	loss_test: 9440.9570	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 14884.7480	loss_val: 14884.8203	loss_test: 14884.8232	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12488.6387	loss_val: 12488.6758	loss_test: 12488.7227	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1627.5807	loss_val: 1627.5968	loss_test: 1627.6156	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 33	curr_val_accuracy: 0.6893	curr_test_accuracy: 0.6818
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33225.3477	loss_val: 33225.3789	loss_test: 33225.3320	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33838.9531	loss_val: 33838.9531	loss_test: 33839.0469	accuracy_train: 0.8023	accuracy_val: 0.8125	accuracy_test: 0.7941
[client 2]	loss_train: 62155.9609	loss_val: 62156.5117	loss_test: 62156.3945	accuracy_train: 0.8675	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 29917.7305	loss_val: 29917.7344	loss_test: 29917.7793	accuracy_train: 0.4151	accuracy_val: 0.4250	accuracy_test: 0.3902
[client 4]	loss_train: 8061.9619	loss_val: 8062.1157	loss_test: 8062.0752	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 9257.3779	loss_val: 9257.4492	loss_test: 9257.4502	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 71256.4922	loss_val: 71256.5078	loss_test: 71256.4688	accuracy_train: 0.4941	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 39769.8477	loss_val: 39769.8633	loss_test: 39769.8633	accuracy_train: 0.5739	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1442.7217	loss_val: 1442.7395	loss_test: 1442.7429	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 82603.7188	loss_val: 82606.0000	loss_test: 82603.7734	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9622.6943	loss_val: 9622.6416	loss_test: 9622.6826	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3183.1584	loss_val: 3183.2449	loss_test: 3183.2170	accuracy_train: 0.6431	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 31226.5723	loss_val: 31226.6836	loss_test: 31226.8672	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 162980.8906	loss_val: 162980.9688	loss_test: 162981.1719	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 14895.2441	loss_val: 14895.2432	loss_test: 14895.2695	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1647.7687	loss_val: 1647.7938	loss_test: 1647.8285	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9468.4795	loss_val: 9468.6816	loss_test: 9468.8730	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14844.8320	loss_val: 14844.9043	loss_test: 14844.9111	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12089.1523	loss_val: 12089.1924	loss_test: 12089.2363	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1632.5673	loss_val: 1632.5819	loss_test: 1632.6016	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 34	curr_val_accuracy: 0.6893	curr_test_accuracy: 0.6839
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34281.4961	loss_val: 34281.5273	loss_test: 34281.4766	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34164.7344	loss_val: 34164.7344	loss_test: 34164.8242	accuracy_train: 0.7984	accuracy_val: 0.8125	accuracy_test: 0.7647
[client 2]	loss_train: 59041.8594	loss_val: 59042.4297	loss_test: 59042.2969	accuracy_train: 0.8795	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 28924.9004	loss_val: 28924.9062	loss_test: 28924.9492	accuracy_train: 0.4151	accuracy_val: 0.4250	accuracy_test: 0.3902
[client 4]	loss_train: 7683.0933	loss_val: 7683.2461	loss_test: 7683.2090	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 9184.7510	loss_val: 9184.8252	loss_test: 9184.8271	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 71426.9922	loss_val: 71427.0156	loss_test: 71426.9688	accuracy_train: 0.4941	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 41550.5586	loss_val: 41550.5781	loss_test: 41550.5742	accuracy_train: 0.5704	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1430.1462	loss_val: 1430.1633	loss_test: 1430.1671	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 72945.3984	loss_val: 72947.8906	loss_test: 72945.4531	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9556.6943	loss_val: 9556.6426	loss_test: 9556.6797	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3187.1504	loss_val: 3187.2410	loss_test: 3187.2166	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 32691.2754	loss_val: 32691.3965	loss_test: 32691.5938	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 156921.0625	loss_val: 156921.1406	loss_test: 156921.3281	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 14500.1035	loss_val: 14500.1055	loss_test: 14500.1309	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1651.4384	loss_val: 1651.4635	loss_test: 1651.4974	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9455.1475	loss_val: 9455.3555	loss_test: 9455.5566	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14342.5137	loss_val: 14342.5869	loss_test: 14342.5957	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12035.5283	loss_val: 12035.5742	loss_test: 12035.6123	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1625.8097	loss_val: 1625.8236	loss_test: 1625.8433	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 35	curr_val_accuracy: 0.6893	curr_test_accuracy: 0.6802
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34584.9023	loss_val: 34584.9414	loss_test: 34584.8789	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34789.9492	loss_val: 34789.9492	loss_test: 34790.0352	accuracy_train: 0.7791	accuracy_val: 0.8125	accuracy_test: 0.7647
[client 2]	loss_train: 58045.4648	loss_val: 58046.0742	loss_test: 58045.9141	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29083.6270	loss_val: 29083.6309	loss_test: 29083.6758	accuracy_train: 0.4340	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7363.9199	loss_val: 7364.0703	loss_test: 7364.0361	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 9767.6553	loss_val: 9767.7275	loss_test: 9767.7363	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 71714.1250	loss_val: 71714.1562	loss_test: 71714.1094	accuracy_train: 0.5000	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 45282.0547	loss_val: 45282.0781	loss_test: 45282.0703	accuracy_train: 0.5775	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1432.0868	loss_val: 1432.1030	loss_test: 1432.1071	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 71074.3203	loss_val: 71077.0156	loss_test: 71074.3750	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9509.1436	loss_val: 9509.0918	loss_test: 9509.1299	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3204.3833	loss_val: 3204.4773	loss_test: 3204.4553	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 33433.3984	loss_val: 33433.5312	loss_test: 33433.7344	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 149232.3438	loss_val: 149232.4219	loss_test: 149232.6094	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14290.8496	loss_val: 14290.8555	loss_test: 14290.8789	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1643.0121	loss_val: 1643.0374	loss_test: 1643.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9390.3828	loss_val: 9390.5957	loss_test: 9390.8057	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14487.7383	loss_val: 14487.8125	loss_test: 14487.8252	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12621.2705	loss_val: 12621.3232	loss_test: 12621.3594	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1615.3147	loss_val: 1615.3281	loss_test: 1615.3469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 36	curr_val_accuracy: 0.6892	curr_test_accuracy: 0.6841
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34398.3945	loss_val: 34398.4336	loss_test: 34398.3672	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 35416.4922	loss_val: 35416.4922	loss_test: 35416.5742	accuracy_train: 0.7636	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 56214.0117	loss_val: 56214.6641	loss_test: 56214.4766	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29912.5762	loss_val: 29912.5762	loss_test: 29912.6250	accuracy_train: 0.4340	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7106.6328	loss_val: 7106.7764	loss_test: 7106.7476	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 9772.8975	loss_val: 9772.9688	loss_test: 9772.9824	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72111.5078	loss_val: 72111.5391	loss_test: 72111.4844	accuracy_train: 0.4941	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 45590.9375	loss_val: 45590.9688	loss_test: 45590.9609	accuracy_train: 0.5775	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1429.2018	loss_val: 1429.2172	loss_test: 1429.2213	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 70762.7891	loss_val: 70765.6328	loss_test: 70762.8281	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9298.2686	loss_val: 9298.2188	loss_test: 9298.2598	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3205.5576	loss_val: 3205.6575	loss_test: 3205.6360	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 34816.3828	loss_val: 34816.5234	loss_test: 34816.7383	accuracy_train: 0.7119	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 142193.5625	loss_val: 142193.6250	loss_test: 142193.8281	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14037.9688	loss_val: 14037.9756	loss_test: 14037.9971	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1636.2567	loss_val: 1636.2821	loss_test: 1636.3147	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9416.7070	loss_val: 9416.9248	loss_test: 9417.1406	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14171.3018	loss_val: 14171.3760	loss_test: 14171.3906	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13807.1309	loss_val: 13807.1895	loss_test: 13807.2207	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1604.6234	loss_val: 1604.6364	loss_test: 1604.6543	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 37	curr_val_accuracy: 0.6872	curr_test_accuracy: 0.6820
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33951.7656	loss_val: 33951.8047	loss_test: 33951.7305	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 35447.9102	loss_val: 35447.9102	loss_test: 35447.9922	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 55938.2188	loss_val: 55938.9023	loss_test: 55938.6992	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 30442.5371	loss_val: 30442.5371	loss_test: 30442.5859	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6920.9810	loss_val: 6921.1191	loss_test: 6921.0938	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 9004.2451	loss_val: 9004.3164	loss_test: 9004.3340	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72400.5234	loss_val: 72400.5625	loss_test: 72400.5078	accuracy_train: 0.5000	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 44287.2578	loss_val: 44287.2930	loss_test: 44287.2891	accuracy_train: 0.5704	accuracy_val: 0.5556	accuracy_test: 0.4865
[client 8]	loss_train: 1419.8098	loss_val: 1419.8242	loss_test: 1419.8280	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 70246.0781	loss_val: 70249.0625	loss_test: 70246.1094	accuracy_train: 0.9423	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9259.0547	loss_val: 9259.0039	loss_test: 9259.0518	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3249.7815	loss_val: 3249.8862	loss_test: 3249.8630	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 33821.2539	loss_val: 33821.4102	loss_test: 33821.6328	accuracy_train: 0.7119	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 140477.4688	loss_val: 140477.5469	loss_test: 140477.7500	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 13933.9941	loss_val: 13934.0029	loss_test: 13934.0225	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1635.4440	loss_val: 1635.4689	loss_test: 1635.5015	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9406.6328	loss_val: 9406.8564	loss_test: 9407.0762	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 13946.4043	loss_val: 13946.4785	loss_test: 13946.4961	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14536.7324	loss_val: 14536.7930	loss_test: 14536.8242	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1578.7142	loss_val: 1578.7266	loss_test: 1578.7450	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 38	curr_val_accuracy: 0.6872	curr_test_accuracy: 0.6838
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34387.0156	loss_val: 34387.0547	loss_test: 34386.9766	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 35395.4805	loss_val: 35395.4805	loss_test: 35395.5586	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 56752.5547	loss_val: 56753.2578	loss_test: 56753.0469	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 30185.2129	loss_val: 30185.2148	loss_test: 30185.2598	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6845.8496	loss_val: 6845.9722	loss_test: 6845.9629	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 8841.6025	loss_val: 8841.6758	loss_test: 8841.6963	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72885.0625	loss_val: 72885.1016	loss_test: 72885.0469	accuracy_train: 0.5118	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 42703.4141	loss_val: 42703.4531	loss_test: 42703.4531	accuracy_train: 0.5739	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1415.7332	loss_val: 1415.7472	loss_test: 1415.7498	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 69369.7891	loss_val: 69372.9297	loss_test: 69369.8281	accuracy_train: 0.9231	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9528.9600	loss_val: 9528.9111	loss_test: 9528.9600	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3281.2629	loss_val: 3281.3677	loss_test: 3281.3452	accuracy_train: 0.6588	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 33129.6523	loss_val: 33129.8164	loss_test: 33130.0469	accuracy_train: 0.7288	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 139065.4844	loss_val: 139065.5625	loss_test: 139065.7656	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 13976.4160	loss_val: 13976.4268	loss_test: 13976.4463	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1621.1193	loss_val: 1621.1440	loss_test: 1621.1761	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9434.0898	loss_val: 9434.3213	loss_test: 9434.5439	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 13750.8086	loss_val: 13750.8809	loss_test: 13750.9072	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14066.8633	loss_val: 14066.9248	loss_test: 14066.9561	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1563.6989	loss_val: 1563.7106	loss_test: 1563.7297	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 39	curr_val_accuracy: 0.6891	curr_test_accuracy: 0.6857
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34541.1172	loss_val: 34541.1602	loss_test: 34541.0742	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 35360.4492	loss_val: 35360.4531	loss_test: 35360.5273	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 55021.4766	loss_val: 55022.1953	loss_test: 55021.9883	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29921.3848	loss_val: 29921.3867	loss_test: 29921.4316	accuracy_train: 0.4403	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6936.3281	loss_val: 6936.4541	loss_test: 6936.4429	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 8852.8037	loss_val: 8852.8740	loss_test: 8852.9072	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72826.5859	loss_val: 72826.6172	loss_test: 72826.5703	accuracy_train: 0.5059	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 40274.0508	loss_val: 40274.0938	loss_test: 40274.0820	accuracy_train: 0.5810	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1411.7661	loss_val: 1411.7806	loss_test: 1411.7816	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 69382.6172	loss_val: 69385.9609	loss_test: 69382.6484	accuracy_train: 0.9231	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9578.3555	loss_val: 9578.3066	loss_test: 9578.3574	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3312.6907	loss_val: 3312.7976	loss_test: 3312.7783	accuracy_train: 0.6588	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 32523.3496	loss_val: 32523.5254	loss_test: 32523.7617	accuracy_train: 0.7288	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 140625.2656	loss_val: 140625.3281	loss_test: 140625.5469	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14068.8467	loss_val: 14068.8584	loss_test: 14068.8779	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1604.3999	loss_val: 1604.4254	loss_test: 1604.4554	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9482.5586	loss_val: 9482.7949	loss_test: 9483.0195	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 13707.2080	loss_val: 13707.2754	loss_test: 13707.3125	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13919.6543	loss_val: 13919.7139	loss_test: 13919.7471	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1551.4335	loss_val: 1551.4447	loss_test: 1551.4650	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 40	curr_val_accuracy: 0.6911	curr_test_accuracy: 0.6838
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34849.9492	loss_val: 34849.9961	loss_test: 34849.9062	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 36134.0078	loss_val: 36134.0156	loss_test: 36134.0820	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 52130.5312	loss_val: 52131.2617	loss_test: 52131.0547	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29399.6191	loss_val: 29399.6211	loss_test: 29399.6680	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6952.0488	loss_val: 6952.1909	loss_test: 6952.1660	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 8934.0449	loss_val: 8934.1123	loss_test: 8934.1543	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72742.9062	loss_val: 72742.9141	loss_test: 72742.8828	accuracy_train: 0.4824	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 41092.6055	loss_val: 41092.6523	loss_test: 41092.6250	accuracy_train: 0.5845	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1403.4818	loss_val: 1403.4972	loss_test: 1403.4958	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 68168.3047	loss_val: 68171.9297	loss_test: 68168.3359	accuracy_train: 0.9615	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9446.7021	loss_val: 9446.6523	loss_test: 9446.7012	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3367.8147	loss_val: 3367.9297	loss_test: 3367.9126	accuracy_train: 0.6510	accuracy_val: 0.5625	accuracy_test: 0.5455
[client 12]	loss_train: 32477.1641	loss_val: 32477.3555	loss_test: 32477.6016	accuracy_train: 0.7373	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 146534.0781	loss_val: 146534.1562	loss_test: 146534.3594	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14160.7822	loss_val: 14160.7988	loss_test: 14160.8145	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1588.9163	loss_val: 1588.9423	loss_test: 1588.9705	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9476.4834	loss_val: 9476.7227	loss_test: 9476.9512	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 13990.7910	loss_val: 13990.8516	loss_test: 13990.9004	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13997.4150	loss_val: 13997.4736	loss_test: 13997.5078	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1542.0056	loss_val: 1542.0166	loss_test: 1542.0370	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 41	curr_val_accuracy: 0.6872	curr_test_accuracy: 0.6857
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34782.7734	loss_val: 34782.8203	loss_test: 34782.7227	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 35390.5352	loss_val: 35390.5469	loss_test: 35390.6133	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 49217.9609	loss_val: 49218.7148	loss_test: 49218.5000	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 28957.4824	loss_val: 28957.4805	loss_test: 28957.5312	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4634
[client 4]	loss_train: 6881.8979	loss_val: 6882.0532	loss_test: 6882.0156	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 8800.8467	loss_val: 8800.9111	loss_test: 8800.9570	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72307.5859	loss_val: 72307.5938	loss_test: 72307.5625	accuracy_train: 0.4765	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 43735.3633	loss_val: 43735.4141	loss_test: 43735.3750	accuracy_train: 0.5775	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1408.8933	loss_val: 1408.9091	loss_test: 1408.9060	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 67270.8359	loss_val: 67274.8047	loss_test: 67270.8750	accuracy_train: 0.9615	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9260.1777	loss_val: 9260.1279	loss_test: 9260.1738	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3441.1902	loss_val: 3441.3154	loss_test: 3441.2969	accuracy_train: 0.6471	accuracy_val: 0.5625	accuracy_test: 0.5455
[client 12]	loss_train: 32402.9688	loss_val: 32403.1777	loss_test: 32403.4336	accuracy_train: 0.7542	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 155463.3750	loss_val: 155463.4688	loss_test: 155463.6719	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14648.9131	loss_val: 14648.9365	loss_test: 14648.9443	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1569.1338	loss_val: 1569.1597	loss_test: 1569.1873	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9456.4170	loss_val: 9456.6592	loss_test: 9456.8896	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14232.5938	loss_val: 14232.6504	loss_test: 14232.7119	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13978.2891	loss_val: 13978.3467	loss_test: 13978.3789	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1540.8839	loss_val: 1540.8950	loss_test: 1540.9143	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 42	curr_val_accuracy: 0.6852	curr_test_accuracy: 0.6893
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34733.7773	loss_val: 34733.8281	loss_test: 34733.7266	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 35496.8711	loss_val: 35496.8906	loss_test: 35496.9531	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47478.6797	loss_val: 47479.4688	loss_test: 47479.2305	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29255.3262	loss_val: 29255.3223	loss_test: 29255.3770	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6703.9565	loss_val: 6704.1138	loss_test: 6704.0757	accuracy_train: 0.6647	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 8714.9160	loss_val: 8714.9814	loss_test: 8715.0254	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72509.9453	loss_val: 72509.9609	loss_test: 72509.9297	accuracy_train: 0.4765	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 46206.4414	loss_val: 46206.5000	loss_test: 46206.4531	accuracy_train: 0.5563	accuracy_val: 0.5278	accuracy_test: 0.4865
[client 8]	loss_train: 1396.8751	loss_val: 1396.8910	loss_test: 1396.8872	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 65666.4297	loss_val: 65670.7188	loss_test: 65666.4766	accuracy_train: 0.9615	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9139.1738	loss_val: 9139.1250	loss_test: 9139.1689	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3525.5059	loss_val: 3525.6379	loss_test: 3525.6167	accuracy_train: 0.6471	accuracy_val: 0.5625	accuracy_test: 0.5152
[client 12]	loss_train: 32331.2988	loss_val: 32331.5254	loss_test: 32331.7910	accuracy_train: 0.7458	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 158521.4844	loss_val: 158521.5781	loss_test: 158521.7812	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14820.1436	loss_val: 14820.1748	loss_test: 14820.1748	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1553.0516	loss_val: 1553.0774	loss_test: 1553.1051	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9477.1436	loss_val: 9477.3896	loss_test: 9477.6221	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14243.3076	loss_val: 14243.3613	loss_test: 14243.4326	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13784.8633	loss_val: 13784.9229	loss_test: 13784.9521	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1546.2251	loss_val: 1546.2366	loss_test: 1546.2543	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 43	curr_val_accuracy: 0.6872	curr_test_accuracy: 0.6835
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34462.4062	loss_val: 34462.4609	loss_test: 34462.3555	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 35262.3086	loss_val: 35262.3281	loss_test: 35262.3945	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46618.3242	loss_val: 46619.1719	loss_test: 46618.8945	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29289.9199	loss_val: 29289.9180	loss_test: 29289.9688	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6525.0933	loss_val: 6525.2427	loss_test: 6525.2134	accuracy_train: 0.6647	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 8983.9072	loss_val: 8983.9756	loss_test: 8984.0176	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 71971.3516	loss_val: 71971.3828	loss_test: 71971.3438	accuracy_train: 0.4882	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 46248.6875	loss_val: 46248.7578	loss_test: 46248.7031	accuracy_train: 0.5458	accuracy_val: 0.5278	accuracy_test: 0.4865
[client 8]	loss_train: 1388.8149	loss_val: 1388.8304	loss_test: 1388.8269	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60985.0117	loss_val: 60989.6172	loss_test: 60985.0547	accuracy_train: 0.9615	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9084.5908	loss_val: 9084.5430	loss_test: 9084.5859	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3593.5557	loss_val: 3593.6921	loss_test: 3593.6685	accuracy_train: 0.6510	accuracy_val: 0.5625	accuracy_test: 0.5152
[client 12]	loss_train: 33113.0312	loss_val: 33113.2812	loss_test: 33113.5508	accuracy_train: 0.7542	accuracy_val: 0.8000	accuracy_test: 0.5294
[client 13]	loss_train: 157166.7188	loss_val: 157166.7969	loss_test: 157167.0156	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14705.9434	loss_val: 14705.9814	loss_test: 14705.9766	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1544.5115	loss_val: 1544.5372	loss_test: 1544.5643	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9575.4990	loss_val: 9575.7520	loss_test: 9575.9863	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14569.9541	loss_val: 14570.0107	loss_test: 14570.0859	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13852.3906	loss_val: 13852.4512	loss_test: 13852.4805	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1532.8087	loss_val: 1532.8208	loss_test: 1532.8368	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 44	curr_val_accuracy: 0.6892	curr_test_accuracy: 0.6853
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34627.0586	loss_val: 34627.1172	loss_test: 34627.0117	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 34716.7734	loss_val: 34716.7930	loss_test: 34716.8516	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46614.6602	loss_val: 46615.5547	loss_test: 46615.2461	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29312.1172	loss_val: 29312.1152	loss_test: 29312.1660	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6360.5234	loss_val: 6360.6626	loss_test: 6360.6426	accuracy_train: 0.6647	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 9233.6787	loss_val: 9233.7471	loss_test: 9233.7910	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70027.0078	loss_val: 70027.0469	loss_test: 70027.0078	accuracy_train: 0.5059	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 47618.8945	loss_val: 47618.9688	loss_test: 47618.9062	accuracy_train: 0.5634	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1380.7889	loss_val: 1380.8042	loss_test: 1380.8008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59016.9297	loss_val: 59021.8672	loss_test: 59016.9805	accuracy_train: 0.9615	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9107.0020	loss_val: 9106.9531	loss_test: 9106.9971	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3679.0571	loss_val: 3679.1978	loss_test: 3679.1702	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 33804.6914	loss_val: 33804.9648	loss_test: 33805.2266	accuracy_train: 0.7712	accuracy_val: 0.8000	accuracy_test: 0.5294
[client 13]	loss_train: 159112.5781	loss_val: 159112.6562	loss_test: 159112.8750	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14601.2588	loss_val: 14601.3037	loss_test: 14601.2920	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1541.4865	loss_val: 1541.5121	loss_test: 1541.5381	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9669.2393	loss_val: 9669.4980	loss_test: 9669.7344	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14572.3799	loss_val: 14572.4385	loss_test: 14572.5186	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13877.1719	loss_val: 13877.2344	loss_test: 13877.2627	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1518.5092	loss_val: 1518.5215	loss_test: 1518.5370	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 45	curr_val_accuracy: 0.6912	curr_test_accuracy: 0.6893
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36084.9648	loss_val: 36085.0234	loss_test: 36084.9180	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 34132.3164	loss_val: 34132.3359	loss_test: 34132.3945	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46502.1328	loss_val: 46503.0781	loss_test: 46502.7266	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 27902.8145	loss_val: 27902.8125	loss_test: 27902.8633	accuracy_train: 0.4528	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6229.0278	loss_val: 6229.1582	loss_test: 6229.1484	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 9253.8506	loss_val: 9253.9141	loss_test: 9253.9600	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 69476.0078	loss_val: 69476.0547	loss_test: 69476.0078	accuracy_train: 0.5235	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 45515.0625	loss_val: 45515.1328	loss_test: 45515.0742	accuracy_train: 0.5704	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1375.8492	loss_val: 1375.8644	loss_test: 1375.8610	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57919.6875	loss_val: 57924.9062	loss_test: 57919.7344	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8801.9336	loss_val: 8801.8848	loss_test: 8801.9287	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3709.8447	loss_val: 3709.9868	loss_test: 3709.9565	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 33853.9648	loss_val: 33854.2617	loss_test: 33854.5273	accuracy_train: 0.7881	accuracy_val: 0.8000	accuracy_test: 0.5882
[client 13]	loss_train: 163926.6250	loss_val: 163926.7031	loss_test: 163926.9219	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14468.2031	loss_val: 14468.2520	loss_test: 14468.2334	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1539.6129	loss_val: 1539.6381	loss_test: 1539.6636	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9841.1289	loss_val: 9841.3936	loss_test: 9841.6309	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14782.9902	loss_val: 14783.0508	loss_test: 14783.1377	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13439.2490	loss_val: 13439.3125	loss_test: 13439.3418	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1504.2822	loss_val: 1504.2948	loss_test: 1504.3105	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 46	curr_val_accuracy: 0.6912	curr_test_accuracy: 0.6910
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 41496.1211	loss_val: 41496.1797	loss_test: 41496.0781	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 34868.9766	loss_val: 34868.9961	loss_test: 34869.0547	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45913.8047	loss_val: 45914.8008	loss_test: 45914.4102	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 27136.5547	loss_val: 27136.5527	loss_test: 27136.6035	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6216.2690	loss_val: 6216.3901	loss_test: 6216.3872	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 8850.2451	loss_val: 8850.3066	loss_test: 8850.3506	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70003.9375	loss_val: 70003.9844	loss_test: 70003.9453	accuracy_train: 0.5294	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 43961.2695	loss_val: 43961.3398	loss_test: 43961.2812	accuracy_train: 0.5704	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1383.1404	loss_val: 1383.1552	loss_test: 1383.1515	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55750.3164	loss_val: 55755.7266	loss_test: 55750.3711	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8801.5859	loss_val: 8801.5371	loss_test: 8801.5830	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3709.2383	loss_val: 3709.3777	loss_test: 3709.3530	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 34081.5977	loss_val: 34081.9180	loss_test: 34082.1797	accuracy_train: 0.8305	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 168528.1562	loss_val: 168528.2188	loss_test: 168528.4375	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14559.3477	loss_val: 14559.3945	loss_test: 14559.3730	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1535.6650	loss_val: 1535.6901	loss_test: 1535.7148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9901.8516	loss_val: 9902.1211	loss_test: 9902.3584	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15041.4766	loss_val: 15041.5332	loss_test: 15041.6270	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12662.6719	loss_val: 12662.7324	loss_test: 12662.7686	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1488.1580	loss_val: 1488.1704	loss_test: 1488.1869	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 47	curr_val_accuracy: 0.6872	curr_test_accuracy: 0.6910
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 45554.5977	loss_val: 45554.6602	loss_test: 45554.5625	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 34951.0273	loss_val: 34951.0508	loss_test: 34951.1055	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44887.8672	loss_val: 44888.9102	loss_test: 44888.4727	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 26514.2891	loss_val: 26514.2871	loss_test: 26514.3379	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4634
[client 4]	loss_train: 6385.0845	loss_val: 6385.1851	loss_test: 6385.1978	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 8996.2070	loss_val: 8996.2734	loss_test: 8996.3145	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70301.4219	loss_val: 70301.4688	loss_test: 70301.4297	accuracy_train: 0.5176	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 44665.3008	loss_val: 44665.3750	loss_test: 44665.3242	accuracy_train: 0.5634	accuracy_val: 0.5000	accuracy_test: 0.4865
[client 8]	loss_train: 1375.1812	loss_val: 1375.1956	loss_test: 1375.1924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53026.3477	loss_val: 53032.0625	loss_test: 53026.4102	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9011.1602	loss_val: 9011.1094	loss_test: 9011.1592	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3654.2068	loss_val: 3654.3423	loss_test: 3654.3281	accuracy_train: 0.6549	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 35116.6719	loss_val: 35117.0156	loss_test: 35117.2812	accuracy_train: 0.8305	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 170952.6094	loss_val: 170952.6875	loss_test: 170952.9219	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14539.8232	loss_val: 14539.8672	loss_test: 14539.8467	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1540.3287	loss_val: 1540.3533	loss_test: 1540.3781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9969.3965	loss_val: 9969.6699	loss_test: 9969.9092	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15571.8887	loss_val: 15571.9453	loss_test: 15572.0469	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11915.7578	loss_val: 11915.8174	loss_test: 11915.8604	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1487.9093	loss_val: 1487.9215	loss_test: 1487.9387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 48	curr_val_accuracy: 0.6872	curr_test_accuracy: 0.6911
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 47843.2617	loss_val: 47843.3242	loss_test: 47843.2305	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 35454.2891	loss_val: 35454.3164	loss_test: 35454.3711	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44061.1445	loss_val: 44062.2266	loss_test: 44061.7500	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 26245.3711	loss_val: 26245.3672	loss_test: 26245.4238	accuracy_train: 0.4623	accuracy_val: 0.4750	accuracy_test: 0.4634
[client 4]	loss_train: 6595.1924	loss_val: 6595.2847	loss_test: 6595.3022	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 9239.1318	loss_val: 9239.1982	loss_test: 9239.2373	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 69675.3750	loss_val: 69675.4297	loss_test: 69675.3828	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 44555.2305	loss_val: 44555.3047	loss_test: 44555.2539	accuracy_train: 0.5634	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1390.2930	loss_val: 1390.3068	loss_test: 1390.3046	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52716.7109	loss_val: 52722.6641	loss_test: 52716.7734	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9558.8945	loss_val: 9558.8457	loss_test: 9558.8975	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3591.0691	loss_val: 3591.2009	loss_test: 3591.1970	accuracy_train: 0.6588	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 35546.9062	loss_val: 35547.2773	loss_test: 35547.5430	accuracy_train: 0.8475	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 178556.7031	loss_val: 178556.7969	loss_test: 178557.0312	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14572.4043	loss_val: 14572.4482	loss_test: 14572.4277	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1542.6754	loss_val: 1542.6995	loss_test: 1542.7230	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9853.3281	loss_val: 9853.6045	loss_test: 9853.8418	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15835.6162	loss_val: 15835.6768	loss_test: 15835.7842	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11703.2842	loss_val: 11703.3467	loss_test: 11703.3906	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1489.7122	loss_val: 1489.7239	loss_test: 1489.7415	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 49	curr_val_accuracy: 0.6873	curr_test_accuracy: 0.6948
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 45573.6484	loss_val: 45573.7148	loss_test: 45573.6250	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 36128.0938	loss_val: 36128.1211	loss_test: 36128.1719	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43498.4688	loss_val: 43499.5977	loss_test: 43499.0781	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 26962.4980	loss_val: 26962.4980	loss_test: 26962.5566	accuracy_train: 0.4308	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6510.0010	loss_val: 6510.0957	loss_test: 6510.1123	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 8544.8965	loss_val: 8544.9639	loss_test: 8545.0088	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70409.3906	loss_val: 70409.4531	loss_test: 70409.3984	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 43412.3867	loss_val: 43412.4648	loss_test: 43412.4102	accuracy_train: 0.5634	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1386.3175	loss_val: 1386.3304	loss_test: 1386.3293	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53857.7383	loss_val: 53864.0117	loss_test: 53857.8008	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9588.2471	loss_val: 9588.1982	loss_test: 9588.2520	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3534.4685	loss_val: 3534.5955	loss_test: 3534.5981	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 33737.7578	loss_val: 33738.1484	loss_test: 33738.4180	accuracy_train: 0.8644	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 190403.1406	loss_val: 190403.2344	loss_test: 190403.4688	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14482.7803	loss_val: 14482.8252	loss_test: 14482.8037	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1540.3684	loss_val: 1540.3922	loss_test: 1540.4148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9745.8447	loss_val: 9746.1260	loss_test: 9746.3623	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 16452.3672	loss_val: 16452.4277	loss_test: 16452.5391	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12005.5908	loss_val: 12005.6631	loss_test: 12005.7031	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1492.9833	loss_val: 1492.9948	loss_test: 1493.0125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 50	curr_val_accuracy: 0.6873	curr_test_accuracy: 0.6909
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 43253.7539	loss_val: 43253.8203	loss_test: 43253.7344	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 36166.1133	loss_val: 36166.1484	loss_test: 36166.1953	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43751.2617	loss_val: 43752.4297	loss_test: 43751.8750	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 27639.6973	loss_val: 27639.6934	loss_test: 27639.7578	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6595.5693	loss_val: 6595.6807	loss_test: 6595.6821	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 9253.5186	loss_val: 9253.5938	loss_test: 9253.6455	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72551.4375	loss_val: 72551.5000	loss_test: 72551.4297	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 41412.4688	loss_val: 41412.5430	loss_test: 41412.4844	accuracy_train: 0.5775	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1399.0248	loss_val: 1399.0371	loss_test: 1399.0366	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58061.2031	loss_val: 58067.7812	loss_test: 58061.2695	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9658.2793	loss_val: 9658.2314	loss_test: 9658.2871	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3504.5759	loss_val: 3504.6970	loss_test: 3504.7009	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.5455
[client 12]	loss_train: 33696.3281	loss_val: 33696.7344	loss_test: 33697.0078	accuracy_train: 0.8729	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 201995.0312	loss_val: 201995.1250	loss_test: 201995.3594	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14471.7627	loss_val: 14471.8086	loss_test: 14471.7852	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1537.7727	loss_val: 1537.7964	loss_test: 1537.8184	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9676.1172	loss_val: 9676.4033	loss_test: 9676.6416	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 16596.7285	loss_val: 16596.7832	loss_test: 16596.8984	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12149.2793	loss_val: 12149.3584	loss_test: 12149.3906	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1494.0741	loss_val: 1494.0854	loss_test: 1494.1029	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 51	curr_val_accuracy: 0.6873	curr_test_accuracy: 0.6889
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 41298.8281	loss_val: 41298.8945	loss_test: 41298.8125	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 35877.2461	loss_val: 35877.2812	loss_test: 35877.3281	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44395.7344	loss_val: 44396.9414	loss_test: 44396.3516	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29869.0234	loss_val: 29869.0156	loss_test: 29869.0820	accuracy_train: 0.4465	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6661.4111	loss_val: 6661.5298	loss_test: 6661.5244	accuracy_train: 0.6647	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 9216.6631	loss_val: 9216.7412	loss_test: 9216.7969	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 73810.5391	loss_val: 73810.6094	loss_test: 73810.5391	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 40348.6484	loss_val: 40348.7227	loss_test: 40348.6680	accuracy_train: 0.5845	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1407.1582	loss_val: 1407.1705	loss_test: 1407.1700	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53743.7461	loss_val: 53750.6484	loss_test: 53743.8086	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9744.3418	loss_val: 9744.2930	loss_test: 9744.3506	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3468.2856	loss_val: 3468.4016	loss_test: 3468.4080	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 34746.1172	loss_val: 34746.5508	loss_test: 34746.8164	accuracy_train: 0.8729	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 203320.4219	loss_val: 203320.5312	loss_test: 203320.7656	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14745.3291	loss_val: 14745.3789	loss_test: 14745.3506	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1519.3738	loss_val: 1519.3976	loss_test: 1519.4191	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9544.6240	loss_val: 9544.9131	loss_test: 9545.1543	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 16665.0078	loss_val: 16665.0586	loss_test: 16665.1758	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12308.8838	loss_val: 12308.9629	loss_test: 12308.9922	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1497.0378	loss_val: 1497.0491	loss_test: 1497.0658	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 52	curr_val_accuracy: 0.6893	curr_test_accuracy: 0.6908
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 40063.3125	loss_val: 40063.3828	loss_test: 40063.3047	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34987.7930	loss_val: 34987.8320	loss_test: 34987.8789	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45266.0742	loss_val: 45267.3438	loss_test: 45266.7031	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 31041.2695	loss_val: 31041.2676	loss_test: 31041.3320	accuracy_train: 0.4623	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6527.1577	loss_val: 6527.2720	loss_test: 6527.2700	accuracy_train: 0.6471	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 9249.0674	loss_val: 9249.1465	loss_test: 9249.2041	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 74564.8359	loss_val: 74564.9141	loss_test: 74564.8281	accuracy_train: 0.5118	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 40591.4336	loss_val: 40591.5078	loss_test: 40591.4531	accuracy_train: 0.5669	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1398.5001	loss_val: 1398.5123	loss_test: 1398.5120	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52184.2227	loss_val: 52191.3125	loss_test: 52184.2852	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9668.3057	loss_val: 9668.2549	loss_test: 9668.3135	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3470.0413	loss_val: 3470.1479	loss_test: 3470.1685	accuracy_train: 0.6627	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 36708.2930	loss_val: 36708.7461	loss_test: 36709.0039	accuracy_train: 0.8729	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 198049.9375	loss_val: 198050.0469	loss_test: 198050.2812	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14969.9551	loss_val: 14970.0117	loss_test: 14969.9785	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1518.0438	loss_val: 1518.0677	loss_test: 1518.0894	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9361.2578	loss_val: 9361.5518	loss_test: 9361.7920	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15753.7900	loss_val: 15753.8379	loss_test: 15753.9551	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12219.0703	loss_val: 12219.1484	loss_test: 12219.1768	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1491.2507	loss_val: 1491.2618	loss_test: 1491.2777	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 53	curr_val_accuracy: 0.6893	curr_test_accuracy: 0.6908
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39568.5000	loss_val: 39568.5742	loss_test: 39568.5000	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34524.8320	loss_val: 34524.8711	loss_test: 34524.9102	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45107.0039	loss_val: 45108.3281	loss_test: 45107.6367	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 31439.3301	loss_val: 31439.3281	loss_test: 31439.3965	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6385.1377	loss_val: 6385.2402	loss_test: 6385.2490	accuracy_train: 0.6471	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 9081.4609	loss_val: 9081.5439	loss_test: 9081.5977	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 75249.3750	loss_val: 75249.4609	loss_test: 75249.3672	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 41966.2227	loss_val: 41966.2969	loss_test: 41966.2422	accuracy_train: 0.5810	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1392.7565	loss_val: 1392.7690	loss_test: 1392.7682	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51385.0781	loss_val: 51392.4922	loss_test: 51385.1406	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9623.6279	loss_val: 9623.5781	loss_test: 9623.6357	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3462.4460	loss_val: 3462.5437	loss_test: 3462.5842	accuracy_train: 0.6627	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 34807.8906	loss_val: 34808.3516	loss_test: 34808.6016	accuracy_train: 0.8729	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 198665.5000	loss_val: 198665.6094	loss_test: 198665.8438	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14890.4385	loss_val: 14890.5020	loss_test: 14890.4600	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1518.0067	loss_val: 1518.0305	loss_test: 1518.0518	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9168.5312	loss_val: 9168.8281	loss_test: 9169.0693	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15654.5791	loss_val: 15654.6240	loss_test: 15654.7461	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12521.8408	loss_val: 12521.9189	loss_test: 12521.9492	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1479.7722	loss_val: 1479.7831	loss_test: 1479.7983	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 54	curr_val_accuracy: 0.6873	curr_test_accuracy: 0.6888
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39394.4805	loss_val: 39394.5586	loss_test: 39394.4961	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33564.1797	loss_val: 33564.2188	loss_test: 33564.2500	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44962.0859	loss_val: 44963.4609	loss_test: 44962.7227	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 30012.9121	loss_val: 30012.9082	loss_test: 30012.9766	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6289.3828	loss_val: 6289.4590	loss_test: 6289.4922	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.7083
[client 5]	loss_train: 8949.1504	loss_val: 8949.2314	loss_test: 8949.2881	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 75742.7109	loss_val: 75742.8047	loss_test: 75742.7188	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 42358.8555	loss_val: 42358.9297	loss_test: 42358.8711	accuracy_train: 0.5915	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1379.6499	loss_val: 1379.6621	loss_test: 1379.6614	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51524.7188	loss_val: 51532.4531	loss_test: 51524.7812	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9645.4609	loss_val: 9645.4121	loss_test: 9645.4688	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3536.5173	loss_val: 3536.6108	loss_test: 3536.6636	accuracy_train: 0.6588	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 32414.0625	loss_val: 32414.5273	loss_test: 32414.7754	accuracy_train: 0.8898	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 202796.1562	loss_val: 202796.2500	loss_test: 202796.5000	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14944.3799	loss_val: 14944.4492	loss_test: 14944.3994	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1509.8739	loss_val: 1509.8975	loss_test: 1509.9188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9105.4287	loss_val: 9105.7314	loss_test: 9105.9736	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 16144.9023	loss_val: 16144.9473	loss_test: 16145.0713	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12906.7939	loss_val: 12906.8730	loss_test: 12906.9004	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1459.6436	loss_val: 1459.6543	loss_test: 1459.6685	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 55	curr_val_accuracy: 0.6893	curr_test_accuracy: 0.6908
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39124.6523	loss_val: 39124.7305	loss_test: 39124.6758	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33362.3633	loss_val: 33362.4023	loss_test: 33362.4375	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44059.5312	loss_val: 44060.9570	loss_test: 44060.1680	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 27976.9512	loss_val: 27976.9590	loss_test: 27977.0195	accuracy_train: 0.4717	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6326.2124	loss_val: 6326.2583	loss_test: 6326.3203	accuracy_train: 0.6353	accuracy_val: 0.6667	accuracy_test: 0.7083
[client 5]	loss_train: 9157.8037	loss_val: 9157.8770	loss_test: 9157.9453	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 76541.8828	loss_val: 76541.9922	loss_test: 76541.8984	accuracy_train: 0.5294	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 43133.0312	loss_val: 43133.1133	loss_test: 43133.0469	accuracy_train: 0.5775	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1374.0118	loss_val: 1374.0231	loss_test: 1374.0232	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51190.6914	loss_val: 51198.6484	loss_test: 51190.7539	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9461.8535	loss_val: 9461.8047	loss_test: 9461.8613	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3576.7039	loss_val: 3576.7979	loss_test: 3576.8503	accuracy_train: 0.6588	accuracy_val: 0.5938	accuracy_test: 0.5455
[client 12]	loss_train: 30623.2266	loss_val: 30623.7031	loss_test: 30623.9453	accuracy_train: 0.8898	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 200415.8281	loss_val: 200415.9375	loss_test: 200416.1875	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14579.1240	loss_val: 14579.2002	loss_test: 14579.1445	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1505.3680	loss_val: 1505.3911	loss_test: 1505.4125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9093.9658	loss_val: 9094.2725	loss_test: 9094.5156	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 16818.7637	loss_val: 16818.8086	loss_test: 16818.9316	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13363.8584	loss_val: 13363.9395	loss_test: 13363.9658	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1456.5802	loss_val: 1456.5908	loss_test: 1456.6041	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 56	curr_val_accuracy: 0.6934	curr_test_accuracy: 0.6908
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38791.1484	loss_val: 38791.2305	loss_test: 38791.1875	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34024.1289	loss_val: 34024.1719	loss_test: 34024.1992	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42651.8477	loss_val: 42653.3203	loss_test: 42652.4883	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 27607.3184	loss_val: 27607.3320	loss_test: 27607.3887	accuracy_train: 0.4843	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6268.6104	loss_val: 6268.6230	loss_test: 6268.7148	accuracy_train: 0.6353	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 9166.0674	loss_val: 9166.1396	loss_test: 9166.2031	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 77544.1250	loss_val: 77544.2422	loss_test: 77544.1406	accuracy_train: 0.5353	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 43918.2109	loss_val: 43918.2969	loss_test: 43918.2344	accuracy_train: 0.6127	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1367.9221	loss_val: 1367.9326	loss_test: 1367.9335	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49650.4805	loss_val: 49658.7344	loss_test: 49650.5469	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9419.4609	loss_val: 9419.4121	loss_test: 9419.4678	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3611.5066	loss_val: 3611.6038	loss_test: 3611.6453	accuracy_train: 0.6588	accuracy_val: 0.5938	accuracy_test: 0.5455
[client 12]	loss_train: 30940.2285	loss_val: 30940.7227	loss_test: 30940.9473	accuracy_train: 0.8898	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 203482.5156	loss_val: 203482.6250	loss_test: 203482.8906	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 14436.5752	loss_val: 14436.6562	loss_test: 14436.5986	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1499.6647	loss_val: 1499.6875	loss_test: 1499.7084	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9100.5166	loss_val: 9100.8291	loss_test: 9101.0723	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 17172.9766	loss_val: 17173.0176	loss_test: 17173.1406	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13616.7344	loss_val: 13616.8164	loss_test: 13616.8428	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1453.1790	loss_val: 1453.1899	loss_test: 1453.2023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 57	curr_val_accuracy: 0.6894	curr_test_accuracy: 0.6890
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39082.7266	loss_val: 39082.8086	loss_test: 39082.7812	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31406.2676	loss_val: 31406.3125	loss_test: 31406.3438	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42219.4258	loss_val: 42220.9375	loss_test: 42220.0625	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29411.5703	loss_val: 29411.5859	loss_test: 29411.6367	accuracy_train: 0.4780	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6230.0356	loss_val: 6230.0557	loss_test: 6230.1411	accuracy_train: 0.6294	accuracy_val: 0.6667	accuracy_test: 0.6250
[client 5]	loss_train: 9160.3545	loss_val: 9160.4268	loss_test: 9160.4824	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 77402.7812	loss_val: 77402.9062	loss_test: 77402.8047	accuracy_train: 0.5353	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 44109.8086	loss_val: 44109.9062	loss_test: 44109.8320	accuracy_train: 0.5880	accuracy_val: 0.5000	accuracy_test: 0.5405
[client 8]	loss_train: 1371.6532	loss_val: 1371.6635	loss_test: 1371.6647	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49425.5859	loss_val: 49434.1406	loss_test: 49425.6562	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9439.8818	loss_val: 9439.8330	loss_test: 9439.8906	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3641.9106	loss_val: 3642.0120	loss_test: 3642.0437	accuracy_train: 0.6549	accuracy_val: 0.5938	accuracy_test: 0.5455
[client 12]	loss_train: 32034.0234	loss_val: 32034.5430	loss_test: 32034.7305	accuracy_train: 0.8983	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 207605.7188	loss_val: 207605.8281	loss_test: 207606.0938	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 14233.9668	loss_val: 14234.0537	loss_test: 14233.9893	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1495.2946	loss_val: 1495.3171	loss_test: 1495.3374	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9057.2783	loss_val: 9057.5947	loss_test: 9057.8398	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 17263.2363	loss_val: 17263.2637	loss_test: 17263.3926	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13669.6416	loss_val: 13669.7266	loss_test: 13669.7520	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1455.1094	loss_val: 1455.1207	loss_test: 1455.1323	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 58	curr_val_accuracy: 0.6873	curr_test_accuracy: 0.6872
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39943.2891	loss_val: 39943.3789	loss_test: 39943.3711	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31763.3672	loss_val: 31763.4141	loss_test: 31763.4473	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41348.3242	loss_val: 41349.8828	loss_test: 41348.9648	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 30488.2676	loss_val: 30488.2832	loss_test: 30488.3242	accuracy_train: 0.4748	accuracy_val: 0.5250	accuracy_test: 0.4146
[client 4]	loss_train: 6380.6069	loss_val: 6380.6431	loss_test: 6380.7163	accuracy_train: 0.6294	accuracy_val: 0.6667	accuracy_test: 0.6250
[client 5]	loss_train: 9089.6025	loss_val: 9089.6699	loss_test: 9089.7266	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 76735.6719	loss_val: 76735.7969	loss_test: 76735.6953	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 45299.7500	loss_val: 45299.8516	loss_test: 45299.7695	accuracy_train: 0.5845	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1382.6702	loss_val: 1382.6799	loss_test: 1382.6815	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49717.7383	loss_val: 49726.5664	loss_test: 49717.8125	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9385.7920	loss_val: 9385.7432	loss_test: 9385.8018	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3658.6604	loss_val: 3658.7676	loss_test: 3658.7839	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 33438.0039	loss_val: 33438.5586	loss_test: 33438.6953	accuracy_train: 0.9068	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 206711.1875	loss_val: 206711.2812	loss_test: 206711.5625	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 14024.7305	loss_val: 14024.8262	loss_test: 14024.7510	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1495.1991	loss_val: 1495.2211	loss_test: 1495.2418	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9018.7090	loss_val: 9019.0293	loss_test: 9019.2773	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 16503.8965	loss_val: 16503.9141	loss_test: 16504.0547	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13359.0576	loss_val: 13359.1406	loss_test: 13359.1641	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1447.7352	loss_val: 1447.7469	loss_test: 1447.7578	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 59	curr_val_accuracy: 0.6934	curr_test_accuracy: 0.6872
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 40576.2852	loss_val: 40576.3789	loss_test: 40576.3789	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32731.6680	loss_val: 32731.7168	loss_test: 32731.7461	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41508.5508	loss_val: 41510.1484	loss_test: 41509.1953	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 30997.4023	loss_val: 30997.4062	loss_test: 30997.4492	accuracy_train: 0.4560	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6428.5688	loss_val: 6428.6094	loss_test: 6428.6792	accuracy_train: 0.6294	accuracy_val: 0.6667	accuracy_test: 0.6250
[client 5]	loss_train: 8879.4336	loss_val: 8879.4941	loss_test: 8879.5576	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 76259.1797	loss_val: 76259.3047	loss_test: 76259.2109	accuracy_train: 0.5647	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 43071.7070	loss_val: 43071.8086	loss_test: 43071.7305	accuracy_train: 0.5845	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1368.5608	loss_val: 1368.5703	loss_test: 1368.5724	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50867.9609	loss_val: 50876.8203	loss_test: 50868.0391	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9401.0439	loss_val: 9400.9951	loss_test: 9401.0527	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3696.0403	loss_val: 3696.1538	loss_test: 3696.1572	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.5758
[client 12]	loss_train: 33991.8711	loss_val: 33992.4688	loss_test: 33992.5352	accuracy_train: 0.8983	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 198344.3750	loss_val: 198344.4688	loss_test: 198344.7500	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 13995.0479	loss_val: 13995.1543	loss_test: 13995.0703	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1500.7571	loss_val: 1500.7784	loss_test: 1500.7994	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8948.8750	loss_val: 8949.2002	loss_test: 8949.4502	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15824.6572	loss_val: 15824.6660	loss_test: 15824.8174	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13204.0840	loss_val: 13204.1650	loss_test: 13204.1875	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1440.5021	loss_val: 1440.5138	loss_test: 1440.5243	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 60	curr_val_accuracy: 0.6954	curr_test_accuracy: 0.6891
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 40826.5898	loss_val: 40826.6836	loss_test: 40826.6992	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32764.4902	loss_val: 32764.5449	loss_test: 32764.5723	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42364.7344	loss_val: 42366.3711	loss_test: 42365.3828	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 30608.8281	loss_val: 30608.8242	loss_test: 30608.8711	accuracy_train: 0.4465	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6232.5972	loss_val: 6232.6514	loss_test: 6232.7070	accuracy_train: 0.6412	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 8217.9785	loss_val: 8218.0430	loss_test: 8218.1104	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 75293.9453	loss_val: 75294.0781	loss_test: 75293.9766	accuracy_train: 0.5941	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 50122.2617	loss_val: 50122.3594	loss_test: 50122.2891	accuracy_train: 0.5880	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1360.6825	loss_val: 1360.6923	loss_test: 1360.6943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49813.6133	loss_val: 49822.5156	loss_test: 49813.6992	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9166.4062	loss_val: 9166.3584	loss_test: 9166.4160	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3735.7583	loss_val: 3735.8784	loss_test: 3735.8777	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.5758
[client 12]	loss_train: 34309.1875	loss_val: 34309.8281	loss_test: 34309.8242	accuracy_train: 0.8983	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 191008.3438	loss_val: 191008.4375	loss_test: 191008.7188	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 14214.4473	loss_val: 14214.5635	loss_test: 14214.4717	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1502.4465	loss_val: 1502.4672	loss_test: 1502.4883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8910.5879	loss_val: 8910.9170	loss_test: 8911.1689	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15402.5068	loss_val: 15402.5107	loss_test: 15402.6680	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12698.9404	loss_val: 12699.0225	loss_test: 12699.0410	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1442.0201	loss_val: 1442.0316	loss_test: 1442.0421	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 61	curr_val_accuracy: 0.6954	curr_test_accuracy: 0.6909
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 40873.0234	loss_val: 40873.1211	loss_test: 40873.1562	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33127.2227	loss_val: 33127.2812	loss_test: 33127.3086	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42835.0000	loss_val: 42836.6836	loss_test: 42835.6484	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 29611.6406	loss_val: 29611.6367	loss_test: 29611.6855	accuracy_train: 0.4371	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6156.5464	loss_val: 6156.5806	loss_test: 6156.6519	accuracy_train: 0.6294	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 8771.5947	loss_val: 8771.6689	loss_test: 8771.7354	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 74378.6562	loss_val: 74378.8047	loss_test: 74378.6953	accuracy_train: 0.5941	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 53075.0000	loss_val: 53075.0898	loss_test: 53075.0273	accuracy_train: 0.6056	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1353.3508	loss_val: 1353.3608	loss_test: 1353.3627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49822.3438	loss_val: 49831.2188	loss_test: 49822.4297	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9088.4287	loss_val: 9088.3809	loss_test: 9088.4385	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3769.3823	loss_val: 3769.5073	loss_test: 3769.5049	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 34263.1055	loss_val: 34263.7930	loss_test: 34263.7188	accuracy_train: 0.8983	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 183897.5312	loss_val: 183897.6406	loss_test: 183897.9062	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 13848.4619	loss_val: 13848.5908	loss_test: 13848.4893	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1499.5165	loss_val: 1499.5366	loss_test: 1499.5577	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8832.6172	loss_val: 8832.9512	loss_test: 8833.2021	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15592.1553	loss_val: 15592.1543	loss_test: 15592.3135	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12238.2217	loss_val: 12238.2988	loss_test: 12238.3184	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1440.9600	loss_val: 1440.9713	loss_test: 1440.9814	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 62	curr_val_accuracy: 0.6915	curr_test_accuracy: 0.6946
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 40052.1367	loss_val: 40052.2344	loss_test: 40052.2812	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32518.9980	loss_val: 32519.0605	loss_test: 32519.0840	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43248.0273	loss_val: 43249.7461	loss_test: 43248.6836	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 29001.2559	loss_val: 29001.2520	loss_test: 29001.3027	accuracy_train: 0.4182	accuracy_val: 0.4750	accuracy_test: 0.3902
[client 4]	loss_train: 6172.0879	loss_val: 6172.1113	loss_test: 6172.1924	accuracy_train: 0.6353	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 9302.4834	loss_val: 9302.5615	loss_test: 9302.6133	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72751.8359	loss_val: 72751.9922	loss_test: 72751.8828	accuracy_train: 0.5941	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 51769.4180	loss_val: 51769.5039	loss_test: 51769.4414	accuracy_train: 0.6021	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1343.6752	loss_val: 1343.6854	loss_test: 1343.6870	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49212.2227	loss_val: 49220.9219	loss_test: 49212.3125	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9080.3506	loss_val: 9080.3037	loss_test: 9080.3594	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3860.1184	loss_val: 3860.2461	loss_test: 3860.2410	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 33538.1133	loss_val: 33538.8438	loss_test: 33538.7031	accuracy_train: 0.8983	accuracy_val: 0.6667	accuracy_test: 0.7647
[client 13]	loss_train: 182874.2188	loss_val: 182874.3281	loss_test: 182874.6094	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13884.1904	loss_val: 13884.3281	loss_test: 13884.2217	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1497.1116	loss_val: 1497.1309	loss_test: 1497.1516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8739.7100	loss_val: 8740.0459	loss_test: 8740.2949	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15650.8281	loss_val: 15650.8223	loss_test: 15650.9844	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11838.2275	loss_val: 11838.2979	loss_test: 11838.3193	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1430.1464	loss_val: 1430.1572	loss_test: 1430.1678	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 63	curr_val_accuracy: 0.6875	curr_test_accuracy: 0.6964
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38557.4219	loss_val: 38557.5234	loss_test: 38557.5781	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33036.9805	loss_val: 33037.0430	loss_test: 33037.0664	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43669.8945	loss_val: 43671.6406	loss_test: 43670.5508	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29390.1191	loss_val: 29390.1230	loss_test: 29390.1621	accuracy_train: 0.4182	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6033.6753	loss_val: 6033.7075	loss_test: 6033.7822	accuracy_train: 0.6412	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 9568.7129	loss_val: 9568.7939	loss_test: 9568.8379	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70797.3828	loss_val: 70797.5469	loss_test: 70797.4375	accuracy_train: 0.5882	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 52050.6055	loss_val: 52050.6914	loss_test: 52050.6250	accuracy_train: 0.5986	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1335.5219	loss_val: 1335.5322	loss_test: 1335.5334	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50126.0898	loss_val: 50134.6211	loss_test: 50126.1836	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8942.2285	loss_val: 8942.1787	loss_test: 8942.2363	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3904.3936	loss_val: 3904.5188	loss_test: 3904.5178	accuracy_train: 0.6431	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 32813.6250	loss_val: 32814.3984	loss_test: 32814.2031	accuracy_train: 0.9068	accuracy_val: 0.6667	accuracy_test: 0.7647
[client 13]	loss_train: 180962.0000	loss_val: 180962.1406	loss_test: 180962.4219	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 14017.1504	loss_val: 14017.2949	loss_test: 14017.1826	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1486.2097	loss_val: 1486.2289	loss_test: 1486.2479	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8750.0586	loss_val: 8750.3984	loss_test: 8750.6455	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15867.8525	loss_val: 15867.8438	loss_test: 15868.0039	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11496.9189	loss_val: 11496.9902	loss_test: 11497.0107	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1427.5199	loss_val: 1427.5303	loss_test: 1427.5414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 64	curr_val_accuracy: 0.6853	curr_test_accuracy: 0.6964
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36675.1211	loss_val: 36675.2227	loss_test: 36675.2930	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32492.2715	loss_val: 32492.3359	loss_test: 32492.3555	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42881.5977	loss_val: 42883.3672	loss_test: 42882.2617	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 29929.3652	loss_val: 29929.3711	loss_test: 29929.4004	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6239.2095	loss_val: 6239.2622	loss_test: 6239.3213	accuracy_train: 0.6412	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 10259.6689	loss_val: 10259.7510	loss_test: 10259.7930	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 69091.4219	loss_val: 69091.5859	loss_test: 69091.4766	accuracy_train: 0.5824	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 54209.9062	loss_val: 54209.9883	loss_test: 54209.9219	accuracy_train: 0.5986	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1327.6998	loss_val: 1327.7101	loss_test: 1327.7115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50757.8047	loss_val: 50766.1328	loss_test: 50757.8984	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8874.4795	loss_val: 8874.4268	loss_test: 8874.4873	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3903.2368	loss_val: 3903.3579	loss_test: 3903.3682	accuracy_train: 0.6431	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 32652.5137	loss_val: 32653.3301	loss_test: 32653.1016	accuracy_train: 0.9068	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 180407.7969	loss_val: 180407.9375	loss_test: 180408.2344	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13778.1797	loss_val: 13778.3320	loss_test: 13778.2080	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1477.8995	loss_val: 1477.9186	loss_test: 1477.9365	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8752.1748	loss_val: 8752.5215	loss_test: 8752.7666	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15758.1289	loss_val: 15758.1221	loss_test: 15758.2773	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11126.7744	loss_val: 11126.8535	loss_test: 11126.8701	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1398.0319	loss_val: 1398.0420	loss_test: 1398.0533	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 65	curr_val_accuracy: 0.6833	curr_test_accuracy: 0.6983
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34995.0742	loss_val: 34995.1797	loss_test: 34995.2656	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31844.9844	loss_val: 31845.0508	loss_test: 31845.0703	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42805.2539	loss_val: 42807.0508	loss_test: 42805.9258	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 28648.4258	loss_val: 28648.4238	loss_test: 28648.4609	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6526.8350	loss_val: 6526.8804	loss_test: 6526.9463	accuracy_train: 0.6353	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 9134.9141	loss_val: 9134.9951	loss_test: 9135.0400	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 67980.7578	loss_val: 67980.9297	loss_test: 67980.8203	accuracy_train: 0.5706	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 52046.7266	loss_val: 52046.8047	loss_test: 52046.7461	accuracy_train: 0.5986	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1311.7268	loss_val: 1311.7369	loss_test: 1311.7385	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52464.2891	loss_val: 52472.4648	loss_test: 52464.3906	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8795.6992	loss_val: 8795.6475	loss_test: 8795.7090	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3910.2888	loss_val: 3910.4041	loss_test: 3910.4292	accuracy_train: 0.6510	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 32601.3887	loss_val: 32602.2637	loss_test: 32602.0312	accuracy_train: 0.9068	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 180883.9375	loss_val: 180884.0781	loss_test: 180884.3750	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13783.6943	loss_val: 13783.8535	loss_test: 13783.7217	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1473.5490	loss_val: 1473.5679	loss_test: 1473.5847	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9214.6279	loss_val: 9214.9863	loss_test: 9215.2314	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15542.0283	loss_val: 15542.0264	loss_test: 15542.1846	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 10924.4209	loss_val: 10924.5029	loss_test: 10924.5176	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1379.1667	loss_val: 1379.1761	loss_test: 1379.1880	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 66	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6964
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33427.1914	loss_val: 33427.2969	loss_test: 33427.3945	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31645.7754	loss_val: 31645.8418	loss_test: 31645.8594	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42439.9180	loss_val: 42441.7305	loss_test: 42440.5938	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 27687.2598	loss_val: 27687.2461	loss_test: 27687.2949	accuracy_train: 0.4088	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6501.2847	loss_val: 6501.3364	loss_test: 6501.4023	accuracy_train: 0.6353	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 9105.0264	loss_val: 9105.1064	loss_test: 9105.1641	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 66448.5547	loss_val: 66448.7344	loss_test: 66448.6250	accuracy_train: 0.5706	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 48968.1562	loss_val: 48968.2383	loss_test: 48968.1758	accuracy_train: 0.5775	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1309.2876	loss_val: 1309.2977	loss_test: 1309.2992	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51769.2891	loss_val: 51777.3086	loss_test: 51769.3945	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8780.2070	loss_val: 8780.1562	loss_test: 8780.2188	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3901.1169	loss_val: 3901.2285	loss_test: 3901.2729	accuracy_train: 0.6510	accuracy_val: 0.5625	accuracy_test: 0.6667
[client 12]	loss_train: 32526.7070	loss_val: 32527.6309	loss_test: 32527.4355	accuracy_train: 0.9153	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 187841.0000	loss_val: 187841.1406	loss_test: 187841.4531	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13590.4932	loss_val: 13590.6533	loss_test: 13590.5176	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1483.8632	loss_val: 1483.8820	loss_test: 1483.8986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9575.7549	loss_val: 9576.1201	loss_test: 9576.3662	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15695.4756	loss_val: 15695.4697	loss_test: 15695.6367	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 10755.1318	loss_val: 10755.2188	loss_test: 10755.2305	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1363.4233	loss_val: 1363.4325	loss_test: 1363.4445	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 67	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6965
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32184.5430	loss_val: 32184.6504	loss_test: 32184.7637	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31763.6719	loss_val: 31763.7402	loss_test: 31763.7539	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7647
[client 2]	loss_train: 41153.7617	loss_val: 41155.6211	loss_test: 41154.4414	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 27902.6582	loss_val: 27902.6328	loss_test: 27902.6953	accuracy_train: 0.4088	accuracy_val: 0.4750	accuracy_test: 0.3902
[client 4]	loss_train: 6628.4951	loss_val: 6628.5615	loss_test: 6628.6235	accuracy_train: 0.6353	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 9380.7207	loss_val: 9380.7979	loss_test: 9380.8672	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 64437.6133	loss_val: 64437.8047	loss_test: 64437.6836	accuracy_train: 0.5824	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 44864.3594	loss_val: 44864.4492	loss_test: 44864.3711	accuracy_train: 0.5880	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1303.1714	loss_val: 1303.1814	loss_test: 1303.1826	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49580.9258	loss_val: 49588.9453	loss_test: 49581.0391	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8853.4990	loss_val: 8853.4502	loss_test: 8853.5127	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3874.2556	loss_val: 3874.3660	loss_test: 3874.4275	accuracy_train: 0.6588	accuracy_val: 0.5625	accuracy_test: 0.6667
[client 12]	loss_train: 33703.7773	loss_val: 33704.7617	loss_test: 33704.6016	accuracy_train: 0.9153	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 190171.2188	loss_val: 190171.3750	loss_test: 190171.7031	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13633.8838	loss_val: 13634.0439	loss_test: 13633.9062	accuracy_train: 0.3287	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1493.5948	loss_val: 1493.6134	loss_test: 1493.6304	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9642.0420	loss_val: 9642.4141	loss_test: 9642.6592	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15643.9082	loss_val: 15643.9023	loss_test: 15644.0801	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11041.5137	loss_val: 11041.6045	loss_test: 11041.6152	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1356.0778	loss_val: 1356.0868	loss_test: 1356.0988	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 68	curr_val_accuracy: 0.6835	curr_test_accuracy: 0.7004
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30988.2969	loss_val: 30988.4023	loss_test: 30988.5391	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32444.4590	loss_val: 32444.5332	loss_test: 32444.5312	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 40882.2539	loss_val: 40884.1562	loss_test: 40882.9414	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 27594.9395	loss_val: 27594.9238	loss_test: 27594.9844	accuracy_train: 0.4025	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6112.0327	loss_val: 6112.1450	loss_test: 6112.1816	accuracy_train: 0.6412	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8332.5967	loss_val: 8332.6865	loss_test: 8332.7412	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 63565.7930	loss_val: 63565.9961	loss_test: 63565.8594	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 40117.0156	loss_val: 40117.1094	loss_test: 40117.0234	accuracy_train: 0.5915	accuracy_val: 0.5278	accuracy_test: 0.5676
[client 8]	loss_train: 1302.2865	loss_val: 1302.2968	loss_test: 1302.2974	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48082.6094	loss_val: 48090.6211	loss_test: 48082.7266	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9013.7188	loss_val: 9013.6689	loss_test: 9013.7334	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3865.7102	loss_val: 3865.8191	loss_test: 3865.8923	accuracy_train: 0.6588	accuracy_val: 0.5312	accuracy_test: 0.6667
[client 12]	loss_train: 34689.8555	loss_val: 34690.8867	loss_test: 34690.7656	accuracy_train: 0.9153	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 189666.4375	loss_val: 189666.5781	loss_test: 189666.9375	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13493.6406	loss_val: 13493.8018	loss_test: 13493.6641	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1487.5039	loss_val: 1487.5220	loss_test: 1487.5404	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9612.5908	loss_val: 9612.9678	loss_test: 9613.2119	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15650.5615	loss_val: 15650.5576	loss_test: 15650.7471	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11387.0684	loss_val: 11387.1660	loss_test: 11387.1709	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1350.6893	loss_val: 1350.6982	loss_test: 1350.7100	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 69	curr_val_accuracy: 0.6794	curr_test_accuracy: 0.7023
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29914.8145	loss_val: 29914.9219	loss_test: 29915.0645	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34370.1250	loss_val: 34370.2109	loss_test: 34370.1953	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 40976.5977	loss_val: 40978.5430	loss_test: 40977.3086	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 27517.0312	loss_val: 27517.0215	loss_test: 27517.0820	accuracy_train: 0.4057	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6091.4888	loss_val: 6091.6509	loss_test: 6091.6621	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 8932.1572	loss_val: 8932.2520	loss_test: 8932.2969	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 61641.3945	loss_val: 61641.6133	loss_test: 61641.4609	accuracy_train: 0.5765	accuracy_val: 0.5000	accuracy_test: 0.5455
[client 7]	loss_train: 37890.8984	loss_val: 37890.9961	loss_test: 37890.9102	accuracy_train: 0.5845	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1311.1370	loss_val: 1311.1475	loss_test: 1311.1473	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48031.3477	loss_val: 48039.3555	loss_test: 48031.4648	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9132.5850	loss_val: 9132.5352	loss_test: 9132.6025	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3847.1233	loss_val: 3847.2324	loss_test: 3847.3120	accuracy_train: 0.6510	accuracy_val: 0.5625	accuracy_test: 0.6667
[client 12]	loss_train: 35228.5352	loss_val: 35229.6094	loss_test: 35229.5078	accuracy_train: 0.9237	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 188929.7812	loss_val: 188929.9219	loss_test: 188930.2969	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13633.6592	loss_val: 13633.8252	loss_test: 13633.6846	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1492.1033	loss_val: 1492.1207	loss_test: 1492.1405	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9488.5840	loss_val: 9488.9629	loss_test: 9489.2061	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15943.0176	loss_val: 15943.0156	loss_test: 15943.2139	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11628.4834	loss_val: 11628.5869	loss_test: 11628.5889	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1353.2659	loss_val: 1353.2749	loss_test: 1353.2863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 70	curr_val_accuracy: 0.6792	curr_test_accuracy: 0.7022
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29685.0801	loss_val: 29685.1875	loss_test: 29685.3359	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 36069.6484	loss_val: 36069.7344	loss_test: 36069.7188	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41749.1289	loss_val: 41751.0742	loss_test: 41749.8672	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 27503.3184	loss_val: 27503.3203	loss_test: 27503.3730	accuracy_train: 0.4088	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6083.3745	loss_val: 6083.5425	loss_test: 6083.5576	accuracy_train: 0.6706	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 9184.1523	loss_val: 9184.2354	loss_test: 9184.2734	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 59689.7812	loss_val: 59690.0117	loss_test: 59689.8555	accuracy_train: 0.5824	accuracy_val: 0.5000	accuracy_test: 0.5455
[client 7]	loss_train: 38245.9258	loss_val: 38246.0234	loss_test: 38245.9375	accuracy_train: 0.5810	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1309.7937	loss_val: 1309.8044	loss_test: 1309.8037	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43084.2461	loss_val: 43092.3281	loss_test: 43084.3672	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9126.5186	loss_val: 9126.4678	loss_test: 9126.5391	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3823.9724	loss_val: 3824.0850	loss_test: 3824.1624	accuracy_train: 0.6392	accuracy_val: 0.5625	accuracy_test: 0.6667
[client 12]	loss_train: 36491.2930	loss_val: 36492.4023	loss_test: 36492.3164	accuracy_train: 0.9407	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 188172.5625	loss_val: 188172.6875	loss_test: 188173.1094	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13736.1680	loss_val: 13736.3438	loss_test: 13736.1943	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1476.9171	loss_val: 1476.9338	loss_test: 1476.9550	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9291.4883	loss_val: 9291.8701	loss_test: 9292.1104	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 16077.8428	loss_val: 16077.8418	loss_test: 16078.0479	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11995.6553	loss_val: 11995.7607	loss_test: 11995.7617	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1358.6287	loss_val: 1358.6381	loss_test: 1358.6487	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 71	curr_val_accuracy: 0.6792	curr_test_accuracy: 0.7022
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29320.9141	loss_val: 29321.0215	loss_test: 29321.1758	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33916.0977	loss_val: 33916.1875	loss_test: 33916.1680	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42234.6602	loss_val: 42236.6250	loss_test: 42235.4258	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 27137.6094	loss_val: 27137.6211	loss_test: 27137.6699	accuracy_train: 0.4151	accuracy_val: 0.4750	accuracy_test: 0.3902
[client 4]	loss_train: 5977.7104	loss_val: 5977.8618	loss_test: 5977.8892	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 8236.6816	loss_val: 8236.7627	loss_test: 8236.8096	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 58832.6914	loss_val: 58832.9453	loss_test: 58832.7734	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 41751.0781	loss_val: 41751.1797	loss_test: 41751.0938	accuracy_train: 0.5669	accuracy_val: 0.5000	accuracy_test: 0.5405
[client 8]	loss_train: 1298.2970	loss_val: 1298.3077	loss_test: 1298.3069	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 41182.5312	loss_val: 41190.8477	loss_test: 41182.6523	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8944.9297	loss_val: 8944.8770	loss_test: 8944.9482	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3849.6948	loss_val: 3849.8115	loss_test: 3849.8823	accuracy_train: 0.6431	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 38109.2227	loss_val: 38110.3047	loss_test: 38110.2227	accuracy_train: 0.9407	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 186318.3906	loss_val: 186318.5156	loss_test: 186318.9531	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13627.8770	loss_val: 13628.0654	loss_test: 13627.9033	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1473.9562	loss_val: 1473.9722	loss_test: 1473.9946	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9134.1562	loss_val: 9134.5420	loss_test: 9134.7783	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 16082.6953	loss_val: 16082.6982	loss_test: 16082.9053	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12521.0596	loss_val: 12521.1699	loss_test: 12521.1650	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1356.5568	loss_val: 1356.5664	loss_test: 1356.5765	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 72	curr_val_accuracy: 0.6773	curr_test_accuracy: 0.6944
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29241.7012	loss_val: 29241.8105	loss_test: 29241.9707	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32497.5742	loss_val: 32497.6699	loss_test: 32497.6484	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42694.3672	loss_val: 42696.3633	loss_test: 42695.1602	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 27442.4238	loss_val: 27442.4297	loss_test: 27442.4883	accuracy_train: 0.4214	accuracy_val: 0.4750	accuracy_test: 0.3902
[client 4]	loss_train: 5915.6108	loss_val: 5915.7319	loss_test: 5915.7803	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 8506.1045	loss_val: 8506.1865	loss_test: 8506.2588	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 58892.5508	loss_val: 58892.8242	loss_test: 58892.6367	accuracy_train: 0.5647	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 44423.2969	loss_val: 44423.4023	loss_test: 44423.3164	accuracy_train: 0.5704	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1292.9728	loss_val: 1292.9830	loss_test: 1292.9824	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 40380.9648	loss_val: 40389.5977	loss_test: 40381.0898	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9041.6318	loss_val: 9041.5771	loss_test: 9041.6465	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3832.0520	loss_val: 3832.1631	loss_test: 3832.2341	accuracy_train: 0.6392	accuracy_val: 0.5625	accuracy_test: 0.5758
[client 12]	loss_train: 36308.6875	loss_val: 36309.8594	loss_test: 36309.8203	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 181109.1875	loss_val: 181109.3125	loss_test: 181109.7656	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13443.1982	loss_val: 13443.3994	loss_test: 13443.2285	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1468.0751	loss_val: 1468.0912	loss_test: 1468.1136	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9055.0352	loss_val: 9055.4258	loss_test: 9055.6621	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15888.7383	loss_val: 15888.7402	loss_test: 15888.9492	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12819.3418	loss_val: 12819.4502	loss_test: 12819.4434	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1355.1002	loss_val: 1355.1100	loss_test: 1355.1199	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 73	curr_val_accuracy: 0.6754	curr_test_accuracy: 0.6888
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29058.8770	loss_val: 29058.9883	loss_test: 29059.1562	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31126.5703	loss_val: 31126.6660	loss_test: 31126.6465	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42403.0391	loss_val: 42405.0625	loss_test: 42403.8516	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 28007.9883	loss_val: 28007.9980	loss_test: 28008.0527	accuracy_train: 0.4403	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 5886.6348	loss_val: 5886.7324	loss_test: 5886.7949	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 8854.5283	loss_val: 8854.6094	loss_test: 8854.6973	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 59926.2773	loss_val: 59926.5664	loss_test: 59926.3750	accuracy_train: 0.5588	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 44777.3789	loss_val: 44777.4883	loss_test: 44777.4023	accuracy_train: 0.5739	accuracy_val: 0.5000	accuracy_test: 0.5405
[client 8]	loss_train: 1279.6302	loss_val: 1279.6401	loss_test: 1279.6398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 39791.4297	loss_val: 39800.3359	loss_test: 39791.5547	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8753.9365	loss_val: 8753.8809	loss_test: 8753.9473	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3829.5010	loss_val: 3829.6021	loss_test: 3829.6814	accuracy_train: 0.6471	accuracy_val: 0.5625	accuracy_test: 0.5758
[client 12]	loss_train: 36909.6914	loss_val: 36910.9062	loss_test: 36910.8945	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 176368.1719	loss_val: 176368.2969	loss_test: 176368.7656	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13558.8828	loss_val: 13559.0781	loss_test: 13558.9111	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1469.6824	loss_val: 1469.6987	loss_test: 1469.7201	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9099.8301	loss_val: 9100.2256	loss_test: 9100.4639	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 16416.6113	loss_val: 16416.6094	loss_test: 16416.8301	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12905.5127	loss_val: 12905.6221	loss_test: 12905.6133	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1351.4434	loss_val: 1351.4530	loss_test: 1351.4630	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 74	curr_val_accuracy: 0.6774	curr_test_accuracy: 0.6927
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30070.6387	loss_val: 30070.7520	loss_test: 30070.9277	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30641.3320	loss_val: 30641.4316	loss_test: 30641.4082	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41785.2773	loss_val: 41787.3516	loss_test: 41786.1016	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 28077.1289	loss_val: 28077.1289	loss_test: 28077.1934	accuracy_train: 0.4591	accuracy_val: 0.4750	accuracy_test: 0.4634
[client 4]	loss_train: 6035.5640	loss_val: 6035.6406	loss_test: 6035.7144	accuracy_train: 0.6471	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8884.2520	loss_val: 8884.3330	loss_test: 8884.4160	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 60940.7969	loss_val: 60941.1016	loss_test: 60940.8984	accuracy_train: 0.5706	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 45558.8594	loss_val: 45558.9688	loss_test: 45558.8789	accuracy_train: 0.5528	accuracy_val: 0.4167	accuracy_test: 0.5135
[client 8]	loss_train: 1280.1307	loss_val: 1280.1399	loss_test: 1280.1399	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 39552.3477	loss_val: 39561.5156	loss_test: 39552.4766	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8767.0332	loss_val: 8766.9775	loss_test: 8767.0439	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3865.6379	loss_val: 3865.7366	loss_test: 3865.8169	accuracy_train: 0.6392	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 39076.6875	loss_val: 39077.9570	loss_test: 39077.9727	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 174036.9844	loss_val: 174037.1094	loss_test: 174037.6094	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13444.6826	loss_val: 13444.8682	loss_test: 13444.7100	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1469.7003	loss_val: 1469.7172	loss_test: 1469.7372	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9253.8174	loss_val: 9254.2178	loss_test: 9254.4570	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 16752.5117	loss_val: 16752.5117	loss_test: 16752.7266	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12826.1709	loss_val: 12826.2900	loss_test: 12826.2754	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1357.6267	loss_val: 1357.6362	loss_test: 1357.6460	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 75	curr_val_accuracy: 0.6735	curr_test_accuracy: 0.6966
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30559.5840	loss_val: 30559.6992	loss_test: 30559.8848	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30836.8105	loss_val: 30836.9121	loss_test: 30836.8789	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 40846.1445	loss_val: 40848.2539	loss_test: 40846.9727	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 28613.1133	loss_val: 28613.1016	loss_test: 28613.1797	accuracy_train: 0.4717	accuracy_val: 0.5000	accuracy_test: 0.4878
[client 4]	loss_train: 6421.0645	loss_val: 6421.1172	loss_test: 6421.2070	accuracy_train: 0.6412	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 7574.2168	loss_val: 7574.2871	loss_test: 7574.3833	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 62181.4023	loss_val: 62181.7305	loss_test: 62181.5117	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 46507.7305	loss_val: 46507.8320	loss_test: 46507.7500	accuracy_train: 0.5458	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1282.3348	loss_val: 1282.3433	loss_test: 1282.3439	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 39608.7773	loss_val: 39618.2031	loss_test: 39608.9062	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8674.5742	loss_val: 8674.5186	loss_test: 8674.5859	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3871.1274	loss_val: 3871.2271	loss_test: 3871.2986	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 38921.7617	loss_val: 38923.0625	loss_test: 38923.1328	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 177305.6094	loss_val: 177305.7188	loss_test: 177306.2188	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13387.3223	loss_val: 13387.4893	loss_test: 13387.3486	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1477.3895	loss_val: 1477.4071	loss_test: 1477.4250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9337.8545	loss_val: 9338.2607	loss_test: 9338.5029	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 16207.9873	loss_val: 16207.9883	loss_test: 16208.1973	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12315.0664	loss_val: 12315.1875	loss_test: 12315.1729	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1360.0956	loss_val: 1360.1051	loss_test: 1360.1141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 76	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6985
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30482.3301	loss_val: 30482.4473	loss_test: 30482.6406	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31486.5566	loss_val: 31486.6641	loss_test: 31486.6172	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 39806.4297	loss_val: 39808.5859	loss_test: 39807.2578	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 29459.5254	loss_val: 29459.5078	loss_test: 29459.5898	accuracy_train: 0.4748	accuracy_val: 0.5250	accuracy_test: 0.4878
[client 4]	loss_train: 5758.4419	loss_val: 5758.5044	loss_test: 5758.5889	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 7307.0894	loss_val: 7307.1519	loss_test: 7307.2646	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 62511.7578	loss_val: 62512.1016	loss_test: 62511.8711	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 45989.9180	loss_val: 45990.0117	loss_test: 45989.9414	accuracy_train: 0.5599	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1286.2146	loss_val: 1286.2223	loss_test: 1286.2236	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 40281.9648	loss_val: 40291.6172	loss_test: 40282.0938	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8636.7676	loss_val: 8636.7100	loss_test: 8636.7812	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3836.1853	loss_val: 3836.2861	loss_test: 3836.3455	accuracy_train: 0.6431	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 37368.5430	loss_val: 37369.8711	loss_test: 37370.0000	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 182856.0938	loss_val: 182856.2500	loss_test: 182856.7500	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13202.2451	loss_val: 13202.3955	loss_test: 13202.2725	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1474.7216	loss_val: 1474.7400	loss_test: 1474.7559	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9330.2227	loss_val: 9330.6377	loss_test: 9330.8818	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 16118.4824	loss_val: 16118.4844	loss_test: 16118.6875	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12213.9355	loss_val: 12214.0596	loss_test: 12214.0459	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1349.2151	loss_val: 1349.2245	loss_test: 1349.2330	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 77	curr_val_accuracy: 0.6835	curr_test_accuracy: 0.6985
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29822.6602	loss_val: 29822.7773	loss_test: 29822.9883	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31602.7910	loss_val: 31602.8867	loss_test: 31602.8457	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 39731.6289	loss_val: 39733.8047	loss_test: 39732.4531	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 30200.9980	loss_val: 30200.9766	loss_test: 30201.0625	accuracy_train: 0.4780	accuracy_val: 0.5500	accuracy_test: 0.4878
[client 4]	loss_train: 5590.5073	loss_val: 5590.6074	loss_test: 5590.6636	accuracy_train: 0.6529	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 7808.9180	loss_val: 7808.9858	loss_test: 7809.0996	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 62654.8320	loss_val: 62655.1797	loss_test: 62654.9492	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 45734.3281	loss_val: 45734.4219	loss_test: 45734.3555	accuracy_train: 0.5845	accuracy_val: 0.5000	accuracy_test: 0.4865
[client 8]	loss_train: 1280.7302	loss_val: 1280.7375	loss_test: 1280.7393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 40991.3359	loss_val: 41001.1055	loss_test: 40991.4688	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8446.8896	loss_val: 8446.8291	loss_test: 8446.9092	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3880.5913	loss_val: 3880.6934	loss_test: 3880.7456	accuracy_train: 0.6392	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 37016.0859	loss_val: 37017.4219	loss_test: 37017.6133	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 195402.0469	loss_val: 195402.2031	loss_test: 195402.7188	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12895.7559	loss_val: 12895.8926	loss_test: 12895.7842	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1471.0687	loss_val: 1471.0878	loss_test: 1471.1029	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9237.4492	loss_val: 9237.8721	loss_test: 9238.1172	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15866.8760	loss_val: 15866.8857	loss_test: 15867.0840	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11490.9326	loss_val: 11491.0635	loss_test: 11491.0430	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1345.4579	loss_val: 1345.4674	loss_test: 1345.4757	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 78	curr_val_accuracy: 0.6895	curr_test_accuracy: 0.6966
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30264.2461	loss_val: 30264.3672	loss_test: 30264.5918	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31051.5918	loss_val: 31051.6797	loss_test: 31051.6445	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 39288.2383	loss_val: 39290.4492	loss_test: 39289.0625	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 30368.2598	loss_val: 30368.2324	loss_test: 30368.3281	accuracy_train: 0.4937	accuracy_val: 0.5250	accuracy_test: 0.4878
[client 4]	loss_train: 5658.4209	loss_val: 5658.5308	loss_test: 5658.5854	accuracy_train: 0.6471	accuracy_val: 0.6190	accuracy_test: 0.7083
[client 5]	loss_train: 8222.3115	loss_val: 8222.3730	loss_test: 8222.4980	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 63445.3555	loss_val: 63445.6836	loss_test: 63445.4727	accuracy_train: 0.5647	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 45379.3906	loss_val: 45379.4883	loss_test: 45379.4180	accuracy_train: 0.5880	accuracy_val: 0.4722	accuracy_test: 0.4865
[client 8]	loss_train: 1282.5726	loss_val: 1282.5796	loss_test: 1282.5815	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 42217.2031	loss_val: 42227.1836	loss_test: 42217.3359	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8498.3203	loss_val: 8498.2578	loss_test: 8498.3438	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3909.7202	loss_val: 3909.8203	loss_test: 3909.8667	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 35969.6758	loss_val: 35970.9922	loss_test: 35971.2383	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 202484.8906	loss_val: 202485.0625	loss_test: 202485.5781	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12784.3916	loss_val: 12784.5234	loss_test: 12784.4160	accuracy_train: 0.3147	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1463.8029	loss_val: 1463.8220	loss_test: 1463.8378	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9259.7432	loss_val: 9260.1719	loss_test: 9260.4189	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15126.2412	loss_val: 15126.2549	loss_test: 15126.4463	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11187.5068	loss_val: 11187.6377	loss_test: 11187.6182	accuracy_train: 0.4228	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1334.3994	loss_val: 1334.4091	loss_test: 1334.4171	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 79	curr_val_accuracy: 0.6813	curr_test_accuracy: 0.6984
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31584.4766	loss_val: 31584.5977	loss_test: 31584.8379	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30865.3906	loss_val: 30865.4746	loss_test: 30865.4375	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 39294.5586	loss_val: 39296.8008	loss_test: 39295.3867	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 29293.7207	loss_val: 29293.7031	loss_test: 29293.7871	accuracy_train: 0.4686	accuracy_val: 0.5000	accuracy_test: 0.4634
[client 4]	loss_train: 5770.3091	loss_val: 5770.3770	loss_test: 5770.4722	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8743.7393	loss_val: 8743.7959	loss_test: 8743.9219	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 64038.0547	loss_val: 64038.3555	loss_test: 64038.1797	accuracy_train: 0.5647	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 44347.6445	loss_val: 44347.7461	loss_test: 44347.6641	accuracy_train: 0.5634	accuracy_val: 0.4444	accuracy_test: 0.4865
[client 8]	loss_train: 1275.4529	loss_val: 1275.4603	loss_test: 1275.4618	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43619.5742	loss_val: 43629.7227	loss_test: 43619.6992	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8757.8496	loss_val: 8757.7861	loss_test: 8757.8740	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3933.2861	loss_val: 3933.3887	loss_test: 3933.4287	accuracy_train: 0.6392	accuracy_val: 0.5625	accuracy_test: 0.5758
[client 12]	loss_train: 34209.8281	loss_val: 34211.1562	loss_test: 34211.4414	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 216492.3594	loss_val: 216492.5469	loss_test: 216493.0312	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12494.8262	loss_val: 12494.9619	loss_test: 12494.8428	accuracy_train: 0.3147	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1460.4796	loss_val: 1460.4985	loss_test: 1460.5148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9343.2764	loss_val: 9343.7100	loss_test: 9343.9580	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15017.6514	loss_val: 15017.6621	loss_test: 15017.8545	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11284.0020	loss_val: 11284.1299	loss_test: 11284.1162	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1326.0631	loss_val: 1326.0728	loss_test: 1326.0807	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 80	curr_val_accuracy: 0.6754	curr_test_accuracy: 0.6927
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32511.5645	loss_val: 32511.6855	loss_test: 32511.9375	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32138.7246	loss_val: 32138.8105	loss_test: 32138.7656	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 39540.4531	loss_val: 39542.6914	loss_test: 39541.3008	accuracy_train: 0.9759	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 29080.3027	loss_val: 29080.3184	loss_test: 29080.3652	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6076.5161	loss_val: 6076.5718	loss_test: 6076.6826	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 9086.2441	loss_val: 9086.2998	loss_test: 9086.4092	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 66369.7812	loss_val: 66370.1094	loss_test: 66369.9375	accuracy_train: 0.5824	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 43532.9727	loss_val: 43533.0859	loss_test: 43532.9844	accuracy_train: 0.5458	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1283.4935	loss_val: 1283.5012	loss_test: 1283.5024	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45571.7695	loss_val: 45582.1875	loss_test: 45571.8906	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8863.4053	loss_val: 8863.3398	loss_test: 8863.4307	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3928.7314	loss_val: 3928.8374	loss_test: 3928.8760	accuracy_train: 0.6392	accuracy_val: 0.5625	accuracy_test: 0.5758
[client 12]	loss_train: 33046.4805	loss_val: 33047.8164	loss_test: 33048.1367	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 253786.2656	loss_val: 253786.4688	loss_test: 253786.9531	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12272.3604	loss_val: 12272.5049	loss_test: 12272.3721	accuracy_train: 0.3217	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1450.0569	loss_val: 1450.0747	loss_test: 1450.0928	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9376.9121	loss_val: 9377.3516	loss_test: 9377.6006	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15065.2188	loss_val: 15065.2227	loss_test: 15065.4170	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11388.3418	loss_val: 11388.4648	loss_test: 11388.4600	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1324.1365	loss_val: 1324.1462	loss_test: 1324.1538	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 81	curr_val_accuracy: 0.6675	curr_test_accuracy: 0.6928
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34619.1016	loss_val: 34619.2266	loss_test: 34619.4961	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31189.5254	loss_val: 31189.6230	loss_test: 31189.5684	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 39321.1016	loss_val: 39323.3320	loss_test: 39321.9648	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 29356.4395	loss_val: 29356.4824	loss_test: 29356.4961	accuracy_train: 0.4277	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 6371.0127	loss_val: 6371.0728	loss_test: 6371.1860	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8420.4834	loss_val: 8420.5361	loss_test: 8420.6484	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 69831.7109	loss_val: 69832.0703	loss_test: 69831.8828	accuracy_train: 0.5588	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 43693.8281	loss_val: 43693.9531	loss_test: 43693.8320	accuracy_train: 0.5352	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1279.4799	loss_val: 1279.4875	loss_test: 1279.4888	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45987.5859	loss_val: 45998.0234	loss_test: 45987.7031	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9118.5293	loss_val: 9118.4639	loss_test: 9118.5557	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3938.1863	loss_val: 3938.2937	loss_test: 3938.3369	accuracy_train: 0.6392	accuracy_val: 0.5625	accuracy_test: 0.5758
[client 12]	loss_train: 32462.3652	loss_val: 32463.7188	loss_test: 32464.0703	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 289296.4688	loss_val: 289296.6875	loss_test: 289297.1562	accuracy_train: 0.9388	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12153.4775	loss_val: 12153.6367	loss_test: 12153.4873	accuracy_train: 0.3217	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1441.5060	loss_val: 1441.5223	loss_test: 1441.5424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9352.4258	loss_val: 9352.8691	loss_test: 9353.1172	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 14996.8613	loss_val: 14996.8730	loss_test: 14997.0703	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11377.8721	loss_val: 11377.9932	loss_test: 11377.9961	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1323.1603	loss_val: 1323.1700	loss_test: 1323.1774	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 82	curr_val_accuracy: 0.6635	curr_test_accuracy: 0.6889
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37141.0938	loss_val: 37141.2188	loss_test: 37141.5078	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31175.8438	loss_val: 31175.9492	loss_test: 31175.8945	accuracy_train: 0.7481	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 38909.7109	loss_val: 38911.9531	loss_test: 38910.5859	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 30181.5527	loss_val: 30181.6172	loss_test: 30181.6133	accuracy_train: 0.4403	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 6726.5161	loss_val: 6726.5596	loss_test: 6726.6997	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8422.1211	loss_val: 8422.1758	loss_test: 8422.2988	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70912.8750	loss_val: 70913.2109	loss_test: 70913.0547	accuracy_train: 0.5765	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 44926.6406	loss_val: 44926.7578	loss_test: 44926.6367	accuracy_train: 0.5246	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1269.2900	loss_val: 1269.2980	loss_test: 1269.2992	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46537.8477	loss_val: 46548.2578	loss_test: 46537.9648	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9121.6064	loss_val: 9121.5410	loss_test: 9121.6318	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3916.2756	loss_val: 3916.3857	loss_test: 3916.4299	accuracy_train: 0.6471	accuracy_val: 0.5625	accuracy_test: 0.5758
[client 12]	loss_train: 32122.8438	loss_val: 32124.2227	loss_test: 32124.5938	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 323980.0000	loss_val: 323980.2188	loss_test: 323980.6875	accuracy_train: 0.9388	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12129.2656	loss_val: 12129.4375	loss_test: 12129.2812	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1437.2926	loss_val: 1437.3076	loss_test: 1437.3292	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9278.2354	loss_val: 9278.6816	loss_test: 9278.9297	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15364.8438	loss_val: 15364.8604	loss_test: 15365.0566	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11601.1611	loss_val: 11601.2852	loss_test: 11601.2900	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1313.9513	loss_val: 1313.9613	loss_test: 1313.9681	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 83	curr_val_accuracy: 0.6636	curr_test_accuracy: 0.6909
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36167.2617	loss_val: 36167.3906	loss_test: 36167.6992	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32433.5430	loss_val: 32433.6543	loss_test: 32433.5957	accuracy_train: 0.7481	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 38626.0625	loss_val: 38628.3242	loss_test: 38626.9492	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 31216.6504	loss_val: 31216.6738	loss_test: 31216.7090	accuracy_train: 0.4591	accuracy_val: 0.4750	accuracy_test: 0.4634
[client 4]	loss_train: 6670.2515	loss_val: 6670.3081	loss_test: 6670.4526	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8988.6543	loss_val: 8988.7148	loss_test: 8988.8340	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70118.2578	loss_val: 70118.5781	loss_test: 70118.4297	accuracy_train: 0.5824	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 46330.0820	loss_val: 46330.1953	loss_test: 46330.0859	accuracy_train: 0.5387	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1258.2155	loss_val: 1258.2236	loss_test: 1258.2247	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46717.8164	loss_val: 46728.3984	loss_test: 46717.9375	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8821.0098	loss_val: 8820.9453	loss_test: 8821.0312	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3884.9954	loss_val: 3885.1086	loss_test: 3885.1545	accuracy_train: 0.6431	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 31651.0898	loss_val: 31652.4805	loss_test: 31652.8691	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 319303.0938	loss_val: 319303.2812	loss_test: 319303.7500	accuracy_train: 0.9388	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12197.2344	loss_val: 12197.4180	loss_test: 12197.2549	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1442.6610	loss_val: 1442.6752	loss_test: 1442.6973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9225.8477	loss_val: 9226.2979	loss_test: 9226.5449	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 15858.8418	loss_val: 15858.8633	loss_test: 15859.0576	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12058.7568	loss_val: 12058.8867	loss_test: 12058.8867	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1307.0243	loss_val: 1307.0343	loss_test: 1307.0411	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 84	curr_val_accuracy: 0.6696	curr_test_accuracy: 0.6948
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34828.6016	loss_val: 34828.7344	loss_test: 34829.0547	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32743.9062	loss_val: 32744.0254	loss_test: 32743.9668	accuracy_train: 0.7481	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 38709.2852	loss_val: 38711.5742	loss_test: 38710.1836	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 35217.2734	loss_val: 35217.2656	loss_test: 35217.3320	accuracy_train: 0.4937	accuracy_val: 0.5750	accuracy_test: 0.4878
[client 4]	loss_train: 6707.5425	loss_val: 6707.6201	loss_test: 6707.7612	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8505.1729	loss_val: 8505.2275	loss_test: 8505.3447	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 69738.7500	loss_val: 69739.0625	loss_test: 69738.9219	accuracy_train: 0.5588	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 46643.8477	loss_val: 46643.9453	loss_test: 46643.8672	accuracy_train: 0.5634	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1249.6293	loss_val: 1249.6371	loss_test: 1249.6382	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46511.5859	loss_val: 46522.0938	loss_test: 46511.7031	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8369.0625	loss_val: 8368.9990	loss_test: 8369.0820	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3892.5056	loss_val: 3892.6218	loss_test: 3892.6731	accuracy_train: 0.6471	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 31798.5586	loss_val: 31799.9590	loss_test: 31800.3457	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 303122.4375	loss_val: 303122.6250	loss_test: 303123.0938	accuracy_train: 0.9388	accuracy_val: 0.8000	accuracy_test: 0.8846
[client 14]	loss_train: 12427.2520	loss_val: 12427.4424	loss_test: 12427.2764	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1442.4673	loss_val: 1442.4810	loss_test: 1442.5031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9147.4072	loss_val: 9147.8623	loss_test: 9148.1055	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17332.1074	loss_val: 17332.1250	loss_test: 17332.3164	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12637.6689	loss_val: 12637.8096	loss_test: 12637.8047	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1303.0139	loss_val: 1303.0237	loss_test: 1303.0304	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 85	curr_val_accuracy: 0.6756	curr_test_accuracy: 0.6968
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34923.5547	loss_val: 34923.6914	loss_test: 34924.0273	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33413.4727	loss_val: 33413.5938	loss_test: 33413.5352	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 38979.3984	loss_val: 38981.7227	loss_test: 38980.3047	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 36774.6875	loss_val: 36774.6758	loss_test: 36774.7422	accuracy_train: 0.5346	accuracy_val: 0.5750	accuracy_test: 0.5122
[client 4]	loss_train: 6309.4800	loss_val: 6309.5874	loss_test: 6309.7100	accuracy_train: 0.6412	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8489.1006	loss_val: 8489.1553	loss_test: 8489.2510	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 69307.8594	loss_val: 69308.1719	loss_test: 69308.0312	accuracy_train: 0.5647	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 46412.9258	loss_val: 46413.0234	loss_test: 46412.9492	accuracy_train: 0.5563	accuracy_val: 0.4722	accuracy_test: 0.4865
[client 8]	loss_train: 1246.1903	loss_val: 1246.1979	loss_test: 1246.1990	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46190.1562	loss_val: 46200.6992	loss_test: 46190.2773	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8897.1270	loss_val: 8897.0625	loss_test: 8897.1416	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3854.1912	loss_val: 3854.3118	loss_test: 3854.3687	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 31585.3320	loss_val: 31586.7559	loss_test: 31587.1172	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 294423.0000	loss_val: 294423.1875	loss_test: 294423.6875	accuracy_train: 0.9388	accuracy_val: 0.8000	accuracy_test: 0.8846
[client 14]	loss_train: 12646.2070	loss_val: 12646.4082	loss_test: 12646.2354	accuracy_train: 0.3287	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1439.9180	loss_val: 1439.9316	loss_test: 1439.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9025.6318	loss_val: 9026.0918	loss_test: 9026.3301	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17817.0508	loss_val: 17817.0762	loss_test: 17817.2480	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13043.0332	loss_val: 13043.1797	loss_test: 13043.1660	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1291.8389	loss_val: 1291.8484	loss_test: 1291.8551	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 86	curr_val_accuracy: 0.6796	curr_test_accuracy: 0.6951
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33841.5859	loss_val: 33841.7227	loss_test: 33842.0781	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34459.0508	loss_val: 34459.1758	loss_test: 34459.1055	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 39277.1523	loss_val: 39279.5156	loss_test: 39278.0664	accuracy_train: 0.9880	accuracy_val: 0.5455	accuracy_test: 0.7273
[client 3]	loss_train: 34694.0938	loss_val: 34694.0859	loss_test: 34694.1484	accuracy_train: 0.5220	accuracy_val: 0.5750	accuracy_test: 0.4878
[client 4]	loss_train: 6179.8447	loss_val: 6179.9595	loss_test: 6180.0791	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8716.1318	loss_val: 8716.1865	loss_test: 8716.2812	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 70371.6016	loss_val: 70371.9688	loss_test: 70371.7891	accuracy_train: 0.5353	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 45170.5078	loss_val: 45170.6055	loss_test: 45170.5312	accuracy_train: 0.5634	accuracy_val: 0.5000	accuracy_test: 0.4865
[client 8]	loss_train: 1242.3879	loss_val: 1242.3953	loss_test: 1242.3966	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45965.4180	loss_val: 45976.1523	loss_test: 45965.5430	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9544.7666	loss_val: 9544.7031	loss_test: 9544.7812	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3876.2888	loss_val: 3876.4143	loss_test: 3876.4744	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 32310.8418	loss_val: 32312.3145	loss_test: 32312.6562	accuracy_train: 0.9576	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 290207.1250	loss_val: 290207.3125	loss_test: 290207.8125	accuracy_train: 0.9388	accuracy_val: 0.8000	accuracy_test: 0.8846
[client 14]	loss_train: 12682.6055	loss_val: 12682.8154	loss_test: 12682.6367	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1434.2012	loss_val: 1434.2148	loss_test: 1434.2352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8981.2734	loss_val: 8981.7383	loss_test: 8981.9746	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17770.0957	loss_val: 17770.1309	loss_test: 17770.2773	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13087.3799	loss_val: 13087.5264	loss_test: 13087.5117	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1287.3838	loss_val: 1287.3932	loss_test: 1287.3998	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 87	curr_val_accuracy: 0.6777	curr_test_accuracy: 0.6949
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35425.0078	loss_val: 35425.1445	loss_test: 35425.5156	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34341.0859	loss_val: 34341.2148	loss_test: 34341.1328	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 40369.1719	loss_val: 40371.5625	loss_test: 40370.0977	accuracy_train: 0.9880	accuracy_val: 0.5455	accuracy_test: 0.7273
[client 3]	loss_train: 31772.2676	loss_val: 31772.2676	loss_test: 31772.3223	accuracy_train: 0.5000	accuracy_val: 0.5250	accuracy_test: 0.4878
[client 4]	loss_train: 6497.5737	loss_val: 6497.7363	loss_test: 6497.8130	accuracy_train: 0.6824	accuracy_val: 0.7143	accuracy_test: 0.6250
[client 5]	loss_train: 8702.3623	loss_val: 8702.4189	loss_test: 8702.5176	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72006.6094	loss_val: 72006.9922	loss_test: 72006.8047	accuracy_train: 0.5471	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 41740.8594	loss_val: 41740.9531	loss_test: 41740.8867	accuracy_train: 0.5704	accuracy_val: 0.4722	accuracy_test: 0.4865
[client 8]	loss_train: 1231.1411	loss_val: 1231.1483	loss_test: 1231.1499	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45013.6523	loss_val: 45024.6133	loss_test: 45013.7773	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10088.7598	loss_val: 10088.6963	loss_test: 10088.7773	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3845.9102	loss_val: 3846.0308	loss_test: 3846.0969	accuracy_train: 0.6549	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 33584.4844	loss_val: 33586.0352	loss_test: 33586.3398	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 281421.9375	loss_val: 281422.1250	loss_test: 281422.6562	accuracy_train: 0.9388	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12764.1729	loss_val: 12764.3828	loss_test: 12764.2100	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1423.8093	loss_val: 1423.8232	loss_test: 1423.8425	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8942.7148	loss_val: 8943.1865	loss_test: 8943.4209	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17075.9531	loss_val: 17075.9902	loss_test: 17076.1270	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13020.5547	loss_val: 13020.6973	loss_test: 13020.6846	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1286.6560	loss_val: 1286.6652	loss_test: 1286.6719	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 88	curr_val_accuracy: 0.6818	curr_test_accuracy: 0.6931
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33829.3555	loss_val: 33829.4922	loss_test: 33829.8906	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 35313.8477	loss_val: 35313.9844	loss_test: 35313.8984	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 39964.9805	loss_val: 39967.3906	loss_test: 39965.9258	accuracy_train: 0.9880	accuracy_val: 0.5455	accuracy_test: 0.7273
[client 3]	loss_train: 30485.4180	loss_val: 30485.4219	loss_test: 30485.4727	accuracy_train: 0.4811	accuracy_val: 0.5250	accuracy_test: 0.4146
[client 4]	loss_train: 6643.0728	loss_val: 6643.2632	loss_test: 6643.3213	accuracy_train: 0.7059	accuracy_val: 0.7143	accuracy_test: 0.6250
[client 5]	loss_train: 8542.2529	loss_val: 8542.3115	loss_test: 8542.4141	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 72076.0859	loss_val: 72076.4375	loss_test: 72076.2891	accuracy_train: 0.5471	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 42180.0820	loss_val: 42180.1797	loss_test: 42180.1133	accuracy_train: 0.5810	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1228.8583	loss_val: 1228.8654	loss_test: 1228.8671	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 44708.6719	loss_val: 44719.7461	loss_test: 44708.8008	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10436.0371	loss_val: 10435.9766	loss_test: 10436.0605	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3836.8799	loss_val: 3836.9963	loss_test: 3837.0645	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 35912.2070	loss_val: 35913.8359	loss_test: 35914.0938	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 262875.1562	loss_val: 262875.3438	loss_test: 262875.8750	accuracy_train: 0.9388	accuracy_val: 0.8000	accuracy_test: 0.8846
[client 14]	loss_train: 13035.0107	loss_val: 13035.2168	loss_test: 13035.0498	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1420.0380	loss_val: 1420.0524	loss_test: 1420.0702	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8918.4336	loss_val: 8918.9111	loss_test: 8919.1426	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17393.2852	loss_val: 17393.3223	loss_test: 17393.4668	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12725.1709	loss_val: 12725.3184	loss_test: 12725.3037	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1300.7517	loss_val: 1300.7609	loss_test: 1300.7677	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 89	curr_val_accuracy: 0.6798	curr_test_accuracy: 0.6892
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 41374.0664	loss_val: 41374.2031	loss_test: 41374.6211	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34418.0703	loss_val: 34418.2070	loss_test: 34418.1250	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 40363.1211	loss_val: 40365.5781	loss_test: 40364.0781	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 29432.7598	loss_val: 29432.7734	loss_test: 29432.8184	accuracy_train: 0.4686	accuracy_val: 0.5250	accuracy_test: 0.4146
[client 4]	loss_train: 6838.0957	loss_val: 6838.2837	loss_test: 6838.3555	accuracy_train: 0.6882	accuracy_val: 0.7143	accuracy_test: 0.6667
[client 5]	loss_train: 8435.4492	loss_val: 8435.5195	loss_test: 8435.6133	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 71302.9141	loss_val: 71303.2422	loss_test: 71303.1094	accuracy_train: 0.5529	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 44920.9453	loss_val: 44921.0508	loss_test: 44920.9766	accuracy_train: 0.5810	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1231.3220	loss_val: 1231.3287	loss_test: 1231.3309	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 44618.9258	loss_val: 44630.2305	loss_test: 44619.0586	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9651.3018	loss_val: 9651.2432	loss_test: 9651.3271	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3837.4834	loss_val: 3837.6011	loss_test: 3837.6738	accuracy_train: 0.6588	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 37353.4648	loss_val: 37355.1484	loss_test: 37355.3672	accuracy_train: 0.9661	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 253275.0000	loss_val: 253275.1719	loss_test: 253275.7344	accuracy_train: 0.9388	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13162.0801	loss_val: 13162.2695	loss_test: 13162.1074	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1419.1603	loss_val: 1419.1753	loss_test: 1419.1915	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8927.7520	loss_val: 8928.2354	loss_test: 8928.4668	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17650.8047	loss_val: 17650.8379	loss_test: 17650.9922	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12152.6846	loss_val: 12152.8359	loss_test: 12152.8145	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1293.6588	loss_val: 1293.6678	loss_test: 1293.6747	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 90	curr_val_accuracy: 0.6837	curr_test_accuracy: 0.6893
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 46592.8867	loss_val: 46593.0273	loss_test: 46593.4688	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34629.2930	loss_val: 34629.4375	loss_test: 34629.3477	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 40144.8086	loss_val: 40147.3281	loss_test: 40145.7773	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 27800.5742	loss_val: 27800.5898	loss_test: 27800.6348	accuracy_train: 0.4560	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6668.5947	loss_val: 6668.7759	loss_test: 6668.8628	accuracy_train: 0.6824	accuracy_val: 0.7143	accuracy_test: 0.6667
[client 5]	loss_train: 8992.8506	loss_val: 8992.9229	loss_test: 8993.0146	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 69136.6250	loss_val: 69136.9219	loss_test: 69136.8047	accuracy_train: 0.5412	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 45556.9844	loss_val: 45557.0977	loss_test: 45557.0156	accuracy_train: 0.5669	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1231.6146	loss_val: 1231.6211	loss_test: 1231.6237	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43476.4180	loss_val: 43488.0391	loss_test: 43476.5547	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9136.3369	loss_val: 9136.2764	loss_test: 9136.3643	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3865.4539	loss_val: 3865.5737	loss_test: 3865.6565	accuracy_train: 0.6549	accuracy_val: 0.5625	accuracy_test: 0.6667
[client 12]	loss_train: 36294.5430	loss_val: 36296.2695	loss_test: 36296.4258	accuracy_train: 0.9661	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 254651.2656	loss_val: 254651.4375	loss_test: 254652.0000	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12977.2725	loss_val: 12977.4453	loss_test: 12977.2861	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1420.7115	loss_val: 1420.7272	loss_test: 1420.7421	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8919.6230	loss_val: 8920.1104	loss_test: 8920.3418	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17494.4766	loss_val: 17494.5059	loss_test: 17494.6680	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11906.5215	loss_val: 11906.6729	loss_test: 11906.6494	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1287.0974	loss_val: 1287.1063	loss_test: 1287.1132	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 91	curr_val_accuracy: 0.6777	curr_test_accuracy: 0.6913
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 47854.9492	loss_val: 47855.0859	loss_test: 47855.5469	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34626.6914	loss_val: 34626.8359	loss_test: 34626.7422	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 39792.2070	loss_val: 39794.7930	loss_test: 39793.1953	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 26920.2480	loss_val: 26920.2715	loss_test: 26920.3125	accuracy_train: 0.4560	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 6279.6797	loss_val: 6279.8340	loss_test: 6279.9404	accuracy_train: 0.6647	accuracy_val: 0.7143	accuracy_test: 0.6667
[client 5]	loss_train: 8635.4668	loss_val: 8635.5283	loss_test: 8635.6240	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 67424.7266	loss_val: 67425.0078	loss_test: 67424.8984	accuracy_train: 0.5412	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 45222.0820	loss_val: 45222.1953	loss_test: 45222.1094	accuracy_train: 0.5775	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1252.1943	loss_val: 1252.2007	loss_test: 1252.2032	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43620.5938	loss_val: 43632.4961	loss_test: 43620.7461	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9162.3672	loss_val: 9162.3037	loss_test: 9162.3945	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3912.2073	loss_val: 3912.3347	loss_test: 3912.4229	accuracy_train: 0.6471	accuracy_val: 0.5312	accuracy_test: 0.6667
[client 12]	loss_train: 35247.4375	loss_val: 35249.2344	loss_test: 35249.3086	accuracy_train: 0.9661	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 251655.7812	loss_val: 251655.9531	loss_test: 251656.5312	accuracy_train: 0.9388	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 13247.5215	loss_val: 13247.6953	loss_test: 13247.5312	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1420.5961	loss_val: 1420.6121	loss_test: 1420.6261	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8868.6475	loss_val: 8869.1377	loss_test: 8869.3682	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17245.0449	loss_val: 17245.0723	loss_test: 17245.2383	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12070.4678	loss_val: 12070.6230	loss_test: 12070.5967	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1278.0385	loss_val: 1278.0474	loss_test: 1278.0542	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 92	curr_val_accuracy: 0.6756	curr_test_accuracy: 0.6932
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 41252.0312	loss_val: 41252.1680	loss_test: 41252.6523	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34278.3477	loss_val: 34278.4961	loss_test: 34278.4102	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 39352.5977	loss_val: 39355.2383	loss_test: 39353.5977	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 26141.4766	loss_val: 26141.4980	loss_test: 26141.5410	accuracy_train: 0.4591	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5945.0444	loss_val: 5945.1807	loss_test: 5945.2930	accuracy_train: 0.6529	accuracy_val: 0.7143	accuracy_test: 0.6667
[client 5]	loss_train: 8801.7812	loss_val: 8801.8486	loss_test: 8801.9336	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 65703.5234	loss_val: 65703.8438	loss_test: 65703.6953	accuracy_train: 0.5353	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 45784.5742	loss_val: 45784.6836	loss_test: 45784.6094	accuracy_train: 0.5775	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1259.1012	loss_val: 1259.1073	loss_test: 1259.1102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 44944.7344	loss_val: 44956.7227	loss_test: 44944.8867	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8938.4014	loss_val: 8938.3311	loss_test: 8938.4268	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3927.9045	loss_val: 3928.0435	loss_test: 3928.1199	accuracy_train: 0.6392	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 40014.7227	loss_val: 40016.5508	loss_test: 40016.5586	accuracy_train: 0.9661	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 241970.4531	loss_val: 241970.6250	loss_test: 241971.2188	accuracy_train: 0.9439	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 12229.5605	loss_val: 12229.7373	loss_test: 12229.5645	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1422.5156	loss_val: 1422.5317	loss_test: 1422.5459	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8862.5977	loss_val: 8863.0898	loss_test: 8863.3213	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17661.8848	loss_val: 17661.9180	loss_test: 17662.0938	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12223.2012	loss_val: 12223.3535	loss_test: 12223.3301	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1270.3806	loss_val: 1270.3893	loss_test: 1270.3964	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 93	curr_val_accuracy: 0.6776	curr_test_accuracy: 0.6874
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38006.0430	loss_val: 38006.1836	loss_test: 38006.6875	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 35212.3086	loss_val: 35212.4531	loss_test: 35212.3711	accuracy_train: 0.7481	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 38978.6172	loss_val: 38981.3281	loss_test: 38979.6328	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 26059.6855	loss_val: 26059.6953	loss_test: 26059.7480	accuracy_train: 0.4686	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 5693.1812	loss_val: 5693.3018	loss_test: 5693.4229	accuracy_train: 0.6471	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 9458.3105	loss_val: 9458.3887	loss_test: 9458.4561	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 64577.9492	loss_val: 64578.2930	loss_test: 64578.1133	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 45886.6211	loss_val: 45886.7266	loss_test: 45886.6562	accuracy_train: 0.5528	accuracy_val: 0.4444	accuracy_test: 0.4595
[client 8]	loss_train: 1257.0325	loss_val: 1257.0389	loss_test: 1257.0417	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45223.0508	loss_val: 45235.2930	loss_test: 45223.2070	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9015.3994	loss_val: 9015.3252	loss_test: 9015.4268	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3969.7766	loss_val: 3969.9287	loss_test: 3969.9812	accuracy_train: 0.6235	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 47454.6992	loss_val: 47456.5430	loss_test: 47456.4805	accuracy_train: 0.9661	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 236916.2969	loss_val: 236916.4688	loss_test: 236917.0781	accuracy_train: 0.9439	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 11336.3457	loss_val: 11336.5244	loss_test: 11336.3428	accuracy_train: 0.3497	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1417.5342	loss_val: 1417.5504	loss_test: 1417.5648	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8850.0693	loss_val: 8850.5664	loss_test: 8850.7979	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17107.1191	loss_val: 17107.1621	loss_test: 17107.3340	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12404.4121	loss_val: 12404.5576	loss_test: 12404.5371	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1267.5592	loss_val: 1267.5679	loss_test: 1267.5748	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 94	curr_val_accuracy: 0.6795	curr_test_accuracy: 0.6854
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36976.3594	loss_val: 36976.4961	loss_test: 36977.0156	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 35246.2539	loss_val: 35246.4023	loss_test: 35246.3242	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 38534.4727	loss_val: 38537.2305	loss_test: 38535.4961	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 26228.6738	loss_val: 26228.6777	loss_test: 26228.7344	accuracy_train: 0.4717	accuracy_val: 0.5250	accuracy_test: 0.4634
[client 4]	loss_train: 5502.3936	loss_val: 5502.5103	loss_test: 5502.6353	accuracy_train: 0.6471	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 9385.7305	loss_val: 9385.8018	loss_test: 9385.8604	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 64476.0977	loss_val: 64476.4531	loss_test: 64476.2539	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 45751.6016	loss_val: 45751.7070	loss_test: 45751.6367	accuracy_train: 0.5493	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1259.9006	loss_val: 1259.9075	loss_test: 1259.9098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 44470.7344	loss_val: 44483.1523	loss_test: 44470.8906	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9254.4678	loss_val: 9254.3945	loss_test: 9254.4980	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4008.9829	loss_val: 4009.1467	loss_test: 4009.1738	accuracy_train: 0.6196	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 44913.4648	loss_val: 44915.2812	loss_test: 44915.1758	accuracy_train: 0.9661	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 238530.5000	loss_val: 238530.6719	loss_test: 238531.2969	accuracy_train: 0.9439	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 11066.2900	loss_val: 11066.4678	loss_test: 11066.2783	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1417.9589	loss_val: 1417.9752	loss_test: 1417.9901	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8784.5322	loss_val: 8785.0322	loss_test: 8785.2637	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17085.3750	loss_val: 17085.4238	loss_test: 17085.5977	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12282.4863	loss_val: 12282.6289	loss_test: 12282.6162	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1261.0399	loss_val: 1261.0483	loss_test: 1261.0554	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 95	curr_val_accuracy: 0.6775	curr_test_accuracy: 0.6893
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36036.3203	loss_val: 36036.4570	loss_test: 36037.0000	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34321.0977	loss_val: 34321.2461	loss_test: 34321.1680	accuracy_train: 0.7481	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 38039.3477	loss_val: 38042.1719	loss_test: 38040.3867	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 27599.6035	loss_val: 27599.6230	loss_test: 27599.6680	accuracy_train: 0.5660	accuracy_val: 0.5500	accuracy_test: 0.5366
[client 4]	loss_train: 5452.7310	loss_val: 5452.8291	loss_test: 5452.9790	accuracy_train: 0.6529	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 7763.0493	loss_val: 7763.0977	loss_test: 7763.1782	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 64700.7344	loss_val: 64701.0742	loss_test: 64700.8828	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 43462.6602	loss_val: 43462.7656	loss_test: 43462.6953	accuracy_train: 0.5528	accuracy_val: 0.3889	accuracy_test: 0.5135
[client 8]	loss_train: 1260.8864	loss_val: 1260.8936	loss_test: 1260.8951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45738.1367	loss_val: 45750.6250	loss_test: 45738.3008	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9370.9678	loss_val: 9370.8965	loss_test: 9370.9971	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4022.3328	loss_val: 4022.5063	loss_test: 4022.5134	accuracy_train: 0.6235	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 45652.6172	loss_val: 45654.4375	loss_test: 45654.2891	accuracy_train: 0.9661	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 229702.7344	loss_val: 229702.9219	loss_test: 229703.5469	accuracy_train: 0.9439	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 11127.9082	loss_val: 11128.0771	loss_test: 11127.8848	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1421.0205	loss_val: 1421.0369	loss_test: 1421.0525	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8791.7559	loss_val: 8792.2598	loss_test: 8792.4912	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17139.1152	loss_val: 17139.1621	loss_test: 17139.3418	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11814.5967	loss_val: 11814.7363	loss_test: 11814.7236	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1254.0333	loss_val: 1254.0415	loss_test: 1254.0486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 96	curr_val_accuracy: 0.6776	curr_test_accuracy: 0.6972
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33885.7266	loss_val: 33885.8633	loss_test: 33886.4297	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33823.3125	loss_val: 33823.4648	loss_test: 33823.3789	accuracy_train: 0.7558	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 39337.0391	loss_val: 39339.9023	loss_test: 39338.0977	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 25307.9551	loss_val: 25307.9805	loss_test: 25308.0449	accuracy_train: 0.6667	accuracy_val: 0.5750	accuracy_test: 0.6341
[client 4]	loss_train: 5637.4146	loss_val: 5637.4785	loss_test: 5637.6704	accuracy_train: 0.6529	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 8080.0195	loss_val: 8080.0571	loss_test: 8080.1660	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 65361.3320	loss_val: 65361.6680	loss_test: 65361.4844	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 40703.9336	loss_val: 40704.0469	loss_test: 40703.9688	accuracy_train: 0.5528	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1251.0001	loss_val: 1251.0077	loss_test: 1251.0087	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46357.0039	loss_val: 46369.6016	loss_test: 46357.1680	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9129.1914	loss_val: 9129.1172	loss_test: 9129.2227	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4022.0767	loss_val: 4022.2559	loss_test: 4022.2515	accuracy_train: 0.6314	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 46270.8672	loss_val: 46272.6953	loss_test: 46272.5078	accuracy_train: 0.9661	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 227200.1562	loss_val: 227200.3438	loss_test: 227200.9531	accuracy_train: 0.9643	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 11469.5000	loss_val: 11469.6562	loss_test: 11469.4658	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1429.6687	loss_val: 1429.6844	loss_test: 1429.7010	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8770.6543	loss_val: 8771.1641	loss_test: 8771.3936	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17171.0449	loss_val: 17171.0703	loss_test: 17171.2695	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11481.3857	loss_val: 11481.5254	loss_test: 11481.5117	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1251.1343	loss_val: 1251.1422	loss_test: 1251.1497	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 97	curr_val_accuracy: 0.6816	curr_test_accuracy: 0.7011
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33064.4570	loss_val: 33064.5938	loss_test: 33065.1914	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33679.3203	loss_val: 33679.4805	loss_test: 33679.3828	accuracy_train: 0.7481	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 39324.6484	loss_val: 39327.5820	loss_test: 39325.7305	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 23039.3105	loss_val: 23039.3379	loss_test: 23039.4219	accuracy_train: 0.6730	accuracy_val: 0.6000	accuracy_test: 0.6341
[client 4]	loss_train: 5881.5889	loss_val: 5881.6597	loss_test: 5881.8467	accuracy_train: 0.6294	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 8257.8467	loss_val: 8257.8936	loss_test: 8258.0029	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 65892.5703	loss_val: 65892.9062	loss_test: 65892.7266	accuracy_train: 0.5588	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 41036.6680	loss_val: 41036.7812	loss_test: 41036.6992	accuracy_train: 0.5528	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1236.9307	loss_val: 1236.9384	loss_test: 1236.9388	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47465.0859	loss_val: 47477.7812	loss_test: 47465.2539	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8659.9414	loss_val: 8659.8633	loss_test: 8659.9785	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4010.5293	loss_val: 4010.7144	loss_test: 4010.7051	accuracy_train: 0.6353	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 45691.4766	loss_val: 45693.2852	loss_test: 45693.0781	accuracy_train: 0.9661	accuracy_val: 0.7333	accuracy_test: 0.7059
[client 13]	loss_train: 228315.2812	loss_val: 228315.4844	loss_test: 228316.0625	accuracy_train: 0.9541	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 11488.8633	loss_val: 11489.0195	loss_test: 11488.8340	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1432.6644	loss_val: 1432.6797	loss_test: 1432.6968	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8739.8291	loss_val: 8740.3457	loss_test: 8740.5723	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17201.0156	loss_val: 17201.0176	loss_test: 17201.2383	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11366.3682	loss_val: 11366.5127	loss_test: 11366.4951	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1246.4176	loss_val: 1246.4253	loss_test: 1246.4327	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 98	curr_val_accuracy: 0.6856	curr_test_accuracy: 0.7011
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33138.6250	loss_val: 33138.7617	loss_test: 33139.3789	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33348.8125	loss_val: 33348.9844	loss_test: 33348.8750	accuracy_train: 0.7442	accuracy_val: 0.7188	accuracy_test: 0.7353
[client 2]	loss_train: 39714.1328	loss_val: 39717.1055	loss_test: 39715.2305	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 21721.2949	loss_val: 21721.3281	loss_test: 21721.4023	accuracy_train: 0.6509	accuracy_val: 0.5750	accuracy_test: 0.6098
[client 4]	loss_train: 6347.7710	loss_val: 6347.8174	loss_test: 6348.0317	accuracy_train: 0.6294	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 8694.3018	loss_val: 8694.3652	loss_test: 8694.4531	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 66517.5625	loss_val: 66517.9062	loss_test: 66517.7344	accuracy_train: 0.5412	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 41935.1055	loss_val: 41935.2148	loss_test: 41935.1367	accuracy_train: 0.5458	accuracy_val: 0.4167	accuracy_test: 0.5135
[client 8]	loss_train: 1228.0952	loss_val: 1228.1031	loss_test: 1228.1033	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48055.1641	loss_val: 48067.9453	loss_test: 48055.3281	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8934.3740	loss_val: 8934.2920	loss_test: 8934.4131	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4007.2537	loss_val: 4007.4448	loss_test: 4007.4309	accuracy_train: 0.6353	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 45397.5586	loss_val: 45399.3750	loss_test: 45399.1328	accuracy_train: 0.9661	accuracy_val: 0.7333	accuracy_test: 0.7059
[client 13]	loss_train: 226773.5156	loss_val: 226773.7188	loss_test: 226774.2656	accuracy_train: 0.9541	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 11358.4980	loss_val: 11358.6631	loss_test: 11358.4785	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1423.0239	loss_val: 1423.0388	loss_test: 1423.0564	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8628.7764	loss_val: 8629.2988	loss_test: 8629.5234	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 17947.5332	loss_val: 17947.5332	loss_test: 17947.7637	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11424.3799	loss_val: 11424.5322	loss_test: 11424.5088	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1238.6954	loss_val: 1238.7028	loss_test: 1238.7102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 99	curr_val_accuracy: 0.6816	curr_test_accuracy: 0.7011
best_round: 17	best_val_accuracy: 0.7193	best_test_accuracy: 0.7187
--------------------------------------------------
