GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1.0853	loss_val: 1.0600	loss_test: 1.0823	accuracy_train: 0.1165	accuracy_val: 0.1429	accuracy_test: 0.1429
[client 1]	loss_train: 0.9819	loss_val: 1.0250	loss_test: 0.9714	accuracy_train: 0.3876	accuracy_val: 0.3125	accuracy_test: 0.3824
[client 2]	loss_train: 1.2514	loss_val: 1.1821	loss_test: 1.0781	accuracy_train: 0.5060	accuracy_val: 0.4545	accuracy_test: 0.3636
[client 3]	loss_train: 1.1324	loss_val: 1.2162	loss_test: 1.1371	accuracy_train: 0.1164	accuracy_val: 0.0750	accuracy_test: 0.1220
[client 4]	loss_train: 1.9931	loss_val: 1.8625	loss_test: 2.1905	accuracy_train: 0.0765	accuracy_val: 0.0476	accuracy_test: 0.0833
[client 5]	loss_train: 0.9260	loss_val: 0.9020	loss_test: 0.9397	accuracy_train: 0.8566	accuracy_val: 0.8333	accuracy_test: 0.8649
[client 6]	loss_train: 1.3879	loss_val: 1.0966	loss_test: 1.2387	accuracy_train: 0.3118	accuracy_val: 0.3636	accuracy_test: 0.3182
[client 7]	loss_train: 1.0175	loss_val: 0.9734	loss_test: 0.9755	accuracy_train: 0.3380	accuracy_val: 0.3333	accuracy_test: 0.3514
[client 8]	loss_train: 0.9921	loss_val: 1.0231	loss_test: 1.0103	accuracy_train: 0.3860	accuracy_val: 0.2778	accuracy_test: 0.3056
[client 9]	loss_train: 1.0347	loss_val: 1.1337	loss_test: 0.9848	accuracy_train: 0.4423	accuracy_val: 0.5714	accuracy_test: 0.5000
[client 10]	loss_train: 1.0930	loss_val: 1.0499	loss_test: 1.1077	accuracy_train: 0.1314	accuracy_val: 0.1765	accuracy_test: 0.0857
[client 11]	loss_train: 1.0577	loss_val: 1.0460	loss_test: 1.0575	accuracy_train: 0.4980	accuracy_val: 0.5625	accuracy_test: 0.3939
[client 12]	loss_train: 1.4176	loss_val: 1.0672	loss_test: 1.1088	accuracy_train: 0.6102	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 1.2546	loss_val: 1.0366	loss_test: 1.0043	accuracy_train: 0.7653	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 1.0369	loss_val: 1.0288	loss_test: 1.0043	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 0.9183	loss_val: 0.9229	loss_test: 0.9024	accuracy_train: 0.9706	accuracy_val: 0.9600	accuracy_test: 0.9615
[client 16]	loss_train: 2.4472	loss_val: 1.6356	loss_test: 1.1237	accuracy_train: 0.2321	accuracy_val: 0.2500	accuracy_test: 0.1250
[client 17]	loss_train: 1.5413	loss_val: 2.0354	loss_test: 2.2337	accuracy_train: 0.1986	accuracy_val: 0.1765	accuracy_test: 0.2105
[client 18]	loss_train: 1.0337	loss_val: 1.0483	loss_test: 1.0024	accuracy_train: 0.3125	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1.2396	loss_val: 1.2381	loss_test: 1.2437	accuracy_train: 0.0550	accuracy_val: 0.0000	accuracy_test: 0.0256
curr_round: 0	curr_val_accuracy: 0.3712	curr_test_accuracy: 0.3734
best_round: 0	best_val_accuracy: 0.3712	best_test_accuracy: 0.3734
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 77384.4531	loss_val: 77384.4062	loss_test: 77384.4141	accuracy_train: 0.1068	accuracy_val: 0.1429	accuracy_test: 0.0714
[client 1]	loss_train: 8815.9326	loss_val: 8815.9873	loss_test: 8815.9043	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 22607.7695	loss_val: 22607.7480	loss_test: 22607.7676	accuracy_train: 0.5542	accuracy_val: 0.4545	accuracy_test: 0.3636
[client 3]	loss_train: 9214.3965	loss_val: 9214.3711	loss_test: 9214.4102	accuracy_train: 0.1384	accuracy_val: 0.1500	accuracy_test: 0.1463
[client 4]	loss_train: 9165.4209	loss_val: 9165.4062	loss_test: 9165.4209	accuracy_train: 0.1647	accuracy_val: 0.0952	accuracy_test: 0.2500
[client 5]	loss_train: 4040.2498	loss_val: 4040.2231	loss_test: 4040.2673	accuracy_train: 0.8636	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 20329.9785	loss_val: 20329.9355	loss_test: 20329.9531	accuracy_train: 0.3176	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 11846.7158	loss_val: 11846.6836	loss_test: 11846.6846	accuracy_train: 0.6127	accuracy_val: 0.6667	accuracy_test: 0.6486
[client 8]	loss_train: 77.8082	loss_val: 77.8320	loss_test: 77.8191	accuracy_train: 0.9193	accuracy_val: 0.9167	accuracy_test: 0.9444
[client 9]	loss_train: 39877.9258	loss_val: 39877.9766	loss_test: 39877.9062	accuracy_train: 0.3846	accuracy_val: 0.4286	accuracy_test: 0.5000
[client 10]	loss_train: 8121.5366	loss_val: 8121.5005	loss_test: 8121.5503	accuracy_train: 0.2044	accuracy_val: 0.2941	accuracy_test: 0.1429
[client 11]	loss_train: 118.8494	loss_val: 118.8533	loss_test: 118.8421	accuracy_train: 0.5961	accuracy_val: 0.6250	accuracy_test: 0.5758
[client 12]	loss_train: 57792.7461	loss_val: 57792.6523	loss_test: 57792.6602	accuracy_train: 0.6102	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 102749.2812	loss_val: 102749.2422	loss_test: 102749.2188	accuracy_train: 0.8827	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 14870.7549	loss_val: 14870.7188	loss_test: 14870.7256	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 83.2320	loss_val: 83.2465	loss_test: 83.2327	accuracy_train: 0.9951	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 16124.3691	loss_val: 16124.1914	loss_test: 16124.1191	accuracy_train: 0.2500	accuracy_val: 0.1250	accuracy_test: 0.1250
[client 17]	loss_train: 19344.6270	loss_val: 19344.6211	loss_test: 19344.5449	accuracy_train: 0.2695	accuracy_val: 0.2353	accuracy_test: 0.4211
[client 18]	loss_train: 6691.8496	loss_val: 6691.8647	loss_test: 6691.8320	accuracy_train: 0.3566	accuracy_val: 0.3235	accuracy_test: 0.3714
[client 19]	loss_train: 90.3376	loss_val: 90.3309	loss_test: 90.3373	accuracy_train: 0.0356	accuracy_val: 0.0000	accuracy_test: 0.0000
curr_round: 1	curr_val_accuracy: 0.4896	curr_test_accuracy: 0.4914
best_round: 1	best_val_accuracy: 0.4896	best_test_accuracy: 0.4914
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 52448.0703	loss_val: 52448.0234	loss_test: 52448.0234	accuracy_train: 0.1068	accuracy_val: 0.1429	accuracy_test: 0.0714
[client 1]	loss_train: 7983.7197	loss_val: 7983.7798	loss_test: 7983.6929	accuracy_train: 0.8140	accuracy_val: 0.8438	accuracy_test: 0.7353
[client 2]	loss_train: 17185.6777	loss_val: 17185.6543	loss_test: 17185.6855	accuracy_train: 0.5422	accuracy_val: 0.5455	accuracy_test: 0.3636
[client 3]	loss_train: 8825.0576	loss_val: 8825.0195	loss_test: 8825.0771	accuracy_train: 0.1918	accuracy_val: 0.2250	accuracy_test: 0.1951
[client 4]	loss_train: 7314.3013	loss_val: 7314.3066	loss_test: 7314.2544	accuracy_train: 0.2176	accuracy_val: 0.1429	accuracy_test: 0.4167
[client 5]	loss_train: 3780.8574	loss_val: 3780.8394	loss_test: 3780.8711	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 14589.6279	loss_val: 14589.5967	loss_test: 14589.6104	accuracy_train: 0.3176	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 13765.8633	loss_val: 13765.8389	loss_test: 13765.8291	accuracy_train: 0.6514	accuracy_val: 0.7222	accuracy_test: 0.7297
[client 8]	loss_train: 116.5939	loss_val: 116.6173	loss_test: 116.5998	accuracy_train: 0.9789	accuracy_val: 0.9722	accuracy_test: 0.9722
[client 9]	loss_train: 36732.2617	loss_val: 36732.2969	loss_test: 36732.2461	accuracy_train: 0.8269	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 7143.2324	loss_val: 7143.1934	loss_test: 7143.2402	accuracy_train: 0.3978	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 11]	loss_train: 142.0520	loss_val: 142.0662	loss_test: 142.0444	accuracy_train: 0.6118	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 38211.1875	loss_val: 38211.1680	loss_test: 38211.1680	accuracy_train: 0.6186	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 85974.6094	loss_val: 85974.6172	loss_test: 85974.5938	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10558.1855	loss_val: 10558.1572	loss_test: 10558.1631	accuracy_train: 0.4406	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 94.9936	loss_val: 95.0113	loss_test: 94.9986	accuracy_train: 0.9951	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9975.0586	loss_val: 9974.9971	loss_test: 9975.0166	accuracy_train: 0.3036	accuracy_val: 0.2500	accuracy_test: 0.1250
[client 17]	loss_train: 14715.9258	loss_val: 14715.8906	loss_test: 14715.8467	accuracy_train: 0.2837	accuracy_val: 0.2941	accuracy_test: 0.3684
[client 18]	loss_train: 6000.5469	loss_val: 6000.5605	loss_test: 6000.5293	accuracy_train: 0.3860	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 151.8221	loss_val: 151.8070	loss_test: 151.8178	accuracy_train: 0.1521	accuracy_val: 0.1026	accuracy_test: 0.1282
curr_round: 2	curr_val_accuracy: 0.5374	curr_test_accuracy: 0.5409
best_round: 2	best_val_accuracy: 0.5374	best_test_accuracy: 0.5409
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 46117.5508	loss_val: 46117.5039	loss_test: 46117.5000	accuracy_train: 0.1068	accuracy_val: 0.1429	accuracy_test: 0.1429
[client 1]	loss_train: 8428.1738	loss_val: 8428.2324	loss_test: 8428.1514	accuracy_train: 0.8527	accuracy_val: 0.8750	accuracy_test: 0.7059
[client 2]	loss_train: 15260.5752	loss_val: 15260.5566	loss_test: 15260.5928	accuracy_train: 0.5301	accuracy_val: 0.5455	accuracy_test: 0.3636
[client 3]	loss_train: 10581.8105	loss_val: 10581.7676	loss_test: 10581.8301	accuracy_train: 0.4528	accuracy_val: 0.6250	accuracy_test: 0.4878
[client 4]	loss_train: 6672.5361	loss_val: 6672.5454	loss_test: 6672.5132	accuracy_train: 0.4765	accuracy_val: 0.3333	accuracy_test: 0.5417
[client 5]	loss_train: 3917.1812	loss_val: 3917.1753	loss_test: 3917.1863	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 13915.8408	loss_val: 13915.8037	loss_test: 13915.8369	accuracy_train: 0.3235	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 16027.5850	loss_val: 16027.5645	loss_test: 16027.5527	accuracy_train: 0.6408	accuracy_val: 0.6944	accuracy_test: 0.7297
[client 8]	loss_train: 182.4168	loss_val: 182.4441	loss_test: 182.4194	accuracy_train: 0.9965	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 33900.7891	loss_val: 33900.8125	loss_test: 33900.7734	accuracy_train: 0.7692	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 7264.7651	loss_val: 7264.7261	loss_test: 7264.7681	accuracy_train: 0.4964	accuracy_val: 0.6176	accuracy_test: 0.5714
[client 11]	loss_train: 191.1963	loss_val: 191.2161	loss_test: 191.1877	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 29219.3027	loss_val: 29219.3203	loss_test: 29219.3125	accuracy_train: 0.6271	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 89289.8281	loss_val: 89289.8438	loss_test: 89289.8203	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9167.8555	loss_val: 9167.8301	loss_test: 9167.8389	accuracy_train: 0.4406	accuracy_val: 0.3529	accuracy_test: 0.4500
[client 15]	loss_train: 125.8765	loss_val: 125.8972	loss_test: 125.8805	accuracy_train: 0.9951	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7340.0464	loss_val: 7340.0156	loss_test: 7340.0615	accuracy_train: 0.3393	accuracy_val: 0.3750	accuracy_test: 0.1250
[client 17]	loss_train: 13032.1523	loss_val: 13032.1162	loss_test: 13032.0771	accuracy_train: 0.2979	accuracy_val: 0.2941	accuracy_test: 0.3684
[client 18]	loss_train: 6723.8979	loss_val: 6723.9102	loss_test: 6723.8828	accuracy_train: 0.3971	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 253.4374	loss_val: 253.4216	loss_test: 253.4335	accuracy_train: 0.8091	accuracy_val: 0.9487	accuracy_test: 0.8205
curr_round: 3	curr_val_accuracy: 0.6611	curr_test_accuracy: 0.6424
best_round: 3	best_val_accuracy: 0.6611	best_test_accuracy: 0.6424
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38454.6758	loss_val: 38454.6289	loss_test: 38454.6250	accuracy_train: 0.1456	accuracy_val: 0.2143	accuracy_test: 0.2857
[client 1]	loss_train: 10076.3301	loss_val: 10076.3936	loss_test: 10076.3047	accuracy_train: 0.8101	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 14772.3477	loss_val: 14772.3359	loss_test: 14772.3750	accuracy_train: 0.5060	accuracy_val: 0.5455	accuracy_test: 0.3636
[client 3]	loss_train: 12701.3984	loss_val: 12701.3525	loss_test: 12701.4248	accuracy_train: 0.6478	accuracy_val: 0.7750	accuracy_test: 0.5610
[client 4]	loss_train: 6118.1025	loss_val: 6118.1152	loss_test: 6118.1030	accuracy_train: 0.6235	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 4296.0020	loss_val: 4296.0005	loss_test: 4296.0073	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 14596.5449	loss_val: 14596.5098	loss_test: 14596.5566	accuracy_train: 0.3294	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 18745.2617	loss_val: 18745.2363	loss_test: 18745.2324	accuracy_train: 0.6585	accuracy_val: 0.7222	accuracy_test: 0.7027
[client 8]	loss_train: 273.6619	loss_val: 273.6952	loss_test: 273.6656	accuracy_train: 0.9965	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 32166.3613	loss_val: 32166.3828	loss_test: 32166.3496	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8261.6963	loss_val: 8261.6602	loss_test: 8261.6982	accuracy_train: 0.5328	accuracy_val: 0.6176	accuracy_test: 0.5714
[client 11]	loss_train: 262.5886	loss_val: 262.6127	loss_test: 262.5799	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 25269.5234	loss_val: 25269.5527	loss_test: 25269.5410	accuracy_train: 0.6441	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 95345.2969	loss_val: 95345.3125	loss_test: 95345.2969	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8878.9961	loss_val: 8878.9785	loss_test: 8878.9854	accuracy_train: 0.3986	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 172.3236	loss_val: 172.3456	loss_test: 172.3307	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5857.7578	loss_val: 5857.7412	loss_test: 5857.8032	accuracy_train: 0.3929	accuracy_val: 0.3750	accuracy_test: 0.1250
[client 17]	loss_train: 12939.6143	loss_val: 12939.5752	loss_test: 12939.5361	accuracy_train: 0.3617	accuracy_val: 0.2941	accuracy_test: 0.3684
[client 18]	loss_train: 7633.1611	loss_val: 7633.1758	loss_test: 7633.1504	accuracy_train: 0.3971	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 394.2456	loss_val: 394.2337	loss_test: 394.2481	accuracy_train: 0.8900	accuracy_val: 0.9744	accuracy_test: 0.8462
curr_round: 4	curr_val_accuracy: 0.6829	curr_test_accuracy: 0.6649
best_round: 4	best_val_accuracy: 0.6829	best_test_accuracy: 0.6649
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31897.4473	loss_val: 31897.4023	loss_test: 31897.3945	accuracy_train: 0.9223	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 12382.0928	loss_val: 12382.1611	loss_test: 12382.0664	accuracy_train: 0.7636	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 14590.4111	loss_val: 14590.4062	loss_test: 14590.4443	accuracy_train: 0.5060	accuracy_val: 0.5455	accuracy_test: 0.3636
[client 3]	loss_train: 14677.8760	loss_val: 14677.8223	loss_test: 14677.9092	accuracy_train: 0.6509	accuracy_val: 0.7750	accuracy_test: 0.6098
[client 4]	loss_train: 5963.5513	loss_val: 5963.5645	loss_test: 5963.5586	accuracy_train: 0.6353	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 4918.7227	loss_val: 4918.7217	loss_test: 4918.7280	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 16178.3818	loss_val: 16178.3477	loss_test: 16178.4043	accuracy_train: 0.3471	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 21345.2422	loss_val: 21345.2129	loss_test: 21345.2168	accuracy_train: 0.6585	accuracy_val: 0.7222	accuracy_test: 0.7027
[client 8]	loss_train: 387.5108	loss_val: 387.5517	loss_test: 387.5227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 29296.0840	loss_val: 29296.0996	loss_test: 29296.0820	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 9608.6943	loss_val: 9608.6533	loss_test: 9608.6992	accuracy_train: 0.5839	accuracy_val: 0.6765	accuracy_test: 0.6000
[client 11]	loss_train: 361.2682	loss_val: 361.2966	loss_test: 361.2580	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 23014.2461	loss_val: 23014.2773	loss_test: 23014.2637	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 106428.6406	loss_val: 106428.6562	loss_test: 106428.6484	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8870.5898	loss_val: 8870.5771	loss_test: 8870.5869	accuracy_train: 0.4126	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 237.9541	loss_val: 237.9797	loss_test: 237.9668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4894.0449	loss_val: 4894.0488	loss_test: 4894.1157	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.1250
[client 17]	loss_train: 13540.4482	loss_val: 13540.4102	loss_test: 13540.3691	accuracy_train: 0.3830	accuracy_val: 0.2941	accuracy_test: 0.3684
[client 18]	loss_train: 8600.3086	loss_val: 8600.3262	loss_test: 8600.3018	accuracy_train: 0.3971	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 576.9436	loss_val: 576.9396	loss_test: 576.9617	accuracy_train: 0.9482	accuracy_val: 1.0000	accuracy_test: 0.9487
curr_round: 5	curr_val_accuracy: 0.7074	curr_test_accuracy: 0.6883
best_round: 5	best_val_accuracy: 0.7074	best_test_accuracy: 0.6883
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27719.6270	loss_val: 27719.5840	loss_test: 27719.5723	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 15463.4678	loss_val: 15463.5352	loss_test: 15463.4463	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 15431.5908	loss_val: 15431.5928	loss_test: 15431.6299	accuracy_train: 0.5181	accuracy_val: 0.4545	accuracy_test: 0.3636
[client 3]	loss_train: 17029.1602	loss_val: 17029.1094	loss_test: 17029.1953	accuracy_train: 0.6698	accuracy_val: 0.7750	accuracy_test: 0.6098
[client 4]	loss_train: 5868.7778	loss_val: 5868.7925	loss_test: 5868.7871	accuracy_train: 0.6471	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 5834.9448	loss_val: 5834.9409	loss_test: 5834.9536	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 18704.2637	loss_val: 18704.2285	loss_test: 18704.2930	accuracy_train: 0.3647	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 23954.1113	loss_val: 23954.0762	loss_test: 23954.0879	accuracy_train: 0.6514	accuracy_val: 0.7222	accuracy_test: 0.7297
[client 8]	loss_train: 527.1664	loss_val: 527.2148	loss_test: 527.1874	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 26244.9883	loss_val: 26245.0098	loss_test: 26244.9941	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 10]	loss_train: 11599.2959	loss_val: 11599.2490	loss_test: 11599.3027	accuracy_train: 0.6022	accuracy_val: 0.6765	accuracy_test: 0.6000
[client 11]	loss_train: 488.8040	loss_val: 488.8363	loss_test: 488.7920	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 21968.8574	loss_val: 21968.8906	loss_test: 21968.8770	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 118251.7656	loss_val: 118251.7891	loss_test: 118251.7812	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8711.7363	loss_val: 8711.7285	loss_test: 8711.7402	accuracy_train: 0.3986	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 318.2011	loss_val: 318.2318	loss_test: 318.2199	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4305.0220	loss_val: 4305.0474	loss_test: 4305.1089	accuracy_train: 0.6429	accuracy_val: 0.5000	accuracy_test: 0.1250
[client 17]	loss_train: 14890.5059	loss_val: 14890.4727	loss_test: 14890.4307	accuracy_train: 0.4255	accuracy_val: 0.2941	accuracy_test: 0.4737
[client 18]	loss_train: 9571.0342	loss_val: 9571.0518	loss_test: 9571.0342	accuracy_train: 0.4081	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 789.7503	loss_val: 789.7540	loss_test: 789.7856	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9744
curr_round: 6	curr_val_accuracy: 0.7035	curr_test_accuracy: 0.6961
best_round: 5	best_val_accuracy: 0.7074	best_test_accuracy: 0.6883
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23726.8184	loss_val: 23726.7754	loss_test: 23726.7637	accuracy_train: 0.9417	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 17318.5215	loss_val: 17318.5898	loss_test: 17318.5039	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 16804.8340	loss_val: 16804.8418	loss_test: 16804.8789	accuracy_train: 0.5301	accuracy_val: 0.4545	accuracy_test: 0.3636
[client 3]	loss_train: 19156.7031	loss_val: 19156.6484	loss_test: 19156.7363	accuracy_train: 0.6855	accuracy_val: 0.7750	accuracy_test: 0.6829
[client 4]	loss_train: 5776.9893	loss_val: 5777.0073	loss_test: 5776.9937	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 6837.5737	loss_val: 6837.5728	loss_test: 6837.5840	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 21284.0547	loss_val: 21284.0176	loss_test: 21284.0820	accuracy_train: 0.3647	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 26497.5918	loss_val: 26497.5488	loss_test: 26497.5664	accuracy_train: 0.6549	accuracy_val: 0.7778	accuracy_test: 0.7568
[client 8]	loss_train: 681.7222	loss_val: 681.7787	loss_test: 681.7501	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 25675.0527	loss_val: 25675.0820	loss_test: 25675.0605	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 10]	loss_train: 13050.0693	loss_val: 13050.0186	loss_test: 13050.0781	accuracy_train: 0.6387	accuracy_val: 0.6176	accuracy_test: 0.6571
[client 11]	loss_train: 648.3835	loss_val: 648.4174	loss_test: 648.3726	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 21154.8809	loss_val: 21154.9180	loss_test: 21154.9043	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 130730.0938	loss_val: 130730.1094	loss_test: 130730.1094	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8431.7275	loss_val: 8431.7256	loss_test: 8431.7354	accuracy_train: 0.4056	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 413.8553	loss_val: 413.8943	loss_test: 413.8794	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 3959.1672	loss_val: 3959.2161	loss_test: 3959.2698	accuracy_train: 0.6786	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 17]	loss_train: 16276.0898	loss_val: 16276.0645	loss_test: 16276.0225	accuracy_train: 0.5532	accuracy_val: 0.3529	accuracy_test: 0.5789
[client 18]	loss_train: 10486.2598	loss_val: 10486.2773	loss_test: 10486.2666	accuracy_train: 0.4081	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 1008.2977	loss_val: 1008.3110	loss_test: 1008.3462	accuracy_train: 0.9935	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 7	curr_val_accuracy: 0.7016	curr_test_accuracy: 0.7171
best_round: 5	best_val_accuracy: 0.7074	best_test_accuracy: 0.6883
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22254.6309	loss_val: 22254.5918	loss_test: 22254.5781	accuracy_train: 0.9417	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 18246.9180	loss_val: 18246.9824	loss_test: 18246.9023	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 18195.5938	loss_val: 18195.6055	loss_test: 18195.6445	accuracy_train: 0.5663	accuracy_val: 0.4545	accuracy_test: 0.3636
[client 3]	loss_train: 20812.4785	loss_val: 20812.4355	loss_test: 20812.5059	accuracy_train: 0.6887	accuracy_val: 0.8000	accuracy_test: 0.7073
[client 4]	loss_train: 5707.6748	loss_val: 5707.6992	loss_test: 5707.6758	accuracy_train: 0.6824	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 7920.0244	loss_val: 7920.0278	loss_test: 7920.0376	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 24359.8418	loss_val: 24359.8066	loss_test: 24359.8691	accuracy_train: 0.3765	accuracy_val: 0.3636	accuracy_test: 0.3182
[client 7]	loss_train: 29337.3984	loss_val: 29337.3574	loss_test: 29337.3730	accuracy_train: 0.6514	accuracy_val: 0.6389	accuracy_test: 0.7027
[client 8]	loss_train: 842.8500	loss_val: 842.9110	loss_test: 842.8807	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 26872.3770	loss_val: 26872.4141	loss_test: 26872.3867	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14017.4355	loss_val: 14017.3789	loss_test: 14017.4453	accuracy_train: 0.6204	accuracy_val: 0.5294	accuracy_test: 0.7143
[client 11]	loss_train: 824.9205	loss_val: 824.9567	loss_test: 824.9133	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 20834.7676	loss_val: 20834.8066	loss_test: 20834.7930	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 145693.5156	loss_val: 145693.5312	loss_test: 145693.5312	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8363.9229	loss_val: 8363.9355	loss_test: 8363.9404	accuracy_train: 0.4056	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 523.1019	loss_val: 523.1518	loss_test: 523.1295	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 3766.2629	loss_val: 3766.3259	loss_test: 3766.3738	accuracy_train: 0.7143	accuracy_val: 0.3750	accuracy_test: 0.2500
[client 17]	loss_train: 17247.7090	loss_val: 17247.6934	loss_test: 17247.6523	accuracy_train: 0.6596	accuracy_val: 0.4706	accuracy_test: 0.5789
[client 18]	loss_train: 11142.1035	loss_val: 11142.1221	loss_test: 11142.1162	accuracy_train: 0.4007	accuracy_val: 0.3235	accuracy_test: 0.4000
[client 19]	loss_train: 1201.8602	loss_val: 1201.8834	loss_test: 1201.9204	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 8	curr_val_accuracy: 0.6920	curr_test_accuracy: 0.7226
best_round: 5	best_val_accuracy: 0.7074	best_test_accuracy: 0.6883
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21573.6270	loss_val: 21573.5879	loss_test: 21573.5723	accuracy_train: 0.9612	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 18822.4629	loss_val: 18822.5234	loss_test: 18822.4512	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 19371.7949	loss_val: 19371.8105	loss_test: 19371.8516	accuracy_train: 0.5904	accuracy_val: 0.5455	accuracy_test: 0.3636
[client 3]	loss_train: 22338.0430	loss_val: 22338.0273	loss_test: 22338.0605	accuracy_train: 0.7013	accuracy_val: 0.7000	accuracy_test: 0.7561
[client 4]	loss_train: 5744.2871	loss_val: 5744.3188	loss_test: 5744.2822	accuracy_train: 0.6765	accuracy_val: 0.6190	accuracy_test: 0.7083
[client 5]	loss_train: 8561.6592	loss_val: 8561.6689	loss_test: 8561.6738	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 28932.4824	loss_val: 28932.4492	loss_test: 28932.5059	accuracy_train: 0.3765	accuracy_val: 0.3636	accuracy_test: 0.3182
[client 7]	loss_train: 31399.2461	loss_val: 31399.2070	loss_test: 31399.2207	accuracy_train: 0.5915	accuracy_val: 0.6111	accuracy_test: 0.6216
[client 8]	loss_train: 980.1469	loss_val: 980.2087	loss_test: 980.1830	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 28754.8242	loss_val: 28754.8652	loss_test: 28754.8340	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14447.7783	loss_val: 14447.7158	loss_test: 14447.7871	accuracy_train: 0.6058	accuracy_val: 0.6176	accuracy_test: 0.6857
[client 11]	loss_train: 1014.6545	loss_val: 1014.6940	loss_test: 1014.6505	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 21302.6953	loss_val: 21302.7363	loss_test: 21302.7246	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 160543.4375	loss_val: 160543.4531	loss_test: 160543.4531	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8327.6465	loss_val: 8327.6777	loss_test: 8327.6758	accuracy_train: 0.4196	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 633.8586	loss_val: 633.9193	loss_test: 633.8879	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 3674.8818	loss_val: 3674.9553	loss_test: 3674.9968	accuracy_train: 0.7321	accuracy_val: 0.2500	accuracy_test: 0.2500
[client 17]	loss_train: 18032.7461	loss_val: 18032.7422	loss_test: 18032.7051	accuracy_train: 0.5745	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11885.3008	loss_val: 11885.3213	loss_test: 11885.3184	accuracy_train: 0.4044	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1338.9985	loss_val: 1339.0255	loss_test: 1339.0680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 9	curr_val_accuracy: 0.6964	curr_test_accuracy: 0.7168
best_round: 5	best_val_accuracy: 0.7074	best_test_accuracy: 0.6883
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21840.0996	loss_val: 21840.0625	loss_test: 21840.0449	accuracy_train: 0.9515	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 19350.9570	loss_val: 19351.0117	loss_test: 19350.9492	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 20665.0137	loss_val: 20665.0352	loss_test: 20665.0781	accuracy_train: 0.5904	accuracy_val: 0.5455	accuracy_test: 0.3636
[client 3]	loss_train: 24308.7402	loss_val: 24308.7168	loss_test: 24308.7598	accuracy_train: 0.6981	accuracy_val: 0.7000	accuracy_test: 0.7561
[client 4]	loss_train: 5918.2002	loss_val: 5918.2388	loss_test: 5918.1846	accuracy_train: 0.6824	accuracy_val: 0.6667	accuracy_test: 0.7083
[client 5]	loss_train: 8915.3398	loss_val: 8915.3516	loss_test: 8915.3555	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 34416.7656	loss_val: 34416.7344	loss_test: 34416.7852	accuracy_train: 0.3706	accuracy_val: 0.3636	accuracy_test: 0.3182
[client 7]	loss_train: 32470.9922	loss_val: 32470.9551	loss_test: 32470.9648	accuracy_train: 0.5528	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1096.5123	loss_val: 1096.5726	loss_test: 1096.5537	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 30894.8320	loss_val: 30894.8789	loss_test: 30894.8457	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14807.3047	loss_val: 14807.2383	loss_test: 14807.3115	accuracy_train: 0.6204	accuracy_val: 0.5882	accuracy_test: 0.5143
[client 11]	loss_train: 1194.2677	loss_val: 1194.3092	loss_test: 1194.2671	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 22669.8867	loss_val: 22669.9297	loss_test: 22669.9199	accuracy_train: 0.6695	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 176979.5312	loss_val: 176979.5625	loss_test: 176979.5625	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8328.2412	loss_val: 8328.2725	loss_test: 8328.2744	accuracy_train: 0.4126	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 748.8430	loss_val: 748.9120	loss_test: 748.8712	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 3649.5181	loss_val: 3649.5950	loss_test: 3649.6355	accuracy_train: 0.7679	accuracy_val: 0.2500	accuracy_test: 0.2500
[client 17]	loss_train: 18994.2227	loss_val: 18994.2324	loss_test: 18994.1973	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12850.7412	loss_val: 12850.7646	loss_test: 12850.7598	accuracy_train: 0.4044	accuracy_val: 0.3824	accuracy_test: 0.3429
[client 19]	loss_train: 1419.9360	loss_val: 1419.9628	loss_test: 1420.0123	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 10	curr_val_accuracy: 0.6965	curr_test_accuracy: 0.6954
best_round: 5	best_val_accuracy: 0.7074	best_test_accuracy: 0.6883
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21701.4473	loss_val: 21701.4121	loss_test: 21701.3926	accuracy_train: 0.9709	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 20108.2441	loss_val: 20108.2910	loss_test: 20108.2422	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 21824.8477	loss_val: 21824.8750	loss_test: 21824.9160	accuracy_train: 0.5904	accuracy_val: 0.5455	accuracy_test: 0.3636
[client 3]	loss_train: 25187.7617	loss_val: 25187.7227	loss_test: 25187.7852	accuracy_train: 0.7170	accuracy_val: 0.7750	accuracy_test: 0.7805
[client 4]	loss_train: 6114.8774	loss_val: 6114.9209	loss_test: 6114.8569	accuracy_train: 0.6706	accuracy_val: 0.6667	accuracy_test: 0.7500
[client 5]	loss_train: 8993.8545	loss_val: 8993.8691	loss_test: 8993.8711	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39336.5156	loss_val: 39336.4844	loss_test: 39336.5352	accuracy_train: 0.3765	accuracy_val: 0.3636	accuracy_test: 0.3182
[client 7]	loss_train: 34222.7422	loss_val: 34222.7070	loss_test: 34222.7148	accuracy_train: 0.5493	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1191.9137	loss_val: 1191.9728	loss_test: 1191.9578	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 33142.4922	loss_val: 33142.5430	loss_test: 33142.5078	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 15643.7334	loss_val: 15643.6631	loss_test: 15643.7373	accuracy_train: 0.6058	accuracy_val: 0.6176	accuracy_test: 0.5429
[client 11]	loss_train: 1379.2484	loss_val: 1379.2931	loss_test: 1379.2501	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 23875.5137	loss_val: 23875.5605	loss_test: 23875.5508	accuracy_train: 0.6695	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 190939.6094	loss_val: 190939.6406	loss_test: 190939.6562	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8444.2881	loss_val: 8444.3252	loss_test: 8444.3203	accuracy_train: 0.3986	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 857.1071	loss_val: 857.1823	loss_test: 857.1332	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 3709.7639	loss_val: 3709.8435	loss_test: 3709.8835	accuracy_train: 0.8036	accuracy_val: 0.2500	accuracy_test: 0.2500
[client 17]	loss_train: 20266.8027	loss_val: 20266.8203	loss_test: 20266.7910	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13698.5439	loss_val: 13698.5693	loss_test: 13698.5615	accuracy_train: 0.4081	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1465.0142	loss_val: 1465.0381	loss_test: 1465.0924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 11	curr_val_accuracy: 0.7045	curr_test_accuracy: 0.7030
best_round: 5	best_val_accuracy: 0.7074	best_test_accuracy: 0.6883
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22419.4941	loss_val: 22419.4648	loss_test: 22419.4414	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20872.9883	loss_val: 20873.0293	loss_test: 20872.9941	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 22980.9160	loss_val: 22980.9512	loss_test: 22980.9941	accuracy_train: 0.6024	accuracy_val: 0.5455	accuracy_test: 0.3636
[client 3]	loss_train: 25186.3164	loss_val: 25186.2637	loss_test: 25186.3477	accuracy_train: 0.6887	accuracy_val: 0.8250	accuracy_test: 0.7317
[client 4]	loss_train: 6396.5151	loss_val: 6396.5630	loss_test: 6396.4956	accuracy_train: 0.6647	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 9109.6816	loss_val: 9109.6973	loss_test: 9109.6982	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44604.1562	loss_val: 44604.1250	loss_test: 44604.1797	accuracy_train: 0.3941	accuracy_val: 0.3636	accuracy_test: 0.3182
[client 7]	loss_train: 35257.5117	loss_val: 35257.4727	loss_test: 35257.4844	accuracy_train: 0.5352	accuracy_val: 0.5278	accuracy_test: 0.4595
[client 8]	loss_train: 1262.7104	loss_val: 1262.7683	loss_test: 1262.7565	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 35571.8125	loss_val: 35571.8711	loss_test: 35571.8242	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 15329.6182	loss_val: 15329.5469	loss_test: 15329.6211	accuracy_train: 0.5839	accuracy_val: 0.5882	accuracy_test: 0.5429
[client 11]	loss_train: 1537.3120	loss_val: 1537.3585	loss_test: 1537.3159	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 24482.9258	loss_val: 24482.9785	loss_test: 24482.9688	accuracy_train: 0.6695	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 199238.5156	loss_val: 199238.5312	loss_test: 199238.5625	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8828.9502	loss_val: 8828.9941	loss_test: 8828.9824	accuracy_train: 0.3846	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 955.9181	loss_val: 955.9980	loss_test: 955.9442	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 3763.8040	loss_val: 3763.8831	loss_test: 3763.9246	accuracy_train: 0.8214	accuracy_val: 0.2500	accuracy_test: 0.3750
[client 17]	loss_train: 20907.4141	loss_val: 20907.4375	loss_test: 20907.4121	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14361.3760	loss_val: 14361.4004	loss_test: 14361.3887	accuracy_train: 0.4081	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1491.4956	loss_val: 1491.5182	loss_test: 1491.5731	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 12	curr_val_accuracy: 0.7043	curr_test_accuracy: 0.6936
best_round: 5	best_val_accuracy: 0.7074	best_test_accuracy: 0.6883
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22088.8340	loss_val: 22088.8066	loss_test: 22088.7812	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20893.0820	loss_val: 20893.1172	loss_test: 20893.0957	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 24230.9512	loss_val: 24230.9902	loss_test: 24231.0371	accuracy_train: 0.6386	accuracy_val: 0.5455	accuracy_test: 0.4545
[client 3]	loss_train: 24262.9238	loss_val: 24262.8672	loss_test: 24262.9590	accuracy_train: 0.6667	accuracy_val: 0.8000	accuracy_test: 0.7561
[client 4]	loss_train: 6806.8857	loss_val: 6806.9395	loss_test: 6806.8691	accuracy_train: 0.6588	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 9149.5361	loss_val: 9149.5537	loss_test: 9149.5518	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50026.3594	loss_val: 50026.3242	loss_test: 50026.3750	accuracy_train: 0.4000	accuracy_val: 0.4091	accuracy_test: 0.3182
[client 7]	loss_train: 36162.1016	loss_val: 36162.0664	loss_test: 36162.0781	accuracy_train: 0.5246	accuracy_val: 0.5556	accuracy_test: 0.4324
[client 8]	loss_train: 1316.7194	loss_val: 1316.7742	loss_test: 1316.7642	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 37850.5234	loss_val: 37850.5859	loss_test: 37850.5352	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14861.1582	loss_val: 14861.0869	loss_test: 14861.1602	accuracy_train: 0.5839	accuracy_val: 0.5588	accuracy_test: 0.5429
[client 11]	loss_train: 1710.7306	loss_val: 1710.7781	loss_test: 1710.7361	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 25269.9746	loss_val: 25270.0332	loss_test: 25270.0254	accuracy_train: 0.6695	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 202172.0938	loss_val: 202172.1250	loss_test: 202172.1562	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9111.5059	loss_val: 9111.5566	loss_test: 9111.5361	accuracy_train: 0.3846	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 1051.2042	loss_val: 1051.2864	loss_test: 1051.2323	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 3780.3369	loss_val: 3780.4194	loss_test: 3780.4631	accuracy_train: 0.8750	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 17]	loss_train: 21525.9082	loss_val: 21525.9395	loss_test: 21525.9102	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14385.6602	loss_val: 14385.6846	loss_test: 14385.6738	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1503.1825	loss_val: 1503.2070	loss_test: 1503.2590	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 13	curr_val_accuracy: 0.7078	curr_test_accuracy: 0.6974
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22644.1191	loss_val: 22644.0957	loss_test: 22644.0684	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20832.2891	loss_val: 20832.3203	loss_test: 20832.3125	accuracy_train: 0.7442	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 25473.1641	loss_val: 25473.2109	loss_test: 25473.2598	accuracy_train: 0.6506	accuracy_val: 0.5455	accuracy_test: 0.4545
[client 3]	loss_train: 23116.1230	loss_val: 23116.0684	loss_test: 23116.1602	accuracy_train: 0.6604	accuracy_val: 0.7250	accuracy_test: 0.7073
[client 4]	loss_train: 7468.0234	loss_val: 7468.0835	loss_test: 7468.0083	accuracy_train: 0.6471	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 9050.9590	loss_val: 9050.9795	loss_test: 9050.9717	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54792.6680	loss_val: 54792.6289	loss_test: 54792.6836	accuracy_train: 0.4000	accuracy_val: 0.4091	accuracy_test: 0.3182
[client 7]	loss_train: 38036.7383	loss_val: 38036.6992	loss_test: 38036.7109	accuracy_train: 0.5000	accuracy_val: 0.5556	accuracy_test: 0.4595
[client 8]	loss_train: 1363.4402	loss_val: 1363.4912	loss_test: 1363.4829	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 40477.5820	loss_val: 40477.6484	loss_test: 40477.5898	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 15009.8320	loss_val: 15009.7617	loss_test: 15009.8340	accuracy_train: 0.5803	accuracy_val: 0.5588	accuracy_test: 0.5429
[client 11]	loss_train: 1888.3893	loss_val: 1888.4369	loss_test: 1888.3950	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 26168.2383	loss_val: 26168.3027	loss_test: 26168.2949	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 206700.9219	loss_val: 206700.9375	loss_test: 206700.9844	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9542.7617	loss_val: 9542.8145	loss_test: 9542.7939	accuracy_train: 0.3636	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 1138.9016	loss_val: 1138.9822	loss_test: 1138.9327	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 3830.2048	loss_val: 3830.2959	loss_test: 3830.3396	accuracy_train: 0.8929	accuracy_val: 0.3750	accuracy_test: 0.6250
[client 17]	loss_train: 21853.5781	loss_val: 21853.6172	loss_test: 21853.5859	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14422.7207	loss_val: 14422.7471	loss_test: 14422.7383	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1509.7860	loss_val: 1509.8146	loss_test: 1509.8601	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 14	curr_val_accuracy: 0.7020	curr_test_accuracy: 0.6972
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22546.8027	loss_val: 22546.7852	loss_test: 22546.7559	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 21913.8105	loss_val: 21913.8379	loss_test: 21913.8418	accuracy_train: 0.7481	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 26717.6113	loss_val: 26717.6641	loss_test: 26717.7168	accuracy_train: 0.6627	accuracy_val: 0.6364	accuracy_test: 0.4545
[client 3]	loss_train: 21539.8809	loss_val: 21539.8320	loss_test: 21539.9199	accuracy_train: 0.6604	accuracy_val: 0.7250	accuracy_test: 0.6585
[client 4]	loss_train: 8159.9819	loss_val: 8160.0493	loss_test: 8159.9663	accuracy_train: 0.6471	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 9078.6074	loss_val: 9078.6279	loss_test: 9078.6182	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 58451.6562	loss_val: 58451.6211	loss_test: 58451.6758	accuracy_train: 0.4000	accuracy_val: 0.4091	accuracy_test: 0.3182
[client 7]	loss_train: 39480.5547	loss_val: 39480.5117	loss_test: 39480.5195	accuracy_train: 0.4789	accuracy_val: 0.5556	accuracy_test: 0.4595
[client 8]	loss_train: 1392.0255	loss_val: 1392.0728	loss_test: 1392.0653	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43223.5820	loss_val: 43223.6523	loss_test: 43223.5898	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14747.4883	loss_val: 14747.4199	loss_test: 14747.4873	accuracy_train: 0.5766	accuracy_val: 0.5588	accuracy_test: 0.5429
[client 11]	loss_train: 2054.0107	loss_val: 2054.0586	loss_test: 2054.0156	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 27075.2285	loss_val: 27075.2988	loss_test: 27075.2930	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 210499.3438	loss_val: 210499.3594	loss_test: 210499.4062	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10106.4258	loss_val: 10106.4727	loss_test: 10106.4570	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 1209.9745	loss_val: 1210.0513	loss_test: 1210.0106	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4010.5981	loss_val: 4010.6987	loss_test: 4010.7478	accuracy_train: 0.8929	accuracy_val: 0.5000	accuracy_test: 0.6250
[client 17]	loss_train: 21818.9902	loss_val: 21819.0332	loss_test: 21818.9941	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14235.2393	loss_val: 14235.2695	loss_test: 14235.2607	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1519.6318	loss_val: 1519.6614	loss_test: 1519.7042	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 15	curr_val_accuracy: 0.7058	curr_test_accuracy: 0.6915
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23513.1426	loss_val: 23513.1309	loss_test: 23513.0977	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22556.7227	loss_val: 22556.7480	loss_test: 22556.7617	accuracy_train: 0.7558	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 27815.1680	loss_val: 27815.2305	loss_test: 27815.2871	accuracy_train: 0.6867	accuracy_val: 0.6364	accuracy_test: 0.4545
[client 3]	loss_train: 19986.1289	loss_val: 19986.0781	loss_test: 19986.1699	accuracy_train: 0.6635	accuracy_val: 0.7000	accuracy_test: 0.6585
[client 4]	loss_train: 8683.3545	loss_val: 8683.4287	loss_test: 8683.3389	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8837.6064	loss_val: 8837.6299	loss_test: 8837.6152	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 61228.0195	loss_val: 61227.9883	loss_test: 61228.0391	accuracy_train: 0.4118	accuracy_val: 0.4091	accuracy_test: 0.3636
[client 7]	loss_train: 38802.2031	loss_val: 38802.1641	loss_test: 38802.1758	accuracy_train: 0.4894	accuracy_val: 0.5278	accuracy_test: 0.4595
[client 8]	loss_train: 1405.7332	loss_val: 1405.7777	loss_test: 1405.7703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45840.2305	loss_val: 45840.3086	loss_test: 45840.2461	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14387.6807	loss_val: 14387.6152	loss_test: 14387.6797	accuracy_train: 0.5730	accuracy_val: 0.5588	accuracy_test: 0.5429
[client 11]	loss_train: 2190.4790	loss_val: 2190.5271	loss_test: 2190.4854	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 28386.7656	loss_val: 28386.8398	loss_test: 28386.8379	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 211444.7344	loss_val: 211444.7656	loss_test: 211444.8125	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10516.3145	loss_val: 10516.3555	loss_test: 10516.3477	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1265.7205	loss_val: 1265.7922	loss_test: 1265.7625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4117.6641	loss_val: 4117.7759	loss_test: 4117.8301	accuracy_train: 0.8929	accuracy_val: 0.5000	accuracy_test: 0.6250
[client 17]	loss_train: 21512.5508	loss_val: 21512.5996	loss_test: 21512.5605	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14256.0244	loss_val: 14256.0537	loss_test: 14256.0439	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1518.6837	loss_val: 1518.7140	loss_test: 1518.7549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 16	curr_val_accuracy: 0.7018	curr_test_accuracy: 0.6898
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24861.7695	loss_val: 24861.7598	loss_test: 24861.7266	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22979.8125	loss_val: 22979.8359	loss_test: 22979.8594	accuracy_train: 0.7674	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 29259.5430	loss_val: 29259.6152	loss_test: 29259.6777	accuracy_train: 0.6988	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 18977.6914	loss_val: 18977.6387	loss_test: 18977.7363	accuracy_train: 0.6415	accuracy_val: 0.7000	accuracy_test: 0.5854
[client 4]	loss_train: 8949.8086	loss_val: 8949.8906	loss_test: 8949.7979	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8660.5186	loss_val: 8660.5420	loss_test: 8660.5264	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 62966.0625	loss_val: 62966.0352	loss_test: 62966.0742	accuracy_train: 0.4118	accuracy_val: 0.4091	accuracy_test: 0.3636
[client 7]	loss_train: 38386.2578	loss_val: 38386.2266	loss_test: 38386.2344	accuracy_train: 0.4789	accuracy_val: 0.5278	accuracy_test: 0.4595
[client 8]	loss_train: 1408.6995	loss_val: 1408.7426	loss_test: 1408.7349	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48370.2305	loss_val: 48370.3164	loss_test: 48370.2461	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14315.0654	loss_val: 14315.0029	loss_test: 14315.0615	accuracy_train: 0.5730	accuracy_val: 0.5882	accuracy_test: 0.5429
[client 11]	loss_train: 2323.0347	loss_val: 2323.0825	loss_test: 2323.0430	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 29517.2070	loss_val: 29517.2852	loss_test: 29517.2852	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 214685.6719	loss_val: 214685.6875	loss_test: 214685.7656	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10847.3896	loss_val: 10847.4189	loss_test: 10847.4209	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1321.5038	loss_val: 1321.5704	loss_test: 1321.5518	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4344.2314	loss_val: 4344.3550	loss_test: 4344.4175	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 21250.6016	loss_val: 21250.6523	loss_test: 21250.6094	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14698.0850	loss_val: 14698.1172	loss_test: 14698.1084	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1526.1484	loss_val: 1526.1804	loss_test: 1526.2183	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 17	curr_val_accuracy: 0.7037	curr_test_accuracy: 0.6858
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26153.7344	loss_val: 26153.7266	loss_test: 26153.6934	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22846.0156	loss_val: 22846.0391	loss_test: 22846.0684	accuracy_train: 0.7713	accuracy_val: 0.8438	accuracy_test: 0.7353
[client 2]	loss_train: 30566.2441	loss_val: 30566.3262	loss_test: 30566.3906	accuracy_train: 0.7108	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 18290.0410	loss_val: 18289.9883	loss_test: 18290.0859	accuracy_train: 0.6384	accuracy_val: 0.6750	accuracy_test: 0.5854
[client 4]	loss_train: 8871.7939	loss_val: 8871.8848	loss_test: 8871.7842	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8450.8730	loss_val: 8450.8975	loss_test: 8450.8818	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 63571.4688	loss_val: 63571.4414	loss_test: 63571.4805	accuracy_train: 0.4059	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 37676.2695	loss_val: 37676.2461	loss_test: 37676.2461	accuracy_train: 0.4789	accuracy_val: 0.5278	accuracy_test: 0.4595
[client 8]	loss_train: 1394.6173	loss_val: 1394.6591	loss_test: 1394.6501	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51107.0273	loss_val: 51107.1133	loss_test: 51107.0430	accuracy_train: 0.8077	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14394.6318	loss_val: 14394.5723	loss_test: 14394.6260	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2424.2310	loss_val: 2424.2791	loss_test: 2424.2407	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 30264.4570	loss_val: 30264.5371	loss_test: 30264.5410	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 221222.3438	loss_val: 221222.3594	loss_test: 221222.4375	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11176.1855	loss_val: 11176.2061	loss_test: 11176.2158	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1370.5012	loss_val: 1370.5632	loss_test: 1370.5552	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4550.4229	loss_val: 4550.5591	loss_test: 4550.6279	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 21082.8594	loss_val: 21082.9141	loss_test: 21082.8652	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15072.2686	loss_val: 15072.3037	loss_test: 15072.2969	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1525.3181	loss_val: 1525.3510	loss_test: 1525.3868	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 18	curr_val_accuracy: 0.7057	curr_test_accuracy: 0.6880
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26785.9512	loss_val: 26785.9473	loss_test: 26785.9141	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22989.2324	loss_val: 22989.2539	loss_test: 22989.2930	accuracy_train: 0.7791	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 31765.6309	loss_val: 31765.7246	loss_test: 31765.7949	accuracy_train: 0.7108	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 18002.3027	loss_val: 18002.2520	loss_test: 18002.3457	accuracy_train: 0.6384	accuracy_val: 0.6750	accuracy_test: 0.6098
[client 4]	loss_train: 8591.7256	loss_val: 8591.8252	loss_test: 8591.7168	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8255.2891	loss_val: 8255.3154	loss_test: 8255.2979	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 62521.6172	loss_val: 62521.5938	loss_test: 62521.6211	accuracy_train: 0.4118	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 36617.5312	loss_val: 36617.5039	loss_test: 36617.5000	accuracy_train: 0.4824	accuracy_val: 0.5278	accuracy_test: 0.4324
[client 8]	loss_train: 1384.7269	loss_val: 1384.7675	loss_test: 1384.7593	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53864.3359	loss_val: 53864.4258	loss_test: 53864.3555	accuracy_train: 0.8269	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 14326.3662	loss_val: 14326.3096	loss_test: 14326.3594	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2465.8220	loss_val: 2465.8701	loss_test: 2465.8337	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 31147.1406	loss_val: 31147.2246	loss_test: 31147.2324	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 223756.5469	loss_val: 223756.5625	loss_test: 223756.6562	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11413.6777	loss_val: 11413.6885	loss_test: 11413.7100	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1405.6058	loss_val: 1405.6637	loss_test: 1405.6656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4828.8823	loss_val: 4829.0342	loss_test: 4829.1108	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 21167.4141	loss_val: 21167.4688	loss_test: 21167.4180	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15818.2705	loss_val: 15818.3096	loss_test: 15818.3047	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1514.2238	loss_val: 1514.2552	loss_test: 1514.2924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 19	curr_val_accuracy: 0.7077	curr_test_accuracy: 0.6899
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27620.4375	loss_val: 27620.4355	loss_test: 27620.4023	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 23530.8301	loss_val: 23530.8516	loss_test: 23530.8984	accuracy_train: 0.7868	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 33145.8789	loss_val: 33145.9844	loss_test: 33146.0625	accuracy_train: 0.7229	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 18036.8086	loss_val: 18036.7598	loss_test: 18036.8477	accuracy_train: 0.6226	accuracy_val: 0.6750	accuracy_test: 0.5854
[client 4]	loss_train: 8265.4688	loss_val: 8265.5771	loss_test: 8265.4609	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8016.4541	loss_val: 8016.4839	loss_test: 8016.4624	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 59259.2031	loss_val: 59259.1797	loss_test: 59259.2031	accuracy_train: 0.4235	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 35842.3359	loss_val: 35842.3125	loss_test: 35842.3086	accuracy_train: 0.4718	accuracy_val: 0.5278	accuracy_test: 0.4324
[client 8]	loss_train: 1375.4005	loss_val: 1375.4406	loss_test: 1375.4325	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56687.4180	loss_val: 56687.5195	loss_test: 56687.4414	accuracy_train: 0.8269	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 14125.0498	loss_val: 14124.9932	loss_test: 14125.0420	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2537.7244	loss_val: 2537.7734	loss_test: 2537.7361	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 32269.6719	loss_val: 32269.7598	loss_test: 32269.7695	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 221894.5156	loss_val: 221894.5312	loss_test: 221894.6250	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11513.9951	loss_val: 11513.9961	loss_test: 11514.0293	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1428.6431	loss_val: 1428.6979	loss_test: 1428.7078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4987.4419	loss_val: 4987.6064	loss_test: 4987.6904	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 20932.1152	loss_val: 20932.1699	loss_test: 20932.1211	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16711.8027	loss_val: 16711.8457	loss_test: 16711.8516	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1488.8988	loss_val: 1488.9290	loss_test: 1488.9667	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 20	curr_val_accuracy: 0.7077	curr_test_accuracy: 0.6880
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28098.4590	loss_val: 28098.4590	loss_test: 28098.4277	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 24033.6953	loss_val: 24033.7129	loss_test: 24033.7695	accuracy_train: 0.7984	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 33855.1055	loss_val: 33855.2188	loss_test: 33855.3008	accuracy_train: 0.7349	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 18873.9941	loss_val: 18873.9453	loss_test: 18874.0332	accuracy_train: 0.6101	accuracy_val: 0.6500	accuracy_test: 0.5610
[client 4]	loss_train: 8295.0762	loss_val: 8295.1924	loss_test: 8295.0703	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 7887.3613	loss_val: 7887.3945	loss_test: 7887.3701	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 56689.6211	loss_val: 56689.6016	loss_test: 56689.6211	accuracy_train: 0.4353	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 34551.7773	loss_val: 34551.7539	loss_test: 34551.7461	accuracy_train: 0.4754	accuracy_val: 0.5278	accuracy_test: 0.4324
[client 8]	loss_train: 1356.9296	loss_val: 1356.9688	loss_test: 1356.9611	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58246.7852	loss_val: 58246.8984	loss_test: 58246.8164	accuracy_train: 0.8269	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 14128.5811	loss_val: 14128.5254	loss_test: 14128.5723	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2643.0354	loss_val: 2643.0854	loss_test: 2643.0469	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33053.8672	loss_val: 33053.9570	loss_test: 33053.9727	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5294
[client 13]	loss_train: 216781.0000	loss_val: 216781.0156	loss_test: 216781.1250	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11584.1670	loss_val: 11584.1592	loss_test: 11584.2031	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1452.3912	loss_val: 1452.4430	loss_test: 1452.4602	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5137.4233	loss_val: 5137.6006	loss_test: 5137.6904	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 20777.3809	loss_val: 20777.4355	loss_test: 20777.3867	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16500.7266	loss_val: 16500.7793	loss_test: 16500.7910	accuracy_train: 0.3971	accuracy_val: 0.3824	accuracy_test: 0.3429
[client 19]	loss_train: 1494.1163	loss_val: 1494.1462	loss_test: 1494.1823	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 21	curr_val_accuracy: 0.7055	curr_test_accuracy: 0.6842
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28129.5957	loss_val: 28129.5996	loss_test: 28129.5703	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 25202.8535	loss_val: 25202.8691	loss_test: 25202.9355	accuracy_train: 0.8140	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 34802.0781	loss_val: 34802.1992	loss_test: 34802.2891	accuracy_train: 0.7590	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 20851.1152	loss_val: 20851.0625	loss_test: 20851.1523	accuracy_train: 0.6069	accuracy_val: 0.6000	accuracy_test: 0.5366
[client 4]	loss_train: 8286.9697	loss_val: 8287.0928	loss_test: 8286.9688	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 7834.6045	loss_val: 7834.6436	loss_test: 7834.6157	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54003.7266	loss_val: 54003.7070	loss_test: 54003.7266	accuracy_train: 0.4529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 34187.8359	loss_val: 34187.8203	loss_test: 34187.8086	accuracy_train: 0.4859	accuracy_val: 0.5278	accuracy_test: 0.4324
[client 8]	loss_train: 1334.1749	loss_val: 1334.2126	loss_test: 1334.2067	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60832.0703	loss_val: 60832.1992	loss_test: 60832.1094	accuracy_train: 0.8846	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14441.7510	loss_val: 14441.6963	loss_test: 14441.7441	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2689.4265	loss_val: 2689.4763	loss_test: 2689.4392	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 32959.7109	loss_val: 32959.8047	loss_test: 32959.8242	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5294
[client 13]	loss_train: 208042.4688	loss_val: 208042.4844	loss_test: 208042.6094	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11654.4258	loss_val: 11654.4141	loss_test: 11654.4648	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1462.9568	loss_val: 1463.0059	loss_test: 1463.0286	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5279.3384	loss_val: 5279.5288	loss_test: 5279.6250	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 20452.1074	loss_val: 20452.1582	loss_test: 20452.1152	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15242.2822	loss_val: 15242.3340	loss_test: 15242.3457	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3429
[client 19]	loss_train: 1479.8495	loss_val: 1479.8793	loss_test: 1479.9125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 22	curr_val_accuracy: 0.7016	curr_test_accuracy: 0.6823
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28404.7109	loss_val: 28404.7168	loss_test: 28404.6934	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 25948.6230	loss_val: 25948.6348	loss_test: 25948.7109	accuracy_train: 0.8062	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 36555.9453	loss_val: 36556.0703	loss_test: 36556.1680	accuracy_train: 0.7831	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 21740.8594	loss_val: 21740.8066	loss_test: 21740.8926	accuracy_train: 0.6132	accuracy_val: 0.6000	accuracy_test: 0.5610
[client 4]	loss_train: 8206.9326	loss_val: 8207.0596	loss_test: 8206.9385	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8174.0264	loss_val: 8174.0688	loss_test: 8174.0420	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51896.8984	loss_val: 51896.8789	loss_test: 51896.8984	accuracy_train: 0.4529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 35196.2852	loss_val: 35196.2734	loss_test: 35196.2539	accuracy_train: 0.4859	accuracy_val: 0.5000	accuracy_test: 0.4324
[client 8]	loss_train: 1319.2076	loss_val: 1319.2438	loss_test: 1319.2391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 65956.0625	loss_val: 65956.2109	loss_test: 65956.1094	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 14429.5312	loss_val: 14429.4785	loss_test: 14429.5244	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2724.5037	loss_val: 2724.5540	loss_test: 2724.5203	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 31665.8672	loss_val: 31665.9688	loss_test: 31665.9883	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5294
[client 13]	loss_train: 215084.0781	loss_val: 215084.0938	loss_test: 215084.2031	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11923.8955	loss_val: 11923.8838	loss_test: 11923.9385	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1471.1226	loss_val: 1471.1697	loss_test: 1471.1946	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5417.3838	loss_val: 5417.5854	loss_test: 5417.6865	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 20149.8652	loss_val: 20149.9160	loss_test: 20149.8809	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14997.6543	loss_val: 14997.7041	loss_test: 14997.7178	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3429
[client 19]	loss_train: 1487.8757	loss_val: 1487.9055	loss_test: 1487.9354	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 23	curr_val_accuracy: 0.6996	curr_test_accuracy: 0.6842
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29036.8594	loss_val: 29036.8652	loss_test: 29036.8496	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 26486.9766	loss_val: 26486.9863	loss_test: 26487.0703	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 37593.1055	loss_val: 37593.2383	loss_test: 37593.3477	accuracy_train: 0.8072	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 21705.7012	loss_val: 21705.6484	loss_test: 21705.7285	accuracy_train: 0.6006	accuracy_val: 0.5750	accuracy_test: 0.5366
[client 4]	loss_train: 8268.1475	loss_val: 8268.2764	loss_test: 8268.1611	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8595.4229	loss_val: 8595.4717	loss_test: 8595.4443	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51753.5312	loss_val: 51753.5078	loss_test: 51753.5273	accuracy_train: 0.4588	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 36767.9648	loss_val: 36767.9648	loss_test: 36767.9414	accuracy_train: 0.5000	accuracy_val: 0.5278	accuracy_test: 0.4595
[client 8]	loss_train: 1295.9495	loss_val: 1295.9841	loss_test: 1295.9797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 72254.7188	loss_val: 72254.8906	loss_test: 72254.7656	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13938.7227	loss_val: 13938.6709	loss_test: 13938.7168	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2732.3906	loss_val: 2732.4421	loss_test: 2732.4106	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 30501.7109	loss_val: 30501.8164	loss_test: 30501.8398	accuracy_train: 0.7034	accuracy_val: 0.6000	accuracy_test: 0.5294
[client 13]	loss_train: 231089.8125	loss_val: 231089.8281	loss_test: 231089.9531	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12204.6924	loss_val: 12204.6846	loss_test: 12204.7373	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1475.0870	loss_val: 1475.1326	loss_test: 1475.1582	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5613.2822	loss_val: 5613.4946	loss_test: 5613.6011	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 20057.4238	loss_val: 20057.4746	loss_test: 20057.4492	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14747.5508	loss_val: 14747.6025	loss_test: 14747.6182	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1494.2969	loss_val: 1494.3264	loss_test: 1494.3540	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 24	curr_val_accuracy: 0.7016	curr_test_accuracy: 0.6879
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29435.2246	loss_val: 29435.2305	loss_test: 29435.2246	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 25959.9648	loss_val: 25959.9707	loss_test: 25960.0586	accuracy_train: 0.7868	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 38256.5430	loss_val: 38256.6836	loss_test: 38256.8008	accuracy_train: 0.8072	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 21868.4004	loss_val: 21868.3516	loss_test: 21868.4277	accuracy_train: 0.5818	accuracy_val: 0.5250	accuracy_test: 0.5366
[client 4]	loss_train: 8293.6221	loss_val: 8293.7529	loss_test: 8293.6416	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8813.2734	loss_val: 8813.3252	loss_test: 8813.3008	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 52737.7500	loss_val: 52737.7227	loss_test: 52737.7422	accuracy_train: 0.4706	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 36644.6367	loss_val: 36644.6406	loss_test: 36644.6133	accuracy_train: 0.4965	accuracy_val: 0.5000	accuracy_test: 0.4595
[client 8]	loss_train: 1286.7111	loss_val: 1286.7439	loss_test: 1286.7400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 78686.4453	loss_val: 78686.6406	loss_test: 78686.5000	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13258.8271	loss_val: 13258.7764	loss_test: 13258.8213	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2794.9707	loss_val: 2795.0242	loss_test: 2794.9934	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 30251.6113	loss_val: 30251.7227	loss_test: 30251.7500	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 242300.6250	loss_val: 242300.6406	loss_test: 242300.7500	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12319.8633	loss_val: 12319.8633	loss_test: 12319.9111	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1483.8901	loss_val: 1483.9340	loss_test: 1483.9604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5756.7856	loss_val: 5757.0083	loss_test: 5757.1206	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 19917.0762	loss_val: 19917.1230	loss_test: 19917.1094	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14989.5137	loss_val: 14989.5674	loss_test: 14989.5840	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1489.5441	loss_val: 1489.5721	loss_test: 1489.5997	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 25	curr_val_accuracy: 0.6995	curr_test_accuracy: 0.6917
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30198.7188	loss_val: 30198.7266	loss_test: 30198.7285	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 25076.2715	loss_val: 25076.2734	loss_test: 25076.3691	accuracy_train: 0.7829	accuracy_val: 0.8438	accuracy_test: 0.7353
[client 2]	loss_train: 38806.8047	loss_val: 38806.9531	loss_test: 38807.0820	accuracy_train: 0.8193	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 20837.0156	loss_val: 20836.9688	loss_test: 20837.0410	accuracy_train: 0.5660	accuracy_val: 0.5250	accuracy_test: 0.5366
[client 4]	loss_train: 8323.2520	loss_val: 8323.3838	loss_test: 8323.2783	accuracy_train: 0.6294	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 8185.6460	loss_val: 8185.7012	loss_test: 8185.6768	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54445.9570	loss_val: 54445.9297	loss_test: 54445.9453	accuracy_train: 0.4765	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 35525.8203	loss_val: 35525.8320	loss_test: 35525.7969	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.4595
[client 8]	loss_train: 1282.1517	loss_val: 1282.1833	loss_test: 1282.1796	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 84718.9062	loss_val: 84719.1328	loss_test: 84718.9688	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13305.1436	loss_val: 13305.0938	loss_test: 13305.1406	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2851.3125	loss_val: 2851.3674	loss_test: 2851.3374	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 30323.2070	loss_val: 30323.3223	loss_test: 30323.3496	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 246286.0938	loss_val: 246286.1094	loss_test: 246286.2344	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12316.6094	loss_val: 12316.6113	loss_test: 12316.6582	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1471.5513	loss_val: 1471.5940	loss_test: 1471.6206	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5925.7612	loss_val: 5925.9932	loss_test: 5926.1118	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 19869.1504	loss_val: 19869.1934	loss_test: 19869.1875	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14980.1885	loss_val: 14980.2441	loss_test: 14980.2656	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1469.6266	loss_val: 1469.6531	loss_test: 1469.6809	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 26	curr_val_accuracy: 0.6994	curr_test_accuracy: 0.6863
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30006.5938	loss_val: 30006.6016	loss_test: 30006.6113	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 24189.4922	loss_val: 24189.4941	loss_test: 24189.5938	accuracy_train: 0.7713	accuracy_val: 0.8438	accuracy_test: 0.7353
[client 2]	loss_train: 39778.9023	loss_val: 39779.0586	loss_test: 39779.2031	accuracy_train: 0.8193	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 19628.8301	loss_val: 19628.7832	loss_test: 19628.8574	accuracy_train: 0.5535	accuracy_val: 0.5250	accuracy_test: 0.5366
[client 4]	loss_train: 8298.2227	loss_val: 8298.3574	loss_test: 8298.2568	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 8007.1978	loss_val: 8007.2573	loss_test: 8007.2334	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 56281.2695	loss_val: 56281.2461	loss_test: 56281.2617	accuracy_train: 0.4824	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 36013.8125	loss_val: 36013.8242	loss_test: 36013.7812	accuracy_train: 0.5070	accuracy_val: 0.4722	accuracy_test: 0.4054
[client 8]	loss_train: 1274.0192	loss_val: 1274.0496	loss_test: 1274.0453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 89774.3125	loss_val: 89774.5703	loss_test: 89774.3828	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13356.6367	loss_val: 13356.5869	loss_test: 13356.6367	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2865.8325	loss_val: 2865.8901	loss_test: 2865.8606	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 31770.6133	loss_val: 31770.7344	loss_test: 31770.7637	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 242508.0938	loss_val: 242508.1250	loss_test: 242508.2344	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12282.6318	loss_val: 12282.6299	loss_test: 12282.6807	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1463.4244	loss_val: 1463.4661	loss_test: 1463.4926	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6061.4609	loss_val: 6061.7046	loss_test: 6061.8286	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 19540.6230	loss_val: 19540.6641	loss_test: 19540.6680	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15682.6084	loss_val: 15682.6660	loss_test: 15682.6904	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1452.5403	loss_val: 1452.5656	loss_test: 1452.5936	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 27	curr_val_accuracy: 0.6973	curr_test_accuracy: 0.6805
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30165.0977	loss_val: 30165.1074	loss_test: 30165.1230	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 24075.6328	loss_val: 24075.6309	loss_test: 24075.7363	accuracy_train: 0.7597	accuracy_val: 0.8125	accuracy_test: 0.7353
[client 2]	loss_train: 40935.6016	loss_val: 40935.7617	loss_test: 40935.9258	accuracy_train: 0.8193	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 18703.2012	loss_val: 18703.1504	loss_test: 18703.2305	accuracy_train: 0.5472	accuracy_val: 0.5250	accuracy_test: 0.5366
[client 4]	loss_train: 8242.5547	loss_val: 8242.6914	loss_test: 8242.5947	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 8240.1621	loss_val: 8240.2227	loss_test: 8240.2031	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 56194.8594	loss_val: 56194.8359	loss_test: 56194.8477	accuracy_train: 0.4882	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 36476.3867	loss_val: 36476.4023	loss_test: 36476.3555	accuracy_train: 0.5070	accuracy_val: 0.4444	accuracy_test: 0.4054
[client 8]	loss_train: 1274.9196	loss_val: 1274.9485	loss_test: 1274.9436	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 89509.3125	loss_val: 89509.6094	loss_test: 89509.3906	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13425.5605	loss_val: 13425.5107	loss_test: 13425.5645	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2854.4141	loss_val: 2854.4744	loss_test: 2854.4458	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33611.7188	loss_val: 33611.8438	loss_test: 33611.8750	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 240096.5312	loss_val: 240096.5625	loss_test: 240096.6875	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11992.1562	loss_val: 11992.1562	loss_test: 11992.2051	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1453.8253	loss_val: 1453.8660	loss_test: 1453.8922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6227.5234	loss_val: 6227.7778	loss_test: 6227.9082	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 19043.6074	loss_val: 19043.6484	loss_test: 19043.6621	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16261.9336	loss_val: 16261.9902	loss_test: 16262.0195	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1439.7246	loss_val: 1439.7483	loss_test: 1439.7750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 28	curr_val_accuracy: 0.6933	curr_test_accuracy: 0.6805
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30717.6660	loss_val: 30717.6777	loss_test: 30717.6973	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23898.4023	loss_val: 23898.3984	loss_test: 23898.5078	accuracy_train: 0.7597	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 42681.2695	loss_val: 42681.4297	loss_test: 42681.6250	accuracy_train: 0.8313	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 17250.4414	loss_val: 17250.3887	loss_test: 17250.4707	accuracy_train: 0.5346	accuracy_val: 0.5000	accuracy_test: 0.5366
[client 4]	loss_train: 8291.0811	loss_val: 8291.2188	loss_test: 8291.1279	accuracy_train: 0.6353	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 8076.0889	loss_val: 8076.1548	loss_test: 8076.1309	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 56948.0352	loss_val: 56948.0078	loss_test: 56948.0156	accuracy_train: 0.4882	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 36449.4844	loss_val: 36449.5039	loss_test: 36449.4531	accuracy_train: 0.5035	accuracy_val: 0.4444	accuracy_test: 0.4324
[client 8]	loss_train: 1268.9200	loss_val: 1268.9476	loss_test: 1268.9424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 88741.9453	loss_val: 88742.2812	loss_test: 88742.0312	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13199.6309	loss_val: 13199.5801	loss_test: 13199.6367	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2854.3535	loss_val: 2854.4165	loss_test: 2854.3882	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33658.3555	loss_val: 33658.4844	loss_test: 33658.5156	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 238726.2344	loss_val: 238726.2812	loss_test: 238726.3906	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11972.7773	loss_val: 11972.7783	loss_test: 11972.8271	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1441.6561	loss_val: 1441.6957	loss_test: 1441.7217	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6291.8779	loss_val: 6292.1450	loss_test: 6292.2812	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 18781.1113	loss_val: 18781.1523	loss_test: 18781.1699	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16633.1484	loss_val: 16633.2051	loss_test: 16633.2383	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1430.3506	loss_val: 1430.3724	loss_test: 1430.3973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 29	curr_val_accuracy: 0.6893	curr_test_accuracy: 0.6842
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30504.6309	loss_val: 30504.6426	loss_test: 30504.6660	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23165.4277	loss_val: 23165.4238	loss_test: 23165.5332	accuracy_train: 0.7558	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 43204.0859	loss_val: 43204.2500	loss_test: 43204.4766	accuracy_train: 0.8434	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 16290.8203	loss_val: 16290.7666	loss_test: 16290.8467	accuracy_train: 0.5189	accuracy_val: 0.5000	accuracy_test: 0.5366
[client 4]	loss_train: 8276.2002	loss_val: 8276.3428	loss_test: 8276.2539	accuracy_train: 0.6353	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 8346.2207	loss_val: 8346.2891	loss_test: 8346.2686	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 56734.1914	loss_val: 56734.1602	loss_test: 56734.1641	accuracy_train: 0.4882	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 37258.4336	loss_val: 37258.4570	loss_test: 37258.4023	accuracy_train: 0.5106	accuracy_val: 0.4444	accuracy_test: 0.4324
[client 8]	loss_train: 1263.4598	loss_val: 1263.4862	loss_test: 1263.4813	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 85130.2031	loss_val: 85130.5703	loss_test: 85130.2891	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13464.8730	loss_val: 13464.8232	loss_test: 13464.8809	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2851.6504	loss_val: 2851.7161	loss_test: 2851.6895	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34169.0273	loss_val: 34169.1641	loss_test: 34169.1953	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 235018.4375	loss_val: 235018.4844	loss_test: 235018.5938	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11971.3428	loss_val: 11971.3438	loss_test: 11971.3936	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1427.8658	loss_val: 1427.9033	loss_test: 1427.9298	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6390.8530	loss_val: 6391.1313	loss_test: 6391.2734	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 18741.2129	loss_val: 18741.2539	loss_test: 18741.2695	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16982.8066	loss_val: 16982.8633	loss_test: 16982.8945	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1432.6321	loss_val: 1432.6526	loss_test: 1432.6760	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 30	curr_val_accuracy: 0.6873	curr_test_accuracy: 0.6842
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31802.6230	loss_val: 31802.6348	loss_test: 31802.6582	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23195.5312	loss_val: 23195.5254	loss_test: 23195.6387	accuracy_train: 0.7519	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 42654.2891	loss_val: 42654.4492	loss_test: 42654.7109	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 16276.6406	loss_val: 16276.5918	loss_test: 16276.6611	accuracy_train: 0.4937	accuracy_val: 0.4750	accuracy_test: 0.5366
[client 4]	loss_train: 8192.6494	loss_val: 8192.7998	loss_test: 8192.7070	accuracy_train: 0.6353	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 8343.8340	loss_val: 8343.9014	loss_test: 8343.8877	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 55323.7695	loss_val: 55323.7422	loss_test: 55323.7383	accuracy_train: 0.4882	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 37503.0195	loss_val: 37503.0508	loss_test: 37502.9883	accuracy_train: 0.5176	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1259.1443	loss_val: 1259.1699	loss_test: 1259.1653	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 83599.3594	loss_val: 83599.7578	loss_test: 83599.4531	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13095.8086	loss_val: 13095.7607	loss_test: 13095.8193	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2832.7366	loss_val: 2832.8047	loss_test: 2832.7820	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33673.7891	loss_val: 33673.9297	loss_test: 33673.9648	accuracy_train: 0.7203	accuracy_val: 0.6667	accuracy_test: 0.4706
[client 13]	loss_train: 229042.9375	loss_val: 229042.9844	loss_test: 229043.0938	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11265.6826	loss_val: 11265.6846	loss_test: 11265.7373	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1413.8022	loss_val: 1413.8380	loss_test: 1413.8655	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6513.2686	loss_val: 6513.5566	loss_test: 6513.7061	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 18951.6738	loss_val: 18951.7188	loss_test: 18951.7344	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16946.4355	loss_val: 16946.4922	loss_test: 16946.5254	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1436.5699	loss_val: 1436.5898	loss_test: 1436.6121	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 31	curr_val_accuracy: 0.6853	curr_test_accuracy: 0.6843
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33208.5586	loss_val: 33208.5742	loss_test: 33208.5938	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23628.4238	loss_val: 23628.4160	loss_test: 23628.5332	accuracy_train: 0.7442	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 42624.8867	loss_val: 42625.0547	loss_test: 42625.3516	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 16813.6680	loss_val: 16813.6230	loss_test: 16813.6875	accuracy_train: 0.4843	accuracy_val: 0.4750	accuracy_test: 0.5122
[client 4]	loss_train: 7888.7422	loss_val: 7888.9009	loss_test: 7888.8042	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 8602.1836	loss_val: 8602.2490	loss_test: 8602.2412	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 52979.6406	loss_val: 52979.6250	loss_test: 52979.6211	accuracy_train: 0.4941	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 38289.7305	loss_val: 38289.7734	loss_test: 38289.7031	accuracy_train: 0.5352	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1257.2924	loss_val: 1257.3174	loss_test: 1257.3129	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 83683.1094	loss_val: 83683.5391	loss_test: 83683.2031	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12905.6260	loss_val: 12905.5781	loss_test: 12905.6377	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2806.3088	loss_val: 2806.3782	loss_test: 2806.3638	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33752.0938	loss_val: 33752.2422	loss_test: 33752.2773	accuracy_train: 0.7203	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 225488.6562	loss_val: 225488.7188	loss_test: 225488.8281	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10735.8984	loss_val: 10735.9014	loss_test: 10735.9590	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1405.9941	loss_val: 1406.0288	loss_test: 1406.0563	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6653.1157	loss_val: 6653.4150	loss_test: 6653.5742	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 19408.0273	loss_val: 19408.0742	loss_test: 19408.0918	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16300.7412	loss_val: 16300.7988	loss_test: 16300.8340	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1433.5986	loss_val: 1433.6184	loss_test: 1433.6398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 32	curr_val_accuracy: 0.6853	curr_test_accuracy: 0.6804
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34584.5039	loss_val: 34584.5156	loss_test: 34584.5352	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23927.8789	loss_val: 23927.8691	loss_test: 23927.9883	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42390.2031	loss_val: 42390.3750	loss_test: 42390.7070	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 17123.9180	loss_val: 17123.8750	loss_test: 17123.9414	accuracy_train: 0.4686	accuracy_val: 0.4750	accuracy_test: 0.4878
[client 4]	loss_train: 7636.1509	loss_val: 7636.3135	loss_test: 7636.2178	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 8310.2656	loss_val: 8310.3291	loss_test: 8310.3262	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50887.0859	loss_val: 50887.0703	loss_test: 50887.0625	accuracy_train: 0.4882	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 38489.3594	loss_val: 38489.4102	loss_test: 38489.3359	accuracy_train: 0.5423	accuracy_val: 0.4167	accuracy_test: 0.4324
[client 8]	loss_train: 1251.0742	loss_val: 1251.0985	loss_test: 1251.0941	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 83273.8203	loss_val: 83274.2969	loss_test: 83273.9219	accuracy_train: 0.9423	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 12563.6943	loss_val: 12563.6455	loss_test: 12563.7080	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2811.3684	loss_val: 2811.4380	loss_test: 2811.4319	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34023.4883	loss_val: 34023.6445	loss_test: 34023.6836	accuracy_train: 0.7458	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 221394.4844	loss_val: 221394.5312	loss_test: 221394.6406	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10552.3721	loss_val: 10552.3760	loss_test: 10552.4355	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1393.3373	loss_val: 1393.3711	loss_test: 1393.3978	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6798.5000	loss_val: 6798.8091	loss_test: 6798.9790	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 20138.9434	loss_val: 20138.9902	loss_test: 20139.0117	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15290.6260	loss_val: 15290.6855	loss_test: 15290.7207	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1427.0389	loss_val: 1427.0585	loss_test: 1427.0791	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 33	curr_val_accuracy: 0.6852	curr_test_accuracy: 0.6783
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34735.2266	loss_val: 34735.2383	loss_test: 34735.2500	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 24312.2812	loss_val: 24312.2734	loss_test: 24312.3926	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43156.6484	loss_val: 43156.8281	loss_test: 43157.1914	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 17143.7812	loss_val: 17143.7383	loss_test: 17143.8047	accuracy_train: 0.4591	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7477.3223	loss_val: 7477.4849	loss_test: 7477.3975	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 8366.3682	loss_val: 8366.4297	loss_test: 8366.4326	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49432.6016	loss_val: 49432.5938	loss_test: 49432.5859	accuracy_train: 0.4824	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 37479.4180	loss_val: 37479.4766	loss_test: 37479.3945	accuracy_train: 0.5352	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1253.7701	loss_val: 1253.7942	loss_test: 1253.7888	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 81137.5938	loss_val: 81138.1250	loss_test: 81137.6953	accuracy_train: 0.9423	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 12711.5742	loss_val: 12711.5234	loss_test: 12711.5898	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2852.6079	loss_val: 2852.6772	loss_test: 2852.6777	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33809.7969	loss_val: 33809.9609	loss_test: 33810.0078	accuracy_train: 0.7542	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 219938.7188	loss_val: 219938.7812	loss_test: 219938.8906	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10790.1611	loss_val: 10790.1680	loss_test: 10790.2295	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1374.3827	loss_val: 1374.4154	loss_test: 1374.4415	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6921.6953	loss_val: 6922.0137	loss_test: 6922.1934	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21344.0566	loss_val: 21344.1055	loss_test: 21344.1309	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14405.1865	loss_val: 14405.2432	loss_test: 14405.2852	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1412.4106	loss_val: 1412.4303	loss_test: 1412.4504	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 34	curr_val_accuracy: 0.6830	curr_test_accuracy: 0.6744
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34485.7930	loss_val: 34485.8047	loss_test: 34485.8125	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 24546.8770	loss_val: 24546.8691	loss_test: 24546.9902	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45472.6797	loss_val: 45472.8594	loss_test: 45473.2578	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 16505.8340	loss_val: 16505.7949	loss_test: 16505.8613	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7396.3140	loss_val: 7396.4722	loss_test: 7396.3984	accuracy_train: 0.6412	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 8004.7036	loss_val: 8004.7637	loss_test: 8004.7725	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48789.7539	loss_val: 48789.7461	loss_test: 48789.7383	accuracy_train: 0.4765	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 37423.9141	loss_val: 37423.9727	loss_test: 37423.8906	accuracy_train: 0.5317	accuracy_val: 0.4167	accuracy_test: 0.4054
[client 8]	loss_train: 1259.2672	loss_val: 1259.2919	loss_test: 1259.2845	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 78404.8594	loss_val: 78405.4297	loss_test: 78404.9609	accuracy_train: 0.9423	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 13108.8242	loss_val: 13108.7734	loss_test: 13108.8418	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2885.9456	loss_val: 2886.0134	loss_test: 2886.0203	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33786.3320	loss_val: 33786.5078	loss_test: 33786.5625	accuracy_train: 0.7542	accuracy_val: 0.8000	accuracy_test: 0.5882
[client 13]	loss_train: 219292.9531	loss_val: 219293.0156	loss_test: 219293.1094	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11015.4492	loss_val: 11015.4590	loss_test: 11015.5205	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1356.8926	loss_val: 1356.9248	loss_test: 1356.9512	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7015.8223	loss_val: 7016.1519	loss_test: 7016.3408	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 22251.6680	loss_val: 22251.7148	loss_test: 22251.7441	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13620.2930	loss_val: 13620.3486	loss_test: 13620.3955	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1393.0380	loss_val: 1393.0570	loss_test: 1393.0776	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 35	curr_val_accuracy: 0.6889	curr_test_accuracy: 0.6705
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36028.7656	loss_val: 36028.7773	loss_test: 36028.7852	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23948.8789	loss_val: 23948.8730	loss_test: 23948.9922	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43370.7930	loss_val: 43370.9766	loss_test: 43371.4023	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15967.5166	loss_val: 15967.4805	loss_test: 15967.5430	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7225.9243	loss_val: 7226.0757	loss_test: 7226.0181	accuracy_train: 0.6353	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 7607.6465	loss_val: 7607.7095	loss_test: 7607.7202	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47247.5430	loss_val: 47247.5469	loss_test: 47247.5273	accuracy_train: 0.4706	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 37889.6875	loss_val: 37889.7500	loss_test: 37889.6719	accuracy_train: 0.5352	accuracy_val: 0.4167	accuracy_test: 0.4054
[client 8]	loss_train: 1260.5859	loss_val: 1260.6106	loss_test: 1260.6027	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 74973.6797	loss_val: 74974.2969	loss_test: 74973.7734	accuracy_train: 0.9423	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 13520.7295	loss_val: 13520.6807	loss_test: 13520.7480	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2901.4597	loss_val: 2901.5276	loss_test: 2901.5374	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 32978.5156	loss_val: 32978.6992	loss_test: 32978.7734	accuracy_train: 0.8051	accuracy_val: 0.8000	accuracy_test: 0.5882
[client 13]	loss_train: 219011.6406	loss_val: 219011.7031	loss_test: 219011.7969	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11143.1270	loss_val: 11143.1396	loss_test: 11143.2012	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1351.4268	loss_val: 1351.4581	loss_test: 1351.4851	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7134.8711	loss_val: 7135.2095	loss_test: 7135.4077	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 22713.8555	loss_val: 22713.9023	loss_test: 22713.9375	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13086.7051	loss_val: 13086.7607	loss_test: 13086.8066	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1382.1334	loss_val: 1382.1519	loss_test: 1382.1722	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 36	curr_val_accuracy: 0.6869	curr_test_accuracy: 0.6705
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37460.2461	loss_val: 37460.2617	loss_test: 37460.2656	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23426.2988	loss_val: 23426.2949	loss_test: 23426.4121	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43639.2148	loss_val: 43639.4023	loss_test: 43639.8555	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15509.2607	loss_val: 15509.2256	loss_test: 15509.2881	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7208.8569	loss_val: 7209.0063	loss_test: 7208.9580	accuracy_train: 0.6353	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 7573.8164	loss_val: 7573.8818	loss_test: 7573.8960	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46526.0547	loss_val: 46526.0859	loss_test: 46526.0508	accuracy_train: 0.4882	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 37509.3633	loss_val: 37509.4258	loss_test: 37509.3477	accuracy_train: 0.5387	accuracy_val: 0.4167	accuracy_test: 0.4324
[client 8]	loss_train: 1261.2180	loss_val: 1261.2424	loss_test: 1261.2338	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 70817.0625	loss_val: 70817.7344	loss_test: 70817.1562	accuracy_train: 0.9423	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 13442.0703	loss_val: 13442.0225	loss_test: 13442.0889	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2867.2117	loss_val: 2867.2820	loss_test: 2867.2947	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 32193.8164	loss_val: 32194.0078	loss_test: 32194.1016	accuracy_train: 0.8136	accuracy_val: 0.8000	accuracy_test: 0.5882
[client 13]	loss_train: 212725.8438	loss_val: 212725.9062	loss_test: 212726.0000	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11051.4277	loss_val: 11051.4443	loss_test: 11051.5059	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1337.9939	loss_val: 1338.0240	loss_test: 1338.0521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7286.1875	loss_val: 7286.5352	loss_test: 7286.7412	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 22811.9238	loss_val: 22811.9668	loss_test: 22812.0098	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12841.8896	loss_val: 12841.9473	loss_test: 12841.9893	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1373.9371	loss_val: 1373.9554	loss_test: 1373.9749	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 37	curr_val_accuracy: 0.6869	curr_test_accuracy: 0.6744
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38134.9023	loss_val: 38134.9180	loss_test: 38134.9180	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23427.7402	loss_val: 23427.7383	loss_test: 23427.8555	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44916.5508	loss_val: 44916.7383	loss_test: 44917.2148	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15543.7217	loss_val: 15543.6846	loss_test: 15543.7490	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7318.1250	loss_val: 7318.2837	loss_test: 7318.2329	accuracy_train: 0.6353	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 7882.6851	loss_val: 7882.7505	loss_test: 7882.7681	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46296.2422	loss_val: 46296.2930	loss_test: 46296.2500	accuracy_train: 0.5118	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 37493.6914	loss_val: 37493.7617	loss_test: 37493.6914	accuracy_train: 0.5352	accuracy_val: 0.4444	accuracy_test: 0.3784
[client 8]	loss_train: 1253.4319	loss_val: 1253.4562	loss_test: 1253.4469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 67627.3047	loss_val: 67628.0391	loss_test: 67627.3984	accuracy_train: 0.9423	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 13347.0283	loss_val: 13346.9805	loss_test: 13347.0449	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2851.0762	loss_val: 2851.1504	loss_test: 2851.1621	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 31644.3867	loss_val: 31644.5879	loss_test: 31644.7051	accuracy_train: 0.8220	accuracy_val: 0.8667	accuracy_test: 0.5882
[client 13]	loss_train: 204455.9844	loss_val: 204456.0469	loss_test: 204456.1250	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10896.9814	loss_val: 10897.0049	loss_test: 10897.0645	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1324.4916	loss_val: 1324.5206	loss_test: 1324.5499	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7392.3462	loss_val: 7392.7017	loss_test: 7392.9155	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 22536.9746	loss_val: 22537.0195	loss_test: 22537.0645	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13163.7002	loss_val: 13163.7607	loss_test: 13163.7998	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1360.5155	loss_val: 1360.5334	loss_test: 1360.5511	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 38	curr_val_accuracy: 0.6909	curr_test_accuracy: 0.6705
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38235.3516	loss_val: 38235.3711	loss_test: 38235.3672	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23248.8262	loss_val: 23248.8262	loss_test: 23248.9414	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45972.2539	loss_val: 45972.4453	loss_test: 45972.9375	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15777.2891	loss_val: 15777.2520	loss_test: 15777.3164	accuracy_train: 0.4308	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7314.5703	loss_val: 7314.7446	loss_test: 7314.6841	accuracy_train: 0.6353	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 8093.3604	loss_val: 8093.4209	loss_test: 8093.4429	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45388.8984	loss_val: 45388.9648	loss_test: 45388.9102	accuracy_train: 0.5176	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 38111.9023	loss_val: 38111.9766	loss_test: 38111.9141	accuracy_train: 0.5387	accuracy_val: 0.4444	accuracy_test: 0.3514
[client 8]	loss_train: 1251.1227	loss_val: 1251.1464	loss_test: 1251.1371	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64902.0820	loss_val: 64902.8633	loss_test: 64902.1797	accuracy_train: 0.9423	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 13188.0293	loss_val: 13187.9795	loss_test: 13188.0449	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2778.9629	loss_val: 2779.0403	loss_test: 2779.0535	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 32204.5898	loss_val: 32204.8027	loss_test: 32204.9414	accuracy_train: 0.8390	accuracy_val: 0.8667	accuracy_test: 0.5882
[client 13]	loss_train: 203378.7969	loss_val: 203378.8438	loss_test: 203378.9375	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10790.0244	loss_val: 10790.0518	loss_test: 10790.1113	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1313.4680	loss_val: 1313.4963	loss_test: 1313.5253	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7499.9170	loss_val: 7500.2788	loss_test: 7500.5005	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 22036.8887	loss_val: 22036.9336	loss_test: 22036.9863	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13675.7891	loss_val: 13675.8525	loss_test: 13675.8916	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1365.6527	loss_val: 1365.6705	loss_test: 1365.6869	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 39	curr_val_accuracy: 0.6929	curr_test_accuracy: 0.6686
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37468.2109	loss_val: 37468.2266	loss_test: 37468.2227	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23120.5156	loss_val: 23120.5195	loss_test: 23120.6328	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47480.6875	loss_val: 47480.8750	loss_test: 47481.3906	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15870.1035	loss_val: 15870.0674	loss_test: 15870.1299	accuracy_train: 0.4308	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7305.2603	loss_val: 7305.4409	loss_test: 7305.3799	accuracy_train: 0.6353	accuracy_val: 0.4286	accuracy_test: 0.5833
[client 5]	loss_train: 8106.1582	loss_val: 8106.2231	loss_test: 8106.2432	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44689.0820	loss_val: 44689.1602	loss_test: 44689.1016	accuracy_train: 0.5176	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 38202.7812	loss_val: 38202.8633	loss_test: 38202.8008	accuracy_train: 0.5387	accuracy_val: 0.4444	accuracy_test: 0.3514
[client 8]	loss_train: 1234.2712	loss_val: 1234.2942	loss_test: 1234.2849	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64095.9844	loss_val: 64096.8242	loss_test: 64096.0742	accuracy_train: 0.9423	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 13120.7715	loss_val: 13120.7207	loss_test: 13120.7871	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2743.4421	loss_val: 2743.5215	loss_test: 2743.5425	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33215.0742	loss_val: 33215.2969	loss_test: 33215.4609	accuracy_train: 0.8475	accuracy_val: 0.8667	accuracy_test: 0.5882
[client 13]	loss_train: 215617.2656	loss_val: 215617.3281	loss_test: 215617.4062	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10625.0811	loss_val: 10625.1113	loss_test: 10625.1709	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1302.2745	loss_val: 1302.3024	loss_test: 1302.3307	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7586.9009	loss_val: 7587.2686	loss_test: 7587.4980	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21762.9570	loss_val: 21763.0039	loss_test: 21763.0645	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13905.4424	loss_val: 13905.5078	loss_test: 13905.5527	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1367.1394	loss_val: 1367.1571	loss_test: 1367.1729	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 40	curr_val_accuracy: 0.6908	curr_test_accuracy: 0.6686
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37020.9336	loss_val: 37020.9492	loss_test: 37020.9453	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22829.5273	loss_val: 22829.5352	loss_test: 22829.6445	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47325.6562	loss_val: 47325.8438	loss_test: 47326.3750	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15381.3398	loss_val: 15381.3047	loss_test: 15381.3672	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7328.5977	loss_val: 7328.7739	loss_test: 7328.7188	accuracy_train: 0.6353	accuracy_val: 0.4286	accuracy_test: 0.5833
[client 5]	loss_train: 8205.0498	loss_val: 8205.1182	loss_test: 8205.1396	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43971.5859	loss_val: 43971.6758	loss_test: 43971.6094	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 38879.3398	loss_val: 38879.4219	loss_test: 38879.3398	accuracy_train: 0.5387	accuracy_val: 0.4167	accuracy_test: 0.4054
[client 8]	loss_train: 1226.3152	loss_val: 1226.3375	loss_test: 1226.3284	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64146.3672	loss_val: 64147.2539	loss_test: 64146.4570	accuracy_train: 0.9423	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 12713.4307	loss_val: 12713.3789	loss_test: 12713.4453	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2767.8640	loss_val: 2767.9448	loss_test: 2767.9690	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34226.2070	loss_val: 34226.4414	loss_test: 34226.6211	accuracy_train: 0.8475	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 235596.4375	loss_val: 235596.5000	loss_test: 235596.5781	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10482.2910	loss_val: 10482.3242	loss_test: 10482.3848	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1289.5291	loss_val: 1289.5570	loss_test: 1289.5842	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7669.9951	loss_val: 7670.3672	loss_test: 7670.6025	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21434.4805	loss_val: 21434.5254	loss_test: 21434.5977	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14346.6670	loss_val: 14346.7334	loss_test: 14346.7812	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1360.3053	loss_val: 1360.3224	loss_test: 1360.3379	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 41	curr_val_accuracy: 0.6829	curr_test_accuracy: 0.6725
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36133.9531	loss_val: 36133.9688	loss_test: 36133.9688	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23498.7676	loss_val: 23498.7793	loss_test: 23498.8887	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46524.3047	loss_val: 46524.4883	loss_test: 46525.0391	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14836.1953	loss_val: 14836.1641	loss_test: 14836.2236	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7070.6411	loss_val: 7070.8076	loss_test: 7070.7607	accuracy_train: 0.6412	accuracy_val: 0.4286	accuracy_test: 0.5833
[client 5]	loss_train: 8638.6104	loss_val: 8638.6758	loss_test: 8638.6973	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42913.2031	loss_val: 42913.3008	loss_test: 42913.2305	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 39007.9883	loss_val: 39008.0742	loss_test: 39007.9805	accuracy_train: 0.5493	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1219.2488	loss_val: 1219.2703	loss_test: 1219.2617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63221.4609	loss_val: 63222.3789	loss_test: 63221.5430	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12659.4775	loss_val: 12659.4258	loss_test: 12659.4922	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2811.6411	loss_val: 2811.7241	loss_test: 2811.7449	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33585.2422	loss_val: 33585.4922	loss_test: 33585.6875	accuracy_train: 0.8475	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 247301.1094	loss_val: 247301.1875	loss_test: 247301.2812	accuracy_train: 0.9286	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10385.3047	loss_val: 10385.3418	loss_test: 10385.4023	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1277.8662	loss_val: 1277.8932	loss_test: 1277.9196	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7708.1973	loss_val: 7708.5713	loss_test: 7708.8140	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21137.5391	loss_val: 21137.5859	loss_test: 21137.6660	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14676.0605	loss_val: 14676.1270	loss_test: 14676.1758	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1350.6029	loss_val: 1350.6194	loss_test: 1350.6351	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 42	curr_val_accuracy: 0.6790	curr_test_accuracy: 0.6745
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35300.4141	loss_val: 35300.4297	loss_test: 35300.4219	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23899.3398	loss_val: 23899.3574	loss_test: 23899.4629	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45884.7305	loss_val: 45884.9180	loss_test: 45885.4727	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14144.6484	loss_val: 14144.6201	loss_test: 14144.6777	accuracy_train: 0.4434	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6817.9966	loss_val: 6818.1567	loss_test: 6818.1152	accuracy_train: 0.6412	accuracy_val: 0.4286	accuracy_test: 0.5833
[client 5]	loss_train: 7593.0859	loss_val: 7593.1597	loss_test: 7593.1797	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41499.1562	loss_val: 41499.2695	loss_test: 41499.1953	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 38159.7773	loss_val: 38159.8633	loss_test: 38159.7695	accuracy_train: 0.5423	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1215.0770	loss_val: 1215.0979	loss_test: 1215.0895	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62291.4102	loss_val: 62292.3711	loss_test: 62291.4961	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13298.0264	loss_val: 13297.9746	loss_test: 13298.0410	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2867.8101	loss_val: 2867.8955	loss_test: 2867.9131	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 34311.5781	loss_val: 34311.8398	loss_test: 34312.0391	accuracy_train: 0.8475	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 276206.6250	loss_val: 276206.7188	loss_test: 276206.8125	accuracy_train: 0.9286	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10155.0703	loss_val: 10155.1084	loss_test: 10155.1719	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1263.7083	loss_val: 1263.7346	loss_test: 1263.7599	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7698.0146	loss_val: 7698.3901	loss_test: 7698.6406	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21046.3867	loss_val: 21046.4297	loss_test: 21046.5137	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14685.5479	loss_val: 14685.6172	loss_test: 14685.6592	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1345.9703	loss_val: 1345.9861	loss_test: 1346.0020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 43	curr_val_accuracy: 0.6790	curr_test_accuracy: 0.6765
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35039.3438	loss_val: 35039.3594	loss_test: 35039.3516	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23627.0430	loss_val: 23627.0625	loss_test: 23627.1660	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46082.8008	loss_val: 46082.9922	loss_test: 46083.5508	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 13501.9395	loss_val: 13501.9121	loss_test: 13501.9688	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6773.9009	loss_val: 6774.0547	loss_test: 6774.0225	accuracy_train: 0.6412	accuracy_val: 0.4286	accuracy_test: 0.5833
[client 5]	loss_train: 7486.2842	loss_val: 7486.3589	loss_test: 7486.3862	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40464.0078	loss_val: 40464.1250	loss_test: 40464.0469	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 36103.8516	loss_val: 36103.9453	loss_test: 36103.8594	accuracy_train: 0.5387	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1220.4373	loss_val: 1220.4576	loss_test: 1220.4495	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61488.6484	loss_val: 61489.6406	loss_test: 61488.7305	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13980.3574	loss_val: 13980.3057	loss_test: 13980.3730	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2880.8857	loss_val: 2880.9751	loss_test: 2880.9878	accuracy_train: 0.6235	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 36133.9141	loss_val: 36134.1953	loss_test: 36134.3906	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 294431.1875	loss_val: 294431.2812	loss_test: 294431.3750	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10157.7588	loss_val: 10157.7979	loss_test: 10157.8623	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1263.5645	loss_val: 1263.5902	loss_test: 1263.6144	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7688.7236	loss_val: 7689.1011	loss_test: 7689.3579	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21521.6582	loss_val: 21521.7051	loss_test: 21521.7852	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14652.4229	loss_val: 14652.4951	loss_test: 14652.5342	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1345.2999	loss_val: 1345.3157	loss_test: 1345.3314	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 44	curr_val_accuracy: 0.6750	curr_test_accuracy: 0.6782
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34949.9141	loss_val: 34949.9258	loss_test: 34949.9141	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23275.6621	loss_val: 23275.6797	loss_test: 23275.7871	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48159.0156	loss_val: 48159.2188	loss_test: 48159.7695	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 13265.3291	loss_val: 13265.3018	loss_test: 13265.3613	accuracy_train: 0.4308	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7042.5557	loss_val: 7042.7017	loss_test: 7042.6831	accuracy_train: 0.6412	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 7361.3213	loss_val: 7361.3882	loss_test: 7361.4185	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39607.2305	loss_val: 39607.3477	loss_test: 39607.2656	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 34793.8594	loss_val: 34793.9609	loss_test: 34793.8711	accuracy_train: 0.5423	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1223.9680	loss_val: 1223.9873	loss_test: 1223.9801	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61230.5195	loss_val: 61231.5430	loss_test: 61230.5977	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 14121.7373	loss_val: 14121.6846	loss_test: 14121.7500	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2908.3262	loss_val: 2908.4231	loss_test: 2908.4302	accuracy_train: 0.6235	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 38781.0430	loss_val: 38781.3398	loss_test: 38781.5273	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 303674.9062	loss_val: 303675.0000	loss_test: 303675.0938	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10415.4199	loss_val: 10415.4619	loss_test: 10415.5264	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1254.1566	loss_val: 1254.1823	loss_test: 1254.2050	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7666.2739	loss_val: 7666.6519	loss_test: 7666.9165	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21505.6230	loss_val: 21505.6758	loss_test: 21505.7578	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14927.5527	loss_val: 14927.6270	loss_test: 14927.6611	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1327.0480	loss_val: 1327.0636	loss_test: 1327.0793	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 45	curr_val_accuracy: 0.6770	curr_test_accuracy: 0.6800
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34048.6367	loss_val: 34048.6523	loss_test: 34048.6250	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22866.7734	loss_val: 22866.7891	loss_test: 22866.8984	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48511.7539	loss_val: 48511.9688	loss_test: 48512.5117	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 12974.0947	loss_val: 12974.0654	loss_test: 12974.1289	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7120.9043	loss_val: 7121.0322	loss_test: 7121.0356	accuracy_train: 0.6353	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 7304.8721	loss_val: 7304.9336	loss_test: 7304.9644	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39614.1914	loss_val: 39614.3086	loss_test: 39614.2227	accuracy_train: 0.5059	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 35109.5938	loss_val: 35109.6992	loss_test: 35109.6055	accuracy_train: 0.5739	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1234.2045	loss_val: 1234.2227	loss_test: 1234.2168	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59914.8750	loss_val: 59915.9414	loss_test: 59914.9531	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13569.2500	loss_val: 13569.1953	loss_test: 13569.2617	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2980.5195	loss_val: 2980.6274	loss_test: 2980.6270	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 40722.5859	loss_val: 40722.9023	loss_test: 40723.0820	accuracy_train: 0.8475	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 299091.5938	loss_val: 299091.6875	loss_test: 299091.7812	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10523.9287	loss_val: 10523.9668	loss_test: 10524.0361	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1245.1145	loss_val: 1245.1399	loss_test: 1245.1617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7655.5254	loss_val: 7655.9038	loss_test: 7656.1753	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21340.2344	loss_val: 21340.2852	loss_test: 21340.3789	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14958.3916	loss_val: 14958.4736	loss_test: 14958.5029	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1321.8392	loss_val: 1321.8545	loss_test: 1321.8699	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 46	curr_val_accuracy: 0.6790	curr_test_accuracy: 0.6820
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32969.4648	loss_val: 32969.4805	loss_test: 32969.4375	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 23116.5039	loss_val: 23116.5195	loss_test: 23116.6328	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 49468.4609	loss_val: 49468.6836	loss_test: 49469.2188	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 12816.1406	loss_val: 12816.1113	loss_test: 12816.1787	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7122.0356	loss_val: 7122.1445	loss_test: 7122.1714	accuracy_train: 0.6353	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7696.0674	loss_val: 7696.1323	loss_test: 7696.1538	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41210.6289	loss_val: 41210.7500	loss_test: 41210.6562	accuracy_train: 0.5118	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 35254.5391	loss_val: 35254.6445	loss_test: 35254.5469	accuracy_train: 0.5704	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1237.8323	loss_val: 1237.8499	loss_test: 1237.8448	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58750.8477	loss_val: 58751.9531	loss_test: 58750.9297	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13008.7197	loss_val: 13008.6650	loss_test: 13008.7314	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3041.4734	loss_val: 3041.5881	loss_test: 3041.5896	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 41327.5664	loss_val: 41327.9023	loss_test: 41328.0664	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 287566.6562	loss_val: 287566.7500	loss_test: 287566.8438	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10843.0010	loss_val: 10843.0342	loss_test: 10843.1094	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1244.1163	loss_val: 1244.1411	loss_test: 1244.1627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7669.9141	loss_val: 7670.2944	loss_test: 7670.5742	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21438.7852	loss_val: 21438.8281	loss_test: 21438.9375	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15020.2871	loss_val: 15020.3750	loss_test: 15020.3955	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1321.4312	loss_val: 1321.4464	loss_test: 1321.4604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 47	curr_val_accuracy: 0.6811	curr_test_accuracy: 0.6838
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32579.9316	loss_val: 32579.9512	loss_test: 32579.8965	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 23032.0020	loss_val: 23032.0195	loss_test: 23032.1328	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 49071.6250	loss_val: 49071.8555	loss_test: 49072.3906	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 13629.9951	loss_val: 13629.9678	loss_test: 13630.0342	accuracy_train: 0.4308	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7007.3691	loss_val: 7007.4746	loss_test: 7007.5059	accuracy_train: 0.6353	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7509.4429	loss_val: 7509.5044	loss_test: 7509.5278	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43489.8633	loss_val: 43489.9844	loss_test: 43489.8945	accuracy_train: 0.5059	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 36123.1836	loss_val: 36123.2852	loss_test: 36123.1797	accuracy_train: 0.5599	accuracy_val: 0.3889	accuracy_test: 0.4865
[client 8]	loss_train: 1232.6653	loss_val: 1232.6820	loss_test: 1232.6780	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56742.0117	loss_val: 56743.1680	loss_test: 56742.0898	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12777.4717	loss_val: 12777.4170	loss_test: 12777.4844	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3081.5574	loss_val: 3081.6760	loss_test: 3081.6746	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 41867.9258	loss_val: 41868.2812	loss_test: 41868.4336	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 279927.1875	loss_val: 279927.2812	loss_test: 279927.3750	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11140.8916	loss_val: 11140.9180	loss_test: 11141.0000	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1248.6365	loss_val: 1248.6605	loss_test: 1248.6824	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7632.0171	loss_val: 7632.3994	loss_test: 7632.6860	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21220.8848	loss_val: 21220.9160	loss_test: 21221.0410	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14575.4512	loss_val: 14575.5439	loss_test: 14575.5576	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1308.4930	loss_val: 1308.5081	loss_test: 1308.5217	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 48	curr_val_accuracy: 0.6812	curr_test_accuracy: 0.6838
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32143.1992	loss_val: 32143.2188	loss_test: 32143.1562	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 22965.9004	loss_val: 22965.9180	loss_test: 22966.0332	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48180.8867	loss_val: 48181.1211	loss_test: 48181.6641	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 16357.8906	loss_val: 16357.8643	loss_test: 16357.9326	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7012.0029	loss_val: 7012.1167	loss_test: 7012.1411	accuracy_train: 0.6353	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7615.8799	loss_val: 7615.9385	loss_test: 7615.9648	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45646.6797	loss_val: 45646.8086	loss_test: 45646.7148	accuracy_train: 0.5118	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 35835.1719	loss_val: 35835.2734	loss_test: 35835.1602	accuracy_train: 0.5704	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1218.2095	loss_val: 1218.2260	loss_test: 1218.2224	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55849.2227	loss_val: 55850.3984	loss_test: 55849.3008	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12910.7998	loss_val: 12910.7461	loss_test: 12910.8154	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3091.6907	loss_val: 3091.8081	loss_test: 3091.8064	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 42066.8125	loss_val: 42067.1875	loss_test: 42067.3281	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 273543.4062	loss_val: 273543.5000	loss_test: 273543.5938	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11292.0107	loss_val: 11292.0322	loss_test: 11292.1191	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1253.3281	loss_val: 1253.3518	loss_test: 1253.3730	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7618.1733	loss_val: 7618.5586	loss_test: 7618.8530	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21288.9219	loss_val: 21288.9434	loss_test: 21289.0801	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14285.5996	loss_val: 14285.6904	loss_test: 14285.6963	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1296.4219	loss_val: 1296.4365	loss_test: 1296.4500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 49	curr_val_accuracy: 0.6753	curr_test_accuracy: 0.6838
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31867.3086	loss_val: 31867.3301	loss_test: 31867.2617	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 22707.1973	loss_val: 22707.2188	loss_test: 22707.3301	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47537.6758	loss_val: 47537.9219	loss_test: 47538.4609	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 17833.2383	loss_val: 17833.2168	loss_test: 17833.2832	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7040.8135	loss_val: 7040.9355	loss_test: 7040.9521	accuracy_train: 0.6353	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 7568.6885	loss_val: 7568.7456	loss_test: 7568.7759	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47117.6016	loss_val: 47117.7383	loss_test: 47117.6406	accuracy_train: 0.5118	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 37271.8555	loss_val: 37271.9609	loss_test: 37271.8438	accuracy_train: 0.5915	accuracy_val: 0.4167	accuracy_test: 0.5135
[client 8]	loss_train: 1195.6429	loss_val: 1195.6589	loss_test: 1195.6558	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54932.4727	loss_val: 54933.6875	loss_test: 54932.5508	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12877.4502	loss_val: 12877.3945	loss_test: 12877.4668	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3081.5488	loss_val: 3081.6663	loss_test: 3081.6699	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 41091.6406	loss_val: 41092.0352	loss_test: 41092.1680	accuracy_train: 0.8559	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 265012.6562	loss_val: 265012.7500	loss_test: 265012.8438	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10823.8682	loss_val: 10823.8867	loss_test: 10823.9805	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1255.8986	loss_val: 1255.9219	loss_test: 1255.9423	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7659.3970	loss_val: 7659.7832	loss_test: 7660.0864	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21028.3633	loss_val: 21028.3789	loss_test: 21028.5234	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13766.9307	loss_val: 13767.0234	loss_test: 13767.0186	accuracy_train: 0.4154	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1300.4554	loss_val: 1300.4698	loss_test: 1300.4832	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 50	curr_val_accuracy: 0.6772	curr_test_accuracy: 0.6858
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31742.9922	loss_val: 31743.0137	loss_test: 31742.9414	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 23197.4492	loss_val: 23197.4746	loss_test: 23197.5820	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46602.6641	loss_val: 46602.9141	loss_test: 46603.4648	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 17623.8535	loss_val: 17623.8301	loss_test: 17623.9004	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7076.9346	loss_val: 7077.0664	loss_test: 7077.0767	accuracy_train: 0.6353	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 7494.9766	loss_val: 7495.0308	loss_test: 7495.0654	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47518.5781	loss_val: 47518.7266	loss_test: 47518.6211	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 37553.3672	loss_val: 37553.4805	loss_test: 37553.3594	accuracy_train: 0.5775	accuracy_val: 0.3889	accuracy_test: 0.5135
[client 8]	loss_train: 1194.2294	loss_val: 1194.2445	loss_test: 1194.2417	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55257.2852	loss_val: 55258.5625	loss_test: 55257.3633	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 13278.0566	loss_val: 13277.9980	loss_test: 13278.0732	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3031.9060	loss_val: 3032.0276	loss_test: 3032.0371	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 40387.0156	loss_val: 40387.4336	loss_test: 40387.5625	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 256316.4375	loss_val: 256316.5156	loss_test: 256316.6250	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10577.3896	loss_val: 10577.4072	loss_test: 10577.5059	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1261.0525	loss_val: 1261.0751	loss_test: 1261.0952	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7727.4595	loss_val: 7727.8486	loss_test: 7728.1597	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20702.3398	loss_val: 20702.3574	loss_test: 20702.5078	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13232.7930	loss_val: 13232.8916	loss_test: 13232.8828	accuracy_train: 0.4118	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1313.3491	loss_val: 1313.3633	loss_test: 1313.3766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 51	curr_val_accuracy: 0.6752	curr_test_accuracy: 0.6838
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31593.4824	loss_val: 31593.5039	loss_test: 31593.4336	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 23375.4375	loss_val: 23375.4668	loss_test: 23375.5723	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45142.7852	loss_val: 45143.0469	loss_test: 45143.6133	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 17164.2090	loss_val: 17164.1797	loss_test: 17164.2598	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6914.1465	loss_val: 6914.2764	loss_test: 6914.2900	accuracy_train: 0.6353	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 7563.2485	loss_val: 7563.3047	loss_test: 7563.3389	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47234.6055	loss_val: 47234.7695	loss_test: 47234.6641	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 36334.2031	loss_val: 36334.3242	loss_test: 36334.2109	accuracy_train: 0.5563	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1191.8674	loss_val: 1191.8817	loss_test: 1191.8793	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55147.0742	loss_val: 55148.4258	loss_test: 55147.1523	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12924.4590	loss_val: 12924.3984	loss_test: 12924.4746	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2951.2979	loss_val: 2951.4172	loss_test: 2951.4409	accuracy_train: 0.6431	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 40452.8281	loss_val: 40453.2695	loss_test: 40453.3984	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 252244.3281	loss_val: 252244.4219	loss_test: 252244.5469	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10352.3945	loss_val: 10352.4150	loss_test: 10352.5166	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1261.5454	loss_val: 1261.5675	loss_test: 1261.5875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7765.3521	loss_val: 7765.7432	loss_test: 7766.0630	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20731.3262	loss_val: 20731.3477	loss_test: 20731.5000	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12857.3408	loss_val: 12857.4424	loss_test: 12857.4297	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1302.6960	loss_val: 1302.7095	loss_test: 1302.7231	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 52	curr_val_accuracy: 0.6693	curr_test_accuracy: 0.6836
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31378.2285	loss_val: 31378.2520	loss_test: 31378.1797	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 23008.5508	loss_val: 23008.5840	loss_test: 23008.6777	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45276.0664	loss_val: 45276.3398	loss_test: 45276.9180	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 16520.5312	loss_val: 16520.5059	loss_test: 16520.5879	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7140.6860	loss_val: 7140.7930	loss_test: 7140.8325	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7564.1987	loss_val: 7564.2554	loss_test: 7564.2905	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47416.5195	loss_val: 47416.7031	loss_test: 47416.5977	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 36542.9492	loss_val: 36543.0820	loss_test: 36542.9531	accuracy_train: 0.5599	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1188.8380	loss_val: 1188.8521	loss_test: 1188.8495	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55537.5156	loss_val: 55538.9375	loss_test: 55537.5938	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12358.6289	loss_val: 12358.5674	loss_test: 12358.6426	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2945.4617	loss_val: 2945.5776	loss_test: 2945.6165	accuracy_train: 0.6431	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 41507.4258	loss_val: 41507.8906	loss_test: 41508.0273	accuracy_train: 0.8475	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 249822.7188	loss_val: 249822.7969	loss_test: 249822.9375	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10224.4385	loss_val: 10224.4678	loss_test: 10224.5674	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1262.7983	loss_val: 1262.8202	loss_test: 1262.8407	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7822.7896	loss_val: 7823.1821	loss_test: 7823.5132	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20528.5254	loss_val: 20528.5527	loss_test: 20528.7090	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12439.7891	loss_val: 12439.8906	loss_test: 12439.8828	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1296.6976	loss_val: 1296.7103	loss_test: 1296.7245	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 53	curr_val_accuracy: 0.6673	curr_test_accuracy: 0.6836
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32738.7715	loss_val: 32738.7949	loss_test: 32738.7246	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 22108.2871	loss_val: 22108.3145	loss_test: 22108.3965	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45063.0000	loss_val: 45063.2773	loss_test: 45063.8672	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 16138.5645	loss_val: 16138.5400	loss_test: 16138.6182	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7141.4824	loss_val: 7141.5615	loss_test: 7141.6216	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7727.0845	loss_val: 7727.1411	loss_test: 7727.1748	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47747.5742	loss_val: 47747.7812	loss_test: 47747.6641	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 38281.0781	loss_val: 38281.2148	loss_test: 38281.0781	accuracy_train: 0.5563	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1187.8933	loss_val: 1187.9072	loss_test: 1187.9042	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55968.3164	loss_val: 55969.7812	loss_test: 55968.3945	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12386.4707	loss_val: 12386.4102	loss_test: 12386.4834	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2910.8093	loss_val: 2910.9158	loss_test: 2910.9612	accuracy_train: 0.6549	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 41167.9531	loss_val: 41168.4453	loss_test: 41168.6016	accuracy_train: 0.8475	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 256888.0938	loss_val: 256888.1719	loss_test: 256888.3281	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10350.3750	loss_val: 10350.4141	loss_test: 10350.5078	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1253.7487	loss_val: 1253.7705	loss_test: 1253.7913	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7957.1729	loss_val: 7957.5679	loss_test: 7957.9111	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20228.1309	loss_val: 20228.1582	loss_test: 20228.3262	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12293.8906	loss_val: 12293.9932	loss_test: 12293.9844	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1308.8662	loss_val: 1308.8779	loss_test: 1308.8921	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 54	curr_val_accuracy: 0.6673	curr_test_accuracy: 0.6816
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33482.8281	loss_val: 33482.8516	loss_test: 33482.7812	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 23157.2891	loss_val: 23157.3047	loss_test: 23157.3906	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46181.1367	loss_val: 46181.4141	loss_test: 46182.0117	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15773.0830	loss_val: 15773.0576	loss_test: 15773.1357	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7088.6934	loss_val: 7088.7583	loss_test: 7088.8301	accuracy_train: 0.6235	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7681.6147	loss_val: 7681.6709	loss_test: 7681.7036	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47424.4414	loss_val: 47424.6719	loss_test: 47424.5430	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 36017.9297	loss_val: 36018.0664	loss_test: 36017.9375	accuracy_train: 0.5634	accuracy_val: 0.4167	accuracy_test: 0.4324
[client 8]	loss_train: 1193.3950	loss_val: 1193.4093	loss_test: 1193.4055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57557.1797	loss_val: 57558.7031	loss_test: 57557.2617	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12574.4170	loss_val: 12574.3564	loss_test: 12574.4307	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2903.6401	loss_val: 2903.7446	loss_test: 2903.7888	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 41204.1953	loss_val: 41204.7148	loss_test: 41204.9023	accuracy_train: 0.8644	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 268290.6562	loss_val: 268290.7500	loss_test: 268290.9062	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10590.4961	loss_val: 10590.5361	loss_test: 10590.6279	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1233.4561	loss_val: 1233.4774	loss_test: 1233.4994	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7907.7754	loss_val: 7908.1748	loss_test: 7908.5259	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19951.4551	loss_val: 19951.4746	loss_test: 19951.6445	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12582.5586	loss_val: 12582.6631	loss_test: 12582.6523	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1310.5292	loss_val: 1310.5399	loss_test: 1310.5536	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 55	curr_val_accuracy: 0.6713	curr_test_accuracy: 0.6758
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32035.7734	loss_val: 32035.7988	loss_test: 32035.7324	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 24667.4941	loss_val: 24667.5098	loss_test: 24667.5977	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46958.6953	loss_val: 46958.9766	loss_test: 46959.5781	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15133.2393	loss_val: 15133.2148	loss_test: 15133.2910	accuracy_train: 0.4434	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7088.2876	loss_val: 7088.3608	loss_test: 7088.4219	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7559.7383	loss_val: 7559.7964	loss_test: 7559.8286	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47581.9688	loss_val: 47582.2109	loss_test: 47582.0781	accuracy_train: 0.5118	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 35311.4258	loss_val: 35311.5586	loss_test: 35311.4570	accuracy_train: 0.5669	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1209.7512	loss_val: 1209.7654	loss_test: 1209.7614	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57888.5312	loss_val: 57890.1172	loss_test: 57888.6133	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12864.1191	loss_val: 12864.0557	loss_test: 12864.1338	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2858.7781	loss_val: 2858.8809	loss_test: 2858.9297	accuracy_train: 0.6431	accuracy_val: 0.5938	accuracy_test: 0.5758
[client 12]	loss_train: 40129.5938	loss_val: 40130.1367	loss_test: 40130.3555	accuracy_train: 0.8729	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 264291.9375	loss_val: 264292.0312	loss_test: 264292.2188	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10721.2510	loss_val: 10721.2881	loss_test: 10721.3828	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1214.3430	loss_val: 1214.3640	loss_test: 1214.3872	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7774.4985	loss_val: 7774.9043	loss_test: 7775.2598	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19899.4199	loss_val: 19899.4316	loss_test: 19899.6113	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13140.3447	loss_val: 13140.4541	loss_test: 13140.4395	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1305.9320	loss_val: 1305.9421	loss_test: 1305.9553	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 56	curr_val_accuracy: 0.6733	curr_test_accuracy: 0.6778
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32105.7344	loss_val: 32105.7598	loss_test: 32105.6934	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 25374.5410	loss_val: 25374.5566	loss_test: 25374.6445	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47281.0039	loss_val: 47281.2852	loss_test: 47281.8867	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15016.6533	loss_val: 15016.6260	loss_test: 15016.7051	accuracy_train: 0.4434	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7001.5376	loss_val: 7001.6265	loss_test: 7001.6704	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7742.5898	loss_val: 7742.6514	loss_test: 7742.6875	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47946.2422	loss_val: 47946.5039	loss_test: 47946.3633	accuracy_train: 0.5118	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 36913.5078	loss_val: 36913.6445	loss_test: 36913.5312	accuracy_train: 0.5634	accuracy_val: 0.4444	accuracy_test: 0.4324
[client 8]	loss_train: 1209.8334	loss_val: 1209.8474	loss_test: 1209.8433	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58230.5859	loss_val: 58232.2383	loss_test: 58230.6680	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13162.7090	loss_val: 13162.6426	loss_test: 13162.7207	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2874.5869	loss_val: 2874.6917	loss_test: 2874.7432	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 39660.6992	loss_val: 39661.2734	loss_test: 39661.5117	accuracy_train: 0.8729	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 258903.7969	loss_val: 258903.8750	loss_test: 258904.0781	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10887.6816	loss_val: 10887.7168	loss_test: 10887.8135	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 1214.4912	loss_val: 1214.5120	loss_test: 1214.5358	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7723.8418	loss_val: 7724.2549	loss_test: 7724.6094	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19965.3828	loss_val: 19965.3867	loss_test: 19965.5723	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13812.7266	loss_val: 13812.8398	loss_test: 13812.8223	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1300.0439	loss_val: 1300.0535	loss_test: 1300.0664	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 57	curr_val_accuracy: 0.6753	curr_test_accuracy: 0.6796
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31123.0098	loss_val: 31123.0352	loss_test: 31122.9707	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 25979.7832	loss_val: 25979.7969	loss_test: 25979.8828	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47780.3438	loss_val: 47780.6211	loss_test: 47781.2227	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14862.9717	loss_val: 14862.9463	loss_test: 14863.0234	accuracy_train: 0.4434	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6839.4785	loss_val: 6839.5747	loss_test: 6839.6050	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7863.4175	loss_val: 7863.4814	loss_test: 7863.5215	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48624.6406	loss_val: 48624.9258	loss_test: 48624.7734	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 38339.0469	loss_val: 38339.1797	loss_test: 38339.0547	accuracy_train: 0.6021	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1213.7195	loss_val: 1213.7334	loss_test: 1213.7292	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57912.8242	loss_val: 57914.5547	loss_test: 57912.9062	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12956.2334	loss_val: 12956.1650	loss_test: 12956.2422	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2904.7773	loss_val: 2904.8857	loss_test: 2904.9382	accuracy_train: 0.6588	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 40296.7344	loss_val: 40297.3359	loss_test: 40297.5977	accuracy_train: 0.8729	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 258186.1562	loss_val: 258186.2344	loss_test: 258186.4531	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10945.5371	loss_val: 10945.5771	loss_test: 10945.6699	accuracy_train: 0.3147	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 1202.3143	loss_val: 1202.3347	loss_test: 1202.3590	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7760.2944	loss_val: 7760.7148	loss_test: 7761.0688	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19864.7129	loss_val: 19864.7207	loss_test: 19864.9043	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14183.2441	loss_val: 14183.3604	loss_test: 14183.3398	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1272.7477	loss_val: 1272.7563	loss_test: 1272.7692	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 58	curr_val_accuracy: 0.6732	curr_test_accuracy: 0.6854
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30841.0098	loss_val: 30841.0352	loss_test: 30840.9707	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 25942.8984	loss_val: 25942.9102	loss_test: 25942.9941	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47207.6992	loss_val: 47207.9727	loss_test: 47208.5703	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14474.6094	loss_val: 14474.5889	loss_test: 14474.6621	accuracy_train: 0.4434	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6799.4878	loss_val: 6799.5859	loss_test: 6799.6089	accuracy_train: 0.6235	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7666.1919	loss_val: 7666.2593	loss_test: 7666.2949	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48872.6133	loss_val: 48872.9141	loss_test: 48872.7578	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 37433.3203	loss_val: 37433.4492	loss_test: 37433.3203	accuracy_train: 0.6021	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1217.1027	loss_val: 1217.1161	loss_test: 1217.1123	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62868.1211	loss_val: 62869.9180	loss_test: 62868.1992	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12829.6162	loss_val: 12829.5488	loss_test: 12829.6250	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2989.3413	loss_val: 2989.4534	loss_test: 2989.5039	accuracy_train: 0.6627	accuracy_val: 0.5625	accuracy_test: 0.6061
[client 12]	loss_train: 40840.7344	loss_val: 40841.3633	loss_test: 40841.6367	accuracy_train: 0.8814	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 262596.2500	loss_val: 262596.3125	loss_test: 262596.5625	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11149.3115	loss_val: 11149.3555	loss_test: 11149.4424	accuracy_train: 0.3147	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 1199.0752	loss_val: 1199.0956	loss_test: 1199.1206	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7783.4238	loss_val: 7783.8501	loss_test: 7784.2056	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19677.2070	loss_val: 19677.2148	loss_test: 19677.4023	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14272.8047	loss_val: 14272.9219	loss_test: 14272.8984	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1259.8065	loss_val: 1259.8149	loss_test: 1259.8280	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 59	curr_val_accuracy: 0.6732	curr_test_accuracy: 0.6854
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31012.8203	loss_val: 31012.8477	loss_test: 31012.7852	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 24325.7695	loss_val: 24325.7812	loss_test: 24325.8613	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46173.4961	loss_val: 46173.7695	loss_test: 46174.3672	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14847.3779	loss_val: 14847.3623	loss_test: 14847.4326	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6639.8457	loss_val: 6639.9438	loss_test: 6639.9619	accuracy_train: 0.6235	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 8754.0908	loss_val: 8754.1572	loss_test: 8754.1904	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47883.3086	loss_val: 47883.6211	loss_test: 47883.4570	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 38994.8984	loss_val: 38995.0352	loss_test: 38994.8945	accuracy_train: 0.6127	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1202.4690	loss_val: 1202.4822	loss_test: 1202.4786	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59825.3906	loss_val: 59827.2773	loss_test: 59825.4727	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12948.6562	loss_val: 12948.5879	loss_test: 12948.6660	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3062.2812	loss_val: 3062.3936	loss_test: 3062.4380	accuracy_train: 0.6549	accuracy_val: 0.5938	accuracy_test: 0.6364
[client 12]	loss_train: 41213.3047	loss_val: 41213.9648	loss_test: 41214.2461	accuracy_train: 0.8898	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 262894.1250	loss_val: 262894.1875	loss_test: 262894.4375	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 11160.0615	loss_val: 11160.1055	loss_test: 11160.1924	accuracy_train: 0.3147	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 1187.9348	loss_val: 1187.9553	loss_test: 1187.9807	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7774.9194	loss_val: 7775.3516	loss_test: 7775.7080	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19528.6055	loss_val: 19528.6270	loss_test: 19528.8086	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14482.9707	loss_val: 14483.0869	loss_test: 14483.0586	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1247.5798	loss_val: 1247.5883	loss_test: 1247.6003	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 60	curr_val_accuracy: 0.6713	curr_test_accuracy: 0.6834
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31848.1387	loss_val: 31848.1680	loss_test: 31848.1035	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 23110.5195	loss_val: 23110.5332	loss_test: 23110.6133	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46945.9141	loss_val: 46946.1914	loss_test: 46946.7891	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 15311.8037	loss_val: 15311.7832	loss_test: 15311.8555	accuracy_train: 0.4403	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6457.0356	loss_val: 6457.1060	loss_test: 6457.1431	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 8275.6387	loss_val: 8275.6973	loss_test: 8275.7266	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47441.7656	loss_val: 47442.0898	loss_test: 47441.9180	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 39241.7266	loss_val: 39241.8594	loss_test: 39241.7266	accuracy_train: 0.6162	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1194.9574	loss_val: 1194.9707	loss_test: 1194.9670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61149.2422	loss_val: 61151.1875	loss_test: 61149.3242	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13555.8545	loss_val: 13555.7871	loss_test: 13555.8672	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3083.1331	loss_val: 3083.2378	loss_test: 3083.2781	accuracy_train: 0.6549	accuracy_val: 0.5938	accuracy_test: 0.6667
[client 12]	loss_train: 40654.6328	loss_val: 40655.3203	loss_test: 40655.6055	accuracy_train: 0.8983	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 260875.6406	loss_val: 260875.7031	loss_test: 260875.9844	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 11124.0850	loss_val: 11124.1299	loss_test: 11124.2188	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 1181.2706	loss_val: 1181.2915	loss_test: 1181.3167	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7788.3008	loss_val: 7788.7388	loss_test: 7789.0967	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19688.2266	loss_val: 19688.2598	loss_test: 19688.4375	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14410.2920	loss_val: 14410.4043	loss_test: 14410.3740	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1250.3147	loss_val: 1250.3235	loss_test: 1250.3346	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 61	curr_val_accuracy: 0.6793	curr_test_accuracy: 0.6892
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31785.3047	loss_val: 31785.3398	loss_test: 31785.2754	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 22469.9199	loss_val: 22469.9336	loss_test: 22470.0117	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45811.9141	loss_val: 45812.2188	loss_test: 45812.7930	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 15332.8486	loss_val: 15332.8223	loss_test: 15332.8975	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6396.3662	loss_val: 6396.4453	loss_test: 6396.4702	accuracy_train: 0.6235	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 6975.5078	loss_val: 6975.5698	loss_test: 6975.6069	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47189.0391	loss_val: 47189.3711	loss_test: 47189.1992	accuracy_train: 0.5588	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 37933.8945	loss_val: 37934.0156	loss_test: 37933.8984	accuracy_train: 0.6162	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1185.4266	loss_val: 1185.4397	loss_test: 1185.4364	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59626.5312	loss_val: 59628.5273	loss_test: 59626.6172	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 14011.8350	loss_val: 14011.7705	loss_test: 14011.8496	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3064.2913	loss_val: 3064.3899	loss_test: 3064.4304	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 12]	loss_train: 39736.7891	loss_val: 39737.5078	loss_test: 39737.8086	accuracy_train: 0.9153	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 255224.6406	loss_val: 255224.6875	loss_test: 255224.9844	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 11480.2188	loss_val: 11480.2725	loss_test: 11480.3604	accuracy_train: 0.3077	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 1169.2827	loss_val: 1169.3041	loss_test: 1169.3282	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7789.5215	loss_val: 7789.9634	loss_test: 7790.3252	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20382.4102	loss_val: 20382.4492	loss_test: 20382.6191	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14478.6572	loss_val: 14478.7705	loss_test: 14478.7354	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1244.9456	loss_val: 1244.9546	loss_test: 1244.9650	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 62	curr_val_accuracy: 0.6772	curr_test_accuracy: 0.6892
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31339.4727	loss_val: 31339.5039	loss_test: 31339.4414	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 21945.5371	loss_val: 21945.5488	loss_test: 21945.6289	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45378.4609	loss_val: 45378.8477	loss_test: 45379.3438	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 14756.7334	loss_val: 14756.7109	loss_test: 14756.7803	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6549.4370	loss_val: 6549.5347	loss_test: 6549.5405	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7119.3379	loss_val: 7119.4033	loss_test: 7119.4507	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47175.8477	loss_val: 47176.1953	loss_test: 47176.0234	accuracy_train: 0.5765	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 37506.7344	loss_val: 37506.8555	loss_test: 37506.7422	accuracy_train: 0.6127	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1174.7458	loss_val: 1174.7585	loss_test: 1174.7556	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58640.7109	loss_val: 58642.7148	loss_test: 58640.8008	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13448.5127	loss_val: 13448.4521	loss_test: 13448.5273	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3030.3928	loss_val: 3030.4900	loss_test: 3030.5337	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 12]	loss_train: 38865.9180	loss_val: 38866.6523	loss_test: 38866.9844	accuracy_train: 0.9153	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 253603.7344	loss_val: 253603.7969	loss_test: 253604.1094	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11581.7764	loss_val: 11581.8428	loss_test: 11581.9248	accuracy_train: 0.3147	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 15]	loss_train: 1158.6367	loss_val: 1158.6584	loss_test: 1158.6814	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7770.9092	loss_val: 7771.3540	loss_test: 7771.7192	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 20976.2402	loss_val: 20976.2852	loss_test: 20976.4512	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14608.9053	loss_val: 14609.0273	loss_test: 14608.9844	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1250.2915	loss_val: 1250.3008	loss_test: 1250.3105	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 63	curr_val_accuracy: 0.6753	curr_test_accuracy: 0.6949
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31013.5508	loss_val: 31013.5859	loss_test: 31013.5215	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 21792.4727	loss_val: 21792.4824	loss_test: 21792.5664	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44545.0781	loss_val: 44545.6367	loss_test: 44545.9727	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14480.0283	loss_val: 14480.0068	loss_test: 14480.0742	accuracy_train: 0.4025	accuracy_val: 0.4250	accuracy_test: 0.3902
[client 4]	loss_train: 6500.0776	loss_val: 6500.1787	loss_test: 6500.1807	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7500.0933	loss_val: 7500.1636	loss_test: 7500.2095	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47402.1250	loss_val: 47402.4961	loss_test: 47402.3125	accuracy_train: 0.5824	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 37551.3438	loss_val: 37551.4688	loss_test: 37551.3516	accuracy_train: 0.6092	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1171.7324	loss_val: 1171.7444	loss_test: 1171.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57629.7461	loss_val: 57631.7539	loss_test: 57629.8398	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13238.2812	loss_val: 13238.2217	loss_test: 13238.2939	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2969.3840	loss_val: 2969.4844	loss_test: 2969.5337	accuracy_train: 0.6431	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 37879.9844	loss_val: 37880.7344	loss_test: 37881.0977	accuracy_train: 0.9068	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 264726.1562	loss_val: 264726.2188	loss_test: 264726.5312	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11414.2842	loss_val: 11414.3682	loss_test: 11414.4375	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 15]	loss_train: 1152.0516	loss_val: 1152.0734	loss_test: 1152.0953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7760.7280	loss_val: 7761.1738	loss_test: 7761.5449	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21275.0703	loss_val: 21275.1172	loss_test: 21275.2852	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14738.3691	loss_val: 14738.5000	loss_test: 14738.4551	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1253.7883	loss_val: 1253.7977	loss_test: 1253.8069	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 64	curr_val_accuracy: 0.6733	curr_test_accuracy: 0.6948
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31134.8965	loss_val: 31134.9355	loss_test: 31134.8711	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 21644.6289	loss_val: 21644.6367	loss_test: 21644.7227	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43183.7148	loss_val: 43184.5117	loss_test: 43184.6250	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15288.7051	loss_val: 15288.6758	loss_test: 15288.7510	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6619.0044	loss_val: 6619.0879	loss_test: 6619.1177	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7041.4268	loss_val: 7041.5151	loss_test: 7041.5552	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46339.1250	loss_val: 46339.5352	loss_test: 46339.3359	accuracy_train: 0.5824	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 38550.7773	loss_val: 38550.9062	loss_test: 38550.7734	accuracy_train: 0.6056	accuracy_val: 0.4167	accuracy_test: 0.5676
[client 8]	loss_train: 1168.2982	loss_val: 1168.3098	loss_test: 1168.3079	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57701.5898	loss_val: 57703.6094	loss_test: 57701.6875	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13149.3047	loss_val: 13149.2432	loss_test: 13149.3164	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2953.0928	loss_val: 2953.2026	loss_test: 2953.2578	accuracy_train: 0.6627	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36967.3320	loss_val: 36968.0977	loss_test: 36968.4922	accuracy_train: 0.9068	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 266891.8438	loss_val: 266891.9375	loss_test: 266892.2500	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11069.2627	loss_val: 11069.3613	loss_test: 11069.4160	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 1143.7200	loss_val: 1143.7412	loss_test: 1143.7632	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7753.6826	loss_val: 7754.1299	loss_test: 7754.5039	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21492.3496	loss_val: 21492.3965	loss_test: 21492.5703	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14330.4551	loss_val: 14330.5869	loss_test: 14330.5410	accuracy_train: 0.4118	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1264.4291	loss_val: 1264.4384	loss_test: 1264.4468	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 65	curr_val_accuracy: 0.6712	curr_test_accuracy: 0.6967
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32762.6562	loss_val: 32762.6992	loss_test: 32762.6348	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 22076.4961	loss_val: 22076.5020	loss_test: 22076.5879	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43000.0117	loss_val: 43001.0156	loss_test: 43000.9453	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16781.8887	loss_val: 16781.8555	loss_test: 16781.9375	accuracy_train: 0.4340	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7002.6494	loss_val: 7002.7231	loss_test: 7002.7734	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7120.4097	loss_val: 7120.5054	loss_test: 7120.5469	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45740.3867	loss_val: 45740.8359	loss_test: 45740.6055	accuracy_train: 0.5824	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 38420.8242	loss_val: 38420.9609	loss_test: 38420.8164	accuracy_train: 0.5986	accuracy_val: 0.3889	accuracy_test: 0.5405
[client 8]	loss_train: 1169.2687	loss_val: 1169.2798	loss_test: 1169.2778	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58169.1250	loss_val: 58171.1641	loss_test: 58169.2305	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13192.7051	loss_val: 13192.6406	loss_test: 13192.7188	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2995.6111	loss_val: 2995.7329	loss_test: 2995.7981	accuracy_train: 0.6745	accuracy_val: 0.6562	accuracy_test: 0.5758
[client 12]	loss_train: 36616.4062	loss_val: 36617.1836	loss_test: 36617.6133	accuracy_train: 0.9153	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 275972.5625	loss_val: 275972.6562	loss_test: 275972.9688	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10396.5186	loss_val: 10396.6270	loss_test: 10396.6738	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 1140.3593	loss_val: 1140.3798	loss_test: 1140.4023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7729.0381	loss_val: 7729.4878	loss_test: 7729.8647	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21361.0293	loss_val: 21361.0742	loss_test: 21361.2500	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14017.1172	loss_val: 14017.2461	loss_test: 14017.2012	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1274.3337	loss_val: 1274.3429	loss_test: 1274.3511	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 66	curr_val_accuracy: 0.6774	curr_test_accuracy: 0.6928
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30930.7461	loss_val: 30930.7910	loss_test: 30930.7266	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 1]	loss_train: 22624.9473	loss_val: 22624.9492	loss_test: 22625.0352	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41173.5430	loss_val: 41174.7227	loss_test: 41174.5156	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 19137.8867	loss_val: 19137.8594	loss_test: 19137.9395	accuracy_train: 0.4403	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7121.4404	loss_val: 7121.5293	loss_test: 7121.5640	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7425.9424	loss_val: 7426.0366	loss_test: 7426.0708	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45819.4297	loss_val: 45819.9023	loss_test: 45819.6523	accuracy_train: 0.5941	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 36682.7852	loss_val: 36682.9219	loss_test: 36682.7812	accuracy_train: 0.5775	accuracy_val: 0.3611	accuracy_test: 0.5135
[client 8]	loss_train: 1170.6150	loss_val: 1170.6259	loss_test: 1170.6239	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55326.5625	loss_val: 55328.5703	loss_test: 55326.6758	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12840.8516	loss_val: 12840.7803	loss_test: 12840.8643	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3010.4761	loss_val: 3010.6062	loss_test: 3010.6799	accuracy_train: 0.6667	accuracy_val: 0.6250	accuracy_test: 0.5758
[client 12]	loss_train: 37056.3047	loss_val: 37057.1016	loss_test: 37057.5391	accuracy_train: 0.9153	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 286295.3125	loss_val: 286295.4062	loss_test: 286295.7188	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10167.1367	loss_val: 10167.2363	loss_test: 10167.2910	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1139.6477	loss_val: 1139.6675	loss_test: 1139.6909	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7684.0396	loss_val: 7684.4902	loss_test: 7684.8721	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21105.0996	loss_val: 21105.1270	loss_test: 21105.3086	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13556.6680	loss_val: 13556.7949	loss_test: 13556.7520	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1272.9747	loss_val: 1272.9838	loss_test: 1272.9919	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 67	curr_val_accuracy: 0.6754	curr_test_accuracy: 0.6910
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30000.4785	loss_val: 30000.5273	loss_test: 30000.4629	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 22683.7852	loss_val: 22683.7852	loss_test: 22683.8711	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 39622.4297	loss_val: 39623.7852	loss_test: 39623.4062	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 20747.4629	loss_val: 20747.4395	loss_test: 20747.5137	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6905.8203	loss_val: 6905.9292	loss_test: 6905.9404	accuracy_train: 0.6294	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7410.3477	loss_val: 7410.4307	loss_test: 7410.4619	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46493.3828	loss_val: 46493.8789	loss_test: 46493.6133	accuracy_train: 0.5824	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 35302.4648	loss_val: 35302.6055	loss_test: 35302.4727	accuracy_train: 0.5599	accuracy_val: 0.3611	accuracy_test: 0.5135
[client 8]	loss_train: 1166.4534	loss_val: 1166.4641	loss_test: 1166.4622	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52976.4648	loss_val: 52978.4570	loss_test: 52976.5859	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 12813.4297	loss_val: 12813.3545	loss_test: 12813.4385	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3141.4272	loss_val: 3141.5596	loss_test: 3141.6270	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.5758
[client 12]	loss_train: 40363.8711	loss_val: 40364.7109	loss_test: 40365.1406	accuracy_train: 0.9153	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 283168.1875	loss_val: 283168.2812	loss_test: 283168.6250	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9989.9902	loss_val: 9990.0820	loss_test: 9990.1445	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1145.4292	loss_val: 1145.4490	loss_test: 1145.4722	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7695.4595	loss_val: 7695.9097	loss_test: 7696.2998	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 20917.3203	loss_val: 20917.3379	loss_test: 20917.5391	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13468.9062	loss_val: 13469.0361	loss_test: 13468.9922	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1272.7996	loss_val: 1272.8087	loss_test: 1272.8165	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 68	curr_val_accuracy: 0.6735	curr_test_accuracy: 0.6910
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29340.8262	loss_val: 29340.8789	loss_test: 29340.8125	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 23019.1738	loss_val: 23019.1738	loss_test: 23019.2617	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 38190.3789	loss_val: 38191.8633	loss_test: 38191.3203	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 20494.6562	loss_val: 20494.6426	loss_test: 20494.7109	accuracy_train: 0.4528	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 6828.9077	loss_val: 6829.0278	loss_test: 6829.0200	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6960.0913	loss_val: 6960.1592	loss_test: 6960.1963	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46833.9062	loss_val: 46834.4062	loss_test: 46834.1406	accuracy_train: 0.5941	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 33443.7891	loss_val: 33443.9336	loss_test: 33443.7969	accuracy_train: 0.5458	accuracy_val: 0.3611	accuracy_test: 0.5135
[client 8]	loss_train: 1164.6526	loss_val: 1164.6636	loss_test: 1164.6613	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52346.1719	loss_val: 52348.0977	loss_test: 52346.3008	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13155.3018	loss_val: 13155.2275	loss_test: 13155.3115	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3216.7085	loss_val: 3216.8391	loss_test: 3216.9016	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36459.0742	loss_val: 36459.9609	loss_test: 36460.3711	accuracy_train: 0.9322	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 279354.5938	loss_val: 279354.6875	loss_test: 279355.0312	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9926.3613	loss_val: 9926.4531	loss_test: 9926.5215	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1153.6062	loss_val: 1153.6256	loss_test: 1153.6490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7725.4932	loss_val: 7725.9443	loss_test: 7726.3418	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 20951.3691	loss_val: 20951.3887	loss_test: 20951.5820	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13460.3701	loss_val: 13460.5029	loss_test: 13460.4551	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1268.2112	loss_val: 1268.2205	loss_test: 1268.2280	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 69	curr_val_accuracy: 0.6735	curr_test_accuracy: 0.6893
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28925.1250	loss_val: 28925.1836	loss_test: 28925.1152	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 23167.4297	loss_val: 23167.4277	loss_test: 23167.5176	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 38869.8438	loss_val: 38871.4922	loss_test: 38870.8750	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 19281.0742	loss_val: 19281.0703	loss_test: 19281.1270	accuracy_train: 0.4591	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 7021.1133	loss_val: 7021.2285	loss_test: 7021.2246	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6841.9346	loss_val: 6841.9902	loss_test: 6842.0352	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47053.6055	loss_val: 47054.0938	loss_test: 47053.8359	accuracy_train: 0.5824	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 32284.2773	loss_val: 32284.4199	loss_test: 32284.2871	accuracy_train: 0.5317	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1168.4520	loss_val: 1168.4633	loss_test: 1168.4607	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52793.2344	loss_val: 52795.1211	loss_test: 52793.3789	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13695.4404	loss_val: 13695.3682	loss_test: 13695.4512	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3312.7756	loss_val: 3312.9045	loss_test: 3312.9612	accuracy_train: 0.6510	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 35030.0352	loss_val: 35030.9609	loss_test: 35031.3555	accuracy_train: 0.9407	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 275977.3438	loss_val: 275977.4375	loss_test: 275977.7812	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9947.9512	loss_val: 9948.0361	loss_test: 9948.1152	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1164.7454	loss_val: 1164.7642	loss_test: 1164.7881	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7755.8516	loss_val: 7756.3032	loss_test: 7756.7070	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 20773.9922	loss_val: 20774.0215	loss_test: 20774.2070	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13491.3066	loss_val: 13491.4404	loss_test: 13491.3857	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1258.6058	loss_val: 1258.6149	loss_test: 1258.6222	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 70	curr_val_accuracy: 0.6695	curr_test_accuracy: 0.6893
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28773.7207	loss_val: 28773.7812	loss_test: 28773.7109	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 23125.8086	loss_val: 23125.8027	loss_test: 23125.8945	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41168.9297	loss_val: 41170.6367	loss_test: 41169.9805	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17876.8887	loss_val: 17876.8945	loss_test: 17876.9434	accuracy_train: 0.4528	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 7063.6953	loss_val: 7063.7866	loss_test: 7063.8115	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6943.4336	loss_val: 6943.4800	loss_test: 6943.5376	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47260.5625	loss_val: 47261.0469	loss_test: 47260.7969	accuracy_train: 0.5765	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 33202.4805	loss_val: 33202.6289	loss_test: 33202.5000	accuracy_train: 0.5423	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1164.5094	loss_val: 1164.5208	loss_test: 1164.5178	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53012.5977	loss_val: 53014.4727	loss_test: 53012.7500	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13860.5273	loss_val: 13860.4570	loss_test: 13860.5361	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3393.8374	loss_val: 3393.9668	loss_test: 3394.0166	accuracy_train: 0.6549	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33963.3008	loss_val: 33964.2812	loss_test: 33964.6445	accuracy_train: 0.9407	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 268987.0000	loss_val: 268987.0625	loss_test: 268987.4688	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10073.1504	loss_val: 10073.2344	loss_test: 10073.3203	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1170.5970	loss_val: 1170.6151	loss_test: 1170.6396	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7783.4575	loss_val: 7783.9111	loss_test: 7784.3198	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 20552.1680	loss_val: 20552.2129	loss_test: 20552.3848	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13398.7939	loss_val: 13398.9258	loss_test: 13398.8604	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1234.4867	loss_val: 1234.4954	loss_test: 1234.5026	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 71	curr_val_accuracy: 0.6734	curr_test_accuracy: 0.6873
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28576.0859	loss_val: 28576.1523	loss_test: 28576.0801	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 23151.4023	loss_val: 23151.3965	loss_test: 23151.4902	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42553.3984	loss_val: 42555.1562	loss_test: 42554.4688	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16675.1152	loss_val: 16675.1230	loss_test: 16675.1699	accuracy_train: 0.4560	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 7179.4062	loss_val: 7179.4702	loss_test: 7179.5317	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7052.5229	loss_val: 7052.5669	loss_test: 7052.6323	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46065.3398	loss_val: 46065.8203	loss_test: 46065.5820	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 34796.0977	loss_val: 34796.2500	loss_test: 34796.1094	accuracy_train: 0.5528	accuracy_val: 0.3611	accuracy_test: 0.4595
[client 8]	loss_train: 1163.8260	loss_val: 1163.8372	loss_test: 1163.8342	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52154.3516	loss_val: 52156.1953	loss_test: 52154.5117	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13773.3857	loss_val: 13773.3154	loss_test: 13773.3936	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3473.1545	loss_val: 3473.2854	loss_test: 3473.3269	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.5758
[client 12]	loss_train: 32641.5527	loss_val: 32642.5645	loss_test: 32642.9102	accuracy_train: 0.9407	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 263561.0312	loss_val: 263561.0938	loss_test: 263561.5000	accuracy_train: 0.9286	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10538.8994	loss_val: 10538.9854	loss_test: 10539.0781	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1174.5935	loss_val: 1174.6115	loss_test: 1174.6357	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7808.2217	loss_val: 7808.6787	loss_test: 7809.0913	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 20672.0312	loss_val: 20672.0820	loss_test: 20672.2559	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13230.9736	loss_val: 13231.1094	loss_test: 13231.0352	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1230.7263	loss_val: 1230.7350	loss_test: 1230.7419	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 72	curr_val_accuracy: 0.6774	curr_test_accuracy: 0.6835
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28073.2246	loss_val: 28073.2930	loss_test: 28073.2207	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22874.8691	loss_val: 22874.8613	loss_test: 22874.9590	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41455.1562	loss_val: 41456.9609	loss_test: 41456.2461	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15768.9395	loss_val: 15768.9434	loss_test: 15769.0020	accuracy_train: 0.4528	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 7346.7607	loss_val: 7346.8110	loss_test: 7346.8940	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7039.2085	loss_val: 7039.2637	loss_test: 7039.3208	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44717.8516	loss_val: 44718.3281	loss_test: 44718.1133	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 36489.3867	loss_val: 36489.5469	loss_test: 36489.4023	accuracy_train: 0.5458	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1154.4080	loss_val: 1154.4189	loss_test: 1154.4159	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52788.3945	loss_val: 52790.2109	loss_test: 52788.5586	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 13873.0986	loss_val: 13873.0264	loss_test: 13873.1074	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3479.6719	loss_val: 3479.8035	loss_test: 3479.8359	accuracy_train: 0.6588	accuracy_val: 0.6875	accuracy_test: 0.6364
[client 12]	loss_train: 31699.5781	loss_val: 31700.6016	loss_test: 31700.9512	accuracy_train: 0.9407	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 256741.8281	loss_val: 256741.9062	loss_test: 256742.3125	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10558.3477	loss_val: 10558.4287	loss_test: 10558.5361	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1175.0051	loss_val: 1175.0229	loss_test: 1175.0466	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7829.9575	loss_val: 7830.4165	loss_test: 7830.8320	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 20987.5273	loss_val: 20987.5781	loss_test: 20987.7480	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13309.5273	loss_val: 13309.6670	loss_test: 13309.5879	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1220.1440	loss_val: 1220.1525	loss_test: 1220.1595	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 73	curr_val_accuracy: 0.6814	curr_test_accuracy: 0.6893
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27940.5430	loss_val: 27940.6133	loss_test: 27940.5410	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22913.6250	loss_val: 22913.6152	loss_test: 22913.7148	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41467.3945	loss_val: 41469.2617	loss_test: 41468.4961	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15177.5801	loss_val: 15177.5742	loss_test: 15177.6484	accuracy_train: 0.4528	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 7909.7354	loss_val: 7909.7876	loss_test: 7909.8730	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6956.3501	loss_val: 6956.4111	loss_test: 6956.4702	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44156.7148	loss_val: 44157.1992	loss_test: 44157.0039	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 36170.7188	loss_val: 36170.8906	loss_test: 36170.7422	accuracy_train: 0.5423	accuracy_val: 0.3611	accuracy_test: 0.4595
[client 8]	loss_train: 1150.7396	loss_val: 1150.7504	loss_test: 1150.7473	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54181.9766	loss_val: 54183.7734	loss_test: 54182.1523	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 14299.6260	loss_val: 14299.5547	loss_test: 14299.6377	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3407.2942	loss_val: 3407.4209	loss_test: 3407.4563	accuracy_train: 0.6588	accuracy_val: 0.6875	accuracy_test: 0.6364
[client 12]	loss_train: 30583.0977	loss_val: 30584.0898	loss_test: 30584.4883	accuracy_train: 0.9407	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 250329.6406	loss_val: 250329.7188	loss_test: 250330.1406	accuracy_train: 0.9388	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10880.1846	loss_val: 10880.2559	loss_test: 10880.3770	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1163.8768	loss_val: 1163.8949	loss_test: 1163.9174	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7822.6582	loss_val: 7823.1191	loss_test: 7823.5371	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 21130.1523	loss_val: 21130.2129	loss_test: 21130.3887	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13360.0273	loss_val: 13360.1680	loss_test: 13360.0938	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1217.1553	loss_val: 1217.1635	loss_test: 1217.1709	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 74	curr_val_accuracy: 0.6855	curr_test_accuracy: 0.6800
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27782.1055	loss_val: 27782.1797	loss_test: 27782.1094	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 23241.1113	loss_val: 23241.1016	loss_test: 23241.1992	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42554.9727	loss_val: 42556.9023	loss_test: 42556.0781	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14810.1025	loss_val: 14810.0908	loss_test: 14810.1729	accuracy_train: 0.4528	accuracy_val: 0.5250	accuracy_test: 0.4390
[client 4]	loss_train: 8064.1743	loss_val: 8064.2324	loss_test: 8064.3140	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6983.3940	loss_val: 6983.4536	loss_test: 6983.5161	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44009.9414	loss_val: 44010.4414	loss_test: 44010.2344	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 35582.9336	loss_val: 35583.1055	loss_test: 35582.9609	accuracy_train: 0.5317	accuracy_val: 0.3611	accuracy_test: 0.4595
[client 8]	loss_train: 1134.4639	loss_val: 1134.4750	loss_test: 1134.4713	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56524.4883	loss_val: 56526.2891	loss_test: 56524.6680	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 13996.5391	loss_val: 13996.4717	loss_test: 13996.5547	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3422.1477	loss_val: 3422.2676	loss_test: 3422.3127	accuracy_train: 0.6627	accuracy_val: 0.6875	accuracy_test: 0.6364
[client 12]	loss_train: 29507.3711	loss_val: 29508.3223	loss_test: 29508.7812	accuracy_train: 0.9407	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 238860.7656	loss_val: 238860.8594	loss_test: 238861.2969	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10854.1807	loss_val: 10854.2432	loss_test: 10854.3721	accuracy_train: 0.3497	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 1156.0009	loss_val: 1156.0190	loss_test: 1156.0403	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7814.5156	loss_val: 7814.9805	loss_test: 7815.3994	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 20583.2598	loss_val: 20583.3281	loss_test: 20583.5059	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13212.3623	loss_val: 13212.5078	loss_test: 13212.4316	accuracy_train: 0.4118	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1214.8137	loss_val: 1214.8217	loss_test: 1214.8295	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 75	curr_val_accuracy: 0.6855	curr_test_accuracy: 0.6837
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29958.0723	loss_val: 29958.1523	loss_test: 29958.0820	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 23490.2598	loss_val: 23490.2520	loss_test: 23490.3477	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43099.7383	loss_val: 43101.7500	loss_test: 43100.8320	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15314.5166	loss_val: 15314.5010	loss_test: 15314.5869	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7635.3472	loss_val: 7635.4028	loss_test: 7635.4844	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6929.5718	loss_val: 6929.6289	loss_test: 6929.6948	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44415.8320	loss_val: 44416.3633	loss_test: 44416.1367	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 35638.6992	loss_val: 35638.8633	loss_test: 35638.7188	accuracy_train: 0.5246	accuracy_val: 0.3889	accuracy_test: 0.4324
[client 8]	loss_train: 1136.5100	loss_val: 1136.5216	loss_test: 1136.5173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59188.4648	loss_val: 59190.2891	loss_test: 59188.6484	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 13567.5527	loss_val: 13567.4873	loss_test: 13567.5713	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3429.0881	loss_val: 3429.1970	loss_test: 3429.2620	accuracy_train: 0.6745	accuracy_val: 0.6875	accuracy_test: 0.6667
[client 12]	loss_train: 29069.2188	loss_val: 29070.1602	loss_test: 29070.6504	accuracy_train: 0.9407	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 232206.0938	loss_val: 232206.1875	loss_test: 232206.6406	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8077
[client 14]	loss_train: 10684.0615	loss_val: 10684.1191	loss_test: 10684.2520	accuracy_train: 0.3636	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 1147.6421	loss_val: 1147.6602	loss_test: 1147.6803	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7809.6504	loss_val: 7810.1201	loss_test: 7810.5386	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 20075.4434	loss_val: 20075.5137	loss_test: 20075.6973	accuracy_train: 0.6454	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13159.2656	loss_val: 13159.4141	loss_test: 13159.3281	accuracy_train: 0.4118	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1216.5123	loss_val: 1216.5198	loss_test: 1216.5277	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 76	curr_val_accuracy: 0.6814	curr_test_accuracy: 0.6780
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31771.0371	loss_val: 31771.1230	loss_test: 31771.0527	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 23047.6836	loss_val: 23047.6797	loss_test: 23047.7695	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43333.4180	loss_val: 43335.5195	loss_test: 43334.4961	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15850.9316	loss_val: 15850.9131	loss_test: 15850.9990	accuracy_train: 0.4528	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7511.8994	loss_val: 7511.9629	loss_test: 7512.0366	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6868.5923	loss_val: 6868.6519	loss_test: 6868.7168	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44437.5547	loss_val: 44438.0938	loss_test: 44437.8633	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 35024.7305	loss_val: 35024.8828	loss_test: 35024.7422	accuracy_train: 0.5246	accuracy_val: 0.3889	accuracy_test: 0.4324
[client 8]	loss_train: 1123.4662	loss_val: 1123.4777	loss_test: 1123.4735	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59506.8086	loss_val: 59508.6836	loss_test: 59507.0039	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 13551.1738	loss_val: 13551.1064	loss_test: 13551.1924	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3413.3533	loss_val: 3413.4504	loss_test: 3413.5352	accuracy_train: 0.6784	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 29570.4805	loss_val: 29571.4492	loss_test: 29571.9297	accuracy_train: 0.9576	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 230694.2812	loss_val: 230694.3750	loss_test: 230694.8438	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8077
[client 14]	loss_train: 10548.4961	loss_val: 10548.5527	loss_test: 10548.6885	accuracy_train: 0.3776	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 1143.4872	loss_val: 1143.5046	loss_test: 1143.5243	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7791.2358	loss_val: 7791.7129	loss_test: 7792.1299	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 19290.4648	loss_val: 19290.5410	loss_test: 19290.7285	accuracy_train: 0.6525	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12816.0361	loss_val: 12816.1865	loss_test: 12816.0996	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1215.5703	loss_val: 1215.5775	loss_test: 1215.5851	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 77	curr_val_accuracy: 0.6794	curr_test_accuracy: 0.6760
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30207.8379	loss_val: 30207.9297	loss_test: 30207.8613	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22462.1816	loss_val: 22462.1797	loss_test: 22462.2637	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43748.6406	loss_val: 43750.8203	loss_test: 43749.7227	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15697.9355	loss_val: 15697.9170	loss_test: 15697.9961	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 7135.6221	loss_val: 7135.6968	loss_test: 7135.7578	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6783.3374	loss_val: 6783.4053	loss_test: 6783.4619	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43155.7148	loss_val: 43156.2852	loss_test: 43156.0391	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 34302.1211	loss_val: 34302.2617	loss_test: 34302.1211	accuracy_train: 0.5106	accuracy_val: 0.3611	accuracy_test: 0.4595
[client 8]	loss_train: 1111.5663	loss_val: 1111.5776	loss_test: 1111.5735	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60399.6875	loss_val: 60401.6133	loss_test: 60399.9023	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 13531.9551	loss_val: 13531.8877	loss_test: 13531.9736	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3428.2515	loss_val: 3428.3518	loss_test: 3428.4436	accuracy_train: 0.6863	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 29777.0840	loss_val: 29778.0938	loss_test: 29778.5547	accuracy_train: 0.9576	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 228080.7344	loss_val: 228080.8125	loss_test: 228081.2969	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8077
[client 14]	loss_train: 10379.4502	loss_val: 10379.5059	loss_test: 10379.6426	accuracy_train: 0.3497	accuracy_val: 0.4118	accuracy_test: 0.3500
[client 15]	loss_train: 1137.2229	loss_val: 1137.2394	loss_test: 1137.2585	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7746.7817	loss_val: 7747.2646	loss_test: 7747.6792	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 19120.3086	loss_val: 19120.3848	loss_test: 19120.5742	accuracy_train: 0.6525	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12649.6602	loss_val: 12649.8105	loss_test: 12649.7305	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1221.7794	loss_val: 1221.7867	loss_test: 1221.7938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 78	curr_val_accuracy: 0.6795	curr_test_accuracy: 0.6779
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29062.0254	loss_val: 29062.1230	loss_test: 29062.0547	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21938.3457	loss_val: 21938.3457	loss_test: 21938.4277	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43978.5508	loss_val: 43980.8164	loss_test: 43979.6562	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15382.0654	loss_val: 15382.0498	loss_test: 15382.1250	accuracy_train: 0.4088	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6814.0410	loss_val: 6814.1201	loss_test: 6814.1738	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 8100.5732	loss_val: 8100.6372	loss_test: 8100.6904	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41576.3477	loss_val: 41576.9297	loss_test: 41576.6680	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 34659.3594	loss_val: 34659.5000	loss_test: 34659.3555	accuracy_train: 0.5106	accuracy_val: 0.3889	accuracy_test: 0.4324
[client 8]	loss_train: 1104.4382	loss_val: 1104.4497	loss_test: 1104.4456	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60991.3828	loss_val: 60993.3594	loss_test: 60991.6133	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12878.7930	loss_val: 12878.7246	loss_test: 12878.8115	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3411.7551	loss_val: 3411.8667	loss_test: 3411.9634	accuracy_train: 0.6863	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 30253.4922	loss_val: 30254.5430	loss_test: 30254.9805	accuracy_train: 0.9576	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 226068.5938	loss_val: 226068.6875	loss_test: 226069.1719	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.8077
[client 14]	loss_train: 9906.7109	loss_val: 9906.7656	loss_test: 9906.9062	accuracy_train: 0.3357	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1135.1044	loss_val: 1135.1198	loss_test: 1135.1387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7717.9287	loss_val: 7718.4146	loss_test: 7718.8276	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 19783.5547	loss_val: 19783.6348	loss_test: 19783.8359	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12827.4727	loss_val: 12827.6211	loss_test: 12827.5498	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1232.9604	loss_val: 1232.9679	loss_test: 1232.9750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 79	curr_val_accuracy: 0.6795	curr_test_accuracy: 0.6706
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28727.7930	loss_val: 28727.8945	loss_test: 28727.8262	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22675.9961	loss_val: 22675.9961	loss_test: 22676.0801	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43224.2812	loss_val: 43226.6406	loss_test: 43225.4180	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15006.3818	loss_val: 15006.3711	loss_test: 15006.4434	accuracy_train: 0.4182	accuracy_val: 0.4250	accuracy_test: 0.3902
[client 4]	loss_train: 7061.5410	loss_val: 7061.6064	loss_test: 7061.6841	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6877.9287	loss_val: 6878.0244	loss_test: 6878.1035	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41992.9531	loss_val: 41993.5273	loss_test: 41993.2734	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 37205.7266	loss_val: 37205.8828	loss_test: 37205.7266	accuracy_train: 0.5141	accuracy_val: 0.3889	accuracy_test: 0.4324
[client 8]	loss_train: 1103.9091	loss_val: 1103.9204	loss_test: 1103.9163	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61043.3555	loss_val: 61045.3633	loss_test: 61043.5938	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 12451.4951	loss_val: 12451.4229	loss_test: 12451.5137	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3392.2915	loss_val: 3392.4172	loss_test: 3392.5139	accuracy_train: 0.6745	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 31168.2949	loss_val: 31169.3711	loss_test: 31169.7695	accuracy_train: 0.9492	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 238789.8594	loss_val: 238789.9531	loss_test: 238790.4531	accuracy_train: 0.9388	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 9808.1924	loss_val: 9808.2500	loss_test: 9808.3896	accuracy_train: 0.3287	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1139.8503	loss_val: 1139.8651	loss_test: 1139.8840	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7662.7417	loss_val: 7663.2314	loss_test: 7663.6392	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 20308.0039	loss_val: 20308.0840	loss_test: 20308.2930	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13283.0127	loss_val: 13283.1611	loss_test: 13283.0830	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3429
[client 19]	loss_train: 1226.0864	loss_val: 1226.0939	loss_test: 1226.1011	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 80	curr_val_accuracy: 0.6795	curr_test_accuracy: 0.6689
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28406.9160	loss_val: 28407.0215	loss_test: 28406.9473	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 23159.2422	loss_val: 23159.2461	loss_test: 23159.3301	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43232.0117	loss_val: 43234.4414	loss_test: 43233.1719	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14550.1963	loss_val: 14550.1934	loss_test: 14550.2549	accuracy_train: 0.4214	accuracy_val: 0.4250	accuracy_test: 0.3902
[client 4]	loss_train: 6976.2979	loss_val: 6976.3267	loss_test: 6976.4482	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7705.6533	loss_val: 7705.7373	loss_test: 7705.8408	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44289.3750	loss_val: 44289.9375	loss_test: 44289.6992	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 39231.3359	loss_val: 39231.4961	loss_test: 39231.3359	accuracy_train: 0.5352	accuracy_val: 0.3611	accuracy_test: 0.4324
[client 8]	loss_train: 1102.7358	loss_val: 1102.7472	loss_test: 1102.7429	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61775.7109	loss_val: 61777.7812	loss_test: 61775.9648	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 12317.9424	loss_val: 12317.8711	loss_test: 12317.9619	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3366.5413	loss_val: 3366.6721	loss_test: 3366.7681	accuracy_train: 0.6706	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35071.8320	loss_val: 35072.9727	loss_test: 35073.3086	accuracy_train: 0.9576	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 248582.5000	loss_val: 248582.5781	loss_test: 248583.0938	accuracy_train: 0.9388	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 9587.8213	loss_val: 9587.8887	loss_test: 9588.0234	accuracy_train: 0.3287	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1137.1073	loss_val: 1137.1217	loss_test: 1137.1410	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7635.2437	loss_val: 7635.7354	loss_test: 7636.1377	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 20830.4531	loss_val: 20830.5254	loss_test: 20830.7305	accuracy_train: 0.6596	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13374.3418	loss_val: 13374.4951	loss_test: 13374.4092	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1212.9220	loss_val: 1212.9292	loss_test: 1212.9368	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 81	curr_val_accuracy: 0.6796	curr_test_accuracy: 0.6708
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28131.0371	loss_val: 28131.1504	loss_test: 28131.0723	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22570.2891	loss_val: 22570.2930	loss_test: 22570.3848	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43246.3438	loss_val: 43248.9219	loss_test: 43247.5273	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14665.2012	loss_val: 14665.1924	loss_test: 14665.2578	accuracy_train: 0.4214	accuracy_val: 0.4250	accuracy_test: 0.3902
[client 4]	loss_train: 7021.3628	loss_val: 7021.3696	loss_test: 7021.5161	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7696.0669	loss_val: 7696.1475	loss_test: 7696.2476	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45178.7422	loss_val: 45179.3164	loss_test: 45179.0781	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 39398.5195	loss_val: 39398.6836	loss_test: 39398.5234	accuracy_train: 0.5211	accuracy_val: 0.3611	accuracy_test: 0.4054
[client 8]	loss_train: 1110.1178	loss_val: 1110.1287	loss_test: 1110.1248	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62603.0781	loss_val: 62605.1875	loss_test: 62603.3438	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 12362.6387	loss_val: 12362.5693	loss_test: 12362.6572	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3312.2385	loss_val: 3312.3674	loss_test: 3312.4590	accuracy_train: 0.6667	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 40349.0586	loss_val: 40350.1992	loss_test: 40350.5000	accuracy_train: 0.9576	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 258190.2188	loss_val: 258190.3125	loss_test: 258190.7969	accuracy_train: 0.9388	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 9542.5752	loss_val: 9542.6475	loss_test: 9542.7812	accuracy_train: 0.3287	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1133.0571	loss_val: 1133.0713	loss_test: 1133.0907	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7593.5752	loss_val: 7594.0698	loss_test: 7594.4644	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 21459.1270	loss_val: 21459.1855	loss_test: 21459.3984	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13413.9414	loss_val: 13414.0918	loss_test: 13414.0039	accuracy_train: 0.4118	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1204.6184	loss_val: 1204.6254	loss_test: 1204.6333	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 82	curr_val_accuracy: 0.6755	curr_test_accuracy: 0.6689
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28068.9824	loss_val: 28069.1016	loss_test: 28069.0234	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21914.1270	loss_val: 21914.1328	loss_test: 21914.2266	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43700.0586	loss_val: 43702.7461	loss_test: 43701.2539	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14856.9551	loss_val: 14856.9482	loss_test: 14857.0127	accuracy_train: 0.4245	accuracy_val: 0.4250	accuracy_test: 0.3902
[client 4]	loss_train: 6877.2769	loss_val: 6877.2759	loss_test: 6877.4355	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7175.0098	loss_val: 7175.0933	loss_test: 7175.1841	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45446.3633	loss_val: 45446.9766	loss_test: 45446.7070	accuracy_train: 0.5647	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 38277.3750	loss_val: 38277.5430	loss_test: 38277.3867	accuracy_train: 0.5106	accuracy_val: 0.3611	accuracy_test: 0.4054
[client 8]	loss_train: 1115.5630	loss_val: 1115.5735	loss_test: 1115.5697	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62645.5547	loss_val: 62647.6953	loss_test: 62645.8359	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.7500
[client 10]	loss_train: 13030.8135	loss_val: 13030.7461	loss_test: 13030.8359	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3361.0959	loss_val: 3361.2124	loss_test: 3361.3008	accuracy_train: 0.6667	accuracy_val: 0.6250	accuracy_test: 0.5758
[client 12]	loss_train: 46826.2930	loss_val: 46827.4180	loss_test: 46827.7266	accuracy_train: 0.9661	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 264922.7188	loss_val: 264922.8438	loss_test: 264923.3125	accuracy_train: 0.9439	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 9440.8662	loss_val: 9440.9404	loss_test: 9441.0732	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1130.2134	loss_val: 1130.2277	loss_test: 1130.2469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7569.1211	loss_val: 7569.6191	loss_test: 7570.0117	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22724.2891	loss_val: 22724.3574	loss_test: 22724.5566	accuracy_train: 0.6738	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13736.9639	loss_val: 13737.1123	loss_test: 13737.0146	accuracy_train: 0.4118	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1196.3848	loss_val: 1196.3916	loss_test: 1196.3998	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 83	curr_val_accuracy: 0.6716	curr_test_accuracy: 0.6650
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28121.7988	loss_val: 28121.9238	loss_test: 28121.8438	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21617.3750	loss_val: 21617.3828	loss_test: 21617.4785	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45117.7812	loss_val: 45120.5820	loss_test: 45118.9961	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14863.4082	loss_val: 14863.4053	loss_test: 14863.4600	accuracy_train: 0.4528	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6818.8643	loss_val: 6818.8662	loss_test: 6819.0288	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7122.5176	loss_val: 7122.5986	loss_test: 7122.6895	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45341.7422	loss_val: 45342.4102	loss_test: 45342.0820	accuracy_train: 0.5765	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 37845.9531	loss_val: 37846.1250	loss_test: 37845.9688	accuracy_train: 0.5106	accuracy_val: 0.3611	accuracy_test: 0.4595
[client 8]	loss_train: 1110.5553	loss_val: 1110.5654	loss_test: 1110.5619	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62905.0664	loss_val: 62907.2227	loss_test: 62905.3555	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.7500
[client 10]	loss_train: 13050.5693	loss_val: 13050.5020	loss_test: 13050.5918	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3394.3438	loss_val: 3394.4509	loss_test: 3394.5398	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 51663.4805	loss_val: 51664.5898	loss_test: 51664.8906	accuracy_train: 0.9661	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 262041.1562	loss_val: 262041.2656	loss_test: 262041.7344	accuracy_train: 0.9439	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9385.2461	loss_val: 9385.3242	loss_test: 9385.4541	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1124.0491	loss_val: 1124.0636	loss_test: 1124.0824	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7538.1680	loss_val: 7538.6704	loss_test: 7539.0605	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22441.3711	loss_val: 22441.4434	loss_test: 22441.6660	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13659.1260	loss_val: 13659.2803	loss_test: 13659.1826	accuracy_train: 0.4118	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1190.0190	loss_val: 1190.0258	loss_test: 1190.0342	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 84	curr_val_accuracy: 0.6796	curr_test_accuracy: 0.6747
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28421.0703	loss_val: 28421.1992	loss_test: 28421.1250	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21709.8340	loss_val: 21709.8438	loss_test: 21709.9375	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46418.2539	loss_val: 46421.0977	loss_test: 46419.4883	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14867.1367	loss_val: 14867.1309	loss_test: 14867.1885	accuracy_train: 0.4591	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6769.0869	loss_val: 6769.1060	loss_test: 6769.2529	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7187.4009	loss_val: 7187.4736	loss_test: 7187.5693	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44459.6758	loss_val: 44460.3594	loss_test: 44460.0000	accuracy_train: 0.6000	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 36471.3438	loss_val: 36471.5273	loss_test: 36471.3672	accuracy_train: 0.5141	accuracy_val: 0.3611	accuracy_test: 0.4324
[client 8]	loss_train: 1104.4474	loss_val: 1104.4575	loss_test: 1104.4536	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64105.6992	loss_val: 64107.8750	loss_test: 64105.9883	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 13133.4502	loss_val: 13133.3838	loss_test: 13133.4766	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3408.3635	loss_val: 3408.4692	loss_test: 3408.5522	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 54579.2656	loss_val: 54580.3867	loss_test: 54580.6562	accuracy_train: 0.9746	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 256916.4219	loss_val: 256916.5312	loss_test: 256917.0156	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9360.7842	loss_val: 9360.8701	loss_test: 9360.9951	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1122.0526	loss_val: 1122.0673	loss_test: 1122.0856	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7467.4463	loss_val: 7467.9507	loss_test: 7468.3389	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22360.3945	loss_val: 22360.4668	loss_test: 22360.7012	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14006.8623	loss_val: 14007.0166	loss_test: 14006.9102	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1183.0590	loss_val: 1183.0656	loss_test: 1183.0745	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 85	curr_val_accuracy: 0.6736	curr_test_accuracy: 0.6764
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28439.6133	loss_val: 28439.7500	loss_test: 28439.6797	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21683.8398	loss_val: 21683.8535	loss_test: 21683.9512	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47225.8711	loss_val: 47228.7500	loss_test: 47227.1328	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14586.2373	loss_val: 14586.2314	loss_test: 14586.2949	accuracy_train: 0.4591	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6540.2886	loss_val: 6540.3398	loss_test: 6540.4629	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7256.0708	loss_val: 7256.1499	loss_test: 7256.2417	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43608.4961	loss_val: 43609.1484	loss_test: 43608.8047	accuracy_train: 0.6000	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 34838.6836	loss_val: 34838.8750	loss_test: 34838.7070	accuracy_train: 0.5211	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1100.6326	loss_val: 1100.6428	loss_test: 1100.6385	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66286.0156	loss_val: 66288.2344	loss_test: 66286.2891	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 13074.8301	loss_val: 13074.7646	loss_test: 13074.8555	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3424.6138	loss_val: 3424.7207	loss_test: 3424.8088	accuracy_train: 0.6549	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 55534.5859	loss_val: 55535.7070	loss_test: 55535.9453	accuracy_train: 0.9746	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 255675.1875	loss_val: 255675.2969	loss_test: 255675.8125	accuracy_train: 0.9184	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9409.2217	loss_val: 9409.3066	loss_test: 9409.4424	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1126.0573	loss_val: 1126.0720	loss_test: 1126.0902	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7494.3486	loss_val: 7494.8545	loss_test: 7495.2432	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22491.8496	loss_val: 22491.9277	loss_test: 22492.1680	accuracy_train: 0.6738	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14145.1973	loss_val: 14145.3486	loss_test: 14145.2363	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1173.5715	loss_val: 1173.5778	loss_test: 1173.5872	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 86	curr_val_accuracy: 0.6716	curr_test_accuracy: 0.6822
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28657.1934	loss_val: 28657.3359	loss_test: 28657.2676	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22046.6992	loss_val: 22046.7148	loss_test: 22046.8145	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47227.4766	loss_val: 47230.3516	loss_test: 47228.7539	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 13832.5000	loss_val: 13832.4990	loss_test: 13832.5605	accuracy_train: 0.4560	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6344.9097	loss_val: 6344.9907	loss_test: 6345.0879	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7123.4912	loss_val: 7123.5723	loss_test: 7123.6694	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42515.1211	loss_val: 42515.7578	loss_test: 42515.4375	accuracy_train: 0.6000	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 34690.7812	loss_val: 34690.9805	loss_test: 34690.8086	accuracy_train: 0.5106	accuracy_val: 0.3611	accuracy_test: 0.4324
[client 8]	loss_train: 1099.9697	loss_val: 1099.9802	loss_test: 1099.9757	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 71868.5859	loss_val: 71870.8125	loss_test: 71868.8516	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13073.8984	loss_val: 13073.8330	loss_test: 13073.9219	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3440.1426	loss_val: 3440.2546	loss_test: 3440.3496	accuracy_train: 0.6588	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 55882.9062	loss_val: 55884.0391	loss_test: 55884.2383	accuracy_train: 0.9746	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 261399.1875	loss_val: 261399.3125	loss_test: 261399.8594	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9741.2441	loss_val: 9741.3301	loss_test: 9741.4688	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1119.0619	loss_val: 1119.0764	loss_test: 1119.0952	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7498.9360	loss_val: 7499.4419	loss_test: 7499.8320	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22631.3125	loss_val: 22631.3984	loss_test: 22631.6348	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13967.2246	loss_val: 13967.3740	loss_test: 13967.2529	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1164.6569	loss_val: 1164.6627	loss_test: 1164.6726	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 87	curr_val_accuracy: 0.6715	curr_test_accuracy: 0.6764
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28753.5527	loss_val: 28753.7031	loss_test: 28753.6367	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21163.3262	loss_val: 21163.3438	loss_test: 21163.4434	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47147.9023	loss_val: 47150.8125	loss_test: 47149.1953	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 13790.0469	loss_val: 13790.0498	loss_test: 13790.1094	accuracy_train: 0.4560	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6498.5508	loss_val: 6498.6548	loss_test: 6498.7319	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6764.4458	loss_val: 6764.5332	loss_test: 6764.6255	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40775.4648	loss_val: 40776.1055	loss_test: 40775.7812	accuracy_train: 0.5941	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 35295.0742	loss_val: 35295.2734	loss_test: 35295.0977	accuracy_train: 0.5106	accuracy_val: 0.3611	accuracy_test: 0.4324
[client 8]	loss_train: 1096.8499	loss_val: 1096.8605	loss_test: 1096.8556	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 72575.5078	loss_val: 72577.6953	loss_test: 72575.7500	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12582.1104	loss_val: 12582.0459	loss_test: 12582.1357	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3379.3772	loss_val: 3379.4971	loss_test: 3379.5955	accuracy_train: 0.6588	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 56702.6953	loss_val: 56703.8320	loss_test: 56703.9961	accuracy_train: 0.9746	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 264643.5312	loss_val: 264643.6562	loss_test: 264644.2188	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 10062.2793	loss_val: 10062.3682	loss_test: 10062.5049	accuracy_train: 0.3357	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1114.5746	loss_val: 1114.5884	loss_test: 1114.6078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7461.5762	loss_val: 7462.0884	loss_test: 7462.4771	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22465.3691	loss_val: 22465.4609	loss_test: 22465.6934	accuracy_train: 0.6738	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13178.9180	loss_val: 13179.0713	loss_test: 13178.9277	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1165.7480	loss_val: 1165.7539	loss_test: 1165.7643	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 88	curr_val_accuracy: 0.6755	curr_test_accuracy: 0.6744
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28676.8066	loss_val: 28676.9648	loss_test: 28676.9004	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 20591.7285	loss_val: 20591.7500	loss_test: 20591.8457	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45696.5156	loss_val: 45699.4414	loss_test: 45697.8242	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14610.1807	loss_val: 14610.1807	loss_test: 14610.2432	accuracy_train: 0.4560	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6651.6265	loss_val: 6651.7251	loss_test: 6651.8101	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6943.9668	loss_val: 6944.0581	loss_test: 6944.1406	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40076.3281	loss_val: 40076.9922	loss_test: 40076.6484	accuracy_train: 0.5941	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 7]	loss_train: 36194.6758	loss_val: 36194.8672	loss_test: 36194.6953	accuracy_train: 0.5035	accuracy_val: 0.3611	accuracy_test: 0.4324
[client 8]	loss_train: 1097.2495	loss_val: 1097.2603	loss_test: 1097.2551	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 68160.4062	loss_val: 68162.5625	loss_test: 68160.6406	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12529.2236	loss_val: 12529.1602	loss_test: 12529.2510	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3349.4094	loss_val: 3349.5408	loss_test: 3349.6299	accuracy_train: 0.6510	accuracy_val: 0.6250	accuracy_test: 0.5758
[client 12]	loss_train: 57442.2812	loss_val: 57443.4258	loss_test: 57443.5469	accuracy_train: 0.9746	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 265377.0625	loss_val: 265377.1875	loss_test: 265377.7812	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9929.4551	loss_val: 9929.5439	loss_test: 9929.6768	accuracy_train: 0.3357	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1116.1227	loss_val: 1116.1361	loss_test: 1116.1554	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7446.9565	loss_val: 7447.4761	loss_test: 7447.8647	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 21912.2207	loss_val: 21912.3184	loss_test: 21912.5312	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12918.7383	loss_val: 12918.8965	loss_test: 12918.7354	accuracy_train: 0.4338	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 1164.8435	loss_val: 1164.8494	loss_test: 1164.8597	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 89	curr_val_accuracy: 0.6755	curr_test_accuracy: 0.6706
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28544.6387	loss_val: 28544.8027	loss_test: 28544.7402	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 20667.0938	loss_val: 20667.1152	loss_test: 20667.2129	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43847.7227	loss_val: 43850.6953	loss_test: 43849.0469	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15389.5557	loss_val: 15389.5498	loss_test: 15389.6182	accuracy_train: 0.4654	accuracy_val: 0.5250	accuracy_test: 0.4146
[client 4]	loss_train: 6660.9902	loss_val: 6661.0537	loss_test: 6661.1763	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6483.4849	loss_val: 6483.5791	loss_test: 6483.6636	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40169.3438	loss_val: 40170.0352	loss_test: 40169.6641	accuracy_train: 0.5941	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 36448.8828	loss_val: 36449.0742	loss_test: 36448.9062	accuracy_train: 0.5141	accuracy_val: 0.3611	accuracy_test: 0.4595
[client 8]	loss_train: 1085.3835	loss_val: 1085.3948	loss_test: 1085.3889	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 67226.6953	loss_val: 67228.8203	loss_test: 67226.9219	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13045.2422	loss_val: 13045.1777	loss_test: 13045.2686	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3274.3608	loss_val: 3274.5020	loss_test: 3274.5815	accuracy_train: 0.6510	accuracy_val: 0.6250	accuracy_test: 0.5758
[client 12]	loss_train: 57910.3242	loss_val: 57911.4766	loss_test: 57911.5625	accuracy_train: 0.9831	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 258177.1719	loss_val: 258177.2812	loss_test: 258177.8750	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9587.0020	loss_val: 9587.0908	loss_test: 9587.2295	accuracy_train: 0.3357	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1112.6882	loss_val: 1112.7015	loss_test: 1112.7207	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7460.9282	loss_val: 7461.4521	loss_test: 7461.8413	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22181.0352	loss_val: 22181.1387	loss_test: 22181.3379	accuracy_train: 0.6596	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12967.2051	loss_val: 12967.3682	loss_test: 12967.2041	accuracy_train: 0.4338	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 1171.5928	loss_val: 1171.5989	loss_test: 1171.6090	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 90	curr_val_accuracy: 0.6755	curr_test_accuracy: 0.6744
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28673.1172	loss_val: 28673.2852	loss_test: 28673.2266	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 20737.5430	loss_val: 20737.5703	loss_test: 20737.6621	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44114.7188	loss_val: 44117.7031	loss_test: 44116.0703	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15510.2188	loss_val: 15510.2051	loss_test: 15510.2773	accuracy_train: 0.4811	accuracy_val: 0.5500	accuracy_test: 0.4390
[client 4]	loss_train: 6636.6318	loss_val: 6636.6904	loss_test: 6636.8169	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6518.4756	loss_val: 6518.5659	loss_test: 6518.6587	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41728.1875	loss_val: 41728.9219	loss_test: 41728.4961	accuracy_train: 0.6059	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 36083.9648	loss_val: 36084.1602	loss_test: 36083.9922	accuracy_train: 0.5176	accuracy_val: 0.3611	accuracy_test: 0.4324
[client 8]	loss_train: 1082.3060	loss_val: 1082.3176	loss_test: 1082.3115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66499.3906	loss_val: 66501.5078	loss_test: 66499.6172	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 13070.5605	loss_val: 13070.4922	loss_test: 13070.5869	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3221.4690	loss_val: 3221.6167	loss_test: 3221.6868	accuracy_train: 0.6510	accuracy_val: 0.6562	accuracy_test: 0.5758
[client 12]	loss_train: 58982.0469	loss_val: 58983.2539	loss_test: 58983.2734	accuracy_train: 0.9831	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 256793.2656	loss_val: 256793.3750	loss_test: 256793.9688	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9604.8447	loss_val: 9604.9297	loss_test: 9605.0713	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1109.3357	loss_val: 1109.3490	loss_test: 1109.3676	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7513.8657	loss_val: 7514.3921	loss_test: 7514.7852	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22408.4609	loss_val: 22408.5703	loss_test: 22408.7617	accuracy_train: 0.6596	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13760.3652	loss_val: 13760.5410	loss_test: 13760.3838	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1170.2538	loss_val: 1170.2599	loss_test: 1170.2697	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 91	curr_val_accuracy: 0.6775	curr_test_accuracy: 0.6725
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28784.7656	loss_val: 28784.9395	loss_test: 28784.8789	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21068.0000	loss_val: 21068.0293	loss_test: 21068.1172	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44053.4023	loss_val: 44056.3828	loss_test: 44054.7812	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16018.6533	loss_val: 16018.6377	loss_test: 16018.7129	accuracy_train: 0.5094	accuracy_val: 0.5500	accuracy_test: 0.4634
[client 4]	loss_train: 6696.6523	loss_val: 6696.7119	loss_test: 6696.8398	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6595.5054	loss_val: 6595.5913	loss_test: 6595.6875	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43626.6758	loss_val: 43627.4180	loss_test: 43626.9609	accuracy_train: 0.6059	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 35231.1758	loss_val: 35231.3750	loss_test: 35231.2031	accuracy_train: 0.5141	accuracy_val: 0.3611	accuracy_test: 0.4054
[client 8]	loss_train: 1071.5707	loss_val: 1071.5825	loss_test: 1071.5762	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 65295.1602	loss_val: 65297.2656	loss_test: 65295.3828	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 13293.2354	loss_val: 13293.1650	loss_test: 13293.2627	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3192.7888	loss_val: 3192.9380	loss_test: 3193.0054	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 58917.9805	loss_val: 58919.2656	loss_test: 58919.1836	accuracy_train: 0.9831	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 251052.6719	loss_val: 251052.7969	loss_test: 251053.3750	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9639.7910	loss_val: 9639.8730	loss_test: 9640.0225	accuracy_train: 0.3147	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1107.8599	loss_val: 1107.8737	loss_test: 1107.8910	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7553.4150	loss_val: 7553.9438	loss_test: 7554.3418	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 17]	loss_train: 22268.0410	loss_val: 22268.1465	loss_test: 22268.3516	accuracy_train: 0.6525	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14271.0742	loss_val: 14271.2549	loss_test: 14271.1035	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1180.0933	loss_val: 1180.0995	loss_test: 1180.1085	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 92	curr_val_accuracy: 0.6756	curr_test_accuracy: 0.6727
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28562.7910	loss_val: 28562.9707	loss_test: 28562.9180	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 20939.6328	loss_val: 20939.6641	loss_test: 20939.7480	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44459.3555	loss_val: 44462.3359	loss_test: 44460.7500	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15487.9551	loss_val: 15487.9453	loss_test: 15488.0146	accuracy_train: 0.4843	accuracy_val: 0.5250	accuracy_test: 0.4634
[client 4]	loss_train: 6375.2754	loss_val: 6375.3237	loss_test: 6375.4424	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6798.0142	loss_val: 6798.1006	loss_test: 6798.2070	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44921.1523	loss_val: 44921.8750	loss_test: 44921.4180	accuracy_train: 0.5882	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 33389.9961	loss_val: 33390.1992	loss_test: 33390.0156	accuracy_train: 0.5211	accuracy_val: 0.3611	accuracy_test: 0.4324
[client 8]	loss_train: 1069.5619	loss_val: 1069.5736	loss_test: 1069.5673	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63989.3828	loss_val: 63991.4766	loss_test: 63989.6094	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 13462.0146	loss_val: 13461.9443	loss_test: 13462.0430	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3207.9849	loss_val: 3208.1296	loss_test: 3208.2117	accuracy_train: 0.6706	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 56161.4453	loss_val: 56162.7891	loss_test: 56162.6211	accuracy_train: 0.9831	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 257985.3281	loss_val: 257985.4531	loss_test: 257986.0156	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9818.4453	loss_val: 9818.5312	loss_test: 9818.6846	accuracy_train: 0.3147	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1109.4729	loss_val: 1109.4873	loss_test: 1109.5039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7612.3867	loss_val: 7612.9165	loss_test: 7613.3169	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 17]	loss_train: 22262.8730	loss_val: 22262.9629	loss_test: 22263.1836	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14849.0078	loss_val: 14849.1807	loss_test: 14849.0400	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1178.2435	loss_val: 1178.2495	loss_test: 1178.2581	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 93	curr_val_accuracy: 0.6736	curr_test_accuracy: 0.6785
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28052.8770	loss_val: 28053.0645	loss_test: 28053.0117	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21203.0605	loss_val: 21203.0879	loss_test: 21203.1738	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44210.3242	loss_val: 44213.2969	loss_test: 44211.7344	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14655.3154	loss_val: 14655.3105	loss_test: 14655.3740	accuracy_train: 0.4623	accuracy_val: 0.5250	accuracy_test: 0.4390
[client 4]	loss_train: 6518.1465	loss_val: 6518.1973	loss_test: 6518.2964	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7742.6938	loss_val: 7742.7812	loss_test: 7742.8999	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44962.2227	loss_val: 44962.8945	loss_test: 44962.4727	accuracy_train: 0.5824	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 32175.5742	loss_val: 32175.7676	loss_test: 32175.5938	accuracy_train: 0.5106	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1062.7827	loss_val: 1062.7942	loss_test: 1062.7881	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64166.4648	loss_val: 64168.5703	loss_test: 64166.7070	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 12920.8555	loss_val: 12920.7842	loss_test: 12920.8838	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3219.9893	loss_val: 3220.1292	loss_test: 3220.2224	accuracy_train: 0.6784	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 52167.3047	loss_val: 52168.7031	loss_test: 52168.4805	accuracy_train: 0.9831	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 264616.5000	loss_val: 264616.6562	loss_test: 264617.1875	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 10071.7979	loss_val: 10071.9082	loss_test: 10072.0488	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1107.0426	loss_val: 1107.0575	loss_test: 1107.0737	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7653.1426	loss_val: 7653.6753	loss_test: 7654.0786	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 17]	loss_train: 21762.2949	loss_val: 21762.3770	loss_test: 21762.6074	accuracy_train: 0.6454	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14887.0615	loss_val: 14887.2305	loss_test: 14887.0889	accuracy_train: 0.4118	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1180.0676	loss_val: 1180.0735	loss_test: 1180.0815	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 94	curr_val_accuracy: 0.6736	curr_test_accuracy: 0.6784
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27518.4023	loss_val: 27518.5977	loss_test: 27518.5488	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21380.2656	loss_val: 21380.2930	loss_test: 21380.3828	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44543.3242	loss_val: 44546.2891	loss_test: 44544.7422	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14094.1836	loss_val: 14094.1846	loss_test: 14094.2412	accuracy_train: 0.4560	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6627.4541	loss_val: 6627.5234	loss_test: 6627.5942	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 8593.9248	loss_val: 8594.0078	loss_test: 8594.1289	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44738.8984	loss_val: 44739.5352	loss_test: 44739.1367	accuracy_train: 0.5647	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 32372.6309	loss_val: 32372.7871	loss_test: 32372.6875	accuracy_train: 0.4894	accuracy_val: 0.3611	accuracy_test: 0.4324
[client 8]	loss_train: 1054.3429	loss_val: 1054.3541	loss_test: 1054.3483	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64871.4844	loss_val: 64873.6055	loss_test: 64871.7383	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 12640.0820	loss_val: 12640.0127	loss_test: 12640.1123	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3265.1011	loss_val: 3265.2432	loss_test: 3265.3447	accuracy_train: 0.6902	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 49942.0938	loss_val: 49943.4727	loss_test: 49943.2617	accuracy_train: 0.9831	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 272476.3125	loss_val: 272476.4688	loss_test: 272477.0000	accuracy_train: 0.9439	accuracy_val: 0.8400	accuracy_test: 0.8077
[client 14]	loss_train: 10144.6104	loss_val: 10144.7393	loss_test: 10144.8691	accuracy_train: 0.3217	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1102.2504	loss_val: 1102.2655	loss_test: 1102.2814	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7694.3350	loss_val: 7694.8726	loss_test: 7695.2734	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 17]	loss_train: 21248.8887	loss_val: 21248.9688	loss_test: 21249.2246	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14879.2393	loss_val: 14879.4033	loss_test: 14879.2549	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1176.5674	loss_val: 1176.5730	loss_test: 1176.5808	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 95	curr_val_accuracy: 0.6696	curr_test_accuracy: 0.6707
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28204.4395	loss_val: 28204.6426	loss_test: 28204.6016	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21247.0254	loss_val: 21247.0527	loss_test: 21247.1426	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43681.2969	loss_val: 43684.2773	loss_test: 43682.7188	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 13616.6758	loss_val: 13616.6670	loss_test: 13616.7324	accuracy_train: 0.4591	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6643.7856	loss_val: 6643.8657	loss_test: 6643.9248	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 8667.3818	loss_val: 8667.4629	loss_test: 8667.5830	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45604.2773	loss_val: 45604.8945	loss_test: 45604.5195	accuracy_train: 0.5471	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 33426.1445	loss_val: 33426.3281	loss_test: 33426.1602	accuracy_train: 0.4930	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1054.4215	loss_val: 1054.4324	loss_test: 1054.4268	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 67359.0703	loss_val: 67361.2031	loss_test: 67359.3359	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 12468.8887	loss_val: 12468.8203	loss_test: 12468.9219	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3325.3115	loss_val: 3325.4565	loss_test: 3325.5642	accuracy_train: 0.6824	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 49157.0195	loss_val: 49158.3594	loss_test: 49158.1641	accuracy_train: 0.9831	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 255150.5469	loss_val: 255150.6719	loss_test: 255151.2500	accuracy_train: 0.9439	accuracy_val: 0.8400	accuracy_test: 0.7692
[client 14]	loss_train: 10303.8271	loss_val: 10303.9580	loss_test: 10304.0898	accuracy_train: 0.3427	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1098.6460	loss_val: 1098.6609	loss_test: 1098.6768	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7684.6304	loss_val: 7685.1733	loss_test: 7685.5679	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 17]	loss_train: 20886.7891	loss_val: 20886.8535	loss_test: 20887.1250	accuracy_train: 0.6738	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14474.2471	loss_val: 14474.4062	loss_test: 14474.2578	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1169.2123	loss_val: 1169.2175	loss_test: 1169.2256	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 96	curr_val_accuracy: 0.6696	curr_test_accuracy: 0.6708
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29535.4316	loss_val: 29535.6406	loss_test: 29535.6152	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 20807.8398	loss_val: 20807.8652	loss_test: 20807.9531	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42389.0469	loss_val: 42392.0430	loss_test: 42390.4609	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 13193.7861	loss_val: 13193.7773	loss_test: 13193.8467	accuracy_train: 0.4623	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6589.5439	loss_val: 6589.6201	loss_test: 6589.6934	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 8186.7891	loss_val: 8186.8687	loss_test: 8186.9858	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46761.0977	loss_val: 46761.7422	loss_test: 46761.3594	accuracy_train: 0.5471	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 34086.5000	loss_val: 34086.6992	loss_test: 34086.5117	accuracy_train: 0.5176	accuracy_val: 0.3611	accuracy_test: 0.4865
[client 8]	loss_train: 1054.1010	loss_val: 1054.1113	loss_test: 1054.1061	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 72640.7109	loss_val: 72642.8828	loss_test: 72640.9766	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 12227.9375	loss_val: 12227.8730	loss_test: 12227.9727	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3372.1089	loss_val: 3372.2576	loss_test: 3372.3591	accuracy_train: 0.6784	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 48406.2695	loss_val: 48407.6055	loss_test: 48407.3906	accuracy_train: 0.9831	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 260989.6250	loss_val: 260989.7656	loss_test: 260990.3438	accuracy_train: 0.9439	accuracy_val: 0.8400	accuracy_test: 0.7308
[client 14]	loss_train: 10313.5488	loss_val: 10313.6709	loss_test: 10313.8125	accuracy_train: 0.3357	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1095.9237	loss_val: 1095.9381	loss_test: 1095.9542	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7666.5303	loss_val: 7667.0815	loss_test: 7667.4653	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 17]	loss_train: 20676.7832	loss_val: 20676.8516	loss_test: 20677.1094	accuracy_train: 0.6809	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13984.4668	loss_val: 13984.6240	loss_test: 13984.4736	accuracy_train: 0.4191	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 1165.9240	loss_val: 1165.9291	loss_test: 1165.9373	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 97	curr_val_accuracy: 0.6716	curr_test_accuracy: 0.6689
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31369.9453	loss_val: 31370.1562	loss_test: 31370.1523	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 20911.4492	loss_val: 20911.4688	loss_test: 20911.5645	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41552.5312	loss_val: 41555.5391	loss_test: 41553.9453	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 12710.9111	loss_val: 12710.9072	loss_test: 12710.9805	accuracy_train: 0.4654	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6568.2988	loss_val: 6568.3706	loss_test: 6568.4634	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7856.3560	loss_val: 7856.4360	loss_test: 7856.5454	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49258.5820	loss_val: 49259.2305	loss_test: 49258.8594	accuracy_train: 0.5471	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 37555.5781	loss_val: 37555.7773	loss_test: 37555.6016	accuracy_train: 0.5282	accuracy_val: 0.4167	accuracy_test: 0.4054
[client 8]	loss_train: 1053.7762	loss_val: 1053.7866	loss_test: 1053.7814	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 77059.2266	loss_val: 77061.4297	loss_test: 77059.5000	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 12044.4912	loss_val: 12044.4277	loss_test: 12044.5264	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3380.3955	loss_val: 3380.5437	loss_test: 3380.6416	accuracy_train: 0.6706	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 48928.0039	loss_val: 48929.3711	loss_test: 48929.1133	accuracy_train: 0.9831	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 271626.0625	loss_val: 271626.2188	loss_test: 271626.7812	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.7308
[client 14]	loss_train: 10272.9619	loss_val: 10273.0811	loss_test: 10273.2295	accuracy_train: 0.3357	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1099.4324	loss_val: 1099.4468	loss_test: 1099.4628	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7650.9009	loss_val: 7651.4565	loss_test: 7651.8325	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 17]	loss_train: 20692.0859	loss_val: 20692.1602	loss_test: 20692.4375	accuracy_train: 0.6809	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13580.4531	loss_val: 13580.6172	loss_test: 13580.4707	accuracy_train: 0.4154	accuracy_val: 0.3529	accuracy_test: 0.4000
[client 19]	loss_train: 1165.9497	loss_val: 1165.9546	loss_test: 1165.9626	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 98	curr_val_accuracy: 0.6796	curr_test_accuracy: 0.6631
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32888.9414	loss_val: 32889.1523	loss_test: 32889.1680	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 20770.6465	loss_val: 20770.6641	loss_test: 20770.7676	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 40852.3242	loss_val: 40855.3555	loss_test: 40853.7617	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 12540.7744	loss_val: 12540.7734	loss_test: 12540.8477	accuracy_train: 0.4560	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6598.3457	loss_val: 6598.4312	loss_test: 6598.5259	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7803.2710	loss_val: 7803.3589	loss_test: 7803.4502	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 52216.6133	loss_val: 52217.2383	loss_test: 52216.8945	accuracy_train: 0.5471	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 41055.2891	loss_val: 41055.4844	loss_test: 41055.3125	accuracy_train: 0.5352	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1049.0303	loss_val: 1049.0408	loss_test: 1049.0354	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59156.7617	loss_val: 59158.9844	loss_test: 59157.0430	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 11959.8496	loss_val: 11959.7861	loss_test: 11959.8848	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3377.5667	loss_val: 3377.7136	loss_test: 3377.8079	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 49496.3672	loss_val: 49497.7539	loss_test: 49497.4688	accuracy_train: 0.9831	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 273080.2500	loss_val: 273080.4062	loss_test: 273081.0000	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.7692
[client 14]	loss_train: 9957.4814	loss_val: 9957.5957	loss_test: 9957.7529	accuracy_train: 0.3287	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1101.0989	loss_val: 1101.1138	loss_test: 1101.1292	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7620.2319	loss_val: 7620.7935	loss_test: 7621.1626	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 17]	loss_train: 20614.7363	loss_val: 20614.8281	loss_test: 20615.1016	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13592.2246	loss_val: 13592.3926	loss_test: 13592.2363	accuracy_train: 0.4191	accuracy_val: 0.3529	accuracy_test: 0.3714
[client 19]	loss_train: 1162.4568	loss_val: 1162.4613	loss_test: 1162.4696	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 99	curr_val_accuracy: 0.6795	curr_test_accuracy: 0.6669
best_round: 13	best_val_accuracy: 0.7078	best_test_accuracy: 0.6974
--------------------------------------------------
