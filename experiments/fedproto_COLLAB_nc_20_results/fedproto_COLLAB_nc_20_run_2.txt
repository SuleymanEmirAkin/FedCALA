GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1.1405	loss_val: 1.0351	loss_test: 0.9705	accuracy_train: 0.0874	accuracy_val: 0.1429	accuracy_test: 0.2143
[client 1]	loss_train: 1.7825	loss_val: 1.9482	loss_test: 1.8968	accuracy_train: 0.5116	accuracy_val: 0.6250	accuracy_test: 0.4412
[client 2]	loss_train: 1.0437	loss_val: 1.0521	loss_test: 1.0683	accuracy_train: 0.4096	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 3]	loss_train: 1.7161	loss_val: 2.1928	loss_test: 1.5127	accuracy_train: 0.3365	accuracy_val: 0.3250	accuracy_test: 0.3659
[client 4]	loss_train: 1.2620	loss_val: 1.1325	loss_test: 1.3530	accuracy_train: 0.4412	accuracy_val: 0.4286	accuracy_test: 0.3333
[client 5]	loss_train: 0.9073	loss_val: 0.8987	loss_test: 0.9182	accuracy_train: 0.8462	accuracy_val: 0.8611	accuracy_test: 0.8378
[client 6]	loss_train: 1.2985	loss_val: 1.1086	loss_test: 1.1365	accuracy_train: 0.5176	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 7]	loss_train: 1.0150	loss_val: 1.0105	loss_test: 0.9815	accuracy_train: 0.4894	accuracy_val: 0.4444	accuracy_test: 0.5946
[client 8]	loss_train: 1.0687	loss_val: 1.0350	loss_test: 1.0722	accuracy_train: 0.6035	accuracy_val: 0.7222	accuracy_test: 0.6389
[client 9]	loss_train: 1.0328	loss_val: 0.9590	loss_test: 0.9713	accuracy_train: 0.6538	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 10]	loss_train: 1.1989	loss_val: 1.1947	loss_test: 1.2152	accuracy_train: 0.0693	accuracy_val: 0.0882	accuracy_test: 0.1429
[client 11]	loss_train: 1.0670	loss_val: 1.0603	loss_test: 1.0287	accuracy_train: 0.4902	accuracy_val: 0.4375	accuracy_test: 0.5758
[client 12]	loss_train: 1.2659	loss_val: 1.0986	loss_test: 1.0581	accuracy_train: 0.3983	accuracy_val: 0.4000	accuracy_test: 0.3529
[client 13]	loss_train: 1.1612	loss_val: 1.0911	loss_test: 1.0803	accuracy_train: 0.0816	accuracy_val: 0.0800	accuracy_test: 0.0769
[client 14]	loss_train: 1.0099	loss_val: 0.9531	loss_test: 0.9897	accuracy_train: 0.3916	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 0.9079	loss_val: 0.9247	loss_test: 0.8917	accuracy_train: 0.9706	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 0.8874	loss_val: 0.8485	loss_test: 1.0429	accuracy_train: 0.5179	accuracy_val: 0.6250	accuracy_test: 0.3750
[client 17]	loss_train: 1.3231	loss_val: 1.6105	loss_test: 1.5771	accuracy_train: 0.2482	accuracy_val: 0.1765	accuracy_test: 0.2105
[client 18]	loss_train: 1.0836	loss_val: 1.0864	loss_test: 1.0919	accuracy_train: 0.2574	accuracy_val: 0.3235	accuracy_test: 0.2857
[client 19]	loss_train: 1.2693	loss_val: 1.2164	loss_test: 1.2421	accuracy_train: 0.0032	accuracy_val: 0.0000	accuracy_test: 0.0256
curr_round: 0	curr_val_accuracy: 0.4212	curr_test_accuracy: 0.4261
best_round: 0	best_val_accuracy: 0.4212	best_test_accuracy: 0.4261
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39756.3984	loss_val: 39756.3750	loss_test: 39756.3516	accuracy_train: 0.0874	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 13260.4570	loss_val: 13260.6240	loss_test: 13260.5098	accuracy_train: 0.6899	accuracy_val: 0.7188	accuracy_test: 0.5882
[client 2]	loss_train: 28485.2363	loss_val: 28485.2441	loss_test: 28485.2676	accuracy_train: 0.4578	accuracy_val: 0.5455	accuracy_test: 0.6364
[client 3]	loss_train: 18234.3086	loss_val: 18234.4160	loss_test: 18234.2578	accuracy_train: 0.3994	accuracy_val: 0.3500	accuracy_test: 0.3415
[client 4]	loss_train: 7732.9380	loss_val: 7732.9487	loss_test: 7732.8838	accuracy_train: 0.4706	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 5823.5122	loss_val: 5823.4946	loss_test: 5823.5337	accuracy_train: 0.8601	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 29024.3516	loss_val: 29024.2129	loss_test: 29024.1973	accuracy_train: 0.5176	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 7]	loss_train: 16869.7695	loss_val: 16869.7559	loss_test: 16869.7402	accuracy_train: 0.6268	accuracy_val: 0.6667	accuracy_test: 0.6757
[client 8]	loss_train: 106.8032	loss_val: 106.7856	loss_test: 106.8037	accuracy_train: 0.9088	accuracy_val: 0.9722	accuracy_test: 0.8611
[client 9]	loss_train: 174218.7500	loss_val: 174218.6875	loss_test: 174218.7656	accuracy_train: 0.7308	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 7175.9336	loss_val: 7175.9331	loss_test: 7175.9136	accuracy_train: 0.0949	accuracy_val: 0.1176	accuracy_test: 0.1714
[client 11]	loss_train: 85.1234	loss_val: 85.1332	loss_test: 85.0963	accuracy_train: 0.4824	accuracy_val: 0.4375	accuracy_test: 0.5758
[client 12]	loss_train: 28112.5215	loss_val: 28112.4766	loss_test: 28112.4531	accuracy_train: 0.5847	accuracy_val: 0.4667	accuracy_test: 0.5294
[client 13]	loss_train: 78524.1250	loss_val: 78524.1250	loss_test: 78524.1094	accuracy_train: 0.1531	accuracy_val: 0.1600	accuracy_test: 0.1923
[client 14]	loss_train: 20610.7793	loss_val: 20610.7441	loss_test: 20610.7480	accuracy_train: 0.4266	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 75.2414	loss_val: 75.2585	loss_test: 75.2436	accuracy_train: 0.9706	accuracy_val: 1.0000	accuracy_test: 0.9615
[client 16]	loss_train: 18081.1641	loss_val: 18081.1719	loss_test: 18081.2637	accuracy_train: 0.4643	accuracy_val: 0.5000	accuracy_test: 0.3750
[client 17]	loss_train: 8998.8545	loss_val: 8998.8525	loss_test: 8998.8828	accuracy_train: 0.2837	accuracy_val: 0.2353	accuracy_test: 0.2632
[client 18]	loss_train: 8022.5854	loss_val: 8022.5942	loss_test: 8022.6338	accuracy_train: 0.3346	accuracy_val: 0.3529	accuracy_test: 0.3143
[client 19]	loss_train: 105.9777	loss_val: 105.9592	loss_test: 105.9676	accuracy_train: 0.0291	accuracy_val: 0.0000	accuracy_test: 0.0513
curr_round: 1	curr_val_accuracy: 0.4754	curr_test_accuracy: 0.4901
best_round: 1	best_val_accuracy: 0.4754	best_test_accuracy: 0.4901
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25902.7090	loss_val: 25902.8457	loss_test: 25902.8379	accuracy_train: 0.0971	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 13964.1426	loss_val: 13964.2617	loss_test: 13964.1748	accuracy_train: 0.6977	accuracy_val: 0.7812	accuracy_test: 0.6471
[client 2]	loss_train: 21402.3359	loss_val: 21402.3340	loss_test: 21402.3574	accuracy_train: 0.5542	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 14899.9189	loss_val: 14899.9062	loss_test: 14899.9150	accuracy_train: 0.6069	accuracy_val: 0.6500	accuracy_test: 0.5854
[client 4]	loss_train: 6366.2974	loss_val: 6366.3208	loss_test: 6366.2383	accuracy_train: 0.4824	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 4518.5142	loss_val: 4518.4946	loss_test: 4518.5439	accuracy_train: 0.8636	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 21232.7871	loss_val: 21232.6914	loss_test: 21232.6406	accuracy_train: 0.5176	accuracy_val: 0.5000	accuracy_test: 0.5455
[client 7]	loss_train: 14435.0957	loss_val: 14435.0713	loss_test: 14435.0771	accuracy_train: 0.6690	accuracy_val: 0.7222	accuracy_test: 0.7027
[client 8]	loss_train: 155.6466	loss_val: 155.6389	loss_test: 155.6393	accuracy_train: 0.9825	accuracy_val: 0.9722	accuracy_test: 0.9722
[client 9]	loss_train: 101809.8125	loss_val: 101809.7891	loss_test: 101809.7891	accuracy_train: 0.7308	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 6986.8491	loss_val: 6986.8320	loss_test: 6986.8403	accuracy_train: 0.1131	accuracy_val: 0.1471	accuracy_test: 0.1714
[client 11]	loss_train: 109.6324	loss_val: 109.6456	loss_test: 109.6128	accuracy_train: 0.4784	accuracy_val: 0.4375	accuracy_test: 0.5455
[client 12]	loss_train: 21918.1934	loss_val: 21918.1797	loss_test: 21918.1641	accuracy_train: 0.6441	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 66277.4297	loss_val: 66277.4453	loss_test: 66277.4297	accuracy_train: 0.7959	accuracy_val: 0.7600	accuracy_test: 0.8462
[client 14]	loss_train: 12730.9053	loss_val: 12730.8750	loss_test: 12730.8730	accuracy_train: 0.4755	accuracy_val: 0.2941	accuracy_test: 0.5000
[client 15]	loss_train: 96.3776	loss_val: 96.3960	loss_test: 96.3895	accuracy_train: 0.9755	accuracy_val: 0.9600	accuracy_test: 0.9231
[client 16]	loss_train: 11840.8760	loss_val: 11840.8945	loss_test: 11840.9805	accuracy_train: 0.4643	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 17]	loss_train: 6205.4663	loss_val: 6205.4707	loss_test: 6205.4707	accuracy_train: 0.3050	accuracy_val: 0.1765	accuracy_test: 0.2632
[client 18]	loss_train: 8151.3545	loss_val: 8151.3628	loss_test: 8151.3960	accuracy_train: 0.3566	accuracy_val: 0.3529	accuracy_test: 0.2571
[client 19]	loss_train: 163.7632	loss_val: 163.7498	loss_test: 163.7604	accuracy_train: 0.0518	accuracy_val: 0.0000	accuracy_test: 0.0513
curr_round: 2	curr_val_accuracy: 0.5389	curr_test_accuracy: 0.5495
best_round: 2	best_val_accuracy: 0.5389	best_test_accuracy: 0.5495
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22805.1699	loss_val: 22805.3477	loss_test: 22805.3418	accuracy_train: 0.1165	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 17618.4492	loss_val: 17618.5254	loss_test: 17618.4355	accuracy_train: 0.7248	accuracy_val: 0.7812	accuracy_test: 0.6765
[client 2]	loss_train: 20263.5742	loss_val: 20263.5703	loss_test: 20263.5977	accuracy_train: 0.5663	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 15042.2832	loss_val: 15042.2305	loss_test: 15042.3086	accuracy_train: 0.6855	accuracy_val: 0.8000	accuracy_test: 0.6098
[client 4]	loss_train: 5989.2651	loss_val: 5989.2905	loss_test: 5989.2158	accuracy_train: 0.4824	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 4354.0898	loss_val: 4354.0713	loss_test: 4354.1255	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 19433.5254	loss_val: 19433.4688	loss_test: 19433.4102	accuracy_train: 0.5235	accuracy_val: 0.5000	accuracy_test: 0.5455
[client 7]	loss_train: 17328.0020	loss_val: 17327.9785	loss_test: 17327.9863	accuracy_train: 0.6725	accuracy_val: 0.7222	accuracy_test: 0.7027
[client 8]	loss_train: 242.4773	loss_val: 242.4773	loss_test: 242.4707	accuracy_train: 0.9930	accuracy_val: 1.0000	accuracy_test: 0.9722
[client 9]	loss_train: 64079.5977	loss_val: 64079.5898	loss_test: 64079.5586	accuracy_train: 0.7115	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 7312.2861	loss_val: 7312.2617	loss_test: 7312.2793	accuracy_train: 0.1460	accuracy_val: 0.1765	accuracy_test: 0.2000
[client 11]	loss_train: 144.4809	loss_val: 144.4957	loss_test: 144.4644	accuracy_train: 0.4902	accuracy_val: 0.4375	accuracy_test: 0.5455
[client 12]	loss_train: 18516.2246	loss_val: 18516.2344	loss_test: 18516.2188	accuracy_train: 0.6356	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 68444.8828	loss_val: 68444.8984	loss_test: 68444.8906	accuracy_train: 0.8878	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 8906.0547	loss_val: 8906.0273	loss_test: 8906.0254	accuracy_train: 0.4406	accuracy_val: 0.2353	accuracy_test: 0.5000
[client 15]	loss_train: 135.9716	loss_val: 135.9929	loss_test: 135.9879	accuracy_train: 0.9755	accuracy_val: 0.9600	accuracy_test: 0.9231
[client 16]	loss_train: 8610.2891	loss_val: 8610.3184	loss_test: 8610.4092	accuracy_train: 0.4821	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 17]	loss_train: 5661.0757	loss_val: 5661.0493	loss_test: 5661.0503	accuracy_train: 0.3050	accuracy_val: 0.2353	accuracy_test: 0.3158
[client 18]	loss_train: 9304.8730	loss_val: 9304.8682	loss_test: 9304.9131	accuracy_train: 0.3603	accuracy_val: 0.3529	accuracy_test: 0.2857
[client 19]	loss_train: 264.2481	loss_val: 264.2402	loss_test: 264.2529	accuracy_train: 0.1197	accuracy_val: 0.0256	accuracy_test: 0.1026
curr_round: 3	curr_val_accuracy: 0.5684	curr_test_accuracy: 0.5688
best_round: 3	best_val_accuracy: 0.5684	best_test_accuracy: 0.5688
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22103.5605	loss_val: 22103.6680	loss_test: 22103.6602	accuracy_train: 0.1165	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 21507.2754	loss_val: 21507.3496	loss_test: 21507.2617	accuracy_train: 0.7597	accuracy_val: 0.8125	accuracy_test: 0.7059
[client 2]	loss_train: 19954.1172	loss_val: 19954.1133	loss_test: 19954.1426	accuracy_train: 0.5783	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 17030.8574	loss_val: 17030.7969	loss_test: 17030.8945	accuracy_train: 0.7013	accuracy_val: 0.7750	accuracy_test: 0.6341
[client 4]	loss_train: 6167.5518	loss_val: 6167.5786	loss_test: 6167.5049	accuracy_train: 0.4824	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 4956.4062	loss_val: 4956.3877	loss_test: 4956.4453	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 19608.6328	loss_val: 19608.6035	loss_test: 19608.5430	accuracy_train: 0.5588	accuracy_val: 0.6818	accuracy_test: 0.5909
[client 7]	loss_train: 22821.9746	loss_val: 22821.9492	loss_test: 22821.9590	accuracy_train: 0.6725	accuracy_val: 0.7222	accuracy_test: 0.7027
[client 8]	loss_train: 367.5778	loss_val: 367.5862	loss_test: 367.5756	accuracy_train: 0.9965	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50498.0664	loss_val: 50498.0703	loss_test: 50498.0234	accuracy_train: 0.7500	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 8436.0801	loss_val: 8436.0527	loss_test: 8436.0732	accuracy_train: 0.1606	accuracy_val: 0.2059	accuracy_test: 0.2000
[client 11]	loss_train: 192.9141	loss_val: 192.9312	loss_test: 192.8970	accuracy_train: 0.5255	accuracy_val: 0.4375	accuracy_test: 0.5758
[client 12]	loss_train: 15769.5430	loss_val: 15769.5596	loss_test: 15769.5420	accuracy_train: 0.6525	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 75708.8438	loss_val: 75708.8672	loss_test: 75708.8594	accuracy_train: 0.9082	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 7164.0249	loss_val: 7164.0029	loss_test: 7164.0015	accuracy_train: 0.4056	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 193.4874	loss_val: 193.5174	loss_test: 193.5080	accuracy_train: 0.9902	accuracy_val: 0.9600	accuracy_test: 0.9231
[client 16]	loss_train: 7092.4263	loss_val: 7092.4536	loss_test: 7092.5508	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 17]	loss_train: 6007.1323	loss_val: 6007.0776	loss_test: 6007.0923	accuracy_train: 0.3050	accuracy_val: 0.2941	accuracy_test: 0.3684
[client 18]	loss_train: 10699.4678	loss_val: 10699.4619	loss_test: 10699.5127	accuracy_train: 0.3640	accuracy_val: 0.3529	accuracy_test: 0.2571
[client 19]	loss_train: 410.5637	loss_val: 410.5649	loss_test: 410.5781	accuracy_train: 0.7896	accuracy_val: 0.8974	accuracy_test: 0.7436
curr_round: 4	curr_val_accuracy: 0.6499	curr_test_accuracy: 0.6263
best_round: 4	best_val_accuracy: 0.6499	best_test_accuracy: 0.6263
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22078.4531	loss_val: 22078.4121	loss_test: 22078.4082	accuracy_train: 0.5534	accuracy_val: 0.7857	accuracy_test: 0.6429
[client 1]	loss_train: 25002.5176	loss_val: 25002.5820	loss_test: 25002.5000	accuracy_train: 0.7752	accuracy_val: 0.8438	accuracy_test: 0.7059
[client 2]	loss_train: 19059.6621	loss_val: 19059.6699	loss_test: 19059.7012	accuracy_train: 0.5904	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 20305.7188	loss_val: 20305.6582	loss_test: 20305.7578	accuracy_train: 0.7075	accuracy_val: 0.8000	accuracy_test: 0.6341
[client 4]	loss_train: 6559.5483	loss_val: 6559.5771	loss_test: 6559.5005	accuracy_train: 0.4824	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 5945.0503	loss_val: 5945.0371	loss_test: 5945.0898	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 20531.6191	loss_val: 20531.6094	loss_test: 20531.5488	accuracy_train: 0.4588	accuracy_val: 0.5909	accuracy_test: 0.4545
[client 7]	loss_train: 27160.9648	loss_val: 27160.9375	loss_test: 27160.9473	accuracy_train: 0.6725	accuracy_val: 0.7500	accuracy_test: 0.7297
[client 8]	loss_train: 531.9826	loss_val: 531.9975	loss_test: 531.9865	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43674.6719	loss_val: 43674.6914	loss_test: 43674.6328	accuracy_train: 0.7500	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 9615.6152	loss_val: 9615.5879	loss_test: 9615.6113	accuracy_train: 0.2372	accuracy_val: 0.3235	accuracy_test: 0.2000
[client 11]	loss_train: 259.6123	loss_val: 259.6324	loss_test: 259.5922	accuracy_train: 0.5451	accuracy_val: 0.4688	accuracy_test: 0.6061
[client 12]	loss_train: 14730.1426	loss_val: 14730.1670	loss_test: 14730.1475	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 85464.0156	loss_val: 85464.0391	loss_test: 85464.0312	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 6827.5420	loss_val: 6827.5239	loss_test: 6827.5269	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 269.8086	loss_val: 269.8484	loss_test: 269.8354	accuracy_train: 0.9902	accuracy_val: 0.9600	accuracy_test: 0.9231
[client 16]	loss_train: 6280.6045	loss_val: 6280.6343	loss_test: 6280.7300	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 17]	loss_train: 6607.9971	loss_val: 6607.9326	loss_test: 6607.9463	accuracy_train: 0.3121	accuracy_val: 0.2941	accuracy_test: 0.3684
[client 18]	loss_train: 11971.7754	loss_val: 11971.7812	loss_test: 11971.8203	accuracy_train: 0.3750	accuracy_val: 0.3529	accuracy_test: 0.3143
[client 19]	loss_train: 596.4637	loss_val: 596.4774	loss_test: 596.4873	accuracy_train: 0.9191	accuracy_val: 0.9231	accuracy_test: 0.8974
curr_round: 5	curr_val_accuracy: 0.6847	curr_test_accuracy: 0.6515
best_round: 5	best_val_accuracy: 0.6847	best_test_accuracy: 0.6515
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23645.3809	loss_val: 23645.3418	loss_test: 23645.3398	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28374.6328	loss_val: 28374.6914	loss_test: 28374.6094	accuracy_train: 0.7752	accuracy_val: 0.8438	accuracy_test: 0.7059
[client 2]	loss_train: 19301.5078	loss_val: 19301.5156	loss_test: 19301.5508	accuracy_train: 0.6145	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 24182.7070	loss_val: 24182.6484	loss_test: 24182.7480	accuracy_train: 0.7107	accuracy_val: 0.8000	accuracy_test: 0.6585
[client 4]	loss_train: 7050.1162	loss_val: 7050.1460	loss_test: 7050.0649	accuracy_train: 0.4882	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 7172.8750	loss_val: 7172.8677	loss_test: 7172.9126	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 22683.0957	loss_val: 22683.1055	loss_test: 22683.0430	accuracy_train: 0.4412	accuracy_val: 0.5000	accuracy_test: 0.4545
[client 7]	loss_train: 32199.6621	loss_val: 32199.6328	loss_test: 32199.6406	accuracy_train: 0.6866	accuracy_val: 0.7778	accuracy_test: 0.7568
[client 8]	loss_train: 716.0435	loss_val: 716.0639	loss_test: 716.0512	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 40950.0781	loss_val: 40950.1094	loss_test: 40950.0352	accuracy_train: 0.7692	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 10768.5068	loss_val: 10768.4775	loss_test: 10768.5049	accuracy_train: 0.5985	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 11]	loss_train: 345.8446	loss_val: 345.8669	loss_test: 345.8203	accuracy_train: 0.5647	accuracy_val: 0.4688	accuracy_test: 0.6061
[client 12]	loss_train: 14704.4805	loss_val: 14704.5088	loss_test: 14704.4883	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 98331.8438	loss_val: 98331.8750	loss_test: 98331.8750	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 7269.4438	loss_val: 7269.4268	loss_test: 7269.4336	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 364.9368	loss_val: 364.9872	loss_test: 364.9734	accuracy_train: 0.9902	accuracy_val: 1.0000	accuracy_test: 0.9615
[client 16]	loss_train: 5415.1953	loss_val: 5415.2241	loss_test: 5415.3203	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 17]	loss_train: 6937.1626	loss_val: 6937.0996	loss_test: 6937.1089	accuracy_train: 0.3050	accuracy_val: 0.2941	accuracy_test: 0.3684
[client 18]	loss_train: 13613.4844	loss_val: 13613.5029	loss_test: 13613.5225	accuracy_train: 0.3934	accuracy_val: 0.3824	accuracy_test: 0.3429
[client 19]	loss_train: 807.6475	loss_val: 807.6734	loss_test: 807.6790	accuracy_train: 0.9773	accuracy_val: 1.0000	accuracy_test: 0.8974
curr_round: 6	curr_val_accuracy: 0.7087	curr_test_accuracy: 0.6942
best_round: 6	best_val_accuracy: 0.7087	best_test_accuracy: 0.6942
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24049.6953	loss_val: 24049.6602	loss_test: 24049.6562	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30511.6816	loss_val: 30511.7363	loss_test: 30511.6543	accuracy_train: 0.7791	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 20254.9785	loss_val: 20254.9883	loss_test: 20255.0254	accuracy_train: 0.6145	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 26504.6309	loss_val: 26504.5742	loss_test: 26504.6738	accuracy_train: 0.7107	accuracy_val: 0.8000	accuracy_test: 0.6585
[client 4]	loss_train: 7268.7471	loss_val: 7268.7788	loss_test: 7268.6909	accuracy_train: 0.5059	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 8016.4688	loss_val: 8016.4648	loss_test: 8016.5063	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 25848.9512	loss_val: 25848.9824	loss_test: 25848.9219	accuracy_train: 0.4294	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 7]	loss_train: 36686.7109	loss_val: 36686.6719	loss_test: 36686.6953	accuracy_train: 0.6831	accuracy_val: 0.7500	accuracy_test: 0.7297
[client 8]	loss_train: 919.9195	loss_val: 919.9410	loss_test: 919.9293	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 41812.5742	loss_val: 41812.6133	loss_test: 41812.5352	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 11934.8711	loss_val: 11934.8340	loss_test: 11934.8740	accuracy_train: 0.6241	accuracy_val: 0.6176	accuracy_test: 0.6000
[client 11]	loss_train: 457.1561	loss_val: 457.1829	loss_test: 457.1260	accuracy_train: 0.5843	accuracy_val: 0.4688	accuracy_test: 0.6364
[client 12]	loss_train: 15087.9121	loss_val: 15087.9453	loss_test: 15087.9248	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 113851.4766	loss_val: 113851.5000	loss_test: 113851.5078	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 7452.6543	loss_val: 7452.6367	loss_test: 7452.6489	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 481.6859	loss_val: 481.7464	loss_test: 481.7294	accuracy_train: 0.9951	accuracy_val: 1.0000	accuracy_test: 0.9615
[client 16]	loss_train: 4893.6538	loss_val: 4893.6821	loss_test: 4893.7749	accuracy_train: 0.5179	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 17]	loss_train: 7189.7480	loss_val: 7189.6992	loss_test: 7189.6978	accuracy_train: 0.3546	accuracy_val: 0.3529	accuracy_test: 0.4211
[client 18]	loss_train: 15597.7012	loss_val: 15597.7178	loss_test: 15597.7227	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1011.7621	loss_val: 1011.7911	loss_test: 1011.7982	accuracy_train: 0.9773	accuracy_val: 1.0000	accuracy_test: 0.9744
curr_round: 7	curr_val_accuracy: 0.7150	curr_test_accuracy: 0.7078
best_round: 7	best_val_accuracy: 0.7150	best_test_accuracy: 0.7078
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24069.7441	loss_val: 24069.7109	loss_test: 24069.7070	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32760.5410	loss_val: 32760.5938	loss_test: 32760.5137	accuracy_train: 0.7597	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 22079.3809	loss_val: 22079.3926	loss_test: 22079.4316	accuracy_train: 0.6265	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 28459.5234	loss_val: 28459.4688	loss_test: 28459.5684	accuracy_train: 0.7201	accuracy_val: 0.7750	accuracy_test: 0.6585
[client 4]	loss_train: 7328.8789	loss_val: 7328.9121	loss_test: 7328.8169	accuracy_train: 0.5176	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 8198.3545	loss_val: 8198.3535	loss_test: 8198.3896	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 30759.8223	loss_val: 30759.8633	loss_test: 30759.8008	accuracy_train: 0.4294	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 7]	loss_train: 40287.8594	loss_val: 40287.8086	loss_test: 40287.8516	accuracy_train: 0.6761	accuracy_val: 0.8056	accuracy_test: 0.7297
[client 8]	loss_train: 1120.5262	loss_val: 1120.5448	loss_test: 1120.5366	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 42528.6211	loss_val: 42528.6602	loss_test: 42528.5820	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 12621.5615	loss_val: 12621.5088	loss_test: 12621.5693	accuracy_train: 0.6131	accuracy_val: 0.6176	accuracy_test: 0.5714
[client 11]	loss_train: 586.9323	loss_val: 586.9648	loss_test: 586.8951	accuracy_train: 0.6392	accuracy_val: 0.5625	accuracy_test: 0.7576
[client 12]	loss_train: 15230.3486	loss_val: 15230.3857	loss_test: 15230.3633	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 128755.3828	loss_val: 128755.4062	loss_test: 128755.4297	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 7446.3848	loss_val: 7446.3711	loss_test: 7446.3853	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 609.8569	loss_val: 609.9270	loss_test: 609.9059	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.9615
[client 16]	loss_train: 4602.2886	loss_val: 4602.3213	loss_test: 4602.4106	accuracy_train: 0.5357	accuracy_val: 0.5000	accuracy_test: 0.3750
[client 17]	loss_train: 7451.2710	loss_val: 7451.2354	loss_test: 7451.2246	accuracy_train: 0.4752	accuracy_val: 0.4706	accuracy_test: 0.5789
[client 18]	loss_train: 16919.0488	loss_val: 16919.0566	loss_test: 16919.0586	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1204.0817	loss_val: 1204.1138	loss_test: 1204.1255	accuracy_train: 0.9871	accuracy_val: 1.0000	accuracy_test: 0.9744
curr_round: 8	curr_val_accuracy: 0.7231	curr_test_accuracy: 0.7172
best_round: 8	best_val_accuracy: 0.7231	best_test_accuracy: 0.7172
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24192.3457	loss_val: 24192.3105	loss_test: 24192.3066	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33386.2148	loss_val: 33386.2656	loss_test: 33386.1914	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 24147.5742	loss_val: 24147.5918	loss_test: 24147.6309	accuracy_train: 0.6265	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 30778.9453	loss_val: 30778.8945	loss_test: 30778.9922	accuracy_train: 0.7264	accuracy_val: 0.8000	accuracy_test: 0.6829
[client 4]	loss_train: 7255.7036	loss_val: 7255.7397	loss_test: 7255.6362	accuracy_train: 0.5588	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 8208.1211	loss_val: 8208.1201	loss_test: 8208.1562	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 35868.4805	loss_val: 35868.5273	loss_test: 35868.4609	accuracy_train: 0.4294	accuracy_val: 0.4091	accuracy_test: 0.4091
[client 7]	loss_train: 43050.5938	loss_val: 43050.5547	loss_test: 43050.5742	accuracy_train: 0.6761	accuracy_val: 0.7222	accuracy_test: 0.7297
[client 8]	loss_train: 1283.1495	loss_val: 1283.1647	loss_test: 1283.1606	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43755.8047	loss_val: 43755.8438	loss_test: 43755.7617	accuracy_train: 0.7885	accuracy_val: 0.7143	accuracy_test: 0.7500
[client 10]	loss_train: 13340.3760	loss_val: 13340.3086	loss_test: 13340.3848	accuracy_train: 0.6022	accuracy_val: 0.6176	accuracy_test: 0.5714
[client 11]	loss_train: 733.5220	loss_val: 733.5585	loss_test: 733.4767	accuracy_train: 0.7059	accuracy_val: 0.6562	accuracy_test: 0.8182
[client 12]	loss_train: 14950.3252	loss_val: 14950.3662	loss_test: 14950.3428	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 143214.8906	loss_val: 143214.9219	loss_test: 143214.9375	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 7455.1997	loss_val: 7455.1919	loss_test: 7455.2046	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 740.7372	loss_val: 740.8122	loss_test: 740.7901	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4445.9355	loss_val: 4445.9751	loss_test: 4446.0625	accuracy_train: 0.6964	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 17]	loss_train: 7995.1401	loss_val: 7995.1118	loss_test: 7995.0952	accuracy_train: 0.5248	accuracy_val: 0.5882	accuracy_test: 0.6842
[client 18]	loss_train: 18014.4551	loss_val: 18014.4609	loss_test: 18014.4648	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1366.8101	loss_val: 1366.8425	loss_test: 1366.8658	accuracy_train: 0.9968	accuracy_val: 1.0000	accuracy_test: 0.9744
curr_round: 9	curr_val_accuracy: 0.7274	curr_test_accuracy: 0.7286
best_round: 9	best_val_accuracy: 0.7274	best_test_accuracy: 0.7286
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23982.3672	loss_val: 23982.3340	loss_test: 23982.3281	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34335.2773	loss_val: 34335.3242	loss_test: 34335.2578	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 25923.0352	loss_val: 25923.0586	loss_test: 25923.0957	accuracy_train: 0.6506	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 33054.8477	loss_val: 33054.7969	loss_test: 33054.8945	accuracy_train: 0.7264	accuracy_val: 0.8250	accuracy_test: 0.6829
[client 4]	loss_train: 7337.1694	loss_val: 7337.2109	loss_test: 7337.0977	accuracy_train: 0.6235	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 8516.6738	loss_val: 8516.6748	loss_test: 8516.7080	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40424.5820	loss_val: 40424.6367	loss_test: 40424.5664	accuracy_train: 0.4353	accuracy_val: 0.4091	accuracy_test: 0.4091
[client 7]	loss_train: 47308.0195	loss_val: 47307.9844	loss_test: 47308.0039	accuracy_train: 0.5880	accuracy_val: 0.5833	accuracy_test: 0.6216
[client 8]	loss_train: 1441.0997	loss_val: 1441.1134	loss_test: 1441.1091	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43669.3047	loss_val: 43669.3477	loss_test: 43669.2656	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 13693.1104	loss_val: 13693.0312	loss_test: 13693.1211	accuracy_train: 0.5949	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 901.6037	loss_val: 901.6437	loss_test: 901.5512	accuracy_train: 0.7451	accuracy_val: 0.7812	accuracy_test: 0.8485
[client 12]	loss_train: 14452.9941	loss_val: 14453.0381	loss_test: 14453.0127	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 156837.7656	loss_val: 156837.7969	loss_test: 156837.8281	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 7564.7588	loss_val: 7564.7559	loss_test: 7564.7686	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 869.9604	loss_val: 870.0366	loss_test: 870.0168	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4407.2710	loss_val: 4407.3081	loss_test: 4407.4014	accuracy_train: 0.7857	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 8651.4746	loss_val: 8651.4570	loss_test: 8651.4365	accuracy_train: 0.6383	accuracy_val: 0.6471	accuracy_test: 0.7368
[client 18]	loss_train: 18753.2812	loss_val: 18753.2871	loss_test: 18753.2910	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1473.8815	loss_val: 1473.9108	loss_test: 1473.9454	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.9744
curr_round: 10	curr_val_accuracy: 0.7274	curr_test_accuracy: 0.7300
best_round: 10	best_val_accuracy: 0.7274	best_test_accuracy: 0.7300
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24796.2578	loss_val: 24796.2246	loss_test: 24796.2188	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34230.8281	loss_val: 34230.8711	loss_test: 34230.8203	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 27562.9316	loss_val: 27562.9648	loss_test: 27563.0000	accuracy_train: 0.6627	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 33213.7305	loss_val: 33213.6836	loss_test: 33213.7812	accuracy_train: 0.7516	accuracy_val: 0.8000	accuracy_test: 0.6585
[client 4]	loss_train: 7473.7485	loss_val: 7473.7930	loss_test: 7473.6743	accuracy_train: 0.6706	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 5]	loss_train: 9065.0801	loss_val: 9065.0820	loss_test: 9065.1133	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43595.2305	loss_val: 43595.2852	loss_test: 43595.2188	accuracy_train: 0.4412	accuracy_val: 0.4091	accuracy_test: 0.4091
[client 7]	loss_train: 50749.0312	loss_val: 50749.0039	loss_test: 50749.0078	accuracy_train: 0.5951	accuracy_val: 0.5556	accuracy_test: 0.6216
[client 8]	loss_train: 1558.4204	loss_val: 1558.4347	loss_test: 1558.4293	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 42421.3203	loss_val: 42421.3711	loss_test: 42421.2812	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 13679.4756	loss_val: 13679.3896	loss_test: 13679.4873	accuracy_train: 0.5876	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1082.1483	loss_val: 1082.1888	loss_test: 1082.0903	accuracy_train: 0.7961	accuracy_val: 0.8125	accuracy_test: 0.8788
[client 12]	loss_train: 13755.1719	loss_val: 13755.2197	loss_test: 13755.1924	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 165148.9062	loss_val: 165148.9375	loss_test: 165148.9844	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 7890.4800	loss_val: 7890.4751	loss_test: 7890.4937	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1000.6796	loss_val: 1000.7554	loss_test: 1000.7382	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4461.3789	loss_val: 4461.4126	loss_test: 4461.5137	accuracy_train: 0.8214	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 9326.5898	loss_val: 9326.5811	loss_test: 9326.5605	accuracy_train: 0.6596	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 18878.8496	loss_val: 18878.8535	loss_test: 18878.8633	accuracy_train: 0.4081	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1551.1504	loss_val: 1551.1765	loss_test: 1551.2201	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 11	curr_val_accuracy: 0.7273	curr_test_accuracy: 0.7356
best_round: 10	best_val_accuracy: 0.7274	best_test_accuracy: 0.7300
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25992.2109	loss_val: 25992.1816	loss_test: 25992.1738	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34667.9531	loss_val: 34667.9922	loss_test: 34667.9570	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 28772.3691	loss_val: 28772.4102	loss_test: 28772.4434	accuracy_train: 0.6747	accuracy_val: 0.8182	accuracy_test: 0.8182
[client 3]	loss_train: 31143.6191	loss_val: 31143.5762	loss_test: 31143.6719	accuracy_train: 0.7296	accuracy_val: 0.8000	accuracy_test: 0.6585
[client 4]	loss_train: 7696.4141	loss_val: 7696.4575	loss_test: 7696.3389	accuracy_train: 0.7118	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 5]	loss_train: 9514.2695	loss_val: 9514.2744	loss_test: 9514.3008	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46335.8672	loss_val: 46335.9258	loss_test: 46335.8594	accuracy_train: 0.4412	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 53026.1445	loss_val: 53026.1250	loss_test: 53026.1211	accuracy_train: 0.5880	accuracy_val: 0.5833	accuracy_test: 0.6216
[client 8]	loss_train: 1627.6406	loss_val: 1627.6561	loss_test: 1627.6499	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 39651.7070	loss_val: 39651.7617	loss_test: 39651.6641	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 13547.3398	loss_val: 13547.2480	loss_test: 13547.3555	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1283.9697	loss_val: 1284.0088	loss_test: 1283.9082	accuracy_train: 0.8196	accuracy_val: 0.8125	accuracy_test: 0.8788
[client 12]	loss_train: 13097.0371	loss_val: 13097.0869	loss_test: 13097.0596	accuracy_train: 0.6695	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 173004.6875	loss_val: 173004.7188	loss_test: 173004.7656	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 8723.4189	loss_val: 8723.4121	loss_test: 8723.4365	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1111.6707	loss_val: 1111.7454	loss_test: 1111.7316	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4465.9834	loss_val: 4466.0195	loss_test: 4466.1230	accuracy_train: 0.8214	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 9869.5645	loss_val: 9869.5576	loss_test: 9869.5391	accuracy_train: 0.6738	accuracy_val: 0.5882	accuracy_test: 0.6842
[client 18]	loss_train: 18427.4102	loss_val: 18427.4141	loss_test: 18427.4297	accuracy_train: 0.4044	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1603.8723	loss_val: 1603.8931	loss_test: 1603.9424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 12	curr_val_accuracy: 0.7312	curr_test_accuracy: 0.7394
best_round: 12	best_val_accuracy: 0.7312	best_test_accuracy: 0.7394
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26694.9219	loss_val: 26694.8965	loss_test: 26694.8887	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 37023.5742	loss_val: 37023.6055	loss_test: 37023.5859	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 30526.6699	loss_val: 30526.7227	loss_test: 30526.7539	accuracy_train: 0.7229	accuracy_val: 0.8182	accuracy_test: 0.8182
[client 3]	loss_train: 29846.3496	loss_val: 29846.3125	loss_test: 29846.4043	accuracy_train: 0.7264	accuracy_val: 0.7500	accuracy_test: 0.6341
[client 4]	loss_train: 7945.6440	loss_val: 7945.6875	loss_test: 7945.5698	accuracy_train: 0.7176	accuracy_val: 0.5714	accuracy_test: 0.7917
[client 5]	loss_train: 9661.5146	loss_val: 9661.5215	loss_test: 9661.5439	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49147.2500	loss_val: 49147.3086	loss_test: 49147.2461	accuracy_train: 0.4471	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 51853.3359	loss_val: 51853.3203	loss_test: 51853.3164	accuracy_train: 0.5880	accuracy_val: 0.6111	accuracy_test: 0.5946
[client 8]	loss_train: 1651.4569	loss_val: 1651.4728	loss_test: 1651.4666	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 39676.2812	loss_val: 39676.3438	loss_test: 39676.2383	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 13525.3496	loss_val: 13525.2549	loss_test: 13525.3682	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1498.2964	loss_val: 1498.3347	loss_test: 1498.2378	accuracy_train: 0.8196	accuracy_val: 0.8125	accuracy_test: 0.9091
[client 12]	loss_train: 12824.6914	loss_val: 12824.7451	loss_test: 12824.7178	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 182931.1094	loss_val: 182931.1562	loss_test: 182931.2031	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9498.7676	loss_val: 9498.7607	loss_test: 9498.7891	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1221.3300	loss_val: 1221.4031	loss_test: 1221.3915	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4524.3765	loss_val: 4524.4194	loss_test: 4524.5220	accuracy_train: 0.8571	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 10186.3496	loss_val: 10186.3477	loss_test: 10186.3271	accuracy_train: 0.6596	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 18123.2871	loss_val: 18123.2930	loss_test: 18123.3125	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1629.3330	loss_val: 1629.3474	loss_test: 1629.4006	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 13	curr_val_accuracy: 0.7292	curr_test_accuracy: 0.7355
best_round: 12	best_val_accuracy: 0.7312	best_test_accuracy: 0.7394
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27198.9961	loss_val: 27198.9727	loss_test: 27198.9629	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 39330.3555	loss_val: 39330.3828	loss_test: 39330.3789	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 31911.8926	loss_val: 31911.9590	loss_test: 31911.9844	accuracy_train: 0.7470	accuracy_val: 0.8182	accuracy_test: 0.8182
[client 3]	loss_train: 28949.7363	loss_val: 28949.7012	loss_test: 28949.7930	accuracy_train: 0.7201	accuracy_val: 0.7750	accuracy_test: 0.6341
[client 4]	loss_train: 7969.7119	loss_val: 7969.7563	loss_test: 7969.6421	accuracy_train: 0.6706	accuracy_val: 0.7619	accuracy_test: 0.8750
[client 5]	loss_train: 9502.8789	loss_val: 9502.8877	loss_test: 9502.9053	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 52565.0078	loss_val: 52565.0625	loss_test: 52565.0039	accuracy_train: 0.4471	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 49536.8398	loss_val: 49536.8203	loss_test: 49536.8281	accuracy_train: 0.5775	accuracy_val: 0.6111	accuracy_test: 0.4865
[client 8]	loss_train: 1664.6964	loss_val: 1664.7117	loss_test: 1664.7079	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 40369.9141	loss_val: 40369.9922	loss_test: 40369.8711	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 13458.5645	loss_val: 13458.4717	loss_test: 13458.5820	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1707.8243	loss_val: 1707.8650	loss_test: 1707.7723	accuracy_train: 0.8392	accuracy_val: 0.7812	accuracy_test: 0.9091
[client 12]	loss_train: 13085.1162	loss_val: 13085.1719	loss_test: 13085.1455	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 189284.8438	loss_val: 189284.8750	loss_test: 189284.9375	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10407.8281	loss_val: 10407.8213	loss_test: 10407.8545	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1315.6685	loss_val: 1315.7394	loss_test: 1315.7311	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4586.1235	loss_val: 4586.1743	loss_test: 4586.2749	accuracy_train: 0.8571	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 10334.1777	loss_val: 10334.1836	loss_test: 10334.1641	accuracy_train: 0.6525	accuracy_val: 0.5294	accuracy_test: 0.6316
[client 18]	loss_train: 18138.2598	loss_val: 18138.2656	loss_test: 18138.2891	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1649.6077	loss_val: 1649.6199	loss_test: 1649.6766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 14	curr_val_accuracy: 0.7353	curr_test_accuracy: 0.7314
best_round: 14	best_val_accuracy: 0.7353	best_test_accuracy: 0.7314
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26262.3711	loss_val: 26262.3477	loss_test: 26262.3379	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 39044.1055	loss_val: 39044.1289	loss_test: 39044.1367	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 33376.6328	loss_val: 33376.7148	loss_test: 33376.7344	accuracy_train: 0.7229	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 27861.7559	loss_val: 27861.7207	loss_test: 27861.8145	accuracy_train: 0.6887	accuracy_val: 0.8000	accuracy_test: 0.7073
[client 4]	loss_train: 7837.5361	loss_val: 7837.5835	loss_test: 7837.4727	accuracy_train: 0.6941	accuracy_val: 0.6667	accuracy_test: 0.8333
[client 5]	loss_train: 9268.3047	loss_val: 9268.3154	loss_test: 9268.3301	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54521.6992	loss_val: 54521.7500	loss_test: 54521.6953	accuracy_train: 0.4529	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 47983.2695	loss_val: 47983.2305	loss_test: 47983.2852	accuracy_train: 0.5599	accuracy_val: 0.6111	accuracy_test: 0.4595
[client 8]	loss_train: 1661.1343	loss_val: 1661.1477	loss_test: 1661.1470	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 41847.3203	loss_val: 41847.4141	loss_test: 41847.2773	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 13230.9482	loss_val: 13230.8574	loss_test: 13230.9658	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1919.0385	loss_val: 1919.0790	loss_test: 1918.9905	accuracy_train: 0.8235	accuracy_val: 0.8125	accuracy_test: 0.8485
[client 12]	loss_train: 13549.6289	loss_val: 13549.6875	loss_test: 13549.6621	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 189077.8906	loss_val: 189077.9219	loss_test: 189078.0000	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10778.8555	loss_val: 10778.8486	loss_test: 10778.8867	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1412.1869	loss_val: 1412.2554	loss_test: 1412.2505	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4579.2568	loss_val: 4579.3135	loss_test: 4579.4141	accuracy_train: 0.8571	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10369.9297	loss_val: 10369.9404	loss_test: 10369.9150	accuracy_train: 0.6596	accuracy_val: 0.5882	accuracy_test: 0.7368
[client 18]	loss_train: 17923.3809	loss_val: 17923.3887	loss_test: 17923.4160	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1683.9778	loss_val: 1683.9890	loss_test: 1684.0486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 15	curr_val_accuracy: 0.7409	curr_test_accuracy: 0.7315
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26007.1602	loss_val: 26007.1406	loss_test: 26007.1309	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 39297.3359	loss_val: 39297.3555	loss_test: 39297.3711	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 34707.3789	loss_val: 34707.4688	loss_test: 34707.4922	accuracy_train: 0.7952	accuracy_val: 0.9091	accuracy_test: 0.6364
[client 3]	loss_train: 27177.4238	loss_val: 27177.3906	loss_test: 27177.4863	accuracy_train: 0.6792	accuracy_val: 0.8000	accuracy_test: 0.6585
[client 4]	loss_train: 7795.6060	loss_val: 7795.6558	loss_test: 7795.5493	accuracy_train: 0.6882	accuracy_val: 0.6190	accuracy_test: 0.7917
[client 5]	loss_train: 9144.1357	loss_val: 9144.1475	loss_test: 9144.1611	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 55130.8984	loss_val: 55130.9453	loss_test: 55130.8945	accuracy_train: 0.4647	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 46722.3984	loss_val: 46722.3633	loss_test: 46722.4141	accuracy_train: 0.5669	accuracy_val: 0.6111	accuracy_test: 0.4595
[client 8]	loss_train: 1648.5995	loss_val: 1648.6118	loss_test: 1648.6141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 44555.8711	loss_val: 44555.9844	loss_test: 44555.8281	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 13074.9502	loss_val: 13074.8604	loss_test: 13074.9658	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2105.2114	loss_val: 2105.2510	loss_test: 2105.1665	accuracy_train: 0.8118	accuracy_val: 0.8125	accuracy_test: 0.8485
[client 12]	loss_train: 14033.7754	loss_val: 14033.8350	loss_test: 14033.8125	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 186046.4062	loss_val: 186046.4375	loss_test: 186046.5156	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10436.5752	loss_val: 10436.5693	loss_test: 10436.6113	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1484.5834	loss_val: 1484.6486	loss_test: 1484.6482	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4626.4116	loss_val: 4626.4731	loss_test: 4626.5747	accuracy_train: 0.8393	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10406.3330	loss_val: 10406.3477	loss_test: 10406.3154	accuracy_train: 0.6525	accuracy_val: 0.5882	accuracy_test: 0.6842
[client 18]	loss_train: 17792.1641	loss_val: 17792.1719	loss_test: 17792.2031	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1690.5488	loss_val: 1690.5586	loss_test: 1690.6223	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 16	curr_val_accuracy: 0.7408	curr_test_accuracy: 0.7220
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26446.7598	loss_val: 26446.7422	loss_test: 26446.7324	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 41428.2734	loss_val: 41428.2930	loss_test: 41428.3164	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 35577.8477	loss_val: 35577.9531	loss_test: 35577.9727	accuracy_train: 0.8434	accuracy_val: 0.9091	accuracy_test: 0.6364
[client 3]	loss_train: 26710.0352	loss_val: 26710.0098	loss_test: 26710.0957	accuracy_train: 0.6509	accuracy_val: 0.7500	accuracy_test: 0.6098
[client 4]	loss_train: 8045.2764	loss_val: 8045.3286	loss_test: 8045.2246	accuracy_train: 0.6941	accuracy_val: 0.6667	accuracy_test: 0.7083
[client 5]	loss_train: 9053.9307	loss_val: 9053.9424	loss_test: 9053.9561	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54327.1914	loss_val: 54327.2344	loss_test: 54327.1914	accuracy_train: 0.4647	accuracy_val: 0.5000	accuracy_test: 0.4091
[client 7]	loss_train: 45363.5664	loss_val: 45363.5508	loss_test: 45363.5664	accuracy_train: 0.5810	accuracy_val: 0.6111	accuracy_test: 0.4595
[client 8]	loss_train: 1640.2562	loss_val: 1640.2679	loss_test: 1640.2733	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46897.6562	loss_val: 46897.7891	loss_test: 46897.6133	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 12673.7871	loss_val: 12673.6992	loss_test: 12673.8018	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2237.1938	loss_val: 2237.2307	loss_test: 2237.1506	accuracy_train: 0.8000	accuracy_val: 0.7812	accuracy_test: 0.8182
[client 12]	loss_train: 14525.3789	loss_val: 14525.4414	loss_test: 14525.4199	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 187795.5781	loss_val: 187795.6094	loss_test: 187795.7031	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10039.1572	loss_val: 10039.1523	loss_test: 10039.1963	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1549.0806	loss_val: 1549.1421	loss_test: 1549.1453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4709.9009	loss_val: 4709.9683	loss_test: 4710.0698	accuracy_train: 0.8393	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10538.0430	loss_val: 10538.0615	loss_test: 10538.0312	accuracy_train: 0.6596	accuracy_val: 0.5882	accuracy_test: 0.6842
[client 18]	loss_train: 18364.0742	loss_val: 18364.0820	loss_test: 18364.1113	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1673.0922	loss_val: 1673.0986	loss_test: 1673.1671	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 17	curr_val_accuracy: 0.7388	curr_test_accuracy: 0.7126
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26660.5684	loss_val: 26660.5527	loss_test: 26660.5430	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 40530.0547	loss_val: 40530.0703	loss_test: 40530.1016	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 36321.3789	loss_val: 36321.5039	loss_test: 36321.5156	accuracy_train: 0.8554	accuracy_val: 0.9091	accuracy_test: 0.6364
[client 3]	loss_train: 26577.6777	loss_val: 26577.6582	loss_test: 26577.7383	accuracy_train: 0.6352	accuracy_val: 0.7250	accuracy_test: 0.5854
[client 4]	loss_train: 8405.4785	loss_val: 8405.5361	loss_test: 8405.4316	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 8962.4385	loss_val: 8962.4512	loss_test: 8962.4639	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 52561.9492	loss_val: 52561.9844	loss_test: 52561.9414	accuracy_train: 0.4706	accuracy_val: 0.5000	accuracy_test: 0.4091
[client 7]	loss_train: 43601.0898	loss_val: 43601.0820	loss_test: 43601.0820	accuracy_train: 0.5986	accuracy_val: 0.6111	accuracy_test: 0.5405
[client 8]	loss_train: 1609.5549	loss_val: 1609.5664	loss_test: 1609.5731	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49154.2031	loss_val: 49154.3594	loss_test: 49154.1641	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12584.6523	loss_val: 12584.5654	loss_test: 12584.6670	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2266.5898	loss_val: 2266.6238	loss_test: 2266.5486	accuracy_train: 0.7922	accuracy_val: 0.7500	accuracy_test: 0.7879
[client 12]	loss_train: 15282.7471	loss_val: 15282.8154	loss_test: 15282.7969	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 190405.2969	loss_val: 190405.3281	loss_test: 190405.4219	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9839.0039	loss_val: 9839.0029	loss_test: 9839.0459	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1599.8018	loss_val: 1599.8607	loss_test: 1599.8669	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4772.0181	loss_val: 4772.0908	loss_test: 4772.1924	accuracy_train: 0.8393	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10593.2588	loss_val: 10593.2832	loss_test: 10593.2520	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6842
[client 18]	loss_train: 18581.9219	loss_val: 18581.9297	loss_test: 18581.9570	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1651.8907	loss_val: 1651.8938	loss_test: 1651.9657	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 18	curr_val_accuracy: 0.7307	curr_test_accuracy: 0.7144
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27337.9531	loss_val: 27337.9395	loss_test: 27337.9336	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 38885.7109	loss_val: 38885.7266	loss_test: 38885.7617	accuracy_train: 0.7481	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 37378.2578	loss_val: 37378.4023	loss_test: 37378.4102	accuracy_train: 0.8434	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 26380.9004	loss_val: 26380.8867	loss_test: 26380.9590	accuracy_train: 0.6384	accuracy_val: 0.7000	accuracy_test: 0.5610
[client 4]	loss_train: 8628.3467	loss_val: 8628.4072	loss_test: 8628.3037	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.7083
[client 5]	loss_train: 8875.1162	loss_val: 8875.1289	loss_test: 8875.1416	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50395.4141	loss_val: 50395.4453	loss_test: 50395.4102	accuracy_train: 0.4765	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 42141.8086	loss_val: 42141.8086	loss_test: 42141.8008	accuracy_train: 0.6021	accuracy_val: 0.6111	accuracy_test: 0.5405
[client 8]	loss_train: 1577.6249	loss_val: 1577.6360	loss_test: 1577.6439	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52758.6758	loss_val: 52758.8555	loss_test: 52758.6367	accuracy_train: 0.8077	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12501.2061	loss_val: 12501.1191	loss_test: 12501.2217	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2271.6301	loss_val: 2271.6611	loss_test: 2271.5876	accuracy_train: 0.8000	accuracy_val: 0.7188	accuracy_test: 0.7576
[client 12]	loss_train: 16036.7432	loss_val: 16036.8174	loss_test: 16036.8027	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 195745.0000	loss_val: 195745.0312	loss_test: 195745.1250	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9862.7666	loss_val: 9862.7695	loss_test: 9862.8115	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1634.0854	loss_val: 1634.1423	loss_test: 1634.1509	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4818.0068	loss_val: 4818.0869	loss_test: 4818.1851	accuracy_train: 0.8393	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10577.9795	loss_val: 10578.0088	loss_test: 10577.9775	accuracy_train: 0.6667	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 17974.0059	loss_val: 17974.0156	loss_test: 17974.0410	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1644.6290	loss_val: 1644.6299	loss_test: 1644.7021	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 19	curr_val_accuracy: 0.7269	curr_test_accuracy: 0.7126
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27553.1797	loss_val: 27553.1680	loss_test: 27553.1660	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 35487.5039	loss_val: 35487.5195	loss_test: 35487.5625	accuracy_train: 0.7481	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 38539.4766	loss_val: 38539.6406	loss_test: 38539.6445	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 26194.7051	loss_val: 26194.6914	loss_test: 26194.7617	accuracy_train: 0.6384	accuracy_val: 0.7000	accuracy_test: 0.5366
[client 4]	loss_train: 8449.5684	loss_val: 8449.6318	loss_test: 8449.5322	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8584.1016	loss_val: 8584.1143	loss_test: 8584.1270	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50143.6523	loss_val: 50143.6719	loss_test: 50143.6367	accuracy_train: 0.4824	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 40359.2070	loss_val: 40359.2031	loss_test: 40359.2031	accuracy_train: 0.6021	accuracy_val: 0.6111	accuracy_test: 0.5676
[client 8]	loss_train: 1539.0149	loss_val: 1539.0260	loss_test: 1539.0330	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51362.5781	loss_val: 51362.7773	loss_test: 51362.5391	accuracy_train: 0.8077	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12442.2539	loss_val: 12442.1689	loss_test: 12442.2705	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2265.4714	loss_val: 2265.4988	loss_test: 2265.4282	accuracy_train: 0.7882	accuracy_val: 0.7188	accuracy_test: 0.7576
[client 12]	loss_train: 17511.8379	loss_val: 17511.9180	loss_test: 17511.9082	accuracy_train: 0.6949	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 199483.2812	loss_val: 199483.3125	loss_test: 199483.4219	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9814.0537	loss_val: 9814.0605	loss_test: 9814.1035	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1665.7098	loss_val: 1665.7649	loss_test: 1665.7750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5024.3071	loss_val: 5024.3975	loss_test: 5024.4946	accuracy_train: 0.8571	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10510.8789	loss_val: 10510.9131	loss_test: 10510.8838	accuracy_train: 0.6525	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 17222.5332	loss_val: 17222.5430	loss_test: 17222.5703	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1664.4611	loss_val: 1664.4614	loss_test: 1664.5305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 20	curr_val_accuracy: 0.7289	curr_test_accuracy: 0.7127
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27955.0273	loss_val: 27955.0195	loss_test: 27955.0215	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33872.8672	loss_val: 33872.8789	loss_test: 33872.9336	accuracy_train: 0.7597	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 40582.7500	loss_val: 40582.9414	loss_test: 40582.9375	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 27134.9062	loss_val: 27134.8887	loss_test: 27134.9648	accuracy_train: 0.6415	accuracy_val: 0.7000	accuracy_test: 0.5366
[client 4]	loss_train: 8334.6572	loss_val: 8334.7256	loss_test: 8334.6289	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 8345.8232	loss_val: 8345.8350	loss_test: 8345.8506	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50507.0781	loss_val: 50507.0977	loss_test: 50507.0664	accuracy_train: 0.5118	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 39567.9492	loss_val: 39567.9375	loss_test: 39567.9648	accuracy_train: 0.5775	accuracy_val: 0.6111	accuracy_test: 0.4865
[client 8]	loss_train: 1501.7932	loss_val: 1501.8043	loss_test: 1501.8082	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49881.4102	loss_val: 49881.6367	loss_test: 49881.3711	accuracy_train: 0.8269	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11984.8232	loss_val: 11984.7412	loss_test: 11984.8398	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2306.4980	loss_val: 2306.5242	loss_test: 2306.4575	accuracy_train: 0.7765	accuracy_val: 0.7188	accuracy_test: 0.7576
[client 12]	loss_train: 18607.9844	loss_val: 18608.0703	loss_test: 18608.0664	accuracy_train: 0.6949	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 198671.4688	loss_val: 198671.5000	loss_test: 198671.6250	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9946.6025	loss_val: 9946.6104	loss_test: 9946.6562	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1680.1017	loss_val: 1680.1567	loss_test: 1680.1674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5255.5640	loss_val: 5255.6665	loss_test: 5255.7612	accuracy_train: 0.8571	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10390.5010	loss_val: 10390.5381	loss_test: 10390.5146	accuracy_train: 0.6525	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 16322.0967	loss_val: 16322.1094	loss_test: 16322.1348	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1672.3851	loss_val: 1672.3856	loss_test: 1672.4489	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 21	curr_val_accuracy: 0.7289	curr_test_accuracy: 0.7051
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26930.6367	loss_val: 26930.6328	loss_test: 26930.6387	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33975.0977	loss_val: 33975.1055	loss_test: 33975.1719	accuracy_train: 0.7674	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 42927.6016	loss_val: 42927.8086	loss_test: 42927.8008	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 28954.9180	loss_val: 28954.9004	loss_test: 28954.9785	accuracy_train: 0.6415	accuracy_val: 0.7000	accuracy_test: 0.5610
[client 4]	loss_train: 8231.0029	loss_val: 8231.0762	loss_test: 8230.9824	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 8111.9028	loss_val: 8111.9146	loss_test: 8111.9316	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51083.0312	loss_val: 51083.0586	loss_test: 51083.0234	accuracy_train: 0.5471	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 40781.7617	loss_val: 40781.7500	loss_test: 40781.7773	accuracy_train: 0.5739	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1494.7998	loss_val: 1494.8118	loss_test: 1494.8126	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48168.1055	loss_val: 48168.3594	loss_test: 48168.0664	accuracy_train: 0.8269	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11808.8936	loss_val: 11808.8145	loss_test: 11808.9121	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2350.3872	loss_val: 2350.4131	loss_test: 2350.3499	accuracy_train: 0.7569	accuracy_val: 0.7500	accuracy_test: 0.7576
[client 12]	loss_train: 18794.6172	loss_val: 18794.7090	loss_test: 18794.7109	accuracy_train: 0.6949	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 194737.5000	loss_val: 194737.5312	loss_test: 194737.6562	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10188.6064	loss_val: 10188.6162	loss_test: 10188.6631	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1680.1710	loss_val: 1680.2263	loss_test: 1680.2372	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5587.1841	loss_val: 5587.2974	loss_test: 5587.3906	accuracy_train: 0.8750	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10247.2988	loss_val: 10247.3359	loss_test: 10247.3184	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 15506.8311	loss_val: 15506.8457	loss_test: 15506.8730	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1654.5195	loss_val: 1654.5209	loss_test: 1654.5808	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 22	curr_val_accuracy: 0.7309	curr_test_accuracy: 0.7053
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26418.8906	loss_val: 26418.8867	loss_test: 26418.9004	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33125.9531	loss_val: 33125.9609	loss_test: 33126.0312	accuracy_train: 0.7674	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 44718.0234	loss_val: 44718.2539	loss_test: 44718.2383	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 29693.1211	loss_val: 29693.1035	loss_test: 29693.1816	accuracy_train: 0.6352	accuracy_val: 0.7000	accuracy_test: 0.5610
[client 4]	loss_train: 8363.1797	loss_val: 8363.2598	loss_test: 8363.1670	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 8025.7715	loss_val: 8025.7827	loss_test: 8025.8032	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51251.2109	loss_val: 51251.2383	loss_test: 51251.2031	accuracy_train: 0.5471	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 42412.4102	loss_val: 42412.4062	loss_test: 42412.4180	accuracy_train: 0.5810	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1479.9503	loss_val: 1479.9636	loss_test: 1479.9623	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47966.4375	loss_val: 47966.7344	loss_test: 47966.3984	accuracy_train: 0.8654	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11693.6045	loss_val: 11693.5273	loss_test: 11693.6221	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2417.4778	loss_val: 2417.5046	loss_test: 2417.4434	accuracy_train: 0.7529	accuracy_val: 0.6875	accuracy_test: 0.7273
[client 12]	loss_train: 19086.7441	loss_val: 19086.8438	loss_test: 19086.8516	accuracy_train: 0.6949	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 191443.8750	loss_val: 191443.9062	loss_test: 191444.0469	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10359.4902	loss_val: 10359.5029	loss_test: 10359.5488	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1690.4980	loss_val: 1690.5531	loss_test: 1690.5632	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5951.8618	loss_val: 5951.9868	loss_test: 5952.0786	accuracy_train: 0.8929	accuracy_val: 0.8750	accuracy_test: 0.7500
[client 17]	loss_train: 10173.9844	loss_val: 10174.0234	loss_test: 10174.0039	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 14897.5527	loss_val: 14897.5693	loss_test: 14897.5967	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1642.5070	loss_val: 1642.5082	loss_test: 1642.5660	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 23	curr_val_accuracy: 0.7249	curr_test_accuracy: 0.7033
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25213.4238	loss_val: 25213.4219	loss_test: 25213.4414	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32788.0430	loss_val: 32788.0469	loss_test: 32788.1250	accuracy_train: 0.7674	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 44534.1289	loss_val: 44534.3750	loss_test: 44534.3516	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 29543.3984	loss_val: 29543.3809	loss_test: 29543.4609	accuracy_train: 0.6384	accuracy_val: 0.7000	accuracy_test: 0.5610
[client 4]	loss_train: 8363.8809	loss_val: 8363.9707	loss_test: 8363.8770	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 8186.6509	loss_val: 8186.6611	loss_test: 8186.6885	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 52770.0977	loss_val: 52770.1328	loss_test: 52770.0977	accuracy_train: 0.5471	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 42632.0859	loss_val: 42632.0859	loss_test: 42632.0938	accuracy_train: 0.5951	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1472.0870	loss_val: 1472.1017	loss_test: 1472.1000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48115.2266	loss_val: 48115.5742	loss_test: 48115.1914	accuracy_train: 0.8846	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 11951.3945	loss_val: 11951.3184	loss_test: 11951.4102	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2511.6772	loss_val: 2511.7070	loss_test: 2511.6504	accuracy_train: 0.7098	accuracy_val: 0.6875	accuracy_test: 0.6970
[client 12]	loss_train: 19771.3555	loss_val: 19771.4590	loss_test: 19771.4766	accuracy_train: 0.6949	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 192973.8125	loss_val: 192973.8438	loss_test: 192974.0000	accuracy_train: 0.9031	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10463.4395	loss_val: 10463.4580	loss_test: 10463.5010	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1700.6135	loss_val: 1700.6685	loss_test: 1700.6772	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6335.4629	loss_val: 6335.5986	loss_test: 6335.6919	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10066.4902	loss_val: 10066.5303	loss_test: 10066.5098	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14706.2988	loss_val: 14706.3193	loss_test: 14706.3457	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1636.4419	loss_val: 1636.4430	loss_test: 1636.4985	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 24	curr_val_accuracy: 0.7212	curr_test_accuracy: 0.7015
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24355.6680	loss_val: 24355.6680	loss_test: 24355.6953	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33516.0156	loss_val: 33516.0195	loss_test: 33516.1016	accuracy_train: 0.7674	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 44672.5117	loss_val: 44672.7852	loss_test: 44672.7461	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 29722.3281	loss_val: 29722.3086	loss_test: 29722.3926	accuracy_train: 0.6164	accuracy_val: 0.6750	accuracy_test: 0.5610
[client 4]	loss_train: 8314.9990	loss_val: 8315.0967	loss_test: 8315.0029	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 8545.4697	loss_val: 8545.4795	loss_test: 8545.5146	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54088.3164	loss_val: 54088.3516	loss_test: 54088.3164	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 44269.6406	loss_val: 44269.6445	loss_test: 44269.6484	accuracy_train: 0.6197	accuracy_val: 0.6111	accuracy_test: 0.5405
[client 8]	loss_train: 1475.5610	loss_val: 1475.5774	loss_test: 1475.5746	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49069.3711	loss_val: 49069.7734	loss_test: 49069.3398	accuracy_train: 0.8846	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12386.9277	loss_val: 12386.8516	loss_test: 12386.9453	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2613.3943	loss_val: 2613.4282	loss_test: 2613.3738	accuracy_train: 0.7059	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 19882.5664	loss_val: 19882.6777	loss_test: 19882.7031	accuracy_train: 0.6949	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 195317.8906	loss_val: 195317.9219	loss_test: 195318.0781	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10770.7461	loss_val: 10770.7725	loss_test: 10770.8105	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1681.6864	loss_val: 1681.7405	loss_test: 1681.7489	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6610.7554	loss_val: 6610.9009	loss_test: 6610.9966	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9953.6797	loss_val: 9953.7217	loss_test: 9953.7061	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14615.3896	loss_val: 14615.4131	loss_test: 14615.4404	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1638.7218	loss_val: 1638.7225	loss_test: 1638.7754	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 25	curr_val_accuracy: 0.7211	curr_test_accuracy: 0.6976
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23595.4355	loss_val: 23595.4355	loss_test: 23595.4707	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34399.9453	loss_val: 34399.9453	loss_test: 34400.0352	accuracy_train: 0.7674	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 45080.8008	loss_val: 45081.0977	loss_test: 45081.0430	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 30487.3750	loss_val: 30487.3535	loss_test: 30487.4414	accuracy_train: 0.6384	accuracy_val: 0.7000	accuracy_test: 0.5854
[client 4]	loss_train: 8221.9668	loss_val: 8222.0723	loss_test: 8221.9805	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 8561.2422	loss_val: 8561.2510	loss_test: 8561.2969	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54748.2500	loss_val: 54748.2773	loss_test: 54748.2383	accuracy_train: 0.5471	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 45654.7461	loss_val: 45654.7578	loss_test: 45654.7539	accuracy_train: 0.6197	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1468.0443	loss_val: 1468.0619	loss_test: 1468.0583	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47991.7109	loss_val: 47992.1719	loss_test: 47991.6797	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 12314.6064	loss_val: 12314.5303	loss_test: 12314.6250	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2677.5515	loss_val: 2677.5884	loss_test: 2677.5381	accuracy_train: 0.6667	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 20203.2422	loss_val: 20203.3594	loss_test: 20203.3945	accuracy_train: 0.6949	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 198155.3906	loss_val: 198155.4375	loss_test: 198155.5938	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10820.6670	loss_val: 10820.6963	loss_test: 10820.7295	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1660.1511	loss_val: 1660.2035	loss_test: 1660.2120	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6920.6509	loss_val: 6920.8047	loss_test: 6920.9048	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10082.0752	loss_val: 10082.1182	loss_test: 10082.1084	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15003.9980	loss_val: 15004.0234	loss_test: 15004.0508	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1653.6354	loss_val: 1653.6361	loss_test: 1653.6852	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 26	curr_val_accuracy: 0.7211	curr_test_accuracy: 0.6976
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22371.2617	loss_val: 22371.2637	loss_test: 22371.3105	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34128.1992	loss_val: 34128.2031	loss_test: 34128.2969	accuracy_train: 0.7674	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 46121.8594	loss_val: 46122.1797	loss_test: 46122.1133	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 29681.1973	loss_val: 29681.1758	loss_test: 29681.2617	accuracy_train: 0.6321	accuracy_val: 0.6250	accuracy_test: 0.5610
[client 4]	loss_train: 7795.1084	loss_val: 7795.2212	loss_test: 7795.1279	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 8126.9297	loss_val: 8126.9399	loss_test: 8126.9937	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54521.6445	loss_val: 54521.6680	loss_test: 54521.6250	accuracy_train: 0.5471	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 46026.3398	loss_val: 46026.3555	loss_test: 46026.3477	accuracy_train: 0.6092	accuracy_val: 0.6111	accuracy_test: 0.4865
[client 8]	loss_train: 1468.5121	loss_val: 1468.5293	loss_test: 1468.5264	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49841.8945	loss_val: 49842.4336	loss_test: 49841.8711	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11668.5947	loss_val: 11668.5195	loss_test: 11668.6143	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2724.1565	loss_val: 2724.1921	loss_test: 2724.1477	accuracy_train: 0.6667	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 20880.2266	loss_val: 20880.3516	loss_test: 20880.3926	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 203344.1094	loss_val: 203344.1562	loss_test: 203344.3125	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10380.4014	loss_val: 10380.4316	loss_test: 10380.4629	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1649.5795	loss_val: 1649.6302	loss_test: 1649.6389	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7149.7930	loss_val: 7149.9536	loss_test: 7150.0571	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10380.2129	loss_val: 10380.2588	loss_test: 10380.2549	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15035.0000	loss_val: 15035.0264	loss_test: 15035.0557	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1634.4594	loss_val: 1634.4597	loss_test: 1634.5054	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 27	curr_val_accuracy: 0.7171	curr_test_accuracy: 0.6937
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23825.9336	loss_val: 23825.9355	loss_test: 23825.9961	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32791.2031	loss_val: 32791.2031	loss_test: 32791.3008	accuracy_train: 0.7597	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 48384.7344	loss_val: 48385.0859	loss_test: 48385.0000	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 27535.3887	loss_val: 27535.3691	loss_test: 27535.4531	accuracy_train: 0.6226	accuracy_val: 0.6250	accuracy_test: 0.5366
[client 4]	loss_train: 7537.9521	loss_val: 7538.0718	loss_test: 7537.9756	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7740.7637	loss_val: 7740.7778	loss_test: 7740.8354	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54161.5938	loss_val: 54161.6172	loss_test: 54161.5703	accuracy_train: 0.5471	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 46977.0391	loss_val: 46977.0586	loss_test: 46977.0430	accuracy_train: 0.5951	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1466.1710	loss_val: 1466.1866	loss_test: 1466.1853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53352.1172	loss_val: 53352.7383	loss_test: 53352.1016	accuracy_train: 0.9231	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11234.6768	loss_val: 11234.6016	loss_test: 11234.6953	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2734.0830	loss_val: 2734.1169	loss_test: 2734.0762	accuracy_train: 0.6667	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 21152.2559	loss_val: 21152.3867	loss_test: 21152.4375	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 200031.9688	loss_val: 200032.0156	loss_test: 200032.1875	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 10033.7842	loss_val: 10033.8135	loss_test: 10033.8438	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1645.7874	loss_val: 1645.8363	loss_test: 1645.8455	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7355.6284	loss_val: 7355.7964	loss_test: 7355.9014	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10487.4102	loss_val: 10487.4570	loss_test: 10487.4619	accuracy_train: 0.6241	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14585.1670	loss_val: 14585.1953	loss_test: 14585.2266	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1624.6011	loss_val: 1624.6018	loss_test: 1624.6445	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 28	curr_val_accuracy: 0.7151	curr_test_accuracy: 0.6920
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24711.2695	loss_val: 24711.2734	loss_test: 24711.3438	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32189.3418	loss_val: 32189.3438	loss_test: 32189.4395	accuracy_train: 0.7519	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 50633.3477	loss_val: 50633.7383	loss_test: 50633.6250	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 26434.0273	loss_val: 26434.0059	loss_test: 26434.0898	accuracy_train: 0.6038	accuracy_val: 0.6250	accuracy_test: 0.5366
[client 4]	loss_train: 7314.0063	loss_val: 7314.1333	loss_test: 7314.0342	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7716.1416	loss_val: 7716.1582	loss_test: 7716.2153	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54152.2227	loss_val: 54152.2539	loss_test: 54152.1992	accuracy_train: 0.5412	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 46189.6211	loss_val: 46189.6211	loss_test: 46189.6289	accuracy_train: 0.5810	accuracy_val: 0.5833	accuracy_test: 0.4595
[client 8]	loss_train: 1465.8569	loss_val: 1465.8710	loss_test: 1465.8708	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55518.4844	loss_val: 55519.2109	loss_test: 55518.4766	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11326.5146	loss_val: 11326.4424	loss_test: 11326.5342	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2691.9641	loss_val: 2691.9971	loss_test: 2691.9587	accuracy_train: 0.6667	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 21354.1836	loss_val: 21354.3203	loss_test: 21354.3809	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 196156.5156	loss_val: 196156.5625	loss_test: 196156.7344	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9806.4482	loss_val: 9806.4795	loss_test: 9806.5049	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1634.7051	loss_val: 1634.7526	loss_test: 1634.7623	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7519.8032	loss_val: 7519.9785	loss_test: 7520.0835	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10483.0674	loss_val: 10483.1143	loss_test: 10483.1152	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13935.4785	loss_val: 13935.5098	loss_test: 13935.5439	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1632.2490	loss_val: 1632.2505	loss_test: 1632.2913	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 29	curr_val_accuracy: 0.7151	curr_test_accuracy: 0.6900
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23704.4961	loss_val: 23704.4980	loss_test: 23704.5781	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34030.4375	loss_val: 34030.4414	loss_test: 34030.5391	accuracy_train: 0.7519	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 49917.1992	loss_val: 49917.6406	loss_test: 49917.4961	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 25345.1270	loss_val: 25345.1035	loss_test: 25345.1895	accuracy_train: 0.5881	accuracy_val: 0.6000	accuracy_test: 0.5366
[client 4]	loss_train: 7023.5859	loss_val: 7023.7197	loss_test: 7023.6187	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7738.6260	loss_val: 7738.6440	loss_test: 7738.7031	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 53953.1445	loss_val: 53953.1875	loss_test: 53953.1289	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 44979.0469	loss_val: 44979.0391	loss_test: 44979.0547	accuracy_train: 0.5845	accuracy_val: 0.5833	accuracy_test: 0.4595
[client 8]	loss_train: 1488.9265	loss_val: 1488.9402	loss_test: 1488.9408	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55360.5898	loss_val: 55361.4258	loss_test: 55360.5938	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11123.7266	loss_val: 11123.6562	loss_test: 11123.7451	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2641.1284	loss_val: 2641.1594	loss_test: 2641.1240	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22246.6152	loss_val: 22246.7559	loss_test: 22246.8281	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 195529.4844	loss_val: 195529.5312	loss_test: 195529.7188	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9475.5156	loss_val: 9475.5488	loss_test: 9475.5684	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1615.4746	loss_val: 1615.5204	loss_test: 1615.5326	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7709.5264	loss_val: 7709.7075	loss_test: 7709.8135	accuracy_train: 0.8929	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10445.3975	loss_val: 10445.4453	loss_test: 10445.4453	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13628.5576	loss_val: 13628.5918	loss_test: 13628.6279	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1620.6718	loss_val: 1620.6732	loss_test: 1620.7133	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 30	curr_val_accuracy: 0.7151	curr_test_accuracy: 0.6918
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24041.2422	loss_val: 24041.2461	loss_test: 24041.3379	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33625.7422	loss_val: 33625.7461	loss_test: 33625.8438	accuracy_train: 0.7558	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 48500.8047	loss_val: 48501.3008	loss_test: 48501.1172	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 24896.5156	loss_val: 24896.4863	loss_test: 24896.5801	accuracy_train: 0.6069	accuracy_val: 0.6250	accuracy_test: 0.5610
[client 4]	loss_train: 6860.7134	loss_val: 6860.8496	loss_test: 6860.7534	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7538.2295	loss_val: 7538.2524	loss_test: 7538.3154	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54157.2070	loss_val: 54157.2656	loss_test: 54157.1992	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 44143.9453	loss_val: 44143.9609	loss_test: 44143.9375	accuracy_train: 0.5951	accuracy_val: 0.5556	accuracy_test: 0.4865
[client 8]	loss_train: 1500.2650	loss_val: 1500.2784	loss_test: 1500.2793	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55369.4688	loss_val: 55370.4297	loss_test: 55369.4805	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10822.6582	loss_val: 10822.5898	loss_test: 10822.6768	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2619.4917	loss_val: 2619.5217	loss_test: 2619.4905	accuracy_train: 0.6667	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22367.5195	loss_val: 22367.6641	loss_test: 22367.7461	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 192863.9219	loss_val: 192863.9844	loss_test: 192864.1562	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9073.9717	loss_val: 9074.0098	loss_test: 9074.0195	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1615.7426	loss_val: 1615.7865	loss_test: 1615.8009	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7875.4170	loss_val: 7875.6050	loss_test: 7875.7109	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10366.3125	loss_val: 10366.3613	loss_test: 10366.3623	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13258.8096	loss_val: 13258.8467	loss_test: 13258.8828	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1632.7656	loss_val: 1632.7666	loss_test: 1632.8063	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 31	curr_val_accuracy: 0.7152	curr_test_accuracy: 0.6939
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25030.6895	loss_val: 25030.6934	loss_test: 25030.7949	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33039.4883	loss_val: 33039.4883	loss_test: 33039.5898	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47670.9531	loss_val: 47671.5000	loss_test: 47671.2891	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 24443.3281	loss_val: 24443.2969	loss_test: 24443.3965	accuracy_train: 0.6006	accuracy_val: 0.6500	accuracy_test: 0.5610
[client 4]	loss_train: 6680.8330	loss_val: 6680.9712	loss_test: 6680.8809	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7489.0073	loss_val: 7489.0396	loss_test: 7489.1040	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54139.7695	loss_val: 54139.8359	loss_test: 54139.7617	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 43737.7734	loss_val: 43737.8047	loss_test: 43737.7656	accuracy_train: 0.6021	accuracy_val: 0.5556	accuracy_test: 0.4865
[client 8]	loss_train: 1505.0337	loss_val: 1505.0470	loss_test: 1505.0474	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55123.9883	loss_val: 55125.0625	loss_test: 55124.0156	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10954.2314	loss_val: 10954.1631	loss_test: 10954.2490	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2571.5864	loss_val: 2571.6165	loss_test: 2571.5874	accuracy_train: 0.6706	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22688.5059	loss_val: 22688.6523	loss_test: 22688.7500	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 190594.5312	loss_val: 190594.5781	loss_test: 190594.7656	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8921.1123	loss_val: 8921.1523	loss_test: 8921.1562	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1613.9921	loss_val: 1614.0342	loss_test: 1614.0509	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7942.9258	loss_val: 7943.1182	loss_test: 7943.2256	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10667.1855	loss_val: 10667.2354	loss_test: 10667.2432	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13168.0811	loss_val: 13168.1201	loss_test: 13168.1582	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1620.9288	loss_val: 1620.9291	loss_test: 1620.9689	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 32	curr_val_accuracy: 0.7171	curr_test_accuracy: 0.6959
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25265.9297	loss_val: 25265.9316	loss_test: 25266.0430	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 33329.9258	loss_val: 33329.9258	loss_test: 33330.0312	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46603.3750	loss_val: 46603.9844	loss_test: 46603.7383	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 24096.9043	loss_val: 24096.8730	loss_test: 24096.9727	accuracy_train: 0.5943	accuracy_val: 0.6500	accuracy_test: 0.5610
[client 4]	loss_train: 6698.8755	loss_val: 6699.0171	loss_test: 6698.9307	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7373.7476	loss_val: 7373.7896	loss_test: 7373.8516	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 55359.0664	loss_val: 55359.1328	loss_test: 55359.0508	accuracy_train: 0.5588	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 42214.1328	loss_val: 42214.1719	loss_test: 42214.1328	accuracy_train: 0.5951	accuracy_val: 0.5278	accuracy_test: 0.4865
[client 8]	loss_train: 1518.2017	loss_val: 1518.2153	loss_test: 1518.2152	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54390.6523	loss_val: 54391.8594	loss_test: 54390.6914	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11151.2373	loss_val: 11151.1709	loss_test: 11151.2559	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2530.8584	loss_val: 2530.8865	loss_test: 2530.8594	accuracy_train: 0.6745	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 23283.0645	loss_val: 23283.2148	loss_test: 23283.3301	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 189687.3125	loss_val: 189687.3750	loss_test: 189687.5625	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8927.7773	loss_val: 8927.8184	loss_test: 8927.8193	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1609.6008	loss_val: 1609.6427	loss_test: 1609.6592	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7991.8940	loss_val: 7992.0913	loss_test: 7992.2007	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10862.7129	loss_val: 10862.7646	loss_test: 10862.7773	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13145.4297	loss_val: 13145.4688	loss_test: 13145.5078	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1613.5134	loss_val: 1613.5127	loss_test: 1613.5522	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 33	curr_val_accuracy: 0.7132	curr_test_accuracy: 0.6959
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24689.8750	loss_val: 24689.8789	loss_test: 24689.9941	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34044.4375	loss_val: 34044.4375	loss_test: 34044.5430	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44988.5195	loss_val: 44989.1875	loss_test: 44988.9141	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 23830.8262	loss_val: 23830.7949	loss_test: 23830.8926	accuracy_train: 0.5975	accuracy_val: 0.6000	accuracy_test: 0.5610
[client 4]	loss_train: 6703.1045	loss_val: 6703.2505	loss_test: 6703.1680	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7672.8628	loss_val: 7672.9092	loss_test: 7672.9707	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 55710.0977	loss_val: 55710.1680	loss_test: 55710.0781	accuracy_train: 0.5588	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 41223.9141	loss_val: 41223.9609	loss_test: 41223.9180	accuracy_train: 0.6021	accuracy_val: 0.5556	accuracy_test: 0.4865
[client 8]	loss_train: 1526.9142	loss_val: 1526.9277	loss_test: 1526.9276	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56204.6641	loss_val: 56205.9727	loss_test: 56204.7188	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11342.2676	loss_val: 11342.2031	loss_test: 11342.2871	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2539.6562	loss_val: 2539.6851	loss_test: 2539.6606	accuracy_train: 0.6784	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 24645.5762	loss_val: 24645.7324	loss_test: 24645.8652	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 187411.5781	loss_val: 187411.6406	loss_test: 187411.8281	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8395.2715	loss_val: 8395.3096	loss_test: 8395.3105	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1597.0834	loss_val: 1597.1252	loss_test: 1597.1412	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7986.6504	loss_val: 7986.8501	loss_test: 7986.9629	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10928.9727	loss_val: 10929.0244	loss_test: 10929.0459	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13126.5479	loss_val: 13126.5879	loss_test: 13126.6279	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1606.7240	loss_val: 1606.7231	loss_test: 1606.7616	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 34	curr_val_accuracy: 0.7112	curr_test_accuracy: 0.6978
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24201.5215	loss_val: 24201.5273	loss_test: 24201.6504	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32943.4180	loss_val: 32943.4180	loss_test: 32943.5234	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44541.5898	loss_val: 44542.3086	loss_test: 44542.0156	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 23259.1602	loss_val: 23259.1328	loss_test: 23259.2266	accuracy_train: 0.5786	accuracy_val: 0.5500	accuracy_test: 0.5366
[client 4]	loss_train: 6818.8120	loss_val: 6818.9648	loss_test: 6818.8823	accuracy_train: 0.6294	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7284.2495	loss_val: 7284.2944	loss_test: 7284.3594	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54965.0195	loss_val: 54965.0898	loss_test: 54964.9961	accuracy_train: 0.5588	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 41761.1602	loss_val: 41761.2109	loss_test: 41761.1680	accuracy_train: 0.6056	accuracy_val: 0.5556	accuracy_test: 0.4865
[client 8]	loss_train: 1500.5753	loss_val: 1500.5881	loss_test: 1500.5884	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56670.1992	loss_val: 56671.6211	loss_test: 56670.2617	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11250.6348	loss_val: 11250.5713	loss_test: 11250.6543	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2588.7571	loss_val: 2588.7874	loss_test: 2588.7649	accuracy_train: 0.6863	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 24550.7500	loss_val: 24550.9102	loss_test: 24551.0625	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 184492.3125	loss_val: 184492.3750	loss_test: 184492.5625	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8221.1660	loss_val: 8221.2012	loss_test: 8221.2012	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1582.5698	loss_val: 1582.6122	loss_test: 1582.6260	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7914.6963	loss_val: 7914.9014	loss_test: 7915.0171	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10910.7295	loss_val: 10910.7832	loss_test: 10910.8076	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13397.8555	loss_val: 13397.8975	loss_test: 13397.9375	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1589.3765	loss_val: 1589.3755	loss_test: 1589.4125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 35	curr_val_accuracy: 0.7051	curr_test_accuracy: 0.6978
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23749.8242	loss_val: 23749.8301	loss_test: 23749.9590	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32607.8730	loss_val: 32607.8750	loss_test: 32607.9805	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44400.6172	loss_val: 44401.3828	loss_test: 44401.0664	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 22752.2383	loss_val: 22752.2148	loss_test: 22752.3047	accuracy_train: 0.5660	accuracy_val: 0.5500	accuracy_test: 0.4878
[client 4]	loss_train: 7186.6694	loss_val: 7186.8262	loss_test: 7186.7476	accuracy_train: 0.6353	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7528.0381	loss_val: 7528.0791	loss_test: 7528.1572	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 53446.5547	loss_val: 53446.6328	loss_test: 53446.5312	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 42203.1328	loss_val: 42203.1836	loss_test: 42203.1445	accuracy_train: 0.6056	accuracy_val: 0.5556	accuracy_test: 0.4865
[client 8]	loss_train: 1479.5144	loss_val: 1479.5260	loss_test: 1479.5271	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57346.8164	loss_val: 57348.3281	loss_test: 57346.8906	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10959.4727	loss_val: 10959.4092	loss_test: 10959.4912	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2631.5354	loss_val: 2631.5674	loss_test: 2631.5464	accuracy_train: 0.6863	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 12]	loss_train: 24462.9629	loss_val: 24463.1309	loss_test: 24463.3008	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 178847.5000	loss_val: 178847.5625	loss_test: 178847.7500	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8260.7070	loss_val: 8260.7422	loss_test: 8260.7422	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1560.1547	loss_val: 1560.1963	loss_test: 1560.2096	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7845.4746	loss_val: 7845.6846	loss_test: 7845.8032	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10696.7051	loss_val: 10696.7627	loss_test: 10696.7949	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13719.1279	loss_val: 13719.1709	loss_test: 13719.2070	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1569.1704	loss_val: 1569.1688	loss_test: 1569.2054	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 36	curr_val_accuracy: 0.7011	curr_test_accuracy: 0.6939
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23865.1152	loss_val: 23865.1211	loss_test: 23865.2539	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 32111.7148	loss_val: 32111.7148	loss_test: 32111.8242	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46555.1055	loss_val: 46555.9102	loss_test: 46555.5781	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 21746.4941	loss_val: 21746.4746	loss_test: 21746.5645	accuracy_train: 0.5566	accuracy_val: 0.5500	accuracy_test: 0.4878
[client 4]	loss_train: 7295.8262	loss_val: 7295.9893	loss_test: 7295.9126	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 8416.2109	loss_val: 8416.2529	loss_test: 8416.3262	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51582.1055	loss_val: 51582.1875	loss_test: 51582.0781	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 40516.6016	loss_val: 40516.6562	loss_test: 40516.6172	accuracy_train: 0.6056	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1458.1205	loss_val: 1458.1310	loss_test: 1458.1327	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58105.7656	loss_val: 58107.3477	loss_test: 58105.8516	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10967.0283	loss_val: 10966.9648	loss_test: 10967.0449	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2703.7031	loss_val: 2703.7356	loss_test: 2703.7175	accuracy_train: 0.6745	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 24056.1504	loss_val: 24056.3242	loss_test: 24056.5176	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.4706
[client 13]	loss_train: 171458.0156	loss_val: 171458.0781	loss_test: 171458.2812	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8481.2109	loss_val: 8481.2422	loss_test: 8481.2471	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1538.7413	loss_val: 1538.7819	loss_test: 1538.7953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7781.6230	loss_val: 7781.8389	loss_test: 7781.9614	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10510.0645	loss_val: 10510.1260	loss_test: 10510.1680	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13740.5215	loss_val: 13740.5635	loss_test: 13740.5977	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1546.2183	loss_val: 1546.2162	loss_test: 1546.2523	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 37	curr_val_accuracy: 0.7050	curr_test_accuracy: 0.6958
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24091.9512	loss_val: 24091.9570	loss_test: 24092.0957	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31495.0547	loss_val: 31495.0527	loss_test: 31495.1660	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48286.1562	loss_val: 48286.9922	loss_test: 48286.6484	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 22093.6914	loss_val: 22093.6699	loss_test: 22093.7637	accuracy_train: 0.5692	accuracy_val: 0.5750	accuracy_test: 0.5122
[client 4]	loss_train: 7264.6455	loss_val: 7264.8125	loss_test: 7264.7378	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 8848.0859	loss_val: 8848.1309	loss_test: 8848.2051	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50147.2344	loss_val: 50147.3164	loss_test: 50147.2031	accuracy_train: 0.5471	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 39571.0000	loss_val: 39571.0547	loss_test: 39571.0156	accuracy_train: 0.6092	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1426.8516	loss_val: 1426.8619	loss_test: 1426.8627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57527.5312	loss_val: 57529.1992	loss_test: 57527.6289	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11219.8252	loss_val: 11219.7598	loss_test: 11219.8398	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2696.4170	loss_val: 2696.4504	loss_test: 2696.4331	accuracy_train: 0.6667	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 23569.7871	loss_val: 23569.9668	loss_test: 23570.1855	accuracy_train: 0.7203	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 170436.0781	loss_val: 170436.1406	loss_test: 170436.3281	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8446.9482	loss_val: 8446.9736	loss_test: 8446.9824	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1509.8654	loss_val: 1509.9044	loss_test: 1509.9187	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7719.9204	loss_val: 7720.1416	loss_test: 7720.2686	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10292.3916	loss_val: 10292.4551	loss_test: 10292.4990	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13435.2461	loss_val: 13435.2881	loss_test: 13435.3223	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1533.1569	loss_val: 1533.1548	loss_test: 1533.1907	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 38	curr_val_accuracy: 0.7031	curr_test_accuracy: 0.6995
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23898.7031	loss_val: 23898.7090	loss_test: 23898.8555	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31102.7441	loss_val: 31102.7441	loss_test: 31102.8574	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47650.4922	loss_val: 47651.3594	loss_test: 47651.0078	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 22381.1445	loss_val: 22381.1230	loss_test: 22381.2168	accuracy_train: 0.5755	accuracy_val: 0.5750	accuracy_test: 0.5366
[client 4]	loss_train: 7020.6812	loss_val: 7020.8506	loss_test: 7020.7773	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 9060.3037	loss_val: 9060.3525	loss_test: 9060.4375	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49430.9219	loss_val: 49431.0039	loss_test: 49430.8867	accuracy_train: 0.5412	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 40627.0469	loss_val: 40627.1016	loss_test: 40627.0664	accuracy_train: 0.6127	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1409.5435	loss_val: 1409.5542	loss_test: 1409.5527	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55520.8398	loss_val: 55522.5273	loss_test: 55520.9414	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11452.1875	loss_val: 11452.1211	loss_test: 11452.2021	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2677.3291	loss_val: 2677.3628	loss_test: 2677.3457	accuracy_train: 0.6667	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 23172.4414	loss_val: 23172.6250	loss_test: 23172.8750	accuracy_train: 0.7542	accuracy_val: 0.8667	accuracy_test: 0.5294
[client 13]	loss_train: 175987.0312	loss_val: 175987.0938	loss_test: 175987.2969	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8527.4316	loss_val: 8527.4551	loss_test: 8527.4648	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1505.3217	loss_val: 1505.3596	loss_test: 1505.3743	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7698.4033	loss_val: 7698.6289	loss_test: 7698.7617	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10123.1992	loss_val: 10123.2666	loss_test: 10123.3066	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13086.5420	loss_val: 13086.5840	loss_test: 13086.6211	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1526.1368	loss_val: 1526.1355	loss_test: 1526.1710	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 39	curr_val_accuracy: 0.7091	curr_test_accuracy: 0.6995
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23693.8164	loss_val: 23693.8242	loss_test: 23693.9746	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 31237.3379	loss_val: 31237.3398	loss_test: 31237.4492	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46350.3320	loss_val: 46351.2422	loss_test: 46350.8633	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 22058.6504	loss_val: 22058.6289	loss_test: 22058.7227	accuracy_train: 0.5660	accuracy_val: 0.5750	accuracy_test: 0.5366
[client 4]	loss_train: 7029.0962	loss_val: 7029.2686	loss_test: 7029.1953	accuracy_train: 0.6706	accuracy_val: 0.4286	accuracy_test: 0.6667
[client 5]	loss_train: 7895.7998	loss_val: 7895.8550	loss_test: 7895.9390	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48877.6016	loss_val: 48877.6914	loss_test: 48877.5664	accuracy_train: 0.5412	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 40861.0703	loss_val: 40861.1289	loss_test: 40861.0859	accuracy_train: 0.6197	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1405.3848	loss_val: 1405.3964	loss_test: 1405.3936	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52782.0703	loss_val: 52783.7656	loss_test: 52782.1719	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11367.7930	loss_val: 11367.7275	loss_test: 11367.8066	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2642.9016	loss_val: 2642.9353	loss_test: 2642.9204	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22653.6680	loss_val: 22653.8574	loss_test: 22654.1387	accuracy_train: 0.8136	accuracy_val: 0.8667	accuracy_test: 0.5294
[client 13]	loss_train: 184231.3594	loss_val: 184231.4219	loss_test: 184231.6250	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8421.2881	loss_val: 8421.3145	loss_test: 8421.3174	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1500.9789	loss_val: 1501.0153	loss_test: 1501.0304	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7662.5732	loss_val: 7662.8057	loss_test: 7662.9429	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9849.9688	loss_val: 9850.0381	loss_test: 9850.0811	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12896.3770	loss_val: 12896.4199	loss_test: 12896.4590	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1536.1167	loss_val: 1536.1157	loss_test: 1536.1503	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 40	curr_val_accuracy: 0.7050	curr_test_accuracy: 0.7013
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23347.1875	loss_val: 23347.1953	loss_test: 23347.3496	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30202.7715	loss_val: 30202.7754	loss_test: 30202.8789	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47814.7305	loss_val: 47815.6758	loss_test: 47815.2812	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20835.2285	loss_val: 20835.2109	loss_test: 20835.3047	accuracy_train: 0.5409	accuracy_val: 0.5500	accuracy_test: 0.4878
[client 4]	loss_train: 6950.8203	loss_val: 6951.0059	loss_test: 6950.9263	accuracy_train: 0.6588	accuracy_val: 0.4286	accuracy_test: 0.7083
[client 5]	loss_train: 7599.4741	loss_val: 7599.5322	loss_test: 7599.6157	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48674.6250	loss_val: 48674.7188	loss_test: 48674.5898	accuracy_train: 0.5412	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 41596.8438	loss_val: 41596.9023	loss_test: 41596.8555	accuracy_train: 0.6232	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1398.6779	loss_val: 1398.6898	loss_test: 1398.6869	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52300.2539	loss_val: 52301.9805	loss_test: 52300.3555	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11591.6279	loss_val: 11591.5625	loss_test: 11591.6416	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2642.2422	loss_val: 2642.2788	loss_test: 2642.2649	accuracy_train: 0.6706	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 21750.3184	loss_val: 21750.5156	loss_test: 21750.8223	accuracy_train: 0.8305	accuracy_val: 0.8000	accuracy_test: 0.5294
[client 13]	loss_train: 185820.7656	loss_val: 185820.8438	loss_test: 185821.0469	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 8243.4893	loss_val: 8243.5117	loss_test: 8243.5146	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1492.3993	loss_val: 1492.4348	loss_test: 1492.4495	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7682.9321	loss_val: 7683.1709	loss_test: 7683.3140	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9805.9600	loss_val: 9806.0293	loss_test: 9806.0791	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12694.7852	loss_val: 12694.8301	loss_test: 12694.8701	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1532.7052	loss_val: 1532.7037	loss_test: 1532.7380	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 41	curr_val_accuracy: 0.6990	curr_test_accuracy: 0.6992
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22587.9297	loss_val: 22587.9375	loss_test: 22588.0957	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29413.4414	loss_val: 29413.4453	loss_test: 29413.5449	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 49286.4102	loss_val: 49287.3672	loss_test: 49286.9688	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19667.2168	loss_val: 19667.2031	loss_test: 19667.2910	accuracy_train: 0.5346	accuracy_val: 0.5500	accuracy_test: 0.4634
[client 4]	loss_train: 6930.5469	loss_val: 6930.7432	loss_test: 6930.6611	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 7547.8574	loss_val: 7547.9175	loss_test: 7548.0034	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49816.6172	loss_val: 49816.7266	loss_test: 49816.5938	accuracy_train: 0.5647	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 43297.7422	loss_val: 43297.8008	loss_test: 43297.7539	accuracy_train: 0.6303	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1379.0465	loss_val: 1379.0583	loss_test: 1379.0558	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50244.5938	loss_val: 50246.3477	loss_test: 50244.6953	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11501.7246	loss_val: 11501.6621	loss_test: 11501.7373	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2639.3198	loss_val: 2639.3601	loss_test: 2639.3467	accuracy_train: 0.6627	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 21472.6328	loss_val: 21472.8398	loss_test: 21473.1738	accuracy_train: 0.8220	accuracy_val: 0.8667	accuracy_test: 0.5294
[client 13]	loss_train: 182530.8438	loss_val: 182530.9219	loss_test: 182531.1406	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 8017.0576	loss_val: 8017.0801	loss_test: 8017.0771	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1491.0140	loss_val: 1491.0490	loss_test: 1491.0627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7697.7305	loss_val: 7697.9746	loss_test: 7698.1240	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9718.0049	loss_val: 9718.0732	loss_test: 9718.1289	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12309.0195	loss_val: 12309.0664	loss_test: 12309.1074	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1547.3896	loss_val: 1547.3878	loss_test: 1547.4203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 42	curr_val_accuracy: 0.7051	curr_test_accuracy: 0.6991
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22483.7461	loss_val: 22483.7539	loss_test: 22483.9180	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29223.1660	loss_val: 29223.1738	loss_test: 29223.2676	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 49674.5391	loss_val: 49675.4922	loss_test: 49675.1094	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20263.8965	loss_val: 20263.8770	loss_test: 20263.9727	accuracy_train: 0.5472	accuracy_val: 0.5750	accuracy_test: 0.5122
[client 4]	loss_train: 6856.4209	loss_val: 6856.6187	loss_test: 6856.5410	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 7513.4346	loss_val: 7513.4976	loss_test: 7513.5889	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51172.0039	loss_val: 51172.1133	loss_test: 51171.9844	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 44542.4102	loss_val: 44542.4688	loss_test: 44542.4297	accuracy_train: 0.6338	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1377.8597	loss_val: 1377.8713	loss_test: 1377.8689	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47356.5664	loss_val: 47358.3281	loss_test: 47356.6680	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11167.3066	loss_val: 11167.2432	loss_test: 11167.3174	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2601.4758	loss_val: 2601.5198	loss_test: 2601.5061	accuracy_train: 0.6627	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 21247.7012	loss_val: 21247.9199	loss_test: 21248.2734	accuracy_train: 0.8390	accuracy_val: 0.8667	accuracy_test: 0.5294
[client 13]	loss_train: 182054.3750	loss_val: 182054.4531	loss_test: 182054.6719	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8093.2603	loss_val: 8093.2881	loss_test: 8093.2769	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1486.9514	loss_val: 1486.9858	loss_test: 1486.9993	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7690.8208	loss_val: 7691.0698	loss_test: 7691.2261	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9729.4639	loss_val: 9729.5283	loss_test: 9729.5938	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11842.4482	loss_val: 11842.4971	loss_test: 11842.5410	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1546.3389	loss_val: 1546.3365	loss_test: 1546.3683	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 43	curr_val_accuracy: 0.7070	curr_test_accuracy: 0.7030
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22442.4961	loss_val: 22442.5039	loss_test: 22442.6719	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29749.3789	loss_val: 29749.3848	loss_test: 29749.4805	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48813.2695	loss_val: 48814.1953	loss_test: 48813.8516	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 21563.2012	loss_val: 21563.1719	loss_test: 21563.2754	accuracy_train: 0.5818	accuracy_val: 0.5750	accuracy_test: 0.5366
[client 4]	loss_train: 6797.0186	loss_val: 6797.2227	loss_test: 6797.1440	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 7604.7954	loss_val: 7604.8608	loss_test: 7604.9536	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 53128.7031	loss_val: 53128.8164	loss_test: 53128.6836	accuracy_train: 0.5588	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 42175.7461	loss_val: 42175.8086	loss_test: 42175.7695	accuracy_train: 0.6338	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1358.8258	loss_val: 1358.8369	loss_test: 1358.8347	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46468.0547	loss_val: 46469.8164	loss_test: 46468.1523	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11063.3887	loss_val: 11063.3252	loss_test: 11063.3984	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2593.8938	loss_val: 2593.9399	loss_test: 2593.9229	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22200.1367	loss_val: 22200.3652	loss_test: 22200.7324	accuracy_train: 0.8305	accuracy_val: 0.8667	accuracy_test: 0.5294
[client 13]	loss_train: 179608.9688	loss_val: 179609.0469	loss_test: 179609.2656	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8400.6934	loss_val: 8400.7266	loss_test: 8400.7080	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1489.4808	loss_val: 1489.5144	loss_test: 1489.5294	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7668.7090	loss_val: 7668.9614	loss_test: 7669.1255	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9802.2686	loss_val: 9802.3271	loss_test: 9802.4053	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11474.2295	loss_val: 11474.2812	loss_test: 11474.3262	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1545.0664	loss_val: 1545.0636	loss_test: 1545.0947	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 44	curr_val_accuracy: 0.7110	curr_test_accuracy: 0.7032
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23537.0703	loss_val: 23537.0781	loss_test: 23537.2480	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30808.3496	loss_val: 30808.3574	loss_test: 30808.4492	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47466.8086	loss_val: 47467.7227	loss_test: 47467.4062	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 21453.7793	loss_val: 21453.7539	loss_test: 21453.8574	accuracy_train: 0.5818	accuracy_val: 0.5750	accuracy_test: 0.5366
[client 4]	loss_train: 6598.0488	loss_val: 6598.2446	loss_test: 6598.1772	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 7586.7256	loss_val: 7586.7910	loss_test: 7586.8789	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54177.3633	loss_val: 54177.4844	loss_test: 54177.3477	accuracy_train: 0.5647	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 38965.7305	loss_val: 38965.7930	loss_test: 38965.7578	accuracy_train: 0.6232	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1366.7799	loss_val: 1366.7904	loss_test: 1366.7886	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47723.6641	loss_val: 47725.5039	loss_test: 47723.7656	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10991.9502	loss_val: 10991.8857	loss_test: 10991.9590	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2561.9727	loss_val: 2562.0212	loss_test: 2561.9995	accuracy_train: 0.6667	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22539.3691	loss_val: 22539.6113	loss_test: 22539.9805	accuracy_train: 0.8305	accuracy_val: 0.8667	accuracy_test: 0.5882
[client 13]	loss_train: 178112.7188	loss_val: 178112.7969	loss_test: 178113.0312	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 8780.1475	loss_val: 8780.1875	loss_test: 8780.1592	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1486.8304	loss_val: 1486.8632	loss_test: 1486.8799	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7643.1777	loss_val: 7643.4336	loss_test: 7643.6055	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9798.8574	loss_val: 9798.9092	loss_test: 9799.0000	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11541.4717	loss_val: 11541.5225	loss_test: 11541.5684	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1532.9954	loss_val: 1532.9929	loss_test: 1533.0240	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 45	curr_val_accuracy: 0.7110	curr_test_accuracy: 0.7049
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24848.7148	loss_val: 24848.7227	loss_test: 24848.9004	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30837.5840	loss_val: 30837.5938	loss_test: 30837.6836	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47192.6172	loss_val: 47193.5234	loss_test: 47193.2383	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 21117.8145	loss_val: 21117.7969	loss_test: 21117.8965	accuracy_train: 0.5818	accuracy_val: 0.5500	accuracy_test: 0.5366
[client 4]	loss_train: 6418.8730	loss_val: 6419.0669	loss_test: 6419.0015	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 7401.1616	loss_val: 7401.2271	loss_test: 7401.3130	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54546.9453	loss_val: 54547.0703	loss_test: 54546.9336	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.6364
[client 7]	loss_train: 37203.1992	loss_val: 37203.2578	loss_test: 37203.2266	accuracy_train: 0.6232	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1359.5443	loss_val: 1359.5546	loss_test: 1359.5526	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48315.4023	loss_val: 48317.3164	loss_test: 48315.5078	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10745.4443	loss_val: 10745.3799	loss_test: 10745.4521	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2510.8330	loss_val: 2510.8850	loss_test: 2510.8577	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22668.6641	loss_val: 22668.9199	loss_test: 22669.2891	accuracy_train: 0.8305	accuracy_val: 0.8000	accuracy_test: 0.5882
[client 13]	loss_train: 175898.4219	loss_val: 175898.5000	loss_test: 175898.7344	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9062.0879	loss_val: 9062.1377	loss_test: 9062.0947	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1491.1406	loss_val: 1491.1726	loss_test: 1491.1898	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7650.9556	loss_val: 7651.2178	loss_test: 7651.3994	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9612.6279	loss_val: 9612.6738	loss_test: 9612.7754	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11671.2012	loss_val: 11671.2520	loss_test: 11671.3027	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1530.1211	loss_val: 1530.1189	loss_test: 1530.1504	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 46	curr_val_accuracy: 0.7050	curr_test_accuracy: 0.7086
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25516.3770	loss_val: 25516.3867	loss_test: 25516.5703	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29944.6211	loss_val: 29944.6328	loss_test: 29944.7246	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46778.4297	loss_val: 46779.3320	loss_test: 46779.0703	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20568.6953	loss_val: 20568.6855	loss_test: 20568.7793	accuracy_train: 0.5849	accuracy_val: 0.5500	accuracy_test: 0.5366
[client 4]	loss_train: 6415.4575	loss_val: 6415.6685	loss_test: 6415.5879	accuracy_train: 0.6588	accuracy_val: 0.4762	accuracy_test: 0.7083
[client 5]	loss_train: 7340.7251	loss_val: 7340.7866	loss_test: 7340.8750	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54226.3438	loss_val: 54226.4727	loss_test: 54226.3320	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.6364
[client 7]	loss_train: 38249.1133	loss_val: 38249.1719	loss_test: 38249.1445	accuracy_train: 0.6056	accuracy_val: 0.5556	accuracy_test: 0.4595
[client 8]	loss_train: 1359.3474	loss_val: 1359.3577	loss_test: 1359.3555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51769.9141	loss_val: 51771.9336	loss_test: 51770.0234	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10516.4404	loss_val: 10516.3750	loss_test: 10516.4482	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2504.1572	loss_val: 2504.2100	loss_test: 2504.1826	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22409.0977	loss_val: 22409.3652	loss_test: 22409.7305	accuracy_train: 0.8390	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 170376.4844	loss_val: 170376.5625	loss_test: 170376.7969	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9256.5166	loss_val: 9256.5693	loss_test: 9256.5166	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1483.3540	loss_val: 1483.3851	loss_test: 1483.4030	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7737.8281	loss_val: 7738.0962	loss_test: 7738.2886	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9454.6787	loss_val: 9454.7148	loss_test: 9454.8291	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11965.5498	loss_val: 11965.6016	loss_test: 11965.6562	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1532.9548	loss_val: 1532.9532	loss_test: 1532.9840	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 47	curr_val_accuracy: 0.7010	curr_test_accuracy: 0.7047
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25430.8750	loss_val: 25430.8848	loss_test: 25431.0762	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28928.5547	loss_val: 28928.5684	loss_test: 28928.6621	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46258.2383	loss_val: 46259.1562	loss_test: 46258.9062	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20474.9258	loss_val: 20474.9180	loss_test: 20475.0059	accuracy_train: 0.5849	accuracy_val: 0.5500	accuracy_test: 0.5366
[client 4]	loss_train: 6250.0103	loss_val: 6250.2266	loss_test: 6250.1470	accuracy_train: 0.6647	accuracy_val: 0.4762	accuracy_test: 0.7083
[client 5]	loss_train: 7428.8843	loss_val: 7428.9424	loss_test: 7429.0425	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 53630.4531	loss_val: 53630.5781	loss_test: 53630.4453	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.6364
[client 7]	loss_train: 39707.2188	loss_val: 39707.2734	loss_test: 39707.2578	accuracy_train: 0.5951	accuracy_val: 0.5556	accuracy_test: 0.4595
[client 8]	loss_train: 1356.2888	loss_val: 1356.2988	loss_test: 1356.2970	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56832.6836	loss_val: 56834.8047	loss_test: 56832.8008	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10536.1465	loss_val: 10536.0801	loss_test: 10536.1562	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2482.1306	loss_val: 2482.1833	loss_test: 2482.1604	accuracy_train: 0.6706	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22149.4805	loss_val: 22149.7617	loss_test: 22150.1309	accuracy_train: 0.8475	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 169300.4531	loss_val: 169300.5312	loss_test: 169300.7656	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9281.3555	loss_val: 9281.4141	loss_test: 9281.3477	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1467.3098	loss_val: 1467.3401	loss_test: 1467.3583	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7816.8623	loss_val: 7817.1372	loss_test: 7817.3379	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9281.1826	loss_val: 9281.2168	loss_test: 9281.3389	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12454.3418	loss_val: 12454.3926	loss_test: 12454.4492	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1519.7012	loss_val: 1519.6998	loss_test: 1519.7307	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 48	curr_val_accuracy: 0.7010	curr_test_accuracy: 0.7047
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24916.0996	loss_val: 24916.1113	loss_test: 24916.3027	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28294.1250	loss_val: 28294.1445	loss_test: 28294.2324	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44863.7305	loss_val: 44864.6641	loss_test: 44864.4258	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 20315.4121	loss_val: 20315.4062	loss_test: 20315.4941	accuracy_train: 0.5818	accuracy_val: 0.5250	accuracy_test: 0.5366
[client 4]	loss_train: 6381.1094	loss_val: 6381.3516	loss_test: 6381.2500	accuracy_train: 0.6824	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 7494.4058	loss_val: 7494.4634	loss_test: 7494.5659	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54111.5156	loss_val: 54111.6445	loss_test: 54111.5156	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.6364
[client 7]	loss_train: 40134.2070	loss_val: 40134.2734	loss_test: 40134.2344	accuracy_train: 0.6021	accuracy_val: 0.5556	accuracy_test: 0.4865
[client 8]	loss_train: 1343.8279	loss_val: 1343.8378	loss_test: 1343.8363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62207.0781	loss_val: 62209.2930	loss_test: 62207.1992	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10888.8467	loss_val: 10888.7803	loss_test: 10888.8584	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2467.7300	loss_val: 2467.7810	loss_test: 2467.7634	accuracy_train: 0.6745	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 22157.9199	loss_val: 22158.2129	loss_test: 22158.5801	accuracy_train: 0.8475	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 165395.7500	loss_val: 165395.8281	loss_test: 165396.0625	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 9229.0215	loss_val: 9229.0869	loss_test: 9229.0088	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1468.7185	loss_val: 1468.7472	loss_test: 1468.7668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7812.7041	loss_val: 7812.9849	loss_test: 7813.1953	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9298.0361	loss_val: 9298.0693	loss_test: 9298.1963	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12715.8516	loss_val: 12715.9053	loss_test: 12715.9600	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1515.3203	loss_val: 1515.3191	loss_test: 1515.3490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 49	curr_val_accuracy: 0.6991	curr_test_accuracy: 0.7048
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24980.9941	loss_val: 24981.0039	loss_test: 24981.2012	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28304.5977	loss_val: 28304.6211	loss_test: 28304.7109	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43813.5352	loss_val: 43814.4805	loss_test: 43814.2461	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 19775.9668	loss_val: 19775.9648	loss_test: 19776.0508	accuracy_train: 0.5252	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 6354.0298	loss_val: 6354.2803	loss_test: 6354.1709	accuracy_train: 0.6824	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 8144.2539	loss_val: 8144.3179	loss_test: 8144.4165	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 54109.9141	loss_val: 54110.0547	loss_test: 54109.9258	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 43780.6328	loss_val: 43780.7031	loss_test: 43780.6602	accuracy_train: 0.6162	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1322.8390	loss_val: 1322.8486	loss_test: 1322.8469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66732.6797	loss_val: 66734.9922	loss_test: 66732.8047	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10958.3447	loss_val: 10958.2803	loss_test: 10958.3584	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2441.0266	loss_val: 2441.0735	loss_test: 2441.0601	accuracy_train: 0.6784	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 21959.0312	loss_val: 21959.3340	loss_test: 21959.7012	accuracy_train: 0.8475	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 165317.9688	loss_val: 165318.0469	loss_test: 165318.2812	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9283.7910	loss_val: 9283.8623	loss_test: 9283.7764	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1476.7015	loss_val: 1476.7295	loss_test: 1476.7493	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7874.9067	loss_val: 7875.1924	loss_test: 7875.4111	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9516.0996	loss_val: 9516.1367	loss_test: 9516.2656	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13336.4395	loss_val: 13336.4922	loss_test: 13336.5469	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1519.0129	loss_val: 1519.0116	loss_test: 1519.0397	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 50	curr_val_accuracy: 0.6951	curr_test_accuracy: 0.6989
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25115.9102	loss_val: 25115.9199	loss_test: 25116.1211	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28584.1660	loss_val: 28584.1914	loss_test: 28584.2793	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43183.2227	loss_val: 43184.1758	loss_test: 43183.9570	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 19199.2695	loss_val: 19199.2617	loss_test: 19199.3535	accuracy_train: 0.5409	accuracy_val: 0.5000	accuracy_test: 0.4634
[client 4]	loss_train: 6292.6069	loss_val: 6292.8633	loss_test: 6292.7495	accuracy_train: 0.6706	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 8202.7461	loss_val: 8202.8135	loss_test: 8202.9297	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 53548.5352	loss_val: 53548.6836	loss_test: 53548.5625	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 45826.0508	loss_val: 45826.1250	loss_test: 45826.0742	accuracy_train: 0.6303	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1313.3374	loss_val: 1313.3467	loss_test: 1313.3446	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66800.6484	loss_val: 66803.0625	loss_test: 66800.7734	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10623.3496	loss_val: 10623.2871	loss_test: 10623.3633	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2441.3992	loss_val: 2441.4429	loss_test: 2441.4326	accuracy_train: 0.6745	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 21283.8418	loss_val: 21284.1562	loss_test: 21284.5234	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 166509.8438	loss_val: 166509.9375	loss_test: 166510.1719	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8673.5029	loss_val: 8673.5801	loss_test: 8673.4902	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1479.3145	loss_val: 1479.3420	loss_test: 1479.3618	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7919.2871	loss_val: 7919.5762	loss_test: 7919.8008	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9967.5830	loss_val: 9967.6240	loss_test: 9967.7529	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13643.1006	loss_val: 13643.1533	loss_test: 13643.2100	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1512.4823	loss_val: 1512.4806	loss_test: 1512.5073	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 51	curr_val_accuracy: 0.6951	curr_test_accuracy: 0.7026
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25130.8359	loss_val: 25130.8438	loss_test: 25131.0449	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29094.9688	loss_val: 29094.9941	loss_test: 29095.0801	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42815.7148	loss_val: 42816.6680	loss_test: 42816.4688	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 18901.3945	loss_val: 18901.3828	loss_test: 18901.4805	accuracy_train: 0.5692	accuracy_val: 0.5000	accuracy_test: 0.4878
[client 4]	loss_train: 6464.7793	loss_val: 6465.0332	loss_test: 6464.9229	accuracy_train: 0.6765	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 7893.5415	loss_val: 7893.6035	loss_test: 7893.7358	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 53578.5625	loss_val: 53578.7188	loss_test: 53578.5898	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 46978.0859	loss_val: 46978.1680	loss_test: 46978.1094	accuracy_train: 0.6162	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1316.8846	loss_val: 1316.8939	loss_test: 1316.8914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61997.1016	loss_val: 61999.6328	loss_test: 61997.2227	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10292.4043	loss_val: 10292.3418	loss_test: 10292.4170	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2501.6206	loss_val: 2501.6638	loss_test: 2501.6531	accuracy_train: 0.6745	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 20881.1582	loss_val: 20881.4824	loss_test: 20881.8496	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 162313.3906	loss_val: 162313.4844	loss_test: 162313.7188	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8495.7041	loss_val: 8495.7881	loss_test: 8495.6924	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1465.5125	loss_val: 1465.5399	loss_test: 1465.5598	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7958.3154	loss_val: 7958.6074	loss_test: 7958.8359	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10373.7461	loss_val: 10373.7852	loss_test: 10373.9160	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13332.4678	loss_val: 13332.5205	loss_test: 13332.5781	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1498.5977	loss_val: 1498.5958	loss_test: 1498.6212	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 52	curr_val_accuracy: 0.6951	curr_test_accuracy: 0.7027
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24752.6914	loss_val: 24752.6992	loss_test: 24752.8965	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30402.2422	loss_val: 30402.2676	loss_test: 30402.3633	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42547.5703	loss_val: 42548.5312	loss_test: 42548.3359	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 18650.3926	loss_val: 18650.3770	loss_test: 18650.4766	accuracy_train: 0.6006	accuracy_val: 0.5250	accuracy_test: 0.5122
[client 4]	loss_train: 6564.0029	loss_val: 6564.2476	loss_test: 6564.1475	accuracy_train: 0.6706	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 7618.6338	loss_val: 7618.6899	loss_test: 7618.8301	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 53278.0703	loss_val: 53278.2383	loss_test: 53278.1016	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 47290.4375	loss_val: 47290.5273	loss_test: 47290.4688	accuracy_train: 0.6056	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1329.0887	loss_val: 1329.0981	loss_test: 1329.0951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55912.9766	loss_val: 55915.6016	loss_test: 55913.0977	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10376.7910	loss_val: 10376.7295	loss_test: 10376.8037	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2597.1318	loss_val: 2597.1772	loss_test: 2597.1616	accuracy_train: 0.6706	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 19363.5195	loss_val: 19363.8535	loss_test: 19364.2266	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 159988.8594	loss_val: 159988.9531	loss_test: 159989.2031	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8233.0859	loss_val: 8233.1768	loss_test: 8233.0752	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1454.6272	loss_val: 1454.6547	loss_test: 1454.6747	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7961.2725	loss_val: 7961.5659	loss_test: 7961.7993	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10030.7568	loss_val: 10030.7930	loss_test: 10030.9287	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12971.2041	loss_val: 12971.2578	loss_test: 12971.3154	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1483.2889	loss_val: 1483.2866	loss_test: 1483.3124	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 53	curr_val_accuracy: 0.6971	curr_test_accuracy: 0.7048
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23911.0371	loss_val: 23911.0469	loss_test: 23911.2344	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30549.8379	loss_val: 30549.8613	loss_test: 30549.9668	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42280.8516	loss_val: 42281.8086	loss_test: 42281.6250	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 18215.1934	loss_val: 18215.1758	loss_test: 18215.2793	accuracy_train: 0.6038	accuracy_val: 0.5250	accuracy_test: 0.5122
[client 4]	loss_train: 6653.3594	loss_val: 6653.5991	loss_test: 6653.5088	accuracy_train: 0.6706	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 7446.2295	loss_val: 7446.2827	loss_test: 7446.4238	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51631.0000	loss_val: 51631.1719	loss_test: 51631.0352	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 45469.7383	loss_val: 45469.8320	loss_test: 45469.7734	accuracy_train: 0.5880	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1330.2369	loss_val: 1330.2462	loss_test: 1330.2433	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50939.1445	loss_val: 50941.8242	loss_test: 50939.2656	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10433.3916	loss_val: 10433.3301	loss_test: 10433.4023	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2717.8284	loss_val: 2717.8762	loss_test: 2717.8613	accuracy_train: 0.6667	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 18140.2754	loss_val: 18140.6191	loss_test: 18141.0098	accuracy_train: 0.8559	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 160220.7500	loss_val: 160220.8281	loss_test: 160221.0938	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8131.0630	loss_val: 8131.1606	loss_test: 8131.0508	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1436.1193	loss_val: 1436.1462	loss_test: 1436.1670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8004.4214	loss_val: 8004.7163	loss_test: 8004.9507	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9666.3213	loss_val: 9666.3545	loss_test: 9666.4951	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12457.7227	loss_val: 12457.7744	loss_test: 12457.8350	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1471.9917	loss_val: 1471.9891	loss_test: 1472.0144	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 54	curr_val_accuracy: 0.6971	curr_test_accuracy: 0.7066
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23124.0254	loss_val: 23124.0352	loss_test: 23124.2129	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29543.4160	loss_val: 29543.4375	loss_test: 29543.5469	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41862.9727	loss_val: 41863.9258	loss_test: 41863.7500	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 17397.6777	loss_val: 17397.6680	loss_test: 17397.7637	accuracy_train: 0.6006	accuracy_val: 0.5500	accuracy_test: 0.5122
[client 4]	loss_train: 6458.2427	loss_val: 6458.4814	loss_test: 6458.3931	accuracy_train: 0.6706	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 7029.1230	loss_val: 7029.1777	loss_test: 7029.3154	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49953.5586	loss_val: 49953.7344	loss_test: 49953.5977	accuracy_train: 0.5824	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 42593.9453	loss_val: 42594.0430	loss_test: 42593.9766	accuracy_train: 0.5986	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1319.4465	loss_val: 1319.4562	loss_test: 1319.4534	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48663.4453	loss_val: 48666.1836	loss_test: 48663.5586	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10436.7412	loss_val: 10436.6816	loss_test: 10436.7529	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2866.7473	loss_val: 2866.7971	loss_test: 2866.7847	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17614.5938	loss_val: 17614.9473	loss_test: 17615.3594	accuracy_train: 0.8559	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 168939.0938	loss_val: 168939.1719	loss_test: 168939.4531	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8155.9185	loss_val: 8156.0215	loss_test: 8155.8994	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1431.8243	loss_val: 1431.8508	loss_test: 1431.8724	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8041.8818	loss_val: 8042.1782	loss_test: 8042.4131	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9472.6416	loss_val: 9472.6680	loss_test: 9472.8115	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12097.9395	loss_val: 12097.9912	loss_test: 12098.0527	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1457.6777	loss_val: 1457.6749	loss_test: 1457.6995	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 55	curr_val_accuracy: 0.7011	curr_test_accuracy: 0.7066
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22420.3184	loss_val: 22420.3262	loss_test: 22420.4980	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 27729.3652	loss_val: 27729.3867	loss_test: 27729.4883	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42733.5508	loss_val: 42734.4961	loss_test: 42734.3281	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 17965.3750	loss_val: 17965.3770	loss_test: 17965.4668	accuracy_train: 0.5975	accuracy_val: 0.5500	accuracy_test: 0.5122
[client 4]	loss_train: 6595.9380	loss_val: 6596.1846	loss_test: 6596.0884	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 6843.7783	loss_val: 6843.8340	loss_test: 6843.9697	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49154.9688	loss_val: 49155.1445	loss_test: 49155.0078	accuracy_train: 0.5882	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 40162.2969	loss_val: 40162.3945	loss_test: 40162.3320	accuracy_train: 0.5986	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1315.6274	loss_val: 1315.6375	loss_test: 1315.6348	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47467.6992	loss_val: 47470.5273	loss_test: 47467.8125	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10320.8408	loss_val: 10320.7822	loss_test: 10320.8496	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2937.1589	loss_val: 2937.2065	loss_test: 2937.1980	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17089.7344	loss_val: 17090.0938	loss_test: 17090.5391	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 174801.3594	loss_val: 174801.4375	loss_test: 174801.7188	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8162.0605	loss_val: 8162.1631	loss_test: 8162.0342	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1433.9260	loss_val: 1433.9520	loss_test: 1433.9746	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8032.8193	loss_val: 8033.1191	loss_test: 8033.3501	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9298.7236	loss_val: 9298.7422	loss_test: 9298.8926	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11702.9775	loss_val: 11703.0273	loss_test: 11703.0908	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1459.2522	loss_val: 1459.2498	loss_test: 1459.2729	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 56	curr_val_accuracy: 0.7050	curr_test_accuracy: 0.7066
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22093.2656	loss_val: 22093.2754	loss_test: 22093.4414	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28180.2383	loss_val: 28180.2559	loss_test: 28180.3477	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43565.5938	loss_val: 43566.5195	loss_test: 43566.3711	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19151.6367	loss_val: 19151.6484	loss_test: 19151.7324	accuracy_train: 0.6132	accuracy_val: 0.5250	accuracy_test: 0.5122
[client 4]	loss_train: 6689.9224	loss_val: 6690.1450	loss_test: 6690.0771	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6870.7280	loss_val: 6870.7866	loss_test: 6870.9185	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48980.9180	loss_val: 48981.0898	loss_test: 48980.9570	accuracy_train: 0.5882	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 39507.8828	loss_val: 39507.9844	loss_test: 39507.9375	accuracy_train: 0.6021	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1311.1398	loss_val: 1311.1499	loss_test: 1311.1475	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47096.9258	loss_val: 47099.7812	loss_test: 47097.0352	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10431.0498	loss_val: 10430.9902	loss_test: 10431.0576	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2964.2615	loss_val: 2964.3064	loss_test: 2964.3044	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 16521.9355	loss_val: 16522.3086	loss_test: 16522.7812	accuracy_train: 0.8559	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 172736.1094	loss_val: 172736.1875	loss_test: 172736.4531	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8303.0752	loss_val: 8303.1777	loss_test: 8303.0449	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1416.7089	loss_val: 1416.7345	loss_test: 1416.7568	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8009.6177	loss_val: 8009.9199	loss_test: 8010.1465	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 9152.6504	loss_val: 9152.6689	loss_test: 9152.8242	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11645.8838	loss_val: 11645.9336	loss_test: 11645.9971	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1456.2863	loss_val: 1456.2841	loss_test: 1456.3070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 57	curr_val_accuracy: 0.6989	curr_test_accuracy: 0.7011
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20963.6602	loss_val: 20963.6699	loss_test: 20963.8281	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28695.5410	loss_val: 28695.5566	loss_test: 28695.6465	accuracy_train: 0.7558	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 43276.2461	loss_val: 43277.1523	loss_test: 43277.0273	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19775.1270	loss_val: 19775.1426	loss_test: 19775.2207	accuracy_train: 0.6038	accuracy_val: 0.5250	accuracy_test: 0.5122
[client 4]	loss_train: 6305.4976	loss_val: 6305.7192	loss_test: 6305.6626	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 7021.5972	loss_val: 7021.6548	loss_test: 7021.7871	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48828.7695	loss_val: 48828.9492	loss_test: 48828.8047	accuracy_train: 0.5765	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 7]	loss_train: 41772.6875	loss_val: 41772.7891	loss_test: 41772.7422	accuracy_train: 0.5951	accuracy_val: 0.5833	accuracy_test: 0.4865
[client 8]	loss_train: 1309.6267	loss_val: 1309.6367	loss_test: 1309.6346	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47095.7500	loss_val: 47098.6406	loss_test: 47095.8555	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10596.0469	loss_val: 10595.9844	loss_test: 10596.0557	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2974.4038	loss_val: 2974.4429	loss_test: 2974.4556	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 16441.9844	loss_val: 16442.3691	loss_test: 16442.8691	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 166462.9375	loss_val: 166463.0156	loss_test: 166463.2812	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8506.1387	loss_val: 8506.2480	loss_test: 8506.1074	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1414.5546	loss_val: 1414.5797	loss_test: 1414.6016	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7981.7305	loss_val: 7982.0381	loss_test: 7982.2607	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 8939.5312	loss_val: 8939.5566	loss_test: 8939.7090	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11927.1172	loss_val: 11927.1699	loss_test: 11927.2314	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1463.0431	loss_val: 1463.0410	loss_test: 1463.0640	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 58	curr_val_accuracy: 0.7009	curr_test_accuracy: 0.7030
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20571.8418	loss_val: 20571.8516	loss_test: 20572.0039	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29239.2617	loss_val: 29239.2773	loss_test: 29239.3711	accuracy_train: 0.7558	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 42618.6328	loss_val: 42619.5352	loss_test: 42619.4141	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20719.9707	loss_val: 20719.9863	loss_test: 20720.0605	accuracy_train: 0.6069	accuracy_val: 0.5500	accuracy_test: 0.5366
[client 4]	loss_train: 6221.4893	loss_val: 6221.7480	loss_test: 6221.6660	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 7045.4248	loss_val: 7045.4785	loss_test: 7045.6182	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48432.7109	loss_val: 48432.8984	loss_test: 48432.7461	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 43818.8867	loss_val: 43818.9805	loss_test: 43818.9375	accuracy_train: 0.5951	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1305.1641	loss_val: 1305.1738	loss_test: 1305.1722	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47720.5898	loss_val: 47723.5391	loss_test: 47720.6914	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10630.5547	loss_val: 10630.4893	loss_test: 10630.5654	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2948.8289	loss_val: 2948.8662	loss_test: 2948.8879	accuracy_train: 0.6510	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17070.0391	loss_val: 17070.4414	loss_test: 17070.9727	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 163096.3906	loss_val: 163096.4688	loss_test: 163096.7344	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8534.7168	loss_val: 8534.8281	loss_test: 8534.6826	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1404.0773	loss_val: 1404.1022	loss_test: 1404.1229	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7922.6138	loss_val: 7922.9287	loss_test: 7923.1489	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 8841.5381	loss_val: 8841.5703	loss_test: 8841.7188	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11664.1621	loss_val: 11664.2178	loss_test: 11664.2734	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1476.5186	loss_val: 1476.5166	loss_test: 1476.5389	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 59	curr_val_accuracy: 0.7009	curr_test_accuracy: 0.7067
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20513.9844	loss_val: 20513.9941	loss_test: 20514.1367	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30065.9121	loss_val: 30065.9297	loss_test: 30066.0254	accuracy_train: 0.7597	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 41312.8828	loss_val: 41313.7891	loss_test: 41313.6680	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 22605.8438	loss_val: 22605.8496	loss_test: 22605.9316	accuracy_train: 0.6164	accuracy_val: 0.5750	accuracy_test: 0.5366
[client 4]	loss_train: 6196.0942	loss_val: 6196.3652	loss_test: 6196.2832	accuracy_train: 0.6706	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 7036.2852	loss_val: 7036.3398	loss_test: 7036.4771	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48060.2070	loss_val: 48060.3984	loss_test: 48060.2422	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 44816.5938	loss_val: 44816.6836	loss_test: 44816.6406	accuracy_train: 0.5986	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1303.4355	loss_val: 1303.4449	loss_test: 1303.4437	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48759.7109	loss_val: 48762.7578	loss_test: 48759.8086	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10094.8018	loss_val: 10094.7363	loss_test: 10094.8164	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2912.4817	loss_val: 2912.5254	loss_test: 2912.5444	accuracy_train: 0.6510	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17320.4102	loss_val: 17320.8301	loss_test: 17321.3828	accuracy_train: 0.8644	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 159103.7656	loss_val: 159103.8438	loss_test: 159104.1094	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8327.1094	loss_val: 8327.2168	loss_test: 8327.0762	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1391.1473	loss_val: 1391.1729	loss_test: 1391.1918	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7868.9097	loss_val: 7869.2310	loss_test: 7869.4512	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 8515.6172	loss_val: 8515.6475	loss_test: 8515.7979	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11516.7529	loss_val: 11516.8105	loss_test: 11516.8623	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1462.6774	loss_val: 1462.6757	loss_test: 1462.6975	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 60	curr_val_accuracy: 0.7050	curr_test_accuracy: 0.7049
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20661.3340	loss_val: 20661.3438	loss_test: 20661.4824	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30381.4492	loss_val: 30381.4707	loss_test: 30381.5547	accuracy_train: 0.7558	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 40674.6680	loss_val: 40675.5781	loss_test: 40675.4492	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 22435.4492	loss_val: 22435.4453	loss_test: 22435.5391	accuracy_train: 0.6195	accuracy_val: 0.5750	accuracy_test: 0.5610
[client 4]	loss_train: 6153.8071	loss_val: 6154.0312	loss_test: 6154.0024	accuracy_train: 0.6647	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 6983.5244	loss_val: 6983.5835	loss_test: 6983.7163	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46920.0000	loss_val: 46920.2070	loss_test: 46920.0430	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 44234.8438	loss_val: 44234.9375	loss_test: 44234.8906	accuracy_train: 0.5810	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1301.1687	loss_val: 1301.1781	loss_test: 1301.1770	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48933.9141	loss_val: 48937.0938	loss_test: 48934.0156	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10279.3008	loss_val: 10279.2363	loss_test: 10279.3174	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2879.3972	loss_val: 2879.4514	loss_test: 2879.4631	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17303.6680	loss_val: 17304.1113	loss_test: 17304.6797	accuracy_train: 0.8644	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 153801.9688	loss_val: 153802.0312	loss_test: 153802.2969	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 7896.5620	loss_val: 7896.6592	loss_test: 7896.5288	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1378.1565	loss_val: 1378.1827	loss_test: 1378.1998	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7765.2295	loss_val: 7765.5552	loss_test: 7765.7778	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 8022.4922	loss_val: 8022.5142	loss_test: 8022.6675	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11623.6250	loss_val: 11623.6846	loss_test: 11623.7373	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1459.2762	loss_val: 1459.2747	loss_test: 1459.2965	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 61	curr_val_accuracy: 0.7010	curr_test_accuracy: 0.7069
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21184.2598	loss_val: 21184.2715	loss_test: 21184.4043	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29451.8906	loss_val: 29451.9238	loss_test: 29451.9941	accuracy_train: 0.7558	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 40550.2109	loss_val: 40551.1328	loss_test: 40550.9922	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 21519.9590	loss_val: 21519.9492	loss_test: 21520.0488	accuracy_train: 0.6132	accuracy_val: 0.5250	accuracy_test: 0.5610
[client 4]	loss_train: 6324.3516	loss_val: 6324.5605	loss_test: 6324.5430	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 6968.2832	loss_val: 6968.3423	loss_test: 6968.4834	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45769.3594	loss_val: 45769.5820	loss_test: 45769.4102	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 43270.5312	loss_val: 43270.6211	loss_test: 43270.5742	accuracy_train: 0.5634	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1298.8651	loss_val: 1298.8748	loss_test: 1298.8737	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59525.0586	loss_val: 59528.4102	loss_test: 59525.1602	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 11057.9287	loss_val: 11057.8652	loss_test: 11057.9463	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2822.6887	loss_val: 2822.7561	loss_test: 2822.7549	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17257.0098	loss_val: 17257.4707	loss_test: 17258.0547	accuracy_train: 0.8644	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 151561.8281	loss_val: 151561.8906	loss_test: 151562.1562	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 7977.6929	loss_val: 7977.7852	loss_test: 7977.6621	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1368.4821	loss_val: 1368.5090	loss_test: 1368.5238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7688.4604	loss_val: 7688.7915	loss_test: 7689.0181	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7718.4932	loss_val: 7718.5093	loss_test: 7718.6631	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11900.3906	loss_val: 11900.4492	loss_test: 11900.5020	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1444.7719	loss_val: 1444.7703	loss_test: 1444.7922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 62	curr_val_accuracy: 0.6890	curr_test_accuracy: 0.7066
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22256.1133	loss_val: 22256.1250	loss_test: 22256.2578	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29400.5781	loss_val: 29400.6172	loss_test: 29400.6797	accuracy_train: 0.7597	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 40480.6680	loss_val: 40481.6133	loss_test: 40481.4453	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20387.4707	loss_val: 20387.4707	loss_test: 20387.5625	accuracy_train: 0.5943	accuracy_val: 0.5500	accuracy_test: 0.5366
[client 4]	loss_train: 6522.2549	loss_val: 6522.4854	loss_test: 6522.4424	accuracy_train: 0.6647	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6792.0522	loss_val: 6792.1108	loss_test: 6792.2563	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44105.4219	loss_val: 44105.6641	loss_test: 44105.4727	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 44383.9141	loss_val: 44384.0039	loss_test: 44383.9531	accuracy_train: 0.5669	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1296.0166	loss_val: 1296.0259	loss_test: 1296.0251	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66533.1641	loss_val: 66536.6797	loss_test: 66533.2578	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10865.3301	loss_val: 10865.2656	loss_test: 10865.3447	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2810.4961	loss_val: 2810.5706	loss_test: 2810.5632	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17230.2402	loss_val: 17230.7227	loss_test: 17231.3262	accuracy_train: 0.8644	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 147595.6875	loss_val: 147595.7344	loss_test: 147596.0000	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8210.1641	loss_val: 8210.2617	loss_test: 8210.1328	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1369.3990	loss_val: 1369.4258	loss_test: 1369.4399	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7653.8286	loss_val: 7654.1636	loss_test: 7654.3950	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7569.6064	loss_val: 7569.6240	loss_test: 7569.7778	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12032.6182	loss_val: 12032.6777	loss_test: 12032.7314	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1422.0327	loss_val: 1422.0311	loss_test: 1422.0537	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 63	curr_val_accuracy: 0.6931	curr_test_accuracy: 0.7029
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22771.4277	loss_val: 22771.4375	loss_test: 22771.5703	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 30205.7578	loss_val: 30205.7969	loss_test: 30205.8652	accuracy_train: 0.7558	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 40632.4414	loss_val: 40633.3906	loss_test: 40633.2227	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 19288.3359	loss_val: 19288.3457	loss_test: 19288.4316	accuracy_train: 0.6006	accuracy_val: 0.5500	accuracy_test: 0.5366
[client 4]	loss_train: 6624.6270	loss_val: 6624.8672	loss_test: 6624.8071	accuracy_train: 0.6647	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 7240.4976	loss_val: 7240.5601	loss_test: 7240.6987	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42455.5859	loss_val: 42455.8398	loss_test: 42455.6406	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 44392.1836	loss_val: 44392.2656	loss_test: 44392.2188	accuracy_train: 0.5563	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1288.9196	loss_val: 1288.9285	loss_test: 1288.9279	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54029.5977	loss_val: 54033.3008	loss_test: 54029.7070	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10390.9268	loss_val: 10390.8604	loss_test: 10390.9385	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2786.2827	loss_val: 2786.3535	loss_test: 2786.3469	accuracy_train: 0.6588	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 16896.5449	loss_val: 16897.0527	loss_test: 16897.6836	accuracy_train: 0.8729	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 144088.0625	loss_val: 144088.1250	loss_test: 144088.3906	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8505.7812	loss_val: 8505.8730	loss_test: 8505.7529	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1376.0548	loss_val: 1376.0806	loss_test: 1376.0946	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7596.8945	loss_val: 7597.2344	loss_test: 7597.4697	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7448.9248	loss_val: 7448.9414	loss_test: 7449.1045	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12158.5771	loss_val: 12158.6416	loss_test: 12158.6963	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1419.6060	loss_val: 1419.6044	loss_test: 1419.6272	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 64	curr_val_accuracy: 0.6891	curr_test_accuracy: 0.7029
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21422.5195	loss_val: 21422.5312	loss_test: 21422.6738	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29650.7910	loss_val: 29650.8340	loss_test: 29650.9043	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42252.8164	loss_val: 42253.7383	loss_test: 42253.5742	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 18258.3418	loss_val: 18258.3613	loss_test: 18258.4414	accuracy_train: 0.6069	accuracy_val: 0.5250	accuracy_test: 0.5366
[client 4]	loss_train: 6588.3276	loss_val: 6588.5645	loss_test: 6588.5054	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 7385.9248	loss_val: 7385.9858	loss_test: 7386.1240	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41387.2930	loss_val: 41387.5586	loss_test: 41387.3594	accuracy_train: 0.5647	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 42724.6445	loss_val: 42724.7266	loss_test: 42724.6836	accuracy_train: 0.5493	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1278.1250	loss_val: 1278.1337	loss_test: 1278.1333	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47367.8867	loss_val: 47371.7734	loss_test: 47368.0000	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10413.3604	loss_val: 10413.2930	loss_test: 10413.3682	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2757.9951	loss_val: 2758.0598	loss_test: 2758.0557	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 16914.2461	loss_val: 16914.7793	loss_test: 16915.4648	accuracy_train: 0.8814	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 143776.8438	loss_val: 143776.9062	loss_test: 143777.1719	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8453.0879	loss_val: 8453.1816	loss_test: 8453.0625	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1374.6051	loss_val: 1374.6299	loss_test: 1374.6439	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7546.1968	loss_val: 7546.5449	loss_test: 7546.7832	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7961.4668	loss_val: 7961.4829	loss_test: 7961.6553	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12445.6172	loss_val: 12445.6846	loss_test: 12445.7393	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1415.1162	loss_val: 1415.1146	loss_test: 1415.1377	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 65	curr_val_accuracy: 0.6812	curr_test_accuracy: 0.7029
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20866.8145	loss_val: 20866.8281	loss_test: 20866.9707	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29120.0508	loss_val: 29120.0996	loss_test: 29120.1641	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45603.3242	loss_val: 45604.1484	loss_test: 45603.9805	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 17515.4629	loss_val: 17515.4824	loss_test: 17515.5625	accuracy_train: 0.6069	accuracy_val: 0.5250	accuracy_test: 0.5122
[client 4]	loss_train: 6494.6162	loss_val: 6494.8398	loss_test: 6494.8027	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7791.2031	loss_val: 7791.2627	loss_test: 7791.4038	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41187.8242	loss_val: 41188.0938	loss_test: 41187.9062	accuracy_train: 0.5647	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 41328.0547	loss_val: 41328.1328	loss_test: 41328.0938	accuracy_train: 0.5528	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1267.1145	loss_val: 1267.1230	loss_test: 1267.1226	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45778.1094	loss_val: 45782.1367	loss_test: 45778.2266	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10195.8857	loss_val: 10195.8184	loss_test: 10195.8926	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2746.1553	loss_val: 2746.2163	loss_test: 2746.2141	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 17289.9668	loss_val: 17290.5254	loss_test: 17291.2617	accuracy_train: 0.8898	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 144464.5625	loss_val: 144464.6250	loss_test: 144464.8906	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8424.3906	loss_val: 8424.4844	loss_test: 8424.3623	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1377.7161	loss_val: 1377.7402	loss_test: 1377.7540	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7512.0913	loss_val: 7512.4478	loss_test: 7512.6870	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7867.1099	loss_val: 7867.1235	loss_test: 7867.3037	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12423.3447	loss_val: 12423.4121	loss_test: 12423.4658	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1402.9506	loss_val: 1402.9491	loss_test: 1402.9720	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 66	curr_val_accuracy: 0.6811	curr_test_accuracy: 0.6991
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20759.7559	loss_val: 20759.7676	loss_test: 20759.9043	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29669.9570	loss_val: 29670.0137	loss_test: 29670.0547	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 40447.4492	loss_val: 40448.4609	loss_test: 40448.2422	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 17221.2578	loss_val: 17221.2734	loss_test: 17221.3574	accuracy_train: 0.5975	accuracy_val: 0.5500	accuracy_test: 0.5122
[client 4]	loss_train: 6277.7480	loss_val: 6277.9453	loss_test: 6277.9419	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7355.5571	loss_val: 7355.6211	loss_test: 7355.7607	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41734.7227	loss_val: 41735.0000	loss_test: 41734.8242	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 42791.5234	loss_val: 42791.6055	loss_test: 42791.5547	accuracy_train: 0.5775	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1262.5337	loss_val: 1262.5422	loss_test: 1262.5420	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45372.5625	loss_val: 45376.6797	loss_test: 45372.6836	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9921.1064	loss_val: 9921.0381	loss_test: 9921.1123	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2764.5618	loss_val: 2764.6223	loss_test: 2764.6213	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17639.7344	loss_val: 17640.3164	loss_test: 17641.1113	accuracy_train: 0.8898	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 139045.9688	loss_val: 139046.0156	loss_test: 139046.2969	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8393.6992	loss_val: 8393.7998	loss_test: 8393.6689	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1380.9454	loss_val: 1380.9689	loss_test: 1380.9823	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7490.4634	loss_val: 7490.8301	loss_test: 7491.0684	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7681.8989	loss_val: 7681.9014	loss_test: 7682.0967	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12678.7061	loss_val: 12678.7744	loss_test: 12678.8281	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1398.3441	loss_val: 1398.3429	loss_test: 1398.3656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 67	curr_val_accuracy: 0.6891	curr_test_accuracy: 0.6990
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21099.9258	loss_val: 21099.9395	loss_test: 21100.0645	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29372.3379	loss_val: 29372.4004	loss_test: 29372.4355	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45477.4648	loss_val: 45478.5508	loss_test: 45478.2891	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 17801.4668	loss_val: 17801.4785	loss_test: 17801.5664	accuracy_train: 0.5849	accuracy_val: 0.5500	accuracy_test: 0.4878
[client 4]	loss_train: 6331.7725	loss_val: 6332.0068	loss_test: 6331.9595	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7102.8184	loss_val: 7102.8838	loss_test: 7103.0195	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42581.7383	loss_val: 42582.0312	loss_test: 42581.8594	accuracy_train: 0.5588	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 44577.6836	loss_val: 44577.7695	loss_test: 44577.7148	accuracy_train: 0.5986	accuracy_val: 0.5556	accuracy_test: 0.5405
[client 8]	loss_train: 1264.3962	loss_val: 1264.4044	loss_test: 1264.4048	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45261.1836	loss_val: 45265.3477	loss_test: 45261.3047	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9921.5840	loss_val: 9921.5156	loss_test: 9921.5889	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2749.6316	loss_val: 2749.6931	loss_test: 2749.6902	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17690.0664	loss_val: 17690.6699	loss_test: 17691.5156	accuracy_train: 0.8983	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 136331.7812	loss_val: 136331.8281	loss_test: 136332.1094	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8359.4297	loss_val: 8359.5400	loss_test: 8359.4014	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1373.8374	loss_val: 1373.8606	loss_test: 1373.8734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7439.7158	loss_val: 7440.0942	loss_test: 7440.3306	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7616.1152	loss_val: 7616.1108	loss_test: 7616.3149	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12973.3662	loss_val: 12973.4375	loss_test: 12973.4941	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1388.5529	loss_val: 1388.5518	loss_test: 1388.5741	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 68	curr_val_accuracy: 0.6971	curr_test_accuracy: 0.6990
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21367.8418	loss_val: 21367.8555	loss_test: 21367.9746	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29814.9688	loss_val: 29815.0312	loss_test: 29815.0645	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 52101.3320	loss_val: 52102.4766	loss_test: 52102.1680	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 18503.8945	loss_val: 18503.9062	loss_test: 18503.9980	accuracy_train: 0.5535	accuracy_val: 0.5500	accuracy_test: 0.4634
[client 4]	loss_train: 6443.9014	loss_val: 6444.1284	loss_test: 6444.0898	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7252.8799	loss_val: 7252.9424	loss_test: 7253.0840	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43273.7930	loss_val: 43274.0938	loss_test: 43273.9141	accuracy_train: 0.5471	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 46594.8750	loss_val: 46594.9648	loss_test: 46594.8984	accuracy_train: 0.6021	accuracy_val: 0.5556	accuracy_test: 0.5405
[client 8]	loss_train: 1262.0592	loss_val: 1262.0675	loss_test: 1262.0685	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 44145.7969	loss_val: 44149.9453	loss_test: 44145.9102	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10334.4033	loss_val: 10334.3359	loss_test: 10334.4092	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2726.3926	loss_val: 2726.4556	loss_test: 2726.4568	accuracy_train: 0.6510	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 17644.5332	loss_val: 17645.1621	loss_test: 17646.0527	accuracy_train: 0.9068	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 147859.4688	loss_val: 147859.5156	loss_test: 147859.8125	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8570.5684	loss_val: 8570.6904	loss_test: 8570.5381	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1368.5604	loss_val: 1368.5826	loss_test: 1368.5957	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7422.0098	loss_val: 7422.4009	loss_test: 7422.6328	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7620.9614	loss_val: 7620.9619	loss_test: 7621.1680	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12954.5439	loss_val: 12954.6182	loss_test: 12954.6748	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1391.7551	loss_val: 1391.7539	loss_test: 1391.7753	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 69	curr_val_accuracy: 0.6991	curr_test_accuracy: 0.6990
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21572.4297	loss_val: 21572.4453	loss_test: 21572.5371	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28735.0645	loss_val: 28735.1250	loss_test: 28735.1582	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 59090.3281	loss_val: 59091.5156	loss_test: 59091.1719	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19236.7012	loss_val: 19236.7090	loss_test: 19236.8105	accuracy_train: 0.5629	accuracy_val: 0.5250	accuracy_test: 0.4390
[client 4]	loss_train: 6448.0415	loss_val: 6448.2622	loss_test: 6448.2349	accuracy_train: 0.6353	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7430.7124	loss_val: 7430.7769	loss_test: 7430.9165	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44850.0625	loss_val: 44850.3711	loss_test: 44850.1836	accuracy_train: 0.5471	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 46804.7344	loss_val: 46804.8281	loss_test: 46804.7539	accuracy_train: 0.6021	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1251.0956	loss_val: 1251.1039	loss_test: 1251.1053	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43697.2656	loss_val: 43701.4727	loss_test: 43697.3711	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10380.4541	loss_val: 10380.3867	loss_test: 10380.4600	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2766.3110	loss_val: 2766.3767	loss_test: 2766.3840	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17457.6074	loss_val: 17458.2676	loss_test: 17459.1973	accuracy_train: 0.9068	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 153520.5000	loss_val: 153520.5469	loss_test: 153520.8438	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8585.5469	loss_val: 8585.6689	loss_test: 8585.5078	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1360.4235	loss_val: 1360.4448	loss_test: 1360.4579	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7385.8833	loss_val: 7386.2852	loss_test: 7386.5137	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7858.0405	loss_val: 7858.0513	loss_test: 7858.2524	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12810.1719	loss_val: 12810.2451	loss_test: 12810.3047	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1403.1422	loss_val: 1403.1410	loss_test: 1403.1610	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 70	curr_val_accuracy: 0.6931	curr_test_accuracy: 0.6951
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21731.0020	loss_val: 21731.0215	loss_test: 21731.0859	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 27613.7598	loss_val: 27613.8203	loss_test: 27613.8574	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 66140.5625	loss_val: 66141.7969	loss_test: 66141.4062	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 19743.9160	loss_val: 19743.9180	loss_test: 19744.0273	accuracy_train: 0.6132	accuracy_val: 0.5500	accuracy_test: 0.5610
[client 4]	loss_train: 6544.2812	loss_val: 6544.4800	loss_test: 6544.4810	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 7638.2041	loss_val: 7638.2695	loss_test: 7638.4033	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46887.2773	loss_val: 46887.5859	loss_test: 46887.3867	accuracy_train: 0.5471	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 45374.3672	loss_val: 45374.4648	loss_test: 45374.3906	accuracy_train: 0.6021	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1246.1272	loss_val: 1246.1356	loss_test: 1246.1371	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 41777.8594	loss_val: 41782.0586	loss_test: 41777.9531	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10405.2666	loss_val: 10405.1992	loss_test: 10405.2725	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2779.9863	loss_val: 2780.0659	loss_test: 2780.0698	accuracy_train: 0.6510	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 16830.6602	loss_val: 16831.3477	loss_test: 16832.3242	accuracy_train: 0.9153	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 161477.8750	loss_val: 161477.9219	loss_test: 161478.2031	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8395.4512	loss_val: 8395.5635	loss_test: 8395.3994	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1356.8508	loss_val: 1356.8721	loss_test: 1356.8845	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7333.9663	loss_val: 7334.3789	loss_test: 7334.6035	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7953.1274	loss_val: 7953.1475	loss_test: 7953.3433	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11999.1953	loss_val: 11999.2646	loss_test: 11999.3271	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1414.9852	loss_val: 1414.9840	loss_test: 1415.0027	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 71	curr_val_accuracy: 0.6932	curr_test_accuracy: 0.7048
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21606.8828	loss_val: 21606.9043	loss_test: 21606.9395	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 27550.7500	loss_val: 27550.8105	loss_test: 27550.8516	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 71195.4609	loss_val: 71196.7344	loss_test: 71196.3047	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19889.1914	loss_val: 19889.1875	loss_test: 19889.3008	accuracy_train: 0.6258	accuracy_val: 0.6000	accuracy_test: 0.5854
[client 4]	loss_train: 6524.0498	loss_val: 6524.2495	loss_test: 6524.2622	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 8052.0425	loss_val: 8052.1025	loss_test: 8052.2417	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49420.2852	loss_val: 49420.5938	loss_test: 49420.3828	accuracy_train: 0.5471	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 43525.0391	loss_val: 43525.1406	loss_test: 43525.0664	accuracy_train: 0.5951	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1256.9066	loss_val: 1256.9149	loss_test: 1256.9166	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 41428.8359	loss_val: 41433.0664	loss_test: 41428.9219	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10421.6396	loss_val: 10421.5723	loss_test: 10421.6475	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2817.2830	loss_val: 2817.3787	loss_test: 2817.3755	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 17067.1426	loss_val: 17067.8594	loss_test: 17068.8750	accuracy_train: 0.9322	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 167133.1719	loss_val: 167133.2188	loss_test: 167133.5156	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8347.8506	loss_val: 8347.9570	loss_test: 8347.7920	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1358.2866	loss_val: 1358.3080	loss_test: 1358.3198	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7312.1211	loss_val: 7312.5435	loss_test: 7312.7627	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 8084.6445	loss_val: 8084.6719	loss_test: 8084.8633	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11728.9580	loss_val: 11729.0283	loss_test: 11729.0898	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1431.0996	loss_val: 1431.0983	loss_test: 1431.1162	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 72	curr_val_accuracy: 0.6970	curr_test_accuracy: 0.7105
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21108.7812	loss_val: 21108.8047	loss_test: 21108.8125	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 27956.8535	loss_val: 27956.9180	loss_test: 27956.9551	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 73091.3672	loss_val: 73092.6641	loss_test: 73092.1953	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20273.1328	loss_val: 20273.1270	loss_test: 20273.2402	accuracy_train: 0.6195	accuracy_val: 0.5750	accuracy_test: 0.5610
[client 4]	loss_train: 6349.1455	loss_val: 6349.3433	loss_test: 6349.3730	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 8014.0054	loss_val: 8014.0664	loss_test: 8014.2041	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51162.2891	loss_val: 51162.6016	loss_test: 51162.3750	accuracy_train: 0.5529	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 44753.7852	loss_val: 44753.8945	loss_test: 44753.8086	accuracy_train: 0.5951	accuracy_val: 0.5000	accuracy_test: 0.5405
[client 8]	loss_train: 1258.1393	loss_val: 1258.1475	loss_test: 1258.1490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 42156.7773	loss_val: 42160.9805	loss_test: 42156.8555	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10321.2607	loss_val: 10321.1914	loss_test: 10321.2686	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2832.0325	loss_val: 2832.1360	loss_test: 2832.1274	accuracy_train: 0.6627	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 17548.7988	loss_val: 17549.5312	loss_test: 17550.5742	accuracy_train: 0.9407	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 170630.8125	loss_val: 170630.8594	loss_test: 170631.1562	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8446.9551	loss_val: 8447.0586	loss_test: 8446.8926	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1345.8623	loss_val: 1345.8835	loss_test: 1345.8954	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7345.7588	loss_val: 7346.1914	loss_test: 7346.4067	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7921.1147	loss_val: 7921.1392	loss_test: 7921.3237	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12082.0137	loss_val: 12082.0850	loss_test: 12082.1465	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1414.5011	loss_val: 1414.4995	loss_test: 1414.5175	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 73	curr_val_accuracy: 0.6911	curr_test_accuracy: 0.7067
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21061.0820	loss_val: 21061.1094	loss_test: 21061.0957	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 27318.0859	loss_val: 27318.1523	loss_test: 27318.1953	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 74300.7188	loss_val: 74302.0469	loss_test: 74301.5547	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20363.5137	loss_val: 20363.5117	loss_test: 20363.6211	accuracy_train: 0.6038	accuracy_val: 0.5500	accuracy_test: 0.5366
[client 4]	loss_train: 6172.1523	loss_val: 6172.3896	loss_test: 6172.3848	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 7626.4424	loss_val: 7626.5083	loss_test: 7626.6377	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51339.9688	loss_val: 51340.2852	loss_test: 51340.0547	accuracy_train: 0.5471	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 47201.1758	loss_val: 47201.2891	loss_test: 47201.1953	accuracy_train: 0.5986	accuracy_val: 0.5000	accuracy_test: 0.5405
[client 8]	loss_train: 1263.1348	loss_val: 1263.1427	loss_test: 1263.1439	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 44319.8906	loss_val: 44324.1016	loss_test: 44319.9688	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10237.1562	loss_val: 10237.0879	loss_test: 10237.1631	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2883.1089	loss_val: 2883.2158	loss_test: 2883.2053	accuracy_train: 0.6549	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 18017.7578	loss_val: 18018.4863	loss_test: 18019.5703	accuracy_train: 0.9407	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 178429.9844	loss_val: 178430.0312	loss_test: 178430.3438	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 8514.9541	loss_val: 8515.0664	loss_test: 8514.8857	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1343.4934	loss_val: 1343.5144	loss_test: 1343.5260	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7378.3428	loss_val: 7378.7871	loss_test: 7378.9976	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7587.2417	loss_val: 7587.2617	loss_test: 7587.4463	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12320.0977	loss_val: 12320.1719	loss_test: 12320.2334	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1405.7692	loss_val: 1405.7677	loss_test: 1405.7852	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 74	curr_val_accuracy: 0.6910	curr_test_accuracy: 0.7104
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20989.6602	loss_val: 20989.6895	loss_test: 20989.6562	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25594.5664	loss_val: 25594.6387	loss_test: 25594.6816	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 75028.0000	loss_val: 75029.3438	loss_test: 75028.8281	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20206.1953	loss_val: 20206.1934	loss_test: 20206.3027	accuracy_train: 0.5723	accuracy_val: 0.5750	accuracy_test: 0.5122
[client 4]	loss_train: 6272.2188	loss_val: 6272.4961	loss_test: 6272.4487	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 7252.1230	loss_val: 7252.1875	loss_test: 7252.3120	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50565.4141	loss_val: 50565.7422	loss_test: 50565.5039	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 49308.3867	loss_val: 49308.5000	loss_test: 49308.4062	accuracy_train: 0.5986	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1261.4911	loss_val: 1261.4990	loss_test: 1261.4999	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51965.9297	loss_val: 51970.2305	loss_test: 51966.0078	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10411.5479	loss_val: 10411.4785	loss_test: 10411.5547	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2885.1946	loss_val: 2885.3032	loss_test: 2885.2898	accuracy_train: 0.6510	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 12]	loss_train: 18171.2441	loss_val: 18171.9551	loss_test: 18173.0977	accuracy_train: 0.9407	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 181237.0000	loss_val: 181237.0469	loss_test: 181237.3906	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 8663.3271	loss_val: 8663.4414	loss_test: 8663.2490	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1339.0984	loss_val: 1339.1187	loss_test: 1339.1304	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7411.5840	loss_val: 7412.0396	loss_test: 7412.2466	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7553.4966	loss_val: 7553.5151	loss_test: 7553.7139	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12450.0742	loss_val: 12450.1533	loss_test: 12450.2129	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1415.2388	loss_val: 1415.2375	loss_test: 1415.2546	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 75	curr_val_accuracy: 0.6989	curr_test_accuracy: 0.7104
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21075.9121	loss_val: 21075.9453	loss_test: 21075.8945	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25063.4023	loss_val: 25063.4766	loss_test: 25063.5156	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 73833.4297	loss_val: 73834.7812	loss_test: 73834.2578	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19843.3984	loss_val: 19843.3926	loss_test: 19843.5078	accuracy_train: 0.5943	accuracy_val: 0.5750	accuracy_test: 0.5366
[client 4]	loss_train: 6108.6006	loss_val: 6108.9004	loss_test: 6108.8296	accuracy_train: 0.6765	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 7220.8296	loss_val: 7220.8901	loss_test: 7221.0151	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49796.2539	loss_val: 49796.5625	loss_test: 49796.3359	accuracy_train: 0.5412	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 50149.1445	loss_val: 50149.2500	loss_test: 50149.1719	accuracy_train: 0.6092	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1263.5077	loss_val: 1263.5154	loss_test: 1263.5160	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60762.4062	loss_val: 60766.7930	loss_test: 60762.4805	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10495.1934	loss_val: 10495.1240	loss_test: 10495.2012	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2889.4080	loss_val: 2889.5195	loss_test: 2889.5007	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 17377.3789	loss_val: 17378.0898	loss_test: 17379.2754	accuracy_train: 0.9407	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 170763.1094	loss_val: 170763.1562	loss_test: 170763.5312	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 8473.7764	loss_val: 8473.8945	loss_test: 8473.6895	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1345.1401	loss_val: 1345.1598	loss_test: 1345.1718	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7483.0859	loss_val: 7483.5518	loss_test: 7483.7573	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 7020.5239	loss_val: 7020.5415	loss_test: 7020.7446	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12327.9189	loss_val: 12328.0029	loss_test: 12328.0576	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1420.0443	loss_val: 1420.0433	loss_test: 1420.0605	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 76	curr_val_accuracy: 0.7029	curr_test_accuracy: 0.7140
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21303.5742	loss_val: 21303.6094	loss_test: 21303.5449	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25109.1406	loss_val: 25109.2227	loss_test: 25109.2480	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 69899.4609	loss_val: 69900.8125	loss_test: 69900.2969	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19245.5898	loss_val: 19245.5859	loss_test: 19245.6973	accuracy_train: 0.5975	accuracy_val: 0.5750	accuracy_test: 0.5610
[client 4]	loss_train: 5993.4434	loss_val: 5993.7324	loss_test: 5993.6719	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 7202.0366	loss_val: 7202.0923	loss_test: 7202.2183	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48824.3047	loss_val: 48824.6133	loss_test: 48824.3906	accuracy_train: 0.5412	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 49613.5234	loss_val: 49613.6250	loss_test: 49613.5625	accuracy_train: 0.6056	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1264.8994	loss_val: 1264.9071	loss_test: 1264.9072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 71581.3984	loss_val: 71585.8984	loss_test: 71581.4297	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10385.6836	loss_val: 10385.6143	loss_test: 10385.6934	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2933.1167	loss_val: 2933.2314	loss_test: 2933.2031	accuracy_train: 0.6471	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 16878.4043	loss_val: 16879.1465	loss_test: 16880.3398	accuracy_train: 0.9407	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 168566.3125	loss_val: 168566.3594	loss_test: 168566.7344	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 8107.5410	loss_val: 8107.6670	loss_test: 8107.4463	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1338.6324	loss_val: 1338.6515	loss_test: 1338.6639	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7511.5684	loss_val: 7512.0405	loss_test: 7512.2480	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 6971.9614	loss_val: 6971.9834	loss_test: 6972.1904	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12432.1719	loss_val: 12432.2598	loss_test: 12432.3066	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1418.3512	loss_val: 1418.3505	loss_test: 1418.3682	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 77	curr_val_accuracy: 0.7010	curr_test_accuracy: 0.7141
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22030.4980	loss_val: 22030.5391	loss_test: 22030.4668	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 26462.5879	loss_val: 26462.6738	loss_test: 26462.7012	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 68166.9609	loss_val: 68168.3281	loss_test: 68167.8125	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19074.5215	loss_val: 19074.5293	loss_test: 19074.6289	accuracy_train: 0.5786	accuracy_val: 0.5500	accuracy_test: 0.5122
[client 4]	loss_train: 5977.7310	loss_val: 5977.9897	loss_test: 5977.9585	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 7186.6680	loss_val: 7186.7222	loss_test: 7186.8452	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47699.7930	loss_val: 47700.1016	loss_test: 47699.8828	accuracy_train: 0.5412	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 47083.6914	loss_val: 47083.7969	loss_test: 47083.7266	accuracy_train: 0.6092	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1259.9603	loss_val: 1259.9679	loss_test: 1259.9680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 36796.3828	loss_val: 36801.1523	loss_test: 36796.4688	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10126.0674	loss_val: 10125.9990	loss_test: 10126.0791	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2997.5798	loss_val: 2997.6934	loss_test: 2997.6614	accuracy_train: 0.6471	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 16906.9512	loss_val: 16907.7227	loss_test: 16908.9238	accuracy_train: 0.9407	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 172508.3594	loss_val: 172508.4062	loss_test: 172508.7969	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 7955.7095	loss_val: 7955.8325	loss_test: 7955.6099	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1338.8363	loss_val: 1338.8551	loss_test: 1338.8674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7558.8921	loss_val: 7559.3711	loss_test: 7559.5806	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 6942.0376	loss_val: 6942.0713	loss_test: 6942.2744	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12947.9277	loss_val: 12948.0078	loss_test: 12948.0635	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1413.1284	loss_val: 1413.1279	loss_test: 1413.1459	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 78	curr_val_accuracy: 0.7011	curr_test_accuracy: 0.7102
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23370.8242	loss_val: 23370.8711	loss_test: 23370.7891	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 26278.8125	loss_val: 26278.8926	loss_test: 26278.9355	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 66607.5469	loss_val: 66608.9297	loss_test: 66608.4141	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 18871.1738	loss_val: 18871.1836	loss_test: 18871.2793	accuracy_train: 0.5472	accuracy_val: 0.5500	accuracy_test: 0.4878
[client 4]	loss_train: 6096.4888	loss_val: 6096.7280	loss_test: 6096.7314	accuracy_train: 0.6471	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 7011.5146	loss_val: 7011.5713	loss_test: 7011.6934	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47629.6562	loss_val: 47629.9727	loss_test: 47629.7539	accuracy_train: 0.5412	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 44731.9844	loss_val: 44732.0977	loss_test: 44732.0117	accuracy_train: 0.6127	accuracy_val: 0.5833	accuracy_test: 0.5405
[client 8]	loss_train: 1247.4980	loss_val: 1247.5050	loss_test: 1247.5055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 38354.4492	loss_val: 38359.4023	loss_test: 38354.5430	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9983.8125	loss_val: 9983.7432	loss_test: 9983.8242	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3023.0251	loss_val: 3023.1323	loss_test: 3023.1035	accuracy_train: 0.6431	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 16675.7793	loss_val: 16676.5684	loss_test: 16677.7930	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 186520.7500	loss_val: 186520.8125	loss_test: 186521.2031	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 7791.1851	loss_val: 7791.2920	loss_test: 7791.0835	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1342.4877	loss_val: 1342.5065	loss_test: 1342.5188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7553.9312	loss_val: 7554.4121	loss_test: 7554.6270	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 6868.1650	loss_val: 6868.2100	loss_test: 6868.4160	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12475.8516	loss_val: 12475.9346	loss_test: 12475.9951	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1403.7728	loss_val: 1403.7723	loss_test: 1403.7909	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 79	curr_val_accuracy: 0.7012	curr_test_accuracy: 0.7102
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24897.9629	loss_val: 24898.0137	loss_test: 24897.9258	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25594.3945	loss_val: 25594.4727	loss_test: 25594.5215	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 64933.4844	loss_val: 64934.8984	loss_test: 64934.3594	accuracy_train: 0.9518	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19203.2031	loss_val: 19203.2051	loss_test: 19203.3066	accuracy_train: 0.5283	accuracy_val: 0.5500	accuracy_test: 0.4634
[client 4]	loss_train: 6146.6807	loss_val: 6146.9243	loss_test: 6146.9390	accuracy_train: 0.6471	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6885.3452	loss_val: 6885.4033	loss_test: 6885.5269	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47481.4766	loss_val: 47481.8125	loss_test: 47481.6016	accuracy_train: 0.5471	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 41078.3945	loss_val: 41078.5000	loss_test: 41078.4336	accuracy_train: 0.6092	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 1244.0597	loss_val: 1244.0662	loss_test: 1244.0673	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 39675.4453	loss_val: 39680.4180	loss_test: 39675.5469	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9967.9941	loss_val: 9967.9238	loss_test: 9968.0078	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3049.3533	loss_val: 3049.4526	loss_test: 3049.4241	accuracy_train: 0.6471	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 16199.3818	loss_val: 16200.2139	loss_test: 16201.4453	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 197488.8125	loss_val: 197488.8594	loss_test: 197489.2812	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 7736.6440	loss_val: 7736.7471	loss_test: 7736.5430	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1338.6929	loss_val: 1338.7115	loss_test: 1338.7238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7517.4551	loss_val: 7517.9380	loss_test: 7518.1582	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 7002.9927	loss_val: 7003.0420	loss_test: 7003.2471	accuracy_train: 0.6241	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11273.6797	loss_val: 11273.7676	loss_test: 11273.8262	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1400.9493	loss_val: 1400.9487	loss_test: 1400.9674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 80	curr_val_accuracy: 0.6991	curr_test_accuracy: 0.7045
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24625.5020	loss_val: 24625.5547	loss_test: 24625.4648	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25069.4141	loss_val: 25069.4941	loss_test: 25069.5410	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 62456.0742	loss_val: 62457.5234	loss_test: 62456.9531	accuracy_train: 0.9759	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19802.6602	loss_val: 19802.6562	loss_test: 19802.7695	accuracy_train: 0.5597	accuracy_val: 0.5500	accuracy_test: 0.4634
[client 4]	loss_train: 6214.7529	loss_val: 6214.9961	loss_test: 6215.0215	accuracy_train: 0.6412	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 6611.0825	loss_val: 6611.1333	loss_test: 6611.2642	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47671.4648	loss_val: 47671.7969	loss_test: 47671.6055	accuracy_train: 0.5471	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 39375.9805	loss_val: 39376.0859	loss_test: 39376.0430	accuracy_train: 0.5845	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1235.1854	loss_val: 1235.1918	loss_test: 1235.1929	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 37791.5664	loss_val: 37796.4570	loss_test: 37791.6680	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10225.3633	loss_val: 10225.2910	loss_test: 10225.3770	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3091.9553	loss_val: 3092.0496	loss_test: 3092.0173	accuracy_train: 0.6510	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 15409.5703	loss_val: 15410.4893	loss_test: 15411.6885	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 196551.4219	loss_val: 196551.4844	loss_test: 196551.9219	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 8068.4214	loss_val: 8068.5283	loss_test: 8068.3115	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1336.1842	loss_val: 1336.2026	loss_test: 1336.2151	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7491.2290	loss_val: 7491.7139	loss_test: 7491.9399	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 7068.2671	loss_val: 7068.3169	loss_test: 7068.5225	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 10815.9766	loss_val: 10816.0771	loss_test: 10816.1211	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1398.0544	loss_val: 1398.0537	loss_test: 1398.0717	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 81	curr_val_accuracy: 0.7012	curr_test_accuracy: 0.7006
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26237.4668	loss_val: 26237.5215	loss_test: 26237.4316	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 24197.7207	loss_val: 24197.8027	loss_test: 24197.8438	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 59949.6328	loss_val: 59951.1172	loss_test: 59950.5195	accuracy_train: 0.9759	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 20120.0918	loss_val: 20120.0840	loss_test: 20120.2090	accuracy_train: 0.5597	accuracy_val: 0.5750	accuracy_test: 0.4878
[client 4]	loss_train: 6262.6221	loss_val: 6262.8408	loss_test: 6262.8979	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 7533.6699	loss_val: 7533.7227	loss_test: 7533.8569	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47438.1797	loss_val: 47438.4766	loss_test: 47438.3125	accuracy_train: 0.5412	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 39284.1758	loss_val: 39284.2734	loss_test: 39284.2383	accuracy_train: 0.5775	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1225.4690	loss_val: 1225.4753	loss_test: 1225.4763	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 36626.8359	loss_val: 36631.6797	loss_test: 36626.9414	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10279.2764	loss_val: 10279.2041	loss_test: 10279.2900	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3081.9814	loss_val: 3082.0750	loss_test: 3082.0366	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 15161.3643	loss_val: 15162.3857	loss_test: 15163.5439	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 189732.7656	loss_val: 189732.8281	loss_test: 189733.2812	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 8035.9844	loss_val: 8036.0947	loss_test: 8035.8735	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1336.5426	loss_val: 1336.5599	loss_test: 1336.5732	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7440.7114	loss_val: 7441.1968	loss_test: 7441.4282	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 7170.5444	loss_val: 7170.5967	loss_test: 7170.8022	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11315.4258	loss_val: 11315.5342	loss_test: 11315.5693	accuracy_train: 0.4228	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1393.6052	loss_val: 1393.6045	loss_test: 1393.6219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 82	curr_val_accuracy: 0.7051	curr_test_accuracy: 0.7045
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27273.9199	loss_val: 27273.9746	loss_test: 27273.8906	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 24002.6875	loss_val: 24002.7734	loss_test: 24002.8047	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 57585.3164	loss_val: 57586.8320	loss_test: 57586.2188	accuracy_train: 0.9759	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19887.3828	loss_val: 19887.3789	loss_test: 19887.5039	accuracy_train: 0.5723	accuracy_val: 0.5750	accuracy_test: 0.5122
[client 4]	loss_train: 6301.8188	loss_val: 6302.0049	loss_test: 6302.1074	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 7974.7803	loss_val: 7974.8364	loss_test: 7974.9634	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48370.7461	loss_val: 48371.0430	loss_test: 48370.8672	accuracy_train: 0.5412	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 39425.9570	loss_val: 39426.0547	loss_test: 39426.0039	accuracy_train: 0.5810	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1219.3986	loss_val: 1219.4049	loss_test: 1219.4059	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 36599.6094	loss_val: 36604.3945	loss_test: 36599.7227	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10609.6768	loss_val: 10609.6035	loss_test: 10609.6904	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3105.5625	loss_val: 3105.6570	loss_test: 3105.6143	accuracy_train: 0.6510	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 15278.2148	loss_val: 15279.3154	loss_test: 15280.4434	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 185213.9688	loss_val: 185214.0312	loss_test: 185214.5000	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 8261.5391	loss_val: 8261.6553	loss_test: 8261.4287	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1325.6281	loss_val: 1325.6450	loss_test: 1325.6587	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7398.6880	loss_val: 7399.1768	loss_test: 7399.4136	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 9690.6777	loss_val: 9690.7285	loss_test: 9690.9385	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11633.9814	loss_val: 11634.0986	loss_test: 11634.1357	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1409.3289	loss_val: 1409.3279	loss_test: 1409.3444	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 83	curr_val_accuracy: 0.7051	curr_test_accuracy: 0.7064
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27388.7559	loss_val: 27388.8105	loss_test: 27388.7266	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 23932.4277	loss_val: 23932.5176	loss_test: 23932.5547	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 55553.8555	loss_val: 55555.3828	loss_test: 55554.7734	accuracy_train: 0.9759	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 19174.7363	loss_val: 19174.7461	loss_test: 19174.8555	accuracy_train: 0.5692	accuracy_val: 0.5750	accuracy_test: 0.4878
[client 4]	loss_train: 6509.8140	loss_val: 6510.0000	loss_test: 6510.1104	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 7585.0396	loss_val: 7585.1050	loss_test: 7585.2246	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49516.8945	loss_val: 49517.2148	loss_test: 49517.0078	accuracy_train: 0.5471	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 40557.8125	loss_val: 40557.9180	loss_test: 40557.8477	accuracy_train: 0.5775	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1216.6869	loss_val: 1216.6932	loss_test: 1216.6947	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 36492.8750	loss_val: 36497.5859	loss_test: 36492.9922	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 11318.3857	loss_val: 11318.3145	loss_test: 11318.3994	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3098.6057	loss_val: 3098.7029	loss_test: 3098.6592	accuracy_train: 0.6471	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 15871.1211	loss_val: 15872.2656	loss_test: 15873.3965	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 181097.5625	loss_val: 181097.6250	loss_test: 181098.1094	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 8414.1738	loss_val: 8414.3027	loss_test: 8414.0703	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1317.7852	loss_val: 1317.8019	loss_test: 1317.8152	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7334.5596	loss_val: 7335.0518	loss_test: 7335.2910	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 7276.0107	loss_val: 7276.0430	loss_test: 7276.2788	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11816.6348	loss_val: 11816.7588	loss_test: 11816.7998	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1408.5332	loss_val: 1408.5321	loss_test: 1408.5476	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 84	curr_val_accuracy: 0.7051	curr_test_accuracy: 0.7045
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26856.9141	loss_val: 26856.9688	loss_test: 26856.8945	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 24836.9258	loss_val: 24837.0117	loss_test: 24837.0586	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 54165.3867	loss_val: 54166.9414	loss_test: 54166.3242	accuracy_train: 0.9759	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 18257.8398	loss_val: 18257.8574	loss_test: 18257.9590	accuracy_train: 0.5503	accuracy_val: 0.5250	accuracy_test: 0.4634
[client 4]	loss_train: 6810.4409	loss_val: 6810.6343	loss_test: 6810.7437	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 7466.4116	loss_val: 7466.4717	loss_test: 7466.6011	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50163.3594	loss_val: 50163.7031	loss_test: 50163.4805	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 41890.5625	loss_val: 41890.6758	loss_test: 41890.5938	accuracy_train: 0.5880	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1216.3539	loss_val: 1216.3602	loss_test: 1216.3618	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 35427.7461	loss_val: 35432.4219	loss_test: 35427.8672	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 11593.7168	loss_val: 11593.6445	loss_test: 11593.7305	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3107.6167	loss_val: 3107.7168	loss_test: 3107.6772	accuracy_train: 0.6471	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 15605.8789	loss_val: 15607.0654	loss_test: 15608.1855	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 175891.9688	loss_val: 175892.0156	loss_test: 175892.5312	accuracy_train: 0.9337	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 8349.9131	loss_val: 8350.0635	loss_test: 8349.8115	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1315.8329	loss_val: 1315.8491	loss_test: 1315.8625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7232.0776	loss_val: 7232.5703	loss_test: 7232.8120	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 7911.2051	loss_val: 7911.2261	loss_test: 7911.4795	accuracy_train: 0.6454	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11791.9434	loss_val: 11792.0693	loss_test: 11792.1133	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1387.4135	loss_val: 1387.4121	loss_test: 1387.4271	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 85	curr_val_accuracy: 0.6991	curr_test_accuracy: 0.7026
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25998.7090	loss_val: 25998.7637	loss_test: 25998.6953	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25333.3848	loss_val: 25333.4746	loss_test: 25333.5137	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 52643.0859	loss_val: 52644.6758	loss_test: 52644.0508	accuracy_train: 0.9759	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 17570.7910	loss_val: 17570.8086	loss_test: 17570.9102	accuracy_train: 0.5220	accuracy_val: 0.5000	accuracy_test: 0.4634
[client 4]	loss_train: 6725.5215	loss_val: 6725.7329	loss_test: 6725.8589	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7580.1602	loss_val: 7580.2124	loss_test: 7580.3472	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50613.3945	loss_val: 50613.7500	loss_test: 50613.5234	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 43190.5938	loss_val: 43190.7188	loss_test: 43190.6289	accuracy_train: 0.5775	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1224.2471	loss_val: 1224.2533	loss_test: 1224.2550	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 34890.3555	loss_val: 34895.0898	loss_test: 34890.4805	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 11170.3877	loss_val: 11170.3154	loss_test: 11170.4014	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3076.3762	loss_val: 3076.4800	loss_test: 3076.4419	accuracy_train: 0.6431	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 16004.0088	loss_val: 16005.2637	loss_test: 16006.3330	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 166177.7031	loss_val: 166177.7500	loss_test: 166178.2969	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 8281.8945	loss_val: 8282.0557	loss_test: 8281.8018	accuracy_train: 0.3007	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1322.1704	loss_val: 1322.1862	loss_test: 1322.2000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7105.6382	loss_val: 7106.1328	loss_test: 7106.3750	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 8346.6113	loss_val: 8346.6260	loss_test: 8346.8877	accuracy_train: 0.6525	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11221.3154	loss_val: 11221.4414	loss_test: 11221.4863	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1371.9500	loss_val: 1371.9486	loss_test: 1371.9630	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 86	curr_val_accuracy: 0.6910	curr_test_accuracy: 0.7026
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25305.6660	loss_val: 25305.7227	loss_test: 25305.6523	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25336.2090	loss_val: 25336.3066	loss_test: 25336.3340	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 51971.7930	loss_val: 51973.4258	loss_test: 51972.7930	accuracy_train: 0.9759	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 17396.0781	loss_val: 17396.0918	loss_test: 17396.1992	accuracy_train: 0.5094	accuracy_val: 0.5000	accuracy_test: 0.4634
[client 4]	loss_train: 6406.2319	loss_val: 6406.4478	loss_test: 6406.6050	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7973.9692	loss_val: 7974.0347	loss_test: 7974.1792	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50707.8828	loss_val: 50708.2148	loss_test: 50708.0039	accuracy_train: 0.5412	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 44386.5195	loss_val: 44386.6445	loss_test: 44386.5547	accuracy_train: 0.5669	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1222.1909	loss_val: 1222.1970	loss_test: 1222.1986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 33362.5938	loss_val: 33367.3633	loss_test: 33362.7266	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10620.0459	loss_val: 10619.9727	loss_test: 10620.0596	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3060.1404	loss_val: 3060.2493	loss_test: 3060.2139	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 12]	loss_train: 16001.7695	loss_val: 16003.0361	loss_test: 16004.0986	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 161050.7812	loss_val: 161050.8281	loss_test: 161051.3906	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 8164.6958	loss_val: 8164.8687	loss_test: 8164.6104	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1320.9207	loss_val: 1320.9359	loss_test: 1320.9498	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7041.5942	loss_val: 7042.0938	loss_test: 7042.3320	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 8743.2354	loss_val: 8743.2441	loss_test: 8743.5059	accuracy_train: 0.6383	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11147.1084	loss_val: 11147.2373	loss_test: 11147.2822	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1366.3889	loss_val: 1366.3877	loss_test: 1366.4020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 87	curr_val_accuracy: 0.6890	curr_test_accuracy: 0.7026
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24132.3359	loss_val: 24132.3926	loss_test: 24132.3223	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25316.2578	loss_val: 25316.3613	loss_test: 25316.3730	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 51927.8594	loss_val: 51929.5391	loss_test: 51928.8906	accuracy_train: 0.9759	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 16897.5352	loss_val: 16897.5430	loss_test: 16897.6562	accuracy_train: 0.5252	accuracy_val: 0.5000	accuracy_test: 0.4634
[client 4]	loss_train: 9517.3438	loss_val: 9517.6602	loss_test: 9517.6787	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 7504.6846	loss_val: 7504.7529	loss_test: 7504.8994	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49049.1055	loss_val: 49049.4219	loss_test: 49049.2266	accuracy_train: 0.5412	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 43740.6836	loss_val: 43740.8086	loss_test: 43740.7227	accuracy_train: 0.5634	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1211.4200	loss_val: 1211.4260	loss_test: 1211.4272	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 32659.5625	loss_val: 32664.3359	loss_test: 32659.6953	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10124.9189	loss_val: 10124.8447	loss_test: 10124.9326	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3085.0923	loss_val: 3085.2073	loss_test: 3085.1799	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 12]	loss_train: 16102.9619	loss_val: 16104.2178	loss_test: 16105.3096	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 157857.2188	loss_val: 157857.2656	loss_test: 157857.8438	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 7984.1201	loss_val: 7984.2979	loss_test: 7984.0298	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1322.1598	loss_val: 1322.1749	loss_test: 1322.1886	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6981.3052	loss_val: 6981.8091	loss_test: 6982.0454	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 9033.1572	loss_val: 9033.1660	loss_test: 9033.4268	accuracy_train: 0.6383	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11095.9092	loss_val: 11096.0400	loss_test: 11096.0869	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1364.7809	loss_val: 1364.7797	loss_test: 1364.7943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 88	curr_val_accuracy: 0.6870	curr_test_accuracy: 0.7044
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22612.1602	loss_val: 22612.2168	loss_test: 22612.1406	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25313.3770	loss_val: 25313.4766	loss_test: 25313.4941	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 51271.8555	loss_val: 51273.6016	loss_test: 51272.8945	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 16447.6875	loss_val: 16447.6895	loss_test: 16447.8086	accuracy_train: 0.5503	accuracy_val: 0.5500	accuracy_test: 0.4634
[client 4]	loss_train: 10515.2061	loss_val: 10515.5967	loss_test: 10515.5352	accuracy_train: 0.7176	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 7902.3828	loss_val: 7902.4443	loss_test: 7902.5752	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47496.0391	loss_val: 47496.3594	loss_test: 47496.1602	accuracy_train: 0.5353	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 7]	loss_train: 43750.3594	loss_val: 43750.4805	loss_test: 43750.3945	accuracy_train: 0.5880	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1202.4254	loss_val: 1202.4314	loss_test: 1202.4329	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 31253.6328	loss_val: 31258.5293	loss_test: 31253.7754	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9834.5781	loss_val: 9834.5020	loss_test: 9834.5938	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3148.0618	loss_val: 3148.1777	loss_test: 3148.1616	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 12]	loss_train: 16182.4023	loss_val: 16183.6533	loss_test: 16184.7832	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 151366.4375	loss_val: 151366.4844	loss_test: 151367.0625	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 8076.9927	loss_val: 8077.1763	loss_test: 8076.8931	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1326.9131	loss_val: 1326.9281	loss_test: 1326.9420	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6938.4126	loss_val: 6938.9194	loss_test: 6939.1519	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 9094.8965	loss_val: 9094.9082	loss_test: 9095.1650	accuracy_train: 0.6383	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 10954.6729	loss_val: 10954.8037	loss_test: 10954.8516	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1354.1344	loss_val: 1354.1334	loss_test: 1354.1484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 89	curr_val_accuracy: 0.6911	curr_test_accuracy: 0.7025
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21785.9453	loss_val: 21786.0039	loss_test: 21785.9238	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 24829.9062	loss_val: 24830.0020	loss_test: 24830.0312	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 50155.2617	loss_val: 50157.1211	loss_test: 50156.3008	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 17194.2695	loss_val: 17194.2715	loss_test: 17194.3887	accuracy_train: 0.5503	accuracy_val: 0.5750	accuracy_test: 0.4634
[client 4]	loss_train: 8557.9727	loss_val: 8558.3574	loss_test: 8558.3047	accuracy_train: 0.6647	accuracy_val: 0.4762	accuracy_test: 0.5833
[client 5]	loss_train: 7536.5684	loss_val: 7536.6309	loss_test: 7536.7568	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46461.9219	loss_val: 46462.2500	loss_test: 46462.0508	accuracy_train: 0.5294	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 45006.0859	loss_val: 45006.2109	loss_test: 45006.1289	accuracy_train: 0.5915	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1208.4968	loss_val: 1208.5029	loss_test: 1208.5049	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 31854.2051	loss_val: 31859.2441	loss_test: 31854.3633	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9834.1240	loss_val: 9834.0469	loss_test: 9834.1396	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3148.3650	loss_val: 3148.4763	loss_test: 3148.4695	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 12]	loss_train: 15948.1826	loss_val: 15949.5088	loss_test: 15950.5869	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 150357.9531	loss_val: 150358.0156	loss_test: 150358.5625	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 8253.5186	loss_val: 8253.7002	loss_test: 8253.4170	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1319.7117	loss_val: 1319.7266	loss_test: 1319.7412	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6927.5103	loss_val: 6928.0244	loss_test: 6928.2515	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 9359.5117	loss_val: 9359.5215	loss_test: 9359.7725	accuracy_train: 0.6383	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 10963.8926	loss_val: 10964.0254	loss_test: 10964.0762	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1336.7928	loss_val: 1336.7921	loss_test: 1336.8081	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 90	curr_val_accuracy: 0.6871	curr_test_accuracy: 0.7007
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21195.6113	loss_val: 21195.6719	loss_test: 21195.5859	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25053.6699	loss_val: 25053.7598	loss_test: 25053.8047	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 49538.6133	loss_val: 49540.5820	loss_test: 49539.6406	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 18324.4609	loss_val: 18324.4688	loss_test: 18324.5781	accuracy_train: 0.5566	accuracy_val: 0.5750	accuracy_test: 0.4634
[client 4]	loss_train: 7676.0137	loss_val: 7676.3330	loss_test: 7676.3428	accuracy_train: 0.6353	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 7182.5312	loss_val: 7182.5913	loss_test: 7182.7178	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46102.6367	loss_val: 46102.9570	loss_test: 46102.7734	accuracy_train: 0.5294	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 44716.4453	loss_val: 44716.5742	loss_test: 44716.4844	accuracy_train: 0.5845	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1223.9835	loss_val: 1223.9896	loss_test: 1223.9919	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 33219.8906	loss_val: 33225.0625	loss_test: 33220.0625	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9691.4951	loss_val: 9691.4170	loss_test: 9691.5098	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3165.0476	loss_val: 3165.1619	loss_test: 3165.1555	accuracy_train: 0.6431	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 15537.8818	loss_val: 15539.3096	loss_test: 15540.3213	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 151065.8750	loss_val: 151065.9375	loss_test: 151066.5000	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 8442.8369	loss_val: 8443.0088	loss_test: 8442.7344	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1316.6609	loss_val: 1316.6759	loss_test: 1316.6902	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6965.6792	loss_val: 6966.1997	loss_test: 6966.4189	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 9677.5156	loss_val: 9677.5195	loss_test: 9677.7666	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11058.5312	loss_val: 11058.6641	loss_test: 11058.7178	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1331.2916	loss_val: 1331.2911	loss_test: 1331.3077	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 91	curr_val_accuracy: 0.6891	curr_test_accuracy: 0.7025
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21103.6211	loss_val: 21103.6816	loss_test: 21103.5938	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 26081.8594	loss_val: 26081.9492	loss_test: 26081.9941	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48612.7383	loss_val: 48614.7773	loss_test: 48613.7656	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 18908.7949	loss_val: 18908.8125	loss_test: 18908.9102	accuracy_train: 0.5440	accuracy_val: 0.5750	accuracy_test: 0.4634
[client 4]	loss_train: 7487.8755	loss_val: 7488.1367	loss_test: 7488.2026	accuracy_train: 0.6353	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 6892.5542	loss_val: 6892.6177	loss_test: 6892.7446	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45476.1484	loss_val: 45476.4648	loss_test: 45476.2969	accuracy_train: 0.5294	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 44592.9492	loss_val: 44593.0820	loss_test: 44592.9922	accuracy_train: 0.5845	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1228.3405	loss_val: 1228.3466	loss_test: 1228.3484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 33806.6367	loss_val: 33811.8945	loss_test: 33806.8203	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9617.5752	loss_val: 9617.4971	loss_test: 9617.5898	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3164.5576	loss_val: 3164.6809	loss_test: 3164.6580	accuracy_train: 0.6510	accuracy_val: 0.6875	accuracy_test: 0.6667
[client 12]	loss_train: 15619.3945	loss_val: 15620.8936	loss_test: 15621.8848	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 155630.6250	loss_val: 155630.6719	loss_test: 155631.2656	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 8265.8477	loss_val: 8266.0137	loss_test: 8265.7471	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1315.6498	loss_val: 1315.6649	loss_test: 1315.6791	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6987.3662	loss_val: 6987.8960	loss_test: 6988.1055	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 9566.9951	loss_val: 9566.9941	loss_test: 9567.2490	accuracy_train: 0.6241	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11077.2393	loss_val: 11077.3691	loss_test: 11077.4287	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1330.1866	loss_val: 1330.1862	loss_test: 1330.2030	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 92	curr_val_accuracy: 0.6931	curr_test_accuracy: 0.6990
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20809.1230	loss_val: 20809.1836	loss_test: 20809.0918	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 27299.4473	loss_val: 27299.5410	loss_test: 27299.5820	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48162.7812	loss_val: 48164.8711	loss_test: 48163.8047	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 19096.0078	loss_val: 19096.0352	loss_test: 19096.1289	accuracy_train: 0.5535	accuracy_val: 0.5500	accuracy_test: 0.4390
[client 4]	loss_train: 7387.3037	loss_val: 7387.5342	loss_test: 7387.6265	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 6831.4731	loss_val: 6831.5425	loss_test: 6831.6724	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45147.7578	loss_val: 45148.0664	loss_test: 45147.9297	accuracy_train: 0.5294	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 45329.1094	loss_val: 45329.2500	loss_test: 45329.1562	accuracy_train: 0.5775	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1215.0260	loss_val: 1215.0322	loss_test: 1215.0336	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 34136.1523	loss_val: 34141.5156	loss_test: 34136.3477	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9738.9805	loss_val: 9738.9014	loss_test: 9738.9932	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3125.6528	loss_val: 3125.7783	loss_test: 3125.7500	accuracy_train: 0.6588	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 16464.1797	loss_val: 16465.8262	loss_test: 16466.7246	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 156738.6406	loss_val: 156738.6875	loss_test: 156739.2969	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 8130.7739	loss_val: 8130.9463	loss_test: 8130.6650	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1313.3284	loss_val: 1313.3440	loss_test: 1313.3579	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7015.1743	loss_val: 7015.7090	loss_test: 7015.9131	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 9232.2139	loss_val: 9232.2119	loss_test: 9232.4785	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 10984.0840	loss_val: 10984.2109	loss_test: 10984.2764	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1333.3264	loss_val: 1333.3260	loss_test: 1333.3424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 93	curr_val_accuracy: 0.6911	curr_test_accuracy: 0.6951
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20500.9883	loss_val: 20501.0508	loss_test: 20500.9551	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 28196.1816	loss_val: 28196.2793	loss_test: 28196.3145	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48689.5078	loss_val: 48691.6523	loss_test: 48690.5469	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 18922.7031	loss_val: 18922.7324	loss_test: 18922.8242	accuracy_train: 0.5472	accuracy_val: 0.5250	accuracy_test: 0.4634
[client 4]	loss_train: 7264.3262	loss_val: 7264.5688	loss_test: 7264.6367	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6744.4199	loss_val: 6744.4980	loss_test: 6744.6250	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45135.7227	loss_val: 45135.9766	loss_test: 45135.9023	accuracy_train: 0.5176	accuracy_val: 0.5000	accuracy_test: 0.4091
[client 7]	loss_train: 46334.8555	loss_val: 46335.0078	loss_test: 46334.8945	accuracy_train: 0.5634	accuracy_val: 0.5000	accuracy_test: 0.4865
[client 8]	loss_train: 1208.0065	loss_val: 1208.0126	loss_test: 1208.0139	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 34706.3828	loss_val: 34711.8164	loss_test: 34706.5898	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 10343.0049	loss_val: 10342.9248	loss_test: 10343.0146	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3054.9077	loss_val: 3055.0276	loss_test: 3055.0017	accuracy_train: 0.6627	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 17342.4434	loss_val: 17344.2266	loss_test: 17345.0391	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 153133.2656	loss_val: 153133.3281	loss_test: 153133.9844	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 8080.7212	loss_val: 8080.8901	loss_test: 8080.5952	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1317.0654	loss_val: 1317.0811	loss_test: 1317.0947	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7040.9028	loss_val: 7041.4429	loss_test: 7041.6421	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 8687.2471	loss_val: 8687.2324	loss_test: 8687.5049	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11451.7002	loss_val: 11451.8281	loss_test: 11451.8994	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1347.6940	loss_val: 1347.6936	loss_test: 1347.7094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 94	curr_val_accuracy: 0.6911	curr_test_accuracy: 0.6933
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20375.9180	loss_val: 20375.9844	loss_test: 20375.8867	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 28688.1895	loss_val: 28688.2930	loss_test: 28688.3281	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48230.0508	loss_val: 48232.2539	loss_test: 48231.1094	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.7273
[client 3]	loss_train: 18992.7676	loss_val: 18992.7988	loss_test: 18992.8906	accuracy_train: 0.5346	accuracy_val: 0.5500	accuracy_test: 0.4634
[client 4]	loss_train: 7104.5156	loss_val: 7104.7812	loss_test: 7104.8179	accuracy_train: 0.6412	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 6664.6465	loss_val: 6664.7314	loss_test: 6664.8491	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44944.2852	loss_val: 44944.5195	loss_test: 44944.4844	accuracy_train: 0.5235	accuracy_val: 0.5000	accuracy_test: 0.4091
[client 7]	loss_train: 47633.0000	loss_val: 47633.1602	loss_test: 47633.0312	accuracy_train: 0.5493	accuracy_val: 0.4722	accuracy_test: 0.4865
[client 8]	loss_train: 1196.6692	loss_val: 1196.6753	loss_test: 1196.6769	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 35290.6562	loss_val: 35296.1641	loss_test: 35290.8594	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 10426.9893	loss_val: 10426.9082	loss_test: 10426.9980	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3059.9741	loss_val: 3060.0881	loss_test: 3060.0637	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 18226.0293	loss_val: 18227.8730	loss_test: 18228.6777	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 168317.5156	loss_val: 168317.5781	loss_test: 168318.2656	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8155.1836	loss_val: 8155.3462	loss_test: 8155.0396	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1312.2432	loss_val: 1312.2583	loss_test: 1312.2722	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7077.9722	loss_val: 7078.5132	loss_test: 7078.7051	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 8274.9170	loss_val: 8274.8955	loss_test: 8275.1797	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11861.0029	loss_val: 11861.1328	loss_test: 11861.2109	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1346.6108	loss_val: 1346.6105	loss_test: 1346.6257	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 95	curr_val_accuracy: 0.6871	curr_test_accuracy: 0.6914
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20426.4941	loss_val: 20426.5586	loss_test: 20426.4590	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 28707.2578	loss_val: 28707.3652	loss_test: 28707.3926	accuracy_train: 0.7597	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47103.6953	loss_val: 47105.9453	loss_test: 47104.7734	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 19200.7480	loss_val: 19200.7754	loss_test: 19200.8730	accuracy_train: 0.5409	accuracy_val: 0.5750	accuracy_test: 0.4634
[client 4]	loss_train: 7188.2251	loss_val: 7188.5112	loss_test: 7188.5205	accuracy_train: 0.6412	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 6755.9263	loss_val: 6756.0195	loss_test: 6756.1328	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44430.5859	loss_val: 44430.8203	loss_test: 44430.7695	accuracy_train: 0.5118	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 48681.4414	loss_val: 48681.5977	loss_test: 48681.4727	accuracy_train: 0.5387	accuracy_val: 0.4444	accuracy_test: 0.4865
[client 8]	loss_train: 1191.5610	loss_val: 1191.5669	loss_test: 1191.5691	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 36357.7148	loss_val: 36363.2656	loss_test: 36357.8984	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 10286.0352	loss_val: 10285.9551	loss_test: 10286.0430	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3065.4573	loss_val: 3065.5627	loss_test: 3065.5381	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6667
[client 12]	loss_train: 18308.3379	loss_val: 18310.1445	loss_test: 18311.0000	accuracy_train: 0.9661	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 206774.3125	loss_val: 206774.3750	loss_test: 206775.1250	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 8501.7070	loss_val: 8501.8760	loss_test: 8501.5684	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3000
[client 15]	loss_train: 1305.6904	loss_val: 1305.7045	loss_test: 1305.7192	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7065.0132	loss_val: 7065.5562	loss_test: 7065.7441	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 8027.1831	loss_val: 8027.1870	loss_test: 8027.4692	accuracy_train: 0.6099	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12025.0684	loss_val: 12025.1992	loss_test: 12025.2793	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1330.4550	loss_val: 1330.4546	loss_test: 1330.4689	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 96	curr_val_accuracy: 0.6891	curr_test_accuracy: 0.6914
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21061.6074	loss_val: 21061.6719	loss_test: 21061.5742	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 29170.2578	loss_val: 29170.3730	loss_test: 29170.3945	accuracy_train: 0.7558	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46090.8320	loss_val: 46093.1484	loss_test: 46091.9375	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 18730.2734	loss_val: 18730.2969	loss_test: 18730.4043	accuracy_train: 0.5472	accuracy_val: 0.5750	accuracy_test: 0.4878
[client 4]	loss_train: 7598.3521	loss_val: 7598.6401	loss_test: 7598.6499	accuracy_train: 0.6412	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 7205.0664	loss_val: 7205.1460	loss_test: 7205.2803	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44003.9180	loss_val: 44004.1641	loss_test: 44004.0781	accuracy_train: 0.5059	accuracy_val: 0.4091	accuracy_test: 0.4091
[client 7]	loss_train: 48686.0469	loss_val: 48686.1992	loss_test: 48686.0820	accuracy_train: 0.5387	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1183.5940	loss_val: 1183.5999	loss_test: 1183.6025	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 37823.4922	loss_val: 37829.1094	loss_test: 37823.6680	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 10165.1943	loss_val: 10165.1162	loss_test: 10165.2012	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3098.1343	loss_val: 3098.2397	loss_test: 3098.2083	accuracy_train: 0.6588	accuracy_val: 0.6875	accuracy_test: 0.6970
[client 12]	loss_train: 17967.8965	loss_val: 17969.6484	loss_test: 17970.5684	accuracy_train: 0.9661	accuracy_val: 0.7333	accuracy_test: 0.7059
[client 13]	loss_train: 211626.8438	loss_val: 211626.8906	loss_test: 211627.6719	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8462
[client 14]	loss_train: 9068.2275	loss_val: 9068.4297	loss_test: 9068.0947	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1298.8563	loss_val: 1298.8698	loss_test: 1298.8854	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6995.6646	loss_val: 6996.2104	loss_test: 6996.3931	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 7916.5806	loss_val: 7916.5977	loss_test: 7916.8740	accuracy_train: 0.6241	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11916.5254	loss_val: 11916.6582	loss_test: 11916.7383	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1326.6376	loss_val: 1326.6372	loss_test: 1326.6512	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 97	curr_val_accuracy: 0.6913	curr_test_accuracy: 0.6951
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21430.3965	loss_val: 21430.4629	loss_test: 21430.3633	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 27489.2422	loss_val: 27489.3613	loss_test: 27489.3789	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46482.8867	loss_val: 46485.2695	loss_test: 46484.0156	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 18232.0645	loss_val: 18232.0859	loss_test: 18232.2012	accuracy_train: 0.5566	accuracy_val: 0.6000	accuracy_test: 0.4878
[client 4]	loss_train: 7652.8779	loss_val: 7653.1616	loss_test: 7653.1890	accuracy_train: 0.6471	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 7407.5088	loss_val: 7407.5815	loss_test: 7407.7202	accuracy_train: 0.8706	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44259.2266	loss_val: 44259.4609	loss_test: 44259.3828	accuracy_train: 0.5059	accuracy_val: 0.4091	accuracy_test: 0.4091
[client 7]	loss_train: 48139.3633	loss_val: 48139.5117	loss_test: 48139.3945	accuracy_train: 0.5387	accuracy_val: 0.4444	accuracy_test: 0.4865
[client 8]	loss_train: 1187.6683	loss_val: 1187.6744	loss_test: 1187.6772	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 40081.5508	loss_val: 40087.2539	loss_test: 40081.7305	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 10127.4121	loss_val: 10127.3320	loss_test: 10127.4170	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3108.2156	loss_val: 3108.3228	loss_test: 3108.2886	accuracy_train: 0.6549	accuracy_val: 0.6562	accuracy_test: 0.6970
[client 12]	loss_train: 17606.5156	loss_val: 17608.1855	loss_test: 17609.2090	accuracy_train: 0.9661	accuracy_val: 0.7333	accuracy_test: 0.7059
[client 13]	loss_train: 200507.2031	loss_val: 200507.2344	loss_test: 200508.0000	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 8793.5908	loss_val: 8793.7979	loss_test: 8793.4727	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1290.4924	loss_val: 1290.5055	loss_test: 1290.5220	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6930.5869	loss_val: 6931.1343	loss_test: 6931.3164	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 7784.5527	loss_val: 7784.5718	loss_test: 7784.8496	accuracy_train: 0.6241	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11570.4023	loss_val: 11570.5371	loss_test: 11570.6182	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1328.3700	loss_val: 1328.3695	loss_test: 1328.3838	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 98	curr_val_accuracy: 0.6913	curr_test_accuracy: 0.6951
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21657.3125	loss_val: 21657.3828	loss_test: 21657.2793	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 25709.0879	loss_val: 25709.2012	loss_test: 25709.2227	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47733.3359	loss_val: 47735.7812	loss_test: 47734.4883	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17825.2734	loss_val: 17825.2891	loss_test: 17825.4082	accuracy_train: 0.5566	accuracy_val: 0.6000	accuracy_test: 0.4878
[client 4]	loss_train: 7487.9424	loss_val: 7488.2134	loss_test: 7488.2710	accuracy_train: 0.6471	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 7284.8223	loss_val: 7284.8931	loss_test: 7285.0322	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46211.9141	loss_val: 46212.1328	loss_test: 46212.0625	accuracy_train: 0.5000	accuracy_val: 0.3636	accuracy_test: 0.4091
[client 7]	loss_train: 47651.1484	loss_val: 47651.2930	loss_test: 47651.1836	accuracy_train: 0.5458	accuracy_val: 0.4444	accuracy_test: 0.4865
[client 8]	loss_train: 1206.3076	loss_val: 1206.3138	loss_test: 1206.3165	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 36825.4648	loss_val: 36831.2227	loss_test: 36825.6484	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9857.9219	loss_val: 9857.8408	loss_test: 9857.9268	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3114.7065	loss_val: 3114.8142	loss_test: 3114.7817	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 12]	loss_train: 17680.2930	loss_val: 17681.8984	loss_test: 17683.0137	accuracy_train: 0.9661	accuracy_val: 0.7333	accuracy_test: 0.7059
[client 13]	loss_train: 187315.7344	loss_val: 187315.7344	loss_test: 187316.5000	accuracy_train: 0.9439	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9115.4814	loss_val: 9115.7158	loss_test: 9115.3721	accuracy_train: 0.3077	accuracy_val: 0.2353	accuracy_test: 0.3500
[client 15]	loss_train: 1285.3236	loss_val: 1285.3368	loss_test: 1285.3531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6884.9204	loss_val: 6885.4707	loss_test: 6885.6543	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 7566.5723	loss_val: 7566.5840	loss_test: 7566.8735	accuracy_train: 0.6241	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11293.1592	loss_val: 11293.2979	loss_test: 11293.3799	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1318.2244	loss_val: 1318.2240	loss_test: 1318.2383	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 99	curr_val_accuracy: 0.6852	curr_test_accuracy: 0.6932
best_round: 15	best_val_accuracy: 0.7409	best_test_accuracy: 0.7315
--------------------------------------------------
