GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2.8951	loss_val: 13.4173	loss_test: 13.4298	accuracy_train: 0.0388	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 0.8839	loss_val: 0.9362	loss_test: 0.8753	accuracy_train: 0.7713	accuracy_val: 0.7812	accuracy_test: 0.7059
[client 2]	loss_train: 1.0511	loss_val: 1.0731	loss_test: 1.0776	accuracy_train: 0.5783	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 3]	loss_train: 1.1206	loss_val: 1.1370	loss_test: 1.1257	accuracy_train: 0.1792	accuracy_val: 0.1500	accuracy_test: 0.2195
[client 4]	loss_train: 1.0521	loss_val: 1.0182	loss_test: 1.1579	accuracy_train: 0.5059	accuracy_val: 0.5714	accuracy_test: 0.3750
[client 5]	loss_train: 0.8902	loss_val: 0.8916	loss_test: 0.9217	accuracy_train: 0.8601	accuracy_val: 0.8611	accuracy_test: 0.8378
[client 6]	loss_train: 1.7502	loss_val: 1.2148	loss_test: 1.3744	accuracy_train: 0.2235	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 7]	loss_train: 1.2559	loss_val: 1.2109	loss_test: 1.3439	accuracy_train: 0.2077	accuracy_val: 0.1667	accuracy_test: 0.1622
[client 8]	loss_train: 1.2441	loss_val: 1.2542	loss_test: 1.2350	accuracy_train: 0.0386	accuracy_val: 0.0278	accuracy_test: 0.0556
[client 9]	loss_train: 2.5778	loss_val: 1.2814	loss_test: 1.2098	accuracy_train: 0.2692	accuracy_val: 0.2857	accuracy_test: 0.2500
[client 10]	loss_train: 0.9932	loss_val: 0.9333	loss_test: 0.9936	accuracy_train: 0.5839	accuracy_val: 0.5588	accuracy_test: 0.5714
[client 11]	loss_train: 0.9990	loss_val: 0.9933	loss_test: 1.0077	accuracy_train: 0.5804	accuracy_val: 0.5938	accuracy_test: 0.5152
[client 12]	loss_train: 1.1842	loss_val: 1.0694	loss_test: 1.0735	accuracy_train: 0.3644	accuracy_val: 0.4000	accuracy_test: 0.2941
[client 13]	loss_train: 1.0659	loss_val: 1.0663	loss_test: 1.2152	accuracy_train: 0.3724	accuracy_val: 0.3200	accuracy_test: 0.3077
[client 14]	loss_train: 0.9470	loss_val: 0.8750	loss_test: 0.9243	accuracy_train: 0.7343	accuracy_val: 0.8235	accuracy_test: 0.7000
[client 15]	loss_train: 1.0173	loss_val: 1.0305	loss_test: 1.0390	accuracy_train: 0.3235	accuracy_val: 0.3600	accuracy_test: 0.3462
[client 16]	loss_train: 1.3665	loss_val: 1.4687	loss_test: 1.0670	accuracy_train: 0.1607	accuracy_val: 0.2500	accuracy_test: 0.1250
[client 17]	loss_train: 1.0812	loss_val: 1.0413	loss_test: 1.1443	accuracy_train: 0.3617	accuracy_val: 0.4118	accuracy_test: 0.4737
[client 18]	loss_train: 1.3543	loss_val: 1.2984	loss_test: 1.5912	accuracy_train: 0.3272	accuracy_val: 0.2941	accuracy_test: 0.3143
[client 19]	loss_train: 1.0503	loss_val: 1.0732	loss_test: 1.0730	accuracy_train: 0.2718	accuracy_val: 0.1795	accuracy_test: 0.1795
curr_round: 0	curr_val_accuracy: 0.3980	curr_test_accuracy: 0.3803
best_round: 0	best_val_accuracy: 0.3980	best_test_accuracy: 0.3803
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33804.4102	loss_val: 33806.7695	loss_test: 33806.7773	accuracy_train: 0.0388	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 10217.8799	loss_val: 10217.9307	loss_test: 10217.8809	accuracy_train: 0.7442	accuracy_val: 0.8438	accuracy_test: 0.6471
[client 2]	loss_train: 38408.6211	loss_val: 38408.6133	loss_test: 38408.6445	accuracy_train: 0.5542	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 10479.4697	loss_val: 10479.4521	loss_test: 10479.4775	accuracy_train: 0.2484	accuracy_val: 0.3500	accuracy_test: 0.2683
[client 4]	loss_train: 6797.0386	loss_val: 6797.0410	loss_test: 6797.0513	accuracy_train: 0.5941	accuracy_val: 0.5714	accuracy_test: 0.5417
[client 5]	loss_train: 4360.9248	loss_val: 4360.9116	loss_test: 4360.9673	accuracy_train: 0.8497	accuracy_val: 0.8611	accuracy_test: 0.8108
[client 6]	loss_train: 18591.9004	loss_val: 18591.6074	loss_test: 18591.6523	accuracy_train: 0.3353	accuracy_val: 0.3182	accuracy_test: 0.4545
[client 7]	loss_train: 11393.8682	loss_val: 11393.8496	loss_test: 11393.8857	accuracy_train: 0.4859	accuracy_val: 0.4722	accuracy_test: 0.4865
[client 8]	loss_train: 86.6330	loss_val: 86.6414	loss_test: 86.6262	accuracy_train: 0.0386	accuracy_val: 0.0278	accuracy_test: 0.0278
[client 9]	loss_train: 79443.8828	loss_val: 79443.4922	loss_test: 79443.5312	accuracy_train: 0.2692	accuracy_val: 0.4286	accuracy_test: 0.2500
[client 10]	loss_train: 6204.1558	loss_val: 6204.1069	loss_test: 6204.1572	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 97.9191	loss_val: 97.9168	loss_test: 97.9199	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 21272.3828	loss_val: 21272.3770	loss_test: 21272.3574	accuracy_train: 0.3136	accuracy_val: 0.3333	accuracy_test: 0.2941
[client 13]	loss_train: 88866.0938	loss_val: 88866.0859	loss_test: 88866.1250	accuracy_train: 0.4898	accuracy_val: 0.4800	accuracy_test: 0.3462
[client 14]	loss_train: 12190.5215	loss_val: 12190.4873	loss_test: 12190.4990	accuracy_train: 0.7413	accuracy_val: 0.8235	accuracy_test: 0.7000
[client 15]	loss_train: 56.0297	loss_val: 56.0429	loss_test: 56.0414	accuracy_train: 0.8088	accuracy_val: 0.6400	accuracy_test: 0.7692
[client 16]	loss_train: 13540.4941	loss_val: 13540.5566	loss_test: 13540.4883	accuracy_train: 0.4821	accuracy_val: 0.2500	accuracy_test: 0.3750
[client 17]	loss_train: 13978.2959	loss_val: 13978.3486	loss_test: 13978.2939	accuracy_train: 0.4823	accuracy_val: 0.4706	accuracy_test: 0.4737
[client 18]	loss_train: 11305.9180	loss_val: 11305.9189	loss_test: 11306.0342	accuracy_train: 0.3199	accuracy_val: 0.2941	accuracy_test: 0.3429
[client 19]	loss_train: 80.2249	loss_val: 80.2189	loss_test: 80.2344	accuracy_train: 0.8738	accuracy_val: 0.9487	accuracy_test: 0.8974
curr_round: 1	curr_val_accuracy: 0.5256	curr_test_accuracy: 0.4991
best_round: 1	best_val_accuracy: 0.5256	best_test_accuracy: 0.4991
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24887.3926	loss_val: 24888.7246	loss_test: 24888.7266	accuracy_train: 0.0388	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 10081.6348	loss_val: 10081.6865	loss_test: 10081.6357	accuracy_train: 0.7713	accuracy_val: 0.7812	accuracy_test: 0.6765
[client 2]	loss_train: 29448.4688	loss_val: 29448.4746	loss_test: 29448.4941	accuracy_train: 0.5301	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 10378.3477	loss_val: 10378.3184	loss_test: 10378.3594	accuracy_train: 0.2830	accuracy_val: 0.3750	accuracy_test: 0.2683
[client 4]	loss_train: 5026.9731	loss_val: 5026.9907	loss_test: 5026.9614	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 3708.5537	loss_val: 3708.5393	loss_test: 3708.5754	accuracy_train: 0.8531	accuracy_val: 0.8611	accuracy_test: 0.8378
[client 6]	loss_train: 16445.4180	loss_val: 16445.2129	loss_test: 16445.2129	accuracy_train: 0.3588	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 7]	loss_train: 10140.7227	loss_val: 10140.7334	loss_test: 10140.7100	accuracy_train: 0.5493	accuracy_val: 0.5278	accuracy_test: 0.5405
[client 8]	loss_train: 144.0011	loss_val: 144.0121	loss_test: 143.9975	accuracy_train: 0.0982	accuracy_val: 0.0556	accuracy_test: 0.1111
[client 9]	loss_train: 47060.9297	loss_val: 47060.6875	loss_test: 47060.7266	accuracy_train: 0.2692	accuracy_val: 0.5714	accuracy_test: 0.3750
[client 10]	loss_train: 5428.2603	loss_val: 5428.2188	loss_test: 5428.2563	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 117.6764	loss_val: 117.6751	loss_test: 117.6740	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 14585.2070	loss_val: 14585.2344	loss_test: 14585.2109	accuracy_train: 0.3136	accuracy_val: 0.3333	accuracy_test: 0.2941
[client 13]	loss_train: 72472.6016	loss_val: 72472.5938	loss_test: 72472.6094	accuracy_train: 0.8571	accuracy_val: 0.8800	accuracy_test: 0.8462
[client 14]	loss_train: 8492.3096	loss_val: 8492.2910	loss_test: 8492.2910	accuracy_train: 0.7413	accuracy_val: 0.8235	accuracy_test: 0.7000
[client 15]	loss_train: 70.3553	loss_val: 70.3680	loss_test: 70.3704	accuracy_train: 0.9118	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 16]	loss_train: 8396.0645	loss_val: 8396.1123	loss_test: 8396.1260	accuracy_train: 0.5893	accuracy_val: 0.6250	accuracy_test: 0.3750
[client 17]	loss_train: 10634.8291	loss_val: 10634.8564	loss_test: 10634.8379	accuracy_train: 0.5106	accuracy_val: 0.4706	accuracy_test: 0.4211
[client 18]	loss_train: 8421.2031	loss_val: 8421.2520	loss_test: 8421.2949	accuracy_train: 0.3125	accuracy_val: 0.2647	accuracy_test: 0.4000
[client 19]	loss_train: 129.5744	loss_val: 129.5503	loss_test: 129.5777	accuracy_train: 0.9288	accuracy_val: 1.0000	accuracy_test: 0.9487
curr_round: 2	curr_val_accuracy: 0.5707	curr_test_accuracy: 0.5490
best_round: 2	best_val_accuracy: 0.5707	best_test_accuracy: 0.5490
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23489.7324	loss_val: 23490.5664	loss_test: 23490.5664	accuracy_train: 0.0485	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 10965.1299	loss_val: 10965.1885	loss_test: 10965.1309	accuracy_train: 0.7752	accuracy_val: 0.8125	accuracy_test: 0.7059
[client 2]	loss_train: 26119.4805	loss_val: 26119.4883	loss_test: 26119.5098	accuracy_train: 0.5422	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 3]	loss_train: 11492.7236	loss_val: 11492.6914	loss_test: 11492.7363	accuracy_train: 0.3899	accuracy_val: 0.4000	accuracy_test: 0.3659
[client 4]	loss_train: 4476.8477	loss_val: 4476.8730	loss_test: 4476.8223	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 3600.5005	loss_val: 3600.4907	loss_test: 3600.5166	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 16667.9805	loss_val: 16667.8242	loss_test: 16667.8203	accuracy_train: 0.3471	accuracy_val: 0.3636	accuracy_test: 0.3182
[client 7]	loss_train: 10738.7090	loss_val: 10738.7178	loss_test: 10738.6992	accuracy_train: 0.6021	accuracy_val: 0.6111	accuracy_test: 0.6216
[client 8]	loss_train: 247.7284	loss_val: 247.7461	loss_test: 247.7313	accuracy_train: 0.7368	accuracy_val: 0.5556	accuracy_test: 0.6944
[client 9]	loss_train: 35899.7852	loss_val: 35899.6445	loss_test: 35899.6680	accuracy_train: 0.3077	accuracy_val: 0.5714	accuracy_test: 0.5000
[client 10]	loss_train: 6112.5732	loss_val: 6112.5239	loss_test: 6112.5605	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 154.5554	loss_val: 154.5547	loss_test: 154.5495	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 12697.5322	loss_val: 12697.5625	loss_test: 12697.5371	accuracy_train: 0.3220	accuracy_val: 0.3333	accuracy_test: 0.2941
[client 13]	loss_train: 78831.1250	loss_val: 78831.1250	loss_test: 78831.1406	accuracy_train: 0.8929	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 7455.4980	loss_val: 7455.4810	loss_test: 7455.4858	accuracy_train: 0.7413	accuracy_val: 0.8235	accuracy_test: 0.7000
[client 15]	loss_train: 95.6102	loss_val: 95.6216	loss_test: 95.6289	accuracy_train: 0.9510	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 16]	loss_train: 6090.3848	loss_val: 6090.4136	loss_test: 6090.4580	accuracy_train: 0.6429	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 9660.5430	loss_val: 9660.5596	loss_test: 9660.5430	accuracy_train: 0.5532	accuracy_val: 0.5882	accuracy_test: 0.4737
[client 18]	loss_train: 8130.8584	loss_val: 8130.9082	loss_test: 8130.9048	accuracy_train: 0.3419	accuracy_val: 0.2941	accuracy_test: 0.4286
[client 19]	loss_train: 216.0091	loss_val: 215.9827	loss_test: 216.0117	accuracy_train: 0.9741	accuracy_val: 1.0000	accuracy_test: 0.9744
curr_round: 3	curr_val_accuracy: 0.6225	curr_test_accuracy: 0.6154
best_round: 3	best_val_accuracy: 0.6225	best_test_accuracy: 0.6154
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22397.0859	loss_val: 22397.6582	loss_test: 22397.6582	accuracy_train: 0.0680	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 13570.7158	loss_val: 13570.7822	loss_test: 13570.7188	accuracy_train: 0.7713	accuracy_val: 0.8125	accuracy_test: 0.7353
[client 2]	loss_train: 25173.7363	loss_val: 25173.7441	loss_test: 25173.7695	accuracy_train: 0.5301	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 3]	loss_train: 13290.2012	loss_val: 13290.1729	loss_test: 13290.2178	accuracy_train: 0.4717	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 4214.8555	loss_val: 4214.8853	loss_test: 4214.8315	accuracy_train: 0.6353	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 3730.2471	loss_val: 3730.2444	loss_test: 3730.2551	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 17272.6484	loss_val: 17272.5469	loss_test: 17272.5410	accuracy_train: 0.3412	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 13094.6260	loss_val: 13094.6162	loss_test: 13094.6113	accuracy_train: 0.5986	accuracy_val: 0.6111	accuracy_test: 0.6216
[client 8]	loss_train: 399.2622	loss_val: 399.2909	loss_test: 399.2733	accuracy_train: 0.8912	accuracy_val: 0.8056	accuracy_test: 0.8889
[client 9]	loss_train: 35190.9531	loss_val: 35190.8828	loss_test: 35190.9023	accuracy_train: 0.3269	accuracy_val: 0.5714	accuracy_test: 0.5000
[client 10]	loss_train: 6897.5669	loss_val: 6897.5122	loss_test: 6897.5547	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 211.1112	loss_val: 211.1120	loss_test: 211.1025	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 12103.5068	loss_val: 12103.5381	loss_test: 12103.5156	accuracy_train: 0.3305	accuracy_val: 0.2667	accuracy_test: 0.2941
[client 13]	loss_train: 95177.5391	loss_val: 95177.5547	loss_test: 95177.5625	accuracy_train: 0.8980	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 7156.0234	loss_val: 7156.0117	loss_test: 7156.0181	accuracy_train: 0.7413	accuracy_val: 0.7647	accuracy_test: 0.7000
[client 15]	loss_train: 131.9164	loss_val: 131.9304	loss_test: 131.9428	accuracy_train: 0.9559	accuracy_val: 0.9600	accuracy_test: 0.9231
[client 16]	loss_train: 4964.8672	loss_val: 4964.8877	loss_test: 4964.9399	accuracy_train: 0.6429	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 9090.7920	loss_val: 9090.7939	loss_test: 9090.7695	accuracy_train: 0.5745	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 9005.4844	loss_val: 9005.5391	loss_test: 9005.5254	accuracy_train: 0.3676	accuracy_val: 0.3235	accuracy_test: 0.4286
[client 19]	loss_train: 347.2917	loss_val: 347.2693	loss_test: 347.2961	accuracy_train: 0.9773	accuracy_val: 1.0000	accuracy_test: 0.9744
curr_round: 4	curr_val_accuracy: 0.6463	curr_test_accuracy: 0.6443
best_round: 4	best_val_accuracy: 0.6463	best_test_accuracy: 0.6443
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21787.9785	loss_val: 21788.3301	loss_test: 21788.3281	accuracy_train: 0.0680	accuracy_val: 0.0714	accuracy_test: 0.0714
[client 1]	loss_train: 16471.7480	loss_val: 16471.8203	loss_test: 16471.7520	accuracy_train: 0.7907	accuracy_val: 0.8125	accuracy_test: 0.7353
[client 2]	loss_train: 25067.7051	loss_val: 25067.7148	loss_test: 25067.7422	accuracy_train: 0.5422	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 3]	loss_train: 15113.0264	loss_val: 15113.0039	loss_test: 15113.0439	accuracy_train: 0.4843	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 4151.8560	loss_val: 4151.8887	loss_test: 4151.8354	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 4169.5854	loss_val: 4169.5898	loss_test: 4169.5938	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 18342.1582	loss_val: 18342.0977	loss_test: 18342.0898	accuracy_train: 0.3412	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 16293.9004	loss_val: 16293.8857	loss_test: 16293.8867	accuracy_train: 0.6303	accuracy_val: 0.6389	accuracy_test: 0.6757
[client 8]	loss_train: 584.0148	loss_val: 584.0592	loss_test: 584.0368	accuracy_train: 0.9649	accuracy_val: 0.8889	accuracy_test: 0.9722
[client 9]	loss_train: 34850.5977	loss_val: 34850.5625	loss_test: 34850.5781	accuracy_train: 0.3462	accuracy_val: 0.4286	accuracy_test: 0.5000
[client 10]	loss_train: 7521.2759	loss_val: 7521.2197	loss_test: 7521.2686	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 291.0918	loss_val: 291.0949	loss_test: 291.0804	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 12613.8779	loss_val: 12613.9111	loss_test: 12613.8887	accuracy_train: 0.4153	accuracy_val: 0.2667	accuracy_test: 0.2941
[client 13]	loss_train: 110722.9062	loss_val: 110722.9219	loss_test: 110722.9297	accuracy_train: 0.9031	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 6813.5786	loss_val: 6813.5625	loss_test: 6813.5718	accuracy_train: 0.7413	accuracy_val: 0.7647	accuracy_test: 0.7000
[client 15]	loss_train: 178.5523	loss_val: 178.5706	loss_test: 178.5879	accuracy_train: 0.9706	accuracy_val: 0.9600	accuracy_test: 0.9231
[client 16]	loss_train: 4421.3066	loss_val: 4421.3296	loss_test: 4421.3755	accuracy_train: 0.7321	accuracy_val: 0.8750	accuracy_test: 0.3750
[client 17]	loss_train: 9263.7656	loss_val: 9263.7598	loss_test: 9263.7295	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 10245.8662	loss_val: 10245.9111	loss_test: 10245.8916	accuracy_train: 0.4007	accuracy_val: 0.4412	accuracy_test: 0.3429
[client 19]	loss_train: 509.1615	loss_val: 509.1430	loss_test: 509.1737	accuracy_train: 0.9935	accuracy_val: 1.0000	accuracy_test: 0.9744
curr_round: 5	curr_val_accuracy: 0.6601	curr_test_accuracy: 0.6502
best_round: 5	best_val_accuracy: 0.6601	best_test_accuracy: 0.6502
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21401.2305	loss_val: 21401.4609	loss_test: 21401.4590	accuracy_train: 0.0777	accuracy_val: 0.1429	accuracy_test: 0.0714
[client 1]	loss_train: 18414.8496	loss_val: 18414.9238	loss_test: 18414.8535	accuracy_train: 0.7984	accuracy_val: 0.8438	accuracy_test: 0.7353
[client 2]	loss_train: 26025.7793	loss_val: 26025.7930	loss_test: 26025.8203	accuracy_train: 0.5542	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 3]	loss_train: 17019.8672	loss_val: 17019.8418	loss_test: 17019.8867	accuracy_train: 0.4780	accuracy_val: 0.4250	accuracy_test: 0.4634
[client 4]	loss_train: 4112.4771	loss_val: 4112.5156	loss_test: 4112.4541	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 4866.1777	loss_val: 4866.1841	loss_test: 4866.1943	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 19893.6133	loss_val: 19893.5762	loss_test: 19893.5645	accuracy_train: 0.3471	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 19351.7578	loss_val: 19351.7324	loss_test: 19351.7441	accuracy_train: 0.6479	accuracy_val: 0.6389	accuracy_test: 0.6486
[client 8]	loss_train: 798.8710	loss_val: 798.9268	loss_test: 798.9080	accuracy_train: 0.9825	accuracy_val: 0.9444	accuracy_test: 1.0000
[client 9]	loss_train: 35469.5156	loss_val: 35469.5000	loss_test: 35469.5117	accuracy_train: 0.6731	accuracy_val: 0.8571	accuracy_test: 0.6250
[client 10]	loss_train: 8097.4126	loss_val: 8097.3521	loss_test: 8097.4097	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 394.7242	loss_val: 394.7296	loss_test: 394.7088	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 13148.1943	loss_val: 13148.2295	loss_test: 13148.2080	accuracy_train: 0.5085	accuracy_val: 0.4000	accuracy_test: 0.2941
[client 13]	loss_train: 123850.7344	loss_val: 123850.7500	loss_test: 123850.7578	accuracy_train: 0.9031	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 6484.3398	loss_val: 6484.3184	loss_test: 6484.3340	accuracy_train: 0.7483	accuracy_val: 0.7647	accuracy_test: 0.7000
[client 15]	loss_train: 236.3839	loss_val: 236.4078	loss_test: 236.4253	accuracy_train: 0.9853	accuracy_val: 1.0000	accuracy_test: 0.9615
[client 16]	loss_train: 4229.0312	loss_val: 4229.0610	loss_test: 4229.0986	accuracy_train: 0.7857	accuracy_val: 0.8750	accuracy_test: 0.3750
[client 17]	loss_train: 9505.9482	loss_val: 9505.9424	loss_test: 9505.9053	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11559.0225	loss_val: 11559.0547	loss_test: 11559.0312	accuracy_train: 0.4375	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 685.5632	loss_val: 685.5447	loss_test: 685.5838	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 6	curr_val_accuracy: 0.6818	curr_test_accuracy: 0.6618
best_round: 6	best_val_accuracy: 0.6818	best_test_accuracy: 0.6618
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21490.2969	loss_val: 21490.3770	loss_test: 21490.3730	accuracy_train: 0.2136	accuracy_val: 0.1429	accuracy_test: 0.2143
[client 1]	loss_train: 19556.9141	loss_val: 19556.9844	loss_test: 19556.9219	accuracy_train: 0.8023	accuracy_val: 0.8438	accuracy_test: 0.7353
[client 2]	loss_train: 27411.2852	loss_val: 27411.3027	loss_test: 27411.3301	accuracy_train: 0.5663	accuracy_val: 0.3636	accuracy_test: 0.3636
[client 3]	loss_train: 19204.6855	loss_val: 19204.6543	loss_test: 19204.7031	accuracy_train: 0.4717	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 4245.4263	loss_val: 4245.4741	loss_test: 4245.3975	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 5677.0771	loss_val: 5677.0850	loss_test: 5677.1016	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 21901.8418	loss_val: 21901.8184	loss_test: 21901.8047	accuracy_train: 0.3412	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 22548.8359	loss_val: 22548.8027	loss_test: 22548.8223	accuracy_train: 0.6373	accuracy_val: 0.6944	accuracy_test: 0.6216
[client 8]	loss_train: 995.9745	loss_val: 996.0387	loss_test: 996.0239	accuracy_train: 0.9965	accuracy_val: 0.9722	accuracy_test: 1.0000
[client 9]	loss_train: 34669.6172	loss_val: 34669.6094	loss_test: 34669.6172	accuracy_train: 0.8077	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 8720.0400	loss_val: 8719.9766	loss_test: 8720.0381	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 523.5042	loss_val: 523.5117	loss_test: 523.4845	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 14313.8584	loss_val: 14313.8945	loss_test: 14313.8730	accuracy_train: 0.5932	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 135622.9375	loss_val: 135622.9688	loss_test: 135622.9844	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 6422.3032	loss_val: 6422.2812	loss_test: 6422.3037	accuracy_train: 0.7552	accuracy_val: 0.8824	accuracy_test: 0.6500
[client 15]	loss_train: 305.6788	loss_val: 305.7068	loss_test: 305.7281	accuracy_train: 0.9902	accuracy_val: 1.0000	accuracy_test: 0.9615
[client 16]	loss_train: 4127.4819	loss_val: 4127.5273	loss_test: 4127.5576	accuracy_train: 0.8571	accuracy_val: 0.8750	accuracy_test: 0.3750
[client 17]	loss_train: 10045.0068	loss_val: 10044.9980	loss_test: 10044.9609	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13343.2207	loss_val: 13343.2373	loss_test: 13343.2188	accuracy_train: 0.4044	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 866.4141	loss_val: 866.3941	loss_test: 866.4430	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 7	curr_val_accuracy: 0.6921	curr_test_accuracy: 0.6721
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22035.6621	loss_val: 22035.6621	loss_test: 22035.6562	accuracy_train: 0.3398	accuracy_val: 0.2143	accuracy_test: 0.3571
[client 1]	loss_train: 21836.9395	loss_val: 21836.9961	loss_test: 21836.9531	accuracy_train: 0.8062	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 29107.1152	loss_val: 29107.1367	loss_test: 29107.1641	accuracy_train: 0.5904	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 3]	loss_train: 18953.1094	loss_val: 18953.0762	loss_test: 18953.1289	accuracy_train: 0.4717	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 4264.5229	loss_val: 4264.5786	loss_test: 4264.4937	accuracy_train: 0.6353	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6340.5024	loss_val: 6340.5122	loss_test: 6340.5303	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 24428.4434	loss_val: 24428.4297	loss_test: 24428.4160	accuracy_train: 0.3529	accuracy_val: 0.3182	accuracy_test: 0.3182
[client 7]	loss_train: 25488.6172	loss_val: 25488.5801	loss_test: 25488.6035	accuracy_train: 0.6620	accuracy_val: 0.7222	accuracy_test: 0.6486
[client 8]	loss_train: 1171.2094	loss_val: 1171.2788	loss_test: 1171.2632	accuracy_train: 0.9965	accuracy_val: 0.9722	accuracy_test: 1.0000
[client 9]	loss_train: 35996.5352	loss_val: 35996.5312	loss_test: 35996.5352	accuracy_train: 0.7692	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 9274.2324	loss_val: 9274.1680	loss_test: 9274.2314	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 677.1764	loss_val: 677.1862	loss_test: 677.1521	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 15409.5205	loss_val: 15409.5586	loss_test: 15409.5381	accuracy_train: 0.6695	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 151775.7969	loss_val: 151775.8281	loss_test: 151775.8438	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 6743.1299	loss_val: 6743.1138	loss_test: 6743.1401	accuracy_train: 0.7413	accuracy_val: 0.8235	accuracy_test: 0.6000
[client 15]	loss_train: 382.2009	loss_val: 382.2314	loss_test: 382.2574	accuracy_train: 0.9951	accuracy_val: 1.0000	accuracy_test: 0.9615
[client 16]	loss_train: 4114.9722	loss_val: 4115.0254	loss_test: 4115.0562	accuracy_train: 0.8571	accuracy_val: 0.5000	accuracy_test: 0.3750
[client 17]	loss_train: 10807.4238	loss_val: 10807.4141	loss_test: 10807.3740	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14966.1309	loss_val: 14966.1416	loss_test: 14966.1299	accuracy_train: 0.3971	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1033.2197	loss_val: 1033.1980	loss_test: 1033.2567	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 8	curr_val_accuracy: 0.6904	curr_test_accuracy: 0.6725
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22475.7344	loss_val: 22475.7422	loss_test: 22475.7383	accuracy_train: 0.5243	accuracy_val: 0.2857	accuracy_test: 0.4286
[client 1]	loss_train: 24341.9961	loss_val: 24342.0391	loss_test: 24342.0137	accuracy_train: 0.8140	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 30637.4082	loss_val: 30637.4336	loss_test: 30637.4609	accuracy_train: 0.6145	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 18529.5098	loss_val: 18529.4766	loss_test: 18529.5312	accuracy_train: 0.4780	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 4488.2646	loss_val: 4488.3271	loss_test: 4488.2373	accuracy_train: 0.6294	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6408.8892	loss_val: 6408.8994	loss_test: 6408.9199	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 27650.1387	loss_val: 27650.1348	loss_test: 27650.1172	accuracy_train: 0.3588	accuracy_val: 0.3182	accuracy_test: 0.3636
[client 7]	loss_train: 26968.6992	loss_val: 26968.6621	loss_test: 26968.6895	accuracy_train: 0.6479	accuracy_val: 0.7222	accuracy_test: 0.6757
[client 8]	loss_train: 1316.9020	loss_val: 1316.9735	loss_test: 1316.9547	accuracy_train: 0.9965	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 37678.3828	loss_val: 37678.3828	loss_test: 37678.3828	accuracy_train: 0.7692	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10145.9277	loss_val: 10145.8643	loss_test: 10145.9287	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 850.8427	loss_val: 850.8546	loss_test: 850.8134	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 16981.1621	loss_val: 16981.2051	loss_test: 16981.1816	accuracy_train: 0.6695	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 166129.7031	loss_val: 166129.7344	loss_test: 166129.7500	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 7466.0659	loss_val: 7466.0562	loss_test: 7466.0850	accuracy_train: 0.7413	accuracy_val: 0.7059	accuracy_test: 0.5500
[client 15]	loss_train: 469.3563	loss_val: 469.3909	loss_test: 469.4179	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4209.7021	loss_val: 4209.7578	loss_test: 4209.7988	accuracy_train: 0.8393	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 17]	loss_train: 11745.7324	loss_val: 11745.7256	loss_test: 11745.6807	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15536.0586	loss_val: 15536.0693	loss_test: 15536.0615	accuracy_train: 0.4007	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1177.8817	loss_val: 1177.8624	loss_test: 1177.9258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 9	curr_val_accuracy: 0.6880	curr_test_accuracy: 0.6820
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22966.4551	loss_val: 22966.4414	loss_test: 22966.4355	accuracy_train: 0.7961	accuracy_val: 0.7857	accuracy_test: 0.6429
[client 1]	loss_train: 25917.7266	loss_val: 25917.7578	loss_test: 25917.7520	accuracy_train: 0.8217	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 32143.5469	loss_val: 32143.5762	loss_test: 32143.6016	accuracy_train: 0.6506	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 18464.5605	loss_val: 18464.5312	loss_test: 18464.5859	accuracy_train: 0.4654	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 4798.8843	loss_val: 4798.9536	loss_test: 4798.8608	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6255.1519	loss_val: 6255.1636	loss_test: 6255.1831	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 31316.2871	loss_val: 31316.2910	loss_test: 31316.2676	accuracy_train: 0.3824	accuracy_val: 0.3182	accuracy_test: 0.4091
[client 7]	loss_train: 27376.4141	loss_val: 27376.3809	loss_test: 27376.4062	accuracy_train: 0.6444	accuracy_val: 0.5833	accuracy_test: 0.6486
[client 8]	loss_train: 1427.5284	loss_val: 1427.6029	loss_test: 1427.5779	accuracy_train: 0.9965	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 39089.7969	loss_val: 39089.8008	loss_test: 39089.7930	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10818.1689	loss_val: 10818.1084	loss_test: 10818.1709	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1055.8474	loss_val: 1055.8628	loss_test: 1055.8137	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 18501.5215	loss_val: 18501.5664	loss_test: 18501.5430	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 184031.7031	loss_val: 184031.7344	loss_test: 184031.7500	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 8598.3770	loss_val: 8598.3662	loss_test: 8598.4014	accuracy_train: 0.5594	accuracy_val: 0.4706	accuracy_test: 0.3500
[client 15]	loss_train: 564.0267	loss_val: 564.0673	loss_test: 564.0936	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4329.8799	loss_val: 4329.9370	loss_test: 4329.9868	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 12826.8994	loss_val: 12826.8955	loss_test: 12826.8506	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16198.8496	loss_val: 16198.8633	loss_test: 16198.8564	accuracy_train: 0.4044	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1316.4132	loss_val: 1316.3983	loss_test: 1316.4644	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 10	curr_val_accuracy: 0.6866	curr_test_accuracy: 0.6822
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24289.7148	loss_val: 24289.7168	loss_test: 24289.7129	accuracy_train: 0.8835	accuracy_val: 0.7857	accuracy_test: 0.8571
[client 1]	loss_train: 25417.4941	loss_val: 25417.5156	loss_test: 25417.5234	accuracy_train: 0.8217	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 34268.7070	loss_val: 34268.7461	loss_test: 34268.7695	accuracy_train: 0.6867	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 3]	loss_train: 17890.3125	loss_val: 17890.2852	loss_test: 17890.3379	accuracy_train: 0.4497	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5001.7124	loss_val: 5001.7866	loss_test: 5001.6924	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6161.3145	loss_val: 6161.3271	loss_test: 6161.3467	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 35104.8633	loss_val: 35104.8711	loss_test: 35104.8477	accuracy_train: 0.3824	accuracy_val: 0.3182	accuracy_test: 0.4091
[client 7]	loss_train: 27543.8105	loss_val: 27543.7812	loss_test: 27543.7988	accuracy_train: 0.6092	accuracy_val: 0.5556	accuracy_test: 0.6486
[client 8]	loss_train: 1514.4027	loss_val: 1514.4799	loss_test: 1514.4490	accuracy_train: 0.9965	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 40919.8320	loss_val: 40919.8398	loss_test: 40919.8281	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10897.3516	loss_val: 10897.2920	loss_test: 10897.3535	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1271.9557	loss_val: 1271.9750	loss_test: 1271.9175	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 19852.1875	loss_val: 19852.2344	loss_test: 19852.2109	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 203493.9688	loss_val: 203494.0156	loss_test: 203494.0312	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9241.1943	loss_val: 9241.1807	loss_test: 9241.2217	accuracy_train: 0.4965	accuracy_val: 0.4118	accuracy_test: 0.3500
[client 15]	loss_train: 660.0829	loss_val: 660.1279	loss_test: 660.1571	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4601.8428	loss_val: 4601.9048	loss_test: 4601.9648	accuracy_train: 0.8750	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 17]	loss_train: 13329.0596	loss_val: 13329.0605	loss_test: 13329.0137	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16633.0020	loss_val: 16633.0176	loss_test: 16633.0098	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1426.4546	loss_val: 1426.4446	loss_test: 1426.5071	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 11	curr_val_accuracy: 0.6807	curr_test_accuracy: 0.6934
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25667.8672	loss_val: 25667.8711	loss_test: 25667.8652	accuracy_train: 0.8835	accuracy_val: 0.7857	accuracy_test: 0.8571
[client 1]	loss_train: 24049.6797	loss_val: 24049.6953	loss_test: 24049.7129	accuracy_train: 0.8140	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 36352.2695	loss_val: 36352.3164	loss_test: 36352.3359	accuracy_train: 0.6988	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 3]	loss_train: 17742.9141	loss_val: 17742.8867	loss_test: 17742.9375	accuracy_train: 0.4528	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5120.8545	loss_val: 5120.9336	loss_test: 5120.8394	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6136.9800	loss_val: 6136.9937	loss_test: 6137.0166	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 38092.5078	loss_val: 38092.5156	loss_test: 38092.4922	accuracy_train: 0.4000	accuracy_val: 0.3636	accuracy_test: 0.4091
[client 7]	loss_train: 27719.0098	loss_val: 27718.9824	loss_test: 27719.0000	accuracy_train: 0.5775	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1589.7654	loss_val: 1589.8427	loss_test: 1589.8109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43423.2852	loss_val: 43423.3008	loss_test: 43423.2773	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10943.4062	loss_val: 10943.3467	loss_test: 10943.4082	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1506.6478	loss_val: 1506.6713	loss_test: 1506.6051	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 21589.8652	loss_val: 21589.9160	loss_test: 21589.8945	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 216175.6094	loss_val: 216175.6719	loss_test: 216175.6875	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9437.0107	loss_val: 9436.9951	loss_test: 9437.0371	accuracy_train: 0.4406	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 754.8209	loss_val: 754.8685	loss_test: 754.9025	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5238.7725	loss_val: 5238.8423	loss_test: 5238.9141	accuracy_train: 0.8750	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 17]	loss_train: 14027.6719	loss_val: 14027.6758	loss_test: 14027.6279	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16193.4883	loss_val: 16193.5088	loss_test: 16193.5049	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1523.7599	loss_val: 1523.7534	loss_test: 1523.8098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 12	curr_val_accuracy: 0.6745	curr_test_accuracy: 0.6877
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26623.2188	loss_val: 26623.2031	loss_test: 26623.1973	accuracy_train: 0.8932	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 23734.4434	loss_val: 23734.4551	loss_test: 23734.4844	accuracy_train: 0.8140	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 38659.9844	loss_val: 38660.0430	loss_test: 38660.0547	accuracy_train: 0.7108	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 18275.9707	loss_val: 18275.9473	loss_test: 18275.9941	accuracy_train: 0.4528	accuracy_val: 0.4250	accuracy_test: 0.4634
[client 4]	loss_train: 5212.5215	loss_val: 5212.6055	loss_test: 5212.5122	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6140.1631	loss_val: 6140.1758	loss_test: 6140.2036	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40910.0781	loss_val: 40910.0898	loss_test: 40910.0625	accuracy_train: 0.3882	accuracy_val: 0.3636	accuracy_test: 0.4091
[client 7]	loss_train: 27786.3379	loss_val: 27786.3105	loss_test: 27786.3281	accuracy_train: 0.5669	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1637.7360	loss_val: 1637.8124	loss_test: 1637.7800	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45363.3477	loss_val: 45363.3750	loss_test: 45363.3398	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10571.5684	loss_val: 10571.5107	loss_test: 10571.5723	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1727.2965	loss_val: 1727.3231	loss_test: 1727.2523	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 22673.2070	loss_val: 22673.2598	loss_test: 22673.2402	accuracy_train: 0.6780	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 227569.8281	loss_val: 227569.8750	loss_test: 227569.9062	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9816.4746	loss_val: 9816.4580	loss_test: 9816.5000	accuracy_train: 0.3986	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 852.4828	loss_val: 852.5320	loss_test: 852.5679	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5588.9165	loss_val: 5588.9902	loss_test: 5589.0684	accuracy_train: 0.8750	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 17]	loss_train: 14714.1006	loss_val: 14714.1064	loss_test: 14714.0596	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14837.5264	loss_val: 14837.5449	loss_test: 14837.5420	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1590.8046	loss_val: 1590.8007	loss_test: 1590.8533	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 13	curr_val_accuracy: 0.6843	curr_test_accuracy: 0.6876
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28483.0957	loss_val: 28483.0820	loss_test: 28483.0762	accuracy_train: 0.9029	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 25918.6348	loss_val: 25918.6445	loss_test: 25918.6855	accuracy_train: 0.8140	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 41670.1602	loss_val: 41670.2266	loss_test: 41670.2344	accuracy_train: 0.7108	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 17984.3535	loss_val: 17984.3281	loss_test: 17984.3770	accuracy_train: 0.4623	accuracy_val: 0.4250	accuracy_test: 0.4634
[client 4]	loss_train: 5433.9946	loss_val: 5434.0845	loss_test: 5433.9951	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6198.6357	loss_val: 6198.6494	loss_test: 6198.6787	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42745.7148	loss_val: 42745.7188	loss_test: 42745.6953	accuracy_train: 0.4059	accuracy_val: 0.3636	accuracy_test: 0.4091
[client 7]	loss_train: 27279.8301	loss_val: 27279.8008	loss_test: 27279.8223	accuracy_train: 0.5915	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1652.1589	loss_val: 1652.2349	loss_test: 1652.2014	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47192.7461	loss_val: 47192.7852	loss_test: 47192.7383	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10600.2451	loss_val: 10600.1885	loss_test: 10600.2500	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1962.5681	loss_val: 1962.5970	loss_test: 1962.5236	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 23200.6406	loss_val: 23200.6953	loss_test: 23200.6797	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 244632.9844	loss_val: 244633.0312	loss_test: 244633.0625	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 10150.2920	loss_val: 10150.2754	loss_test: 10150.3184	accuracy_train: 0.3427	accuracy_val: 0.3529	accuracy_test: 0.3500
[client 15]	loss_train: 937.8729	loss_val: 937.9233	loss_test: 937.9606	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5906.4272	loss_val: 5906.5049	loss_test: 5906.5923	accuracy_train: 0.8750	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 15204.0713	loss_val: 15204.0771	loss_test: 15204.0342	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14314.8877	loss_val: 14314.9150	loss_test: 14314.9160	accuracy_train: 0.3971	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1604.5081	loss_val: 1604.5051	loss_test: 1604.5560	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 14	curr_val_accuracy: 0.6880	curr_test_accuracy: 0.6894
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29934.1445	loss_val: 29934.1191	loss_test: 29934.1113	accuracy_train: 0.9223	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 25168.7617	loss_val: 25168.7695	loss_test: 25168.8164	accuracy_train: 0.8023	accuracy_val: 0.8438	accuracy_test: 0.7941
[client 2]	loss_train: 43774.5352	loss_val: 43774.6133	loss_test: 43774.6172	accuracy_train: 0.7229	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 17797.1738	loss_val: 17797.1504	loss_test: 17797.2012	accuracy_train: 0.4686	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5673.8936	loss_val: 5673.9897	loss_test: 5673.8999	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 6213.8433	loss_val: 6213.8564	loss_test: 6213.8872	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44344.6289	loss_val: 44344.6250	loss_test: 44344.6055	accuracy_train: 0.4059	accuracy_val: 0.3636	accuracy_test: 0.4091
[client 7]	loss_train: 26908.6934	loss_val: 26908.6602	loss_test: 26908.6816	accuracy_train: 0.6021	accuracy_val: 0.6111	accuracy_test: 0.5405
[client 8]	loss_train: 1646.0707	loss_val: 1646.1458	loss_test: 1646.1121	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48657.2656	loss_val: 48657.3203	loss_test: 48657.2539	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10696.9580	loss_val: 10696.9023	loss_test: 10696.9639	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2175.5938	loss_val: 2175.6262	loss_test: 2175.5503	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 23998.1562	loss_val: 23998.2168	loss_test: 23998.2031	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 259464.0312	loss_val: 259464.0938	loss_test: 259464.1250	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 10396.7275	loss_val: 10396.7119	loss_test: 10396.7559	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1019.9271	loss_val: 1019.9789	loss_test: 1020.0198	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6069.3511	loss_val: 6069.4346	loss_test: 6069.5288	accuracy_train: 0.8750	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 15850.2021	loss_val: 15850.2080	loss_test: 15850.1709	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14005.9229	loss_val: 14005.9541	loss_test: 14005.9609	accuracy_train: 0.3971	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1621.3646	loss_val: 1621.3635	loss_test: 1621.4124	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 15	curr_val_accuracy: 0.6859	curr_test_accuracy: 0.6894
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30769.5391	loss_val: 30769.5078	loss_test: 30769.5000	accuracy_train: 0.9223	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 24645.0684	loss_val: 24645.0801	loss_test: 24645.1289	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 46407.1328	loss_val: 46407.2227	loss_test: 46407.2227	accuracy_train: 0.7470	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 17427.9414	loss_val: 17427.9160	loss_test: 17427.9688	accuracy_train: 0.4686	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5879.7725	loss_val: 5879.8755	loss_test: 5879.7866	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5982.9390	loss_val: 5982.9531	loss_test: 5982.9824	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45880.6250	loss_val: 45880.6133	loss_test: 45880.5938	accuracy_train: 0.4294	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 26398.4727	loss_val: 26398.4434	loss_test: 26398.4590	accuracy_train: 0.6056	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1639.1536	loss_val: 1639.2272	loss_test: 1639.1948	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48871.3750	loss_val: 48871.4414	loss_test: 48871.3633	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10559.8916	loss_val: 10559.8359	loss_test: 10559.8965	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2360.6196	loss_val: 2360.6555	loss_test: 2360.5796	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 24743.3203	loss_val: 24743.3848	loss_test: 24743.3770	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 268824.9062	loss_val: 268824.9375	loss_test: 268825.0000	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 10255.8945	loss_val: 10255.8789	loss_test: 10255.9258	accuracy_train: 0.3147	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1083.4393	loss_val: 1083.4928	loss_test: 1083.5356	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6241.3062	loss_val: 6241.3960	loss_test: 6241.4980	accuracy_train: 0.8750	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 16418.4004	loss_val: 16418.4062	loss_test: 16418.3770	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13762.3545	loss_val: 13762.3789	loss_test: 13762.3809	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1611.1372	loss_val: 1611.1364	loss_test: 1611.1841	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 16	curr_val_accuracy: 0.6879	curr_test_accuracy: 0.6895
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31623.3398	loss_val: 31623.3047	loss_test: 31623.2930	accuracy_train: 0.9223	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 24534.3594	loss_val: 24534.3711	loss_test: 24534.4219	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 51221.6133	loss_val: 51221.7109	loss_test: 51221.7070	accuracy_train: 0.7831	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 17111.4961	loss_val: 17111.4727	loss_test: 17111.5215	accuracy_train: 0.4686	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 6118.5884	loss_val: 6118.6968	loss_test: 6118.6099	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5688.9712	loss_val: 5688.9878	loss_test: 5689.0161	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47353.7188	loss_val: 47353.6992	loss_test: 47353.6836	accuracy_train: 0.4294	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 25785.3672	loss_val: 25785.3418	loss_test: 25785.3555	accuracy_train: 0.5951	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1624.3021	loss_val: 1624.3735	loss_test: 1624.3435	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47976.0117	loss_val: 47976.0938	loss_test: 47975.9961	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10219.9551	loss_val: 10219.8994	loss_test: 10219.9590	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2573.8716	loss_val: 2573.9094	loss_test: 2573.8340	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 25466.3066	loss_val: 25466.3730	loss_test: 25466.3711	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 267789.1250	loss_val: 267789.1875	loss_test: 267789.2188	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9963.9365	loss_val: 9963.9180	loss_test: 9963.9707	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1142.4814	loss_val: 1142.5377	loss_test: 1142.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6481.9272	loss_val: 6482.0278	loss_test: 6482.1343	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 16371.8682	loss_val: 16371.8760	loss_test: 16371.8525	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13262.7275	loss_val: 13262.7461	loss_test: 13262.7451	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1614.6976	loss_val: 1614.6985	loss_test: 1614.7448	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 17	curr_val_accuracy: 0.6879	curr_test_accuracy: 0.6876
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31878.3281	loss_val: 31878.2969	loss_test: 31878.2832	accuracy_train: 0.9223	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 27357.8672	loss_val: 27357.8828	loss_test: 27357.9355	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 54230.9258	loss_val: 54231.0352	loss_test: 54231.0273	accuracy_train: 0.7831	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 16307.6436	loss_val: 16307.6191	loss_test: 16307.6689	accuracy_train: 0.4686	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6356.9341	loss_val: 6357.0493	loss_test: 6356.9604	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5401.7422	loss_val: 5401.7627	loss_test: 5401.7891	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49093.4297	loss_val: 49093.4062	loss_test: 49093.3945	accuracy_train: 0.4294	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 25745.9629	loss_val: 25745.9414	loss_test: 25745.9512	accuracy_train: 0.5951	accuracy_val: 0.6111	accuracy_test: 0.5405
[client 8]	loss_train: 1604.4210	loss_val: 1604.4912	loss_test: 1604.4620	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47754.9883	loss_val: 47755.0898	loss_test: 47754.9727	accuracy_train: 0.8077	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10152.4326	loss_val: 10152.3779	loss_test: 10152.4355	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2760.7903	loss_val: 2760.8311	loss_test: 2760.7563	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 25632.3750	loss_val: 25632.4453	loss_test: 25632.4492	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 263663.7500	loss_val: 263663.8125	loss_test: 263663.8750	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9867.3564	loss_val: 9867.3379	loss_test: 9867.3936	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1186.2916	loss_val: 1186.3501	loss_test: 1186.3877	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6772.3091	loss_val: 6772.4229	loss_test: 6772.5337	accuracy_train: 0.8750	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 15873.3242	loss_val: 15873.3340	loss_test: 15873.3164	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13219.4805	loss_val: 13219.4980	loss_test: 13219.5000	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1632.5610	loss_val: 1632.5641	loss_test: 1632.6071	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 18	curr_val_accuracy: 0.6918	curr_test_accuracy: 0.6915
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31525.4180	loss_val: 31525.3887	loss_test: 31525.3730	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 30064.5156	loss_val: 30064.5312	loss_test: 30064.5918	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 56065.1797	loss_val: 56065.3008	loss_test: 56065.2852	accuracy_train: 0.7831	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 15745.0098	loss_val: 15744.9795	loss_test: 15745.0371	accuracy_train: 0.4623	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 6406.8374	loss_val: 6406.9585	loss_test: 6406.8716	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5408.2163	loss_val: 5408.2383	loss_test: 5408.2656	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50457.0469	loss_val: 50457.0195	loss_test: 50457.0156	accuracy_train: 0.4353	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 25959.3184	loss_val: 25959.3008	loss_test: 25959.3047	accuracy_train: 0.5915	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1579.1141	loss_val: 1579.1830	loss_test: 1579.1552	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47114.5977	loss_val: 47114.7266	loss_test: 47114.5859	accuracy_train: 0.8077	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10180.8516	loss_val: 10180.7969	loss_test: 10180.8545	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2929.8789	loss_val: 2929.9221	loss_test: 2929.8491	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 26073.8574	loss_val: 26073.9336	loss_test: 26073.9414	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 254838.9375	loss_val: 254839.0000	loss_test: 254839.0469	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10129.7100	loss_val: 10129.6885	loss_test: 10129.7490	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1231.9934	loss_val: 1232.0533	loss_test: 1232.0881	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7057.8042	loss_val: 7057.9297	loss_test: 7058.0464	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 15412.8623	loss_val: 15412.8770	loss_test: 15412.8613	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13579.2764	loss_val: 13579.2930	loss_test: 13579.2969	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1648.0455	loss_val: 1648.0507	loss_test: 1648.0892	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 19	curr_val_accuracy: 0.6917	curr_test_accuracy: 0.6895
best_round: 7	best_val_accuracy: 0.6921	best_test_accuracy: 0.6721
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31971.6934	loss_val: 31971.6660	loss_test: 31971.6484	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 34556.1484	loss_val: 34556.1680	loss_test: 34556.2344	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 59787.6562	loss_val: 59787.7930	loss_test: 59787.7695	accuracy_train: 0.7952	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 15824.4883	loss_val: 15824.4561	loss_test: 15824.5166	accuracy_train: 0.4528	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 6367.3877	loss_val: 6367.5127	loss_test: 6367.4297	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5658.6792	loss_val: 5658.7036	loss_test: 5658.7310	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51619.0391	loss_val: 51619.0117	loss_test: 51619.0078	accuracy_train: 0.4471	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 26940.8027	loss_val: 26940.7891	loss_test: 26940.7930	accuracy_train: 0.5951	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1536.9669	loss_val: 1537.0345	loss_test: 1537.0077	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47286.3906	loss_val: 47286.5469	loss_test: 47286.3789	accuracy_train: 0.8077	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10152.4854	loss_val: 10152.4297	loss_test: 10152.4863	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3063.4568	loss_val: 3063.5012	loss_test: 3063.4292	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 26630.0312	loss_val: 26630.1113	loss_test: 26630.1250	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 249349.3594	loss_val: 249349.4219	loss_test: 249349.4688	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10544.0947	loss_val: 10544.0713	loss_test: 10544.1357	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1268.0767	loss_val: 1268.1359	loss_test: 1268.1702	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7367.3472	loss_val: 7367.4819	loss_test: 7367.6079	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 15335.9453	loss_val: 15335.9648	loss_test: 15335.9531	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14388.7041	loss_val: 14388.7217	loss_test: 14388.7285	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1632.2113	loss_val: 1632.2170	loss_test: 1632.2521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 20	curr_val_accuracy: 0.6937	curr_test_accuracy: 0.6878
best_round: 20	best_val_accuracy: 0.6937	best_test_accuracy: 0.6878
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32644.5664	loss_val: 32644.5430	loss_test: 32644.5234	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 27802.1953	loss_val: 27802.2148	loss_test: 27802.2832	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 61040.1406	loss_val: 61040.2891	loss_test: 61040.2617	accuracy_train: 0.7952	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 15876.0908	loss_val: 15876.0586	loss_test: 15876.1230	accuracy_train: 0.4528	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6319.9561	loss_val: 6320.0874	loss_test: 6320.0039	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5619.9995	loss_val: 5620.0264	loss_test: 5620.0532	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51950.0742	loss_val: 51950.0469	loss_test: 51950.0430	accuracy_train: 0.4471	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 27916.5254	loss_val: 27916.5137	loss_test: 27916.5195	accuracy_train: 0.5845	accuracy_val: 0.6111	accuracy_test: 0.4865
[client 8]	loss_train: 1514.5835	loss_val: 1514.6487	loss_test: 1514.6238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47809.8633	loss_val: 47810.0508	loss_test: 47809.8555	accuracy_train: 0.8462	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 10095.4404	loss_val: 10095.3848	loss_test: 10095.4414	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3207.7075	loss_val: 3207.7529	loss_test: 3207.6826	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 27723.1094	loss_val: 27723.1914	loss_test: 27723.2109	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 251139.0000	loss_val: 251139.0625	loss_test: 251139.1250	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10782.1494	loss_val: 10782.1260	loss_test: 10782.1934	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1292.5579	loss_val: 1292.6149	loss_test: 1292.6520	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7503.7803	loss_val: 7503.9258	loss_test: 7504.0620	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 15306.3662	loss_val: 15306.3926	loss_test: 15306.3857	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14705.3340	loss_val: 14705.3535	loss_test: 14705.3652	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1603.6294	loss_val: 1603.6346	loss_test: 1603.6671	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 21	curr_val_accuracy: 0.6975	curr_test_accuracy: 0.6859
best_round: 21	best_val_accuracy: 0.6975	best_test_accuracy: 0.6859
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33390.2031	loss_val: 33390.1797	loss_test: 33390.1641	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 25927.3164	loss_val: 25927.3379	loss_test: 25927.4102	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 61406.6523	loss_val: 61406.8125	loss_test: 61406.7852	accuracy_train: 0.8072	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 15872.0225	loss_val: 15871.9912	loss_test: 15872.0576	accuracy_train: 0.4371	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6236.2017	loss_val: 6236.3394	loss_test: 6236.2549	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5458.4053	loss_val: 5458.4351	loss_test: 5458.4619	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 52210.6094	loss_val: 52210.5820	loss_test: 52210.5742	accuracy_train: 0.4588	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 28151.5977	loss_val: 28151.5879	loss_test: 28151.5918	accuracy_train: 0.5810	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1501.1461	loss_val: 1501.2084	loss_test: 1501.1858	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47603.9688	loss_val: 47604.1875	loss_test: 47603.9648	accuracy_train: 0.8462	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 10107.8447	loss_val: 10107.7900	loss_test: 10107.8447	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3325.7249	loss_val: 3325.7705	loss_test: 3325.7014	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 28541.1641	loss_val: 28541.2500	loss_test: 28541.2734	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 255864.5469	loss_val: 255864.6094	loss_test: 255864.6719	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10964.4678	loss_val: 10964.4414	loss_test: 10964.5146	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1304.7488	loss_val: 1304.8041	loss_test: 1304.8428	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7551.1279	loss_val: 7551.2852	loss_test: 7551.4341	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 15405.1201	loss_val: 15405.1523	loss_test: 15405.1553	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14949.6123	loss_val: 14949.6348	loss_test: 14949.6475	accuracy_train: 0.4191	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1592.3562	loss_val: 1592.3616	loss_test: 1592.3920	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 22	curr_val_accuracy: 0.7015	curr_test_accuracy: 0.6878
best_round: 22	best_val_accuracy: 0.7015	best_test_accuracy: 0.6878
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33686.7227	loss_val: 33686.7070	loss_test: 33686.6875	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 26953.7383	loss_val: 26953.7617	loss_test: 26953.8340	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 61279.1719	loss_val: 61279.3438	loss_test: 61279.3164	accuracy_train: 0.8193	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 15495.3994	loss_val: 15495.3711	loss_test: 15495.4365	accuracy_train: 0.4308	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6130.3647	loss_val: 6130.5059	loss_test: 6130.4233	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5420.3691	loss_val: 5420.4033	loss_test: 5420.4253	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51689.6641	loss_val: 51689.6445	loss_test: 51689.6289	accuracy_train: 0.4588	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 26758.9824	loss_val: 26758.9805	loss_test: 26758.9746	accuracy_train: 0.5880	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1491.7328	loss_val: 1491.7917	loss_test: 1491.7722	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48291.1055	loss_val: 48291.3594	loss_test: 48291.1094	accuracy_train: 0.8462	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 10163.3252	loss_val: 10163.2695	loss_test: 10163.3242	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3439.8455	loss_val: 3439.8904	loss_test: 3439.8237	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 28254.7031	loss_val: 28254.7930	loss_test: 28254.8203	accuracy_train: 0.6949	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 255285.9844	loss_val: 255286.0469	loss_test: 255286.1094	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11252.4062	loss_val: 11252.3789	loss_test: 11252.4541	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1315.8977	loss_val: 1315.9520	loss_test: 1315.9918	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7654.9292	loss_val: 7655.0996	loss_test: 7655.2578	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 15738.2246	loss_val: 15738.2607	loss_test: 15738.2734	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14733.7412	loss_val: 14733.7686	loss_test: 14733.7832	accuracy_train: 0.4338	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1568.0961	loss_val: 1568.1011	loss_test: 1568.1300	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 23	curr_val_accuracy: 0.7053	curr_test_accuracy: 0.6859
best_round: 23	best_val_accuracy: 0.7053	best_test_accuracy: 0.6859
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33916.3984	loss_val: 33916.3828	loss_test: 33916.3633	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 28326.4668	loss_val: 28326.4883	loss_test: 28326.5684	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 61482.4023	loss_val: 61482.5859	loss_test: 61482.5586	accuracy_train: 0.8313	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 15131.7480	loss_val: 15131.7217	loss_test: 15131.7852	accuracy_train: 0.4308	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 6067.6191	loss_val: 6067.7637	loss_test: 6067.6860	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5499.2383	loss_val: 5499.2793	loss_test: 5499.2935	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50511.7109	loss_val: 50511.6914	loss_test: 50511.6719	accuracy_train: 0.4647	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 26314.2090	loss_val: 26314.2129	loss_test: 26314.1953	accuracy_train: 0.5845	accuracy_val: 0.6111	accuracy_test: 0.5135
[client 8]	loss_train: 1485.2721	loss_val: 1485.3275	loss_test: 1485.3104	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48829.5664	loss_val: 48829.8672	loss_test: 48829.5781	accuracy_train: 0.8846	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 10350.3076	loss_val: 10350.2520	loss_test: 10350.3066	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3507.6028	loss_val: 3507.6467	loss_test: 3507.5840	accuracy_train: 0.6118	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 27819.7051	loss_val: 27819.7988	loss_test: 27819.8262	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 249771.9375	loss_val: 249771.9688	loss_test: 249772.0312	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11375.6689	loss_val: 11375.6406	loss_test: 11375.7188	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1335.1129	loss_val: 1335.1652	loss_test: 1335.2072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7814.4312	loss_val: 7814.6167	loss_test: 7814.7847	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 16106.1523	loss_val: 16106.1895	loss_test: 16106.2119	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14435.9502	loss_val: 14435.9824	loss_test: 14435.9990	accuracy_train: 0.4338	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1543.6682	loss_val: 1543.6732	loss_test: 1543.7009	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 24	curr_val_accuracy: 0.7053	curr_test_accuracy: 0.6841
best_round: 24	best_val_accuracy: 0.7053	best_test_accuracy: 0.6841
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34205.6055	loss_val: 34205.5938	loss_test: 34205.5742	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 28322.8809	loss_val: 28322.9004	loss_test: 28322.9883	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 60768.9102	loss_val: 60769.1016	loss_test: 60769.0781	accuracy_train: 0.8313	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 14855.7422	loss_val: 14855.7168	loss_test: 14855.7754	accuracy_train: 0.4403	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 6034.2324	loss_val: 6034.3818	loss_test: 6034.3086	accuracy_train: 0.6353	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5574.0830	loss_val: 5574.1294	loss_test: 5574.1421	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49744.8242	loss_val: 49744.8047	loss_test: 49744.7773	accuracy_train: 0.4706	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 26671.2383	loss_val: 26671.2520	loss_test: 26671.2246	accuracy_train: 0.5845	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1472.3743	loss_val: 1472.4266	loss_test: 1472.4111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49264.9375	loss_val: 49265.2891	loss_test: 49264.9492	accuracy_train: 0.8846	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 10341.4219	loss_val: 10341.3652	loss_test: 10341.4209	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3569.5396	loss_val: 3569.5820	loss_test: 3569.5239	accuracy_train: 0.6118	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 26968.2871	loss_val: 26968.3848	loss_test: 26968.4141	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 240916.2969	loss_val: 240916.2969	loss_test: 240916.3750	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11313.9385	loss_val: 11313.9111	loss_test: 11313.9912	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1352.7087	loss_val: 1352.7589	loss_test: 1352.8036	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8008.1807	loss_val: 8008.3809	loss_test: 8008.5586	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 16500.9844	loss_val: 16501.0176	loss_test: 16501.0469	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14099.7666	loss_val: 14099.8018	loss_test: 14099.8203	accuracy_train: 0.4412	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1540.5505	loss_val: 1540.5562	loss_test: 1540.5820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 25	curr_val_accuracy: 0.7033	curr_test_accuracy: 0.6841
best_round: 24	best_val_accuracy: 0.7053	best_test_accuracy: 0.6841
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34797.4258	loss_val: 34797.4180	loss_test: 34797.4023	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 27115.9941	loss_val: 27116.0117	loss_test: 27116.1055	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 59325.3281	loss_val: 59325.5312	loss_test: 59325.5078	accuracy_train: 0.8434	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 15148.7568	loss_val: 15148.7324	loss_test: 15148.7871	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6043.0278	loss_val: 6043.1821	loss_test: 6043.1138	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 5603.9766	loss_val: 5604.0244	loss_test: 5604.0459	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48890.1797	loss_val: 48890.1641	loss_test: 48890.1328	accuracy_train: 0.4882	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 27400.7852	loss_val: 27400.8086	loss_test: 27400.7734	accuracy_train: 0.5915	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1465.6813	loss_val: 1465.7319	loss_test: 1465.7173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48651.2773	loss_val: 48651.6875	loss_test: 48651.2969	accuracy_train: 0.9231	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 10196.5078	loss_val: 10196.4512	loss_test: 10196.5059	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3687.0410	loss_val: 3687.0820	loss_test: 3687.0288	accuracy_train: 0.6118	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 27436.6367	loss_val: 27436.7363	loss_test: 27436.7715	accuracy_train: 0.7203	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 234083.8750	loss_val: 234083.8750	loss_test: 234083.9531	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11373.0430	loss_val: 11373.0156	loss_test: 11373.0986	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1354.4956	loss_val: 1354.5431	loss_test: 1354.5909	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8159.2583	loss_val: 8159.4717	loss_test: 8159.6587	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 16797.9746	loss_val: 16798.0078	loss_test: 16798.0410	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14205.9346	loss_val: 14205.9678	loss_test: 14205.9873	accuracy_train: 0.4449	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1529.9149	loss_val: 1529.9211	loss_test: 1529.9448	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 26	curr_val_accuracy: 0.7052	curr_test_accuracy: 0.6841
best_round: 24	best_val_accuracy: 0.7053	best_test_accuracy: 0.6841
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34417.1758	loss_val: 34417.1719	loss_test: 34417.1562	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 26420.5020	loss_val: 26420.5195	loss_test: 26420.6133	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 58536.9375	loss_val: 58537.1562	loss_test: 58537.1328	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14521.2109	loss_val: 14521.1865	loss_test: 14521.2393	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6073.6826	loss_val: 6073.8379	loss_test: 6073.7817	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 5728.1675	loss_val: 5728.2202	loss_test: 5728.2461	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47926.4492	loss_val: 47926.4453	loss_test: 47926.4141	accuracy_train: 0.4941	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 25605.6250	loss_val: 25605.6602	loss_test: 25605.6152	accuracy_train: 0.5951	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1443.4731	loss_val: 1443.5236	loss_test: 1443.5088	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49237.3672	loss_val: 49237.8438	loss_test: 49237.3945	accuracy_train: 0.9231	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 10013.9863	loss_val: 10013.9297	loss_test: 10013.9834	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3760.3162	loss_val: 3760.3567	loss_test: 3760.3074	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 27399.1875	loss_val: 27399.2891	loss_test: 27399.3320	accuracy_train: 0.7119	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 237201.6719	loss_val: 237201.7188	loss_test: 237201.7969	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11420.8076	loss_val: 11420.7812	loss_test: 11420.8643	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1355.4872	loss_val: 1355.5325	loss_test: 1355.5822	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8223.2051	loss_val: 8223.4297	loss_test: 8223.6221	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 17004.1777	loss_val: 17004.2109	loss_test: 17004.2480	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13477.6416	loss_val: 13477.6787	loss_test: 13477.6943	accuracy_train: 0.4412	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1536.9329	loss_val: 1536.9393	loss_test: 1536.9613	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 27	curr_val_accuracy: 0.7072	curr_test_accuracy: 0.6859
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34532.5117	loss_val: 34532.5117	loss_test: 34532.5039	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23743.0547	loss_val: 23743.0684	loss_test: 23743.1680	accuracy_train: 0.7907	accuracy_val: 0.8438	accuracy_test: 0.7647
[client 2]	loss_train: 57130.7344	loss_val: 57130.9648	loss_test: 57130.9414	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 13626.0654	loss_val: 13626.0410	loss_test: 13626.0947	accuracy_train: 0.4403	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 6200.0205	loss_val: 6200.1768	loss_test: 6200.1299	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 6026.0151	loss_val: 6026.0718	loss_test: 6026.1011	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46921.8516	loss_val: 46921.8477	loss_test: 46921.8164	accuracy_train: 0.5059	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 22700.6895	loss_val: 22700.7285	loss_test: 22700.6797	accuracy_train: 0.5880	accuracy_val: 0.5833	accuracy_test: 0.5135
[client 8]	loss_train: 1404.9886	loss_val: 1405.0388	loss_test: 1405.0231	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50789.5586	loss_val: 50790.1094	loss_test: 50789.5938	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9793.5557	loss_val: 9793.4980	loss_test: 9793.5527	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3806.8318	loss_val: 3806.8723	loss_test: 3806.8257	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 27873.7402	loss_val: 27873.8477	loss_test: 27873.8965	accuracy_train: 0.7373	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 246501.1094	loss_val: 246501.1719	loss_test: 246501.2656	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11444.5586	loss_val: 11444.5352	loss_test: 11444.6152	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1350.3553	loss_val: 1350.3988	loss_test: 1350.4498	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8459.4844	loss_val: 8459.7217	loss_test: 8459.9199	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 17158.1309	loss_val: 17158.1641	loss_test: 17158.2012	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13636.1143	loss_val: 13636.1572	loss_test: 13636.1709	accuracy_train: 0.4228	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1549.5912	loss_val: 1549.5979	loss_test: 1549.6193	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 28	curr_val_accuracy: 0.7032	curr_test_accuracy: 0.6841
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34537.8516	loss_val: 34537.8555	loss_test: 34537.8516	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21916.1855	loss_val: 21916.1992	loss_test: 21916.2988	accuracy_train: 0.7752	accuracy_val: 0.8125	accuracy_test: 0.7353
[client 2]	loss_train: 57304.5781	loss_val: 57304.8242	loss_test: 57304.8008	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14113.2705	loss_val: 14113.2441	loss_test: 14113.3018	accuracy_train: 0.4371	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 6172.7788	loss_val: 6172.9331	loss_test: 6172.8965	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 5427.2534	loss_val: 5427.3066	loss_test: 5427.3467	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45760.3242	loss_val: 45760.3242	loss_test: 45760.2930	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 21040.4316	loss_val: 21040.4707	loss_test: 21040.4219	accuracy_train: 0.5845	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1391.8828	loss_val: 1391.9310	loss_test: 1391.9138	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52089.6719	loss_val: 52090.3203	loss_test: 52089.7109	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9821.9678	loss_val: 9821.9092	loss_test: 9821.9639	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3865.8586	loss_val: 3865.8984	loss_test: 3865.8538	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 27906.9316	loss_val: 27907.0410	loss_test: 27907.0977	accuracy_train: 0.7373	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 255684.5469	loss_val: 255684.6250	loss_test: 255684.7188	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11415.8242	loss_val: 11415.8018	loss_test: 11415.8809	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1333.1169	loss_val: 1333.1594	loss_test: 1333.2113	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8692.4492	loss_val: 8692.6992	loss_test: 8692.9004	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 17870.2148	loss_val: 17870.2500	loss_test: 17870.2832	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14572.2031	loss_val: 14572.2510	loss_test: 14572.2656	accuracy_train: 0.4154	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1564.2797	loss_val: 1564.2867	loss_test: 1564.3071	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 29	curr_val_accuracy: 0.6953	curr_test_accuracy: 0.6841
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35323.7656	loss_val: 35323.7695	loss_test: 35323.7695	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21336.0996	loss_val: 21336.1133	loss_test: 21336.2148	accuracy_train: 0.7752	accuracy_val: 0.8125	accuracy_test: 0.7353
[client 2]	loss_train: 56834.8398	loss_val: 56835.1016	loss_test: 56835.0742	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14456.8926	loss_val: 14456.8662	loss_test: 14456.9248	accuracy_train: 0.4371	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6106.2798	loss_val: 6106.4302	loss_test: 6106.4023	accuracy_train: 0.6471	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 5420.8696	loss_val: 5420.9253	loss_test: 5420.9653	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45014.7227	loss_val: 45014.7188	loss_test: 45014.6875	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 19886.1445	loss_val: 19886.1875	loss_test: 19886.1348	accuracy_train: 0.5775	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1388.0452	loss_val: 1388.0916	loss_test: 1388.0732	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57903.3359	loss_val: 57904.0820	loss_test: 57903.3828	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9539.4746	loss_val: 9539.4150	loss_test: 9539.4697	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3864.9419	loss_val: 3864.9810	loss_test: 3864.9395	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 28114.8516	loss_val: 28114.9648	loss_test: 28115.0312	accuracy_train: 0.7458	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 265229.6250	loss_val: 265229.6875	loss_test: 265229.8125	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11385.0977	loss_val: 11385.0752	loss_test: 11385.1553	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1309.7959	loss_val: 1309.8376	loss_test: 1309.8901	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 8937.9131	loss_val: 8938.1787	loss_test: 8938.3809	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 18446.0488	loss_val: 18446.0840	loss_test: 18446.1152	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15015.8564	loss_val: 15015.9082	loss_test: 15015.9258	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1560.7860	loss_val: 1560.7930	loss_test: 1560.8137	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 30	curr_val_accuracy: 0.6932	curr_test_accuracy: 0.6876
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36925.2812	loss_val: 36925.2930	loss_test: 36925.3047	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21241.1621	loss_val: 21241.1758	loss_test: 21241.2773	accuracy_train: 0.7636	accuracy_val: 0.8125	accuracy_test: 0.7353
[client 2]	loss_train: 56896.5664	loss_val: 56896.8438	loss_test: 56896.8164	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14713.7969	loss_val: 14713.7725	loss_test: 14713.8301	accuracy_train: 0.4371	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6141.1499	loss_val: 6141.2983	loss_test: 6141.2764	accuracy_train: 0.6529	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 5395.3818	loss_val: 5395.4429	loss_test: 5395.4829	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44629.3750	loss_val: 44629.3711	loss_test: 44629.3438	accuracy_train: 0.5294	accuracy_val: 0.4091	accuracy_test: 0.5000
[client 7]	loss_train: 19519.5078	loss_val: 19519.5527	loss_test: 19519.4980	accuracy_train: 0.5704	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1387.9620	loss_val: 1388.0071	loss_test: 1387.9880	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62335.8672	loss_val: 62336.7266	loss_test: 62335.9219	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9122.3672	loss_val: 9122.3086	loss_test: 9122.3623	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3855.0576	loss_val: 3855.0952	loss_test: 3855.0586	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 28180.9004	loss_val: 28181.0195	loss_test: 28181.0977	accuracy_train: 0.7627	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 283981.1250	loss_val: 283981.1875	loss_test: 283981.2812	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11054.0332	loss_val: 11054.0117	loss_test: 11054.0918	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1301.5966	loss_val: 1301.6378	loss_test: 1301.6908	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9241.6582	loss_val: 9241.9443	loss_test: 9242.1465	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 18450.7344	loss_val: 18450.7695	loss_test: 18450.7988	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15065.1064	loss_val: 15065.1621	loss_test: 15065.1885	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1566.0956	loss_val: 1566.1028	loss_test: 1566.1237	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 31	curr_val_accuracy: 0.6952	curr_test_accuracy: 0.6839
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37403.2773	loss_val: 37403.2930	loss_test: 37403.3047	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22966.6543	loss_val: 22966.6680	loss_test: 22966.7695	accuracy_train: 0.7636	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 57944.4023	loss_val: 57944.6992	loss_test: 57944.6758	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14528.1484	loss_val: 14528.1260	loss_test: 14528.1836	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6080.8164	loss_val: 6080.9629	loss_test: 6080.9443	accuracy_train: 0.6529	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 5049.1353	loss_val: 5049.2021	loss_test: 5049.2451	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45066.0312	loss_val: 45066.0352	loss_test: 45066.0039	accuracy_train: 0.5412	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 20094.1602	loss_val: 20094.2090	loss_test: 20094.1523	accuracy_train: 0.5634	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1378.2775	loss_val: 1378.3215	loss_test: 1378.3019	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 65513.5664	loss_val: 65514.5391	loss_test: 65513.6289	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8912.1602	loss_val: 8912.1006	loss_test: 8912.1543	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3907.1550	loss_val: 3907.1919	loss_test: 3907.1587	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 28427.9141	loss_val: 28428.0410	loss_test: 28428.1328	accuracy_train: 0.7627	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 293081.5938	loss_val: 293081.6875	loss_test: 293081.7812	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10861.3242	loss_val: 10861.3027	loss_test: 10861.3818	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1302.2256	loss_val: 1302.2662	loss_test: 1302.3201	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9519.5713	loss_val: 9519.8750	loss_test: 9520.0742	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 18470.6797	loss_val: 18470.7168	loss_test: 18470.7461	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14546.1846	loss_val: 14546.2412	loss_test: 14546.2725	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1570.4056	loss_val: 1570.4127	loss_test: 1570.4335	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 32	curr_val_accuracy: 0.6951	curr_test_accuracy: 0.6839
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37933.9180	loss_val: 37933.9414	loss_test: 37933.9648	accuracy_train: 0.9612	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22878.4375	loss_val: 22878.4531	loss_test: 22878.5527	accuracy_train: 0.7481	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 56829.1484	loss_val: 56829.4570	loss_test: 56829.4375	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14647.2979	loss_val: 14647.2764	loss_test: 14647.3330	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6107.3477	loss_val: 6107.4966	loss_test: 6107.4761	accuracy_train: 0.6647	accuracy_val: 0.4762	accuracy_test: 0.6667
[client 5]	loss_train: 5261.4673	loss_val: 5261.5381	loss_test: 5261.5850	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45832.4648	loss_val: 45832.4727	loss_test: 45832.4375	accuracy_train: 0.5412	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 20651.0586	loss_val: 20651.1113	loss_test: 20651.0508	accuracy_train: 0.5599	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1373.7456	loss_val: 1373.7887	loss_test: 1373.7694	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 69418.8750	loss_val: 69419.9688	loss_test: 69418.9453	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8948.6748	loss_val: 8948.6152	loss_test: 8948.6699	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3952.2759	loss_val: 3952.3140	loss_test: 3952.2815	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 28711.4121	loss_val: 28711.5469	loss_test: 28711.6562	accuracy_train: 0.7712	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 302501.9688	loss_val: 302502.0625	loss_test: 302502.1562	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10955.2188	loss_val: 10955.1953	loss_test: 10955.2754	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1293.6733	loss_val: 1293.7130	loss_test: 1293.7675	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9855.9746	loss_val: 9856.2949	loss_test: 9856.4922	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 18442.6172	loss_val: 18442.6602	loss_test: 18442.6895	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13558.8047	loss_val: 13558.8594	loss_test: 13558.8916	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1545.7150	loss_val: 1545.7213	loss_test: 1545.7419	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 33	curr_val_accuracy: 0.6971	curr_test_accuracy: 0.6857
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37488.2344	loss_val: 37488.2930	loss_test: 37488.3203	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.8571
[client 1]	loss_train: 22513.9609	loss_val: 22513.9746	loss_test: 22514.0742	accuracy_train: 0.7481	accuracy_val: 0.7812	accuracy_test: 0.7353
[client 2]	loss_train: 57244.1016	loss_val: 57244.4258	loss_test: 57244.4219	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14109.4072	loss_val: 14109.3848	loss_test: 14109.4404	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 6045.2246	loss_val: 6045.3765	loss_test: 6045.3530	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 5338.7881	loss_val: 5338.8584	loss_test: 5338.9146	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46873.8750	loss_val: 46873.8945	loss_test: 46873.8516	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 21404.2441	loss_val: 21404.2949	loss_test: 21404.2363	accuracy_train: 0.5423	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1382.5979	loss_val: 1382.6389	loss_test: 1382.6206	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 69781.4297	loss_val: 69782.6641	loss_test: 69781.5000	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8473.3105	loss_val: 8473.2500	loss_test: 8473.3057	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3979.8545	loss_val: 3979.8943	loss_test: 3979.8599	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 29318.7949	loss_val: 29318.9395	loss_test: 29319.0645	accuracy_train: 0.7966	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 311010.8750	loss_val: 311010.9688	loss_test: 311011.0938	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10873.6094	loss_val: 10873.5879	loss_test: 10873.6660	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1279.8400	loss_val: 1279.8790	loss_test: 1279.9331	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10032.5752	loss_val: 10032.9102	loss_test: 10033.1074	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 18313.7227	loss_val: 18313.7656	loss_test: 18313.7949	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13180.6260	loss_val: 13180.6807	loss_test: 13180.7139	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1531.1868	loss_val: 1531.1923	loss_test: 1531.2124	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 34	curr_val_accuracy: 0.6973	curr_test_accuracy: 0.6838
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37224.3242	loss_val: 37224.5195	loss_test: 37224.5547	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.8571
[client 1]	loss_train: 23801.1895	loss_val: 23801.2031	loss_test: 23801.3027	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 58586.3711	loss_val: 58586.7031	loss_test: 58586.7188	accuracy_train: 0.8916	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 13646.5811	loss_val: 13646.5566	loss_test: 13646.6133	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5916.2383	loss_val: 5916.3887	loss_test: 5916.3711	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 5119.8369	loss_val: 5119.8999	loss_test: 5119.9766	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47900.2617	loss_val: 47900.2891	loss_test: 47900.2344	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 21013.1113	loss_val: 21013.1602	loss_test: 21013.1055	accuracy_train: 0.5493	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1378.9558	loss_val: 1378.9934	loss_test: 1378.9774	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 69606.3125	loss_val: 69607.6875	loss_test: 69606.3906	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8352.2109	loss_val: 8352.1494	loss_test: 8352.2061	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3999.4749	loss_val: 3999.5159	loss_test: 3999.4805	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 30125.2559	loss_val: 30125.4102	loss_test: 30125.5488	accuracy_train: 0.7881	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 318006.6562	loss_val: 318006.7500	loss_test: 318006.8750	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10616.3584	loss_val: 10616.3408	loss_test: 10616.4131	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1270.1804	loss_val: 1270.2188	loss_test: 1270.2723	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10021.8057	loss_val: 10022.1523	loss_test: 10022.3545	accuracy_train: 0.9286	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 18086.7070	loss_val: 18086.7520	loss_test: 18086.7812	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13277.5801	loss_val: 13277.6348	loss_test: 13277.6699	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1531.0596	loss_val: 1531.0642	loss_test: 1531.0842	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 35	curr_val_accuracy: 0.6953	curr_test_accuracy: 0.6856
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36809.5352	loss_val: 36809.8906	loss_test: 36809.9375	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.8571
[client 1]	loss_train: 22624.2754	loss_val: 22624.2871	loss_test: 22624.3887	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 59273.7031	loss_val: 59274.0391	loss_test: 59274.0742	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 13303.4297	loss_val: 13303.4043	loss_test: 13303.4629	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5759.1274	loss_val: 5759.2637	loss_test: 5759.2671	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 5202.6489	loss_val: 5202.7134	loss_test: 5202.7979	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48118.7617	loss_val: 48118.8008	loss_test: 48118.7383	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 20139.1250	loss_val: 20139.1758	loss_test: 20139.1250	accuracy_train: 0.5599	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1385.9487	loss_val: 1385.9843	loss_test: 1385.9684	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 70668.5859	loss_val: 70670.1172	loss_test: 70668.6641	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8436.2793	loss_val: 8436.2148	loss_test: 8436.2725	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4041.9006	loss_val: 4041.9431	loss_test: 4041.9067	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 30804.7832	loss_val: 30804.9473	loss_test: 30805.1016	accuracy_train: 0.7881	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 330214.5625	loss_val: 330214.6875	loss_test: 330214.8125	accuracy_train: 0.9286	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10426.9287	loss_val: 10426.9170	loss_test: 10426.9844	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1252.8501	loss_val: 1252.8876	loss_test: 1252.9407	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9941.0918	loss_val: 9941.4473	loss_test: 9941.6572	accuracy_train: 0.9286	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 18078.5000	loss_val: 18078.5449	loss_test: 18078.5801	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13461.4570	loss_val: 13461.5137	loss_test: 13461.5508	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1514.3605	loss_val: 1514.3652	loss_test: 1514.3851	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 36	curr_val_accuracy: 0.6973	curr_test_accuracy: 0.6895
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35779.6172	loss_val: 35779.9961	loss_test: 35780.0469	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.8571
[client 1]	loss_train: 21682.9980	loss_val: 21683.0117	loss_test: 21683.1074	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 61286.5156	loss_val: 61286.8555	loss_test: 61286.9062	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 13358.0967	loss_val: 13358.0732	loss_test: 13358.1309	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5737.8506	loss_val: 5737.9990	loss_test: 5737.9976	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 5634.8359	loss_val: 5634.9077	loss_test: 5634.9863	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48225.6094	loss_val: 48225.6602	loss_test: 48225.5898	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 20163.1621	loss_val: 20163.2168	loss_test: 20163.1680	accuracy_train: 0.5669	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1371.8521	loss_val: 1371.8868	loss_test: 1371.8702	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 70253.9844	loss_val: 70255.6797	loss_test: 70254.0703	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8544.8018	loss_val: 8544.7363	loss_test: 8544.7939	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4084.3716	loss_val: 4084.4155	loss_test: 4084.3787	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 31487.5625	loss_val: 31487.7324	loss_test: 31487.9023	accuracy_train: 0.7966	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 334142.5312	loss_val: 334142.6250	loss_test: 334142.7812	accuracy_train: 0.9286	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10195.3252	loss_val: 10195.3164	loss_test: 10195.3799	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1247.7308	loss_val: 1247.7667	loss_test: 1247.8196	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9875.4482	loss_val: 9875.8105	loss_test: 9876.0273	accuracy_train: 0.9286	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 18383.7988	loss_val: 18383.8477	loss_test: 18383.8867	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13913.4824	loss_val: 13913.5420	loss_test: 13913.5840	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1506.9999	loss_val: 1507.0049	loss_test: 1507.0248	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 37	curr_val_accuracy: 0.6952	curr_test_accuracy: 0.6895
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34848.4727	loss_val: 34848.7227	loss_test: 34848.7852	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.8571
[client 1]	loss_train: 23148.9609	loss_val: 23148.9746	loss_test: 23149.0703	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 66187.7969	loss_val: 66188.1406	loss_test: 66188.2109	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14522.1240	loss_val: 14522.1045	loss_test: 14522.1582	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5647.2129	loss_val: 5647.3672	loss_test: 5647.3623	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.7083
[client 5]	loss_train: 5192.4409	loss_val: 5192.5181	loss_test: 5192.6001	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48304.8477	loss_val: 48304.9062	loss_test: 48304.8359	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 20658.2109	loss_val: 20658.2695	loss_test: 20658.2148	accuracy_train: 0.5634	accuracy_val: 0.5556	accuracy_test: 0.5135
[client 8]	loss_train: 1370.7838	loss_val: 1370.8182	loss_test: 1370.8009	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 68861.0859	loss_val: 68862.9453	loss_test: 68861.1719	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8989.1641	loss_val: 8989.0977	loss_test: 8989.1572	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4070.9219	loss_val: 4070.9673	loss_test: 4070.9316	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 31974.7910	loss_val: 31974.9668	loss_test: 31975.1523	accuracy_train: 0.7881	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 323718.6562	loss_val: 323718.7500	loss_test: 323718.9062	accuracy_train: 0.9235	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10040.3242	loss_val: 10040.3184	loss_test: 10040.3799	accuracy_train: 0.3077	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1246.2451	loss_val: 1246.2795	loss_test: 1246.3323	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9820.3887	loss_val: 9820.7578	loss_test: 9820.9805	accuracy_train: 0.9286	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 18810.2695	loss_val: 18810.3223	loss_test: 18810.3594	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14858.8984	loss_val: 14858.9619	loss_test: 14859.0107	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1502.3447	loss_val: 1502.3494	loss_test: 1502.3695	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 38	curr_val_accuracy: 0.6952	curr_test_accuracy: 0.6895
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34175.1719	loss_val: 34175.2617	loss_test: 34175.3320	accuracy_train: 0.9612	accuracy_val: 0.9286	accuracy_test: 0.8571
[client 1]	loss_train: 23761.1523	loss_val: 23761.1660	loss_test: 23761.2578	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 70183.1797	loss_val: 70183.5469	loss_test: 70183.6094	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 14089.6084	loss_val: 14089.5869	loss_test: 14089.6445	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5576.7617	loss_val: 5576.9175	loss_test: 5576.9077	accuracy_train: 0.6471	accuracy_val: 0.6190	accuracy_test: 0.7083
[client 5]	loss_train: 4977.6299	loss_val: 4977.7129	loss_test: 4977.7959	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48600.2031	loss_val: 48600.2617	loss_test: 48600.1953	accuracy_train: 0.5824	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 20491.9609	loss_val: 20492.0234	loss_test: 20491.9609	accuracy_train: 0.5599	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1368.7820	loss_val: 1368.8159	loss_test: 1368.7976	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 68615.3594	loss_val: 68617.3906	loss_test: 68615.4453	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9287.6211	loss_val: 9287.5518	loss_test: 9287.6172	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4039.7168	loss_val: 4039.7634	loss_test: 4039.7324	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 32340.5273	loss_val: 32340.7070	loss_test: 32340.9102	accuracy_train: 0.7966	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 308897.2188	loss_val: 308897.3125	loss_test: 308897.4688	accuracy_train: 0.9286	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10205.5557	loss_val: 10205.5527	loss_test: 10205.6104	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1250.1968	loss_val: 1250.2299	loss_test: 1250.2820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9715.6465	loss_val: 9716.0273	loss_test: 9716.2549	accuracy_train: 0.9286	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 19165.7109	loss_val: 19165.7676	loss_test: 19165.7988	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15372.7227	loss_val: 15372.7812	loss_test: 15372.8340	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1500.7130	loss_val: 1500.7172	loss_test: 1500.7367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 39	curr_val_accuracy: 0.6973	curr_test_accuracy: 0.6895
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34433.5742	loss_val: 34433.5898	loss_test: 34433.6641	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 24351.2617	loss_val: 24351.2715	loss_test: 24351.3633	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 68915.5469	loss_val: 68915.9219	loss_test: 68916.0000	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 13173.2568	loss_val: 13173.2334	loss_test: 13173.2939	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5631.6021	loss_val: 5631.7559	loss_test: 5631.7417	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.7083
[client 5]	loss_train: 4905.0117	loss_val: 4905.0967	loss_test: 4905.1826	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48566.3398	loss_val: 48566.4023	loss_test: 48566.3359	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 7]	loss_train: 19768.4844	loss_val: 19768.5449	loss_test: 19768.4824	accuracy_train: 0.5669	accuracy_val: 0.5278	accuracy_test: 0.5135
[client 8]	loss_train: 1353.8301	loss_val: 1353.8633	loss_test: 1353.8452	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 68637.3594	loss_val: 68639.6094	loss_test: 68637.4453	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9525.6445	loss_val: 9525.5732	loss_test: 9525.6426	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4031.9551	loss_val: 4032.0017	loss_test: 4031.9802	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 32621.3066	loss_val: 32621.4902	loss_test: 32621.7168	accuracy_train: 0.7797	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 295685.2500	loss_val: 295685.3438	loss_test: 295685.5000	accuracy_train: 0.9286	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10517.1895	loss_val: 10517.1943	loss_test: 10517.2461	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1248.6805	loss_val: 1248.7124	loss_test: 1248.7637	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9643.8516	loss_val: 9644.2432	loss_test: 9644.4736	accuracy_train: 0.9286	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 19938.9238	loss_val: 19938.9805	loss_test: 19939.0117	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15268.6016	loss_val: 15268.6592	loss_test: 15268.7119	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1496.9474	loss_val: 1496.9513	loss_test: 1496.9703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 40	curr_val_accuracy: 0.6992	curr_test_accuracy: 0.6933
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35563.8477	loss_val: 35563.8633	loss_test: 35563.9336	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 26164.2969	loss_val: 26164.3008	loss_test: 26164.3945	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 67009.1641	loss_val: 67009.5625	loss_test: 67009.6406	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 12292.3340	loss_val: 12292.3086	loss_test: 12292.3711	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5670.1733	loss_val: 5670.3188	loss_test: 5670.3115	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.7083
[client 5]	loss_train: 4813.6919	loss_val: 4813.7744	loss_test: 4813.8691	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48921.1367	loss_val: 48921.2070	loss_test: 48921.1328	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 18902.0059	loss_val: 18902.0684	loss_test: 18902.0078	accuracy_train: 0.5704	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1355.7770	loss_val: 1355.8099	loss_test: 1355.7922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 69446.2266	loss_val: 69448.7031	loss_test: 69446.3125	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9344.4482	loss_val: 9344.3740	loss_test: 9344.4453	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3954.1602	loss_val: 3954.2024	loss_test: 3954.1919	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 33374.9023	loss_val: 33375.0859	loss_test: 33375.3320	accuracy_train: 0.8051	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 282264.4062	loss_val: 282264.5312	loss_test: 282264.6875	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11156.6475	loss_val: 11156.6494	loss_test: 11156.7080	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1250.5753	loss_val: 1250.6068	loss_test: 1250.6565	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9474.2520	loss_val: 9474.6504	loss_test: 9474.8799	accuracy_train: 0.9286	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 19530.0605	loss_val: 19530.1211	loss_test: 19530.1484	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14896.0693	loss_val: 14896.1260	loss_test: 14896.1816	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1491.1819	loss_val: 1491.1854	loss_test: 1491.2042	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 41	curr_val_accuracy: 0.6952	curr_test_accuracy: 0.6914
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37112.4453	loss_val: 37112.4609	loss_test: 37112.5352	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 24922.6504	loss_val: 24922.6582	loss_test: 24922.7500	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 65269.6172	loss_val: 65270.0547	loss_test: 65270.1211	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 12204.5361	loss_val: 12204.5078	loss_test: 12204.5713	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5665.9712	loss_val: 5666.1035	loss_test: 5666.1113	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 5026.6865	loss_val: 5026.7661	loss_test: 5026.8652	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49079.1719	loss_val: 49079.2500	loss_test: 49079.1680	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 18741.2207	loss_val: 18741.2832	loss_test: 18741.2266	accuracy_train: 0.5634	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1346.8633	loss_val: 1346.8959	loss_test: 1346.8784	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 69268.8750	loss_val: 69271.5781	loss_test: 69268.9688	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9019.7959	loss_val: 9019.7207	loss_test: 9019.7910	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3876.0579	loss_val: 3876.0972	loss_test: 3876.0967	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34247.4375	loss_val: 34247.6250	loss_test: 34247.8867	accuracy_train: 0.7966	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 269350.0312	loss_val: 269350.1250	loss_test: 269350.3125	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11788.9805	loss_val: 11788.9873	loss_test: 11789.0449	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1241.9916	loss_val: 1242.0233	loss_test: 1242.0726	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9457.0498	loss_val: 9457.4561	loss_test: 9457.6797	accuracy_train: 0.9286	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 19413.2012	loss_val: 19413.2598	loss_test: 19413.2891	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14304.8408	loss_val: 14304.8975	loss_test: 14304.9580	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1480.7302	loss_val: 1480.7335	loss_test: 1480.7522	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 42	curr_val_accuracy: 0.6912	curr_test_accuracy: 0.6896
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38003.1094	loss_val: 38003.1250	loss_test: 38003.1992	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22124.0957	loss_val: 22124.1035	loss_test: 22124.1973	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 64047.1719	loss_val: 64047.6445	loss_test: 64047.6992	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 12440.9902	loss_val: 12440.9619	loss_test: 12441.0254	accuracy_train: 0.4403	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5620.8369	loss_val: 5620.9375	loss_test: 5620.9790	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5203.7734	loss_val: 5203.8481	loss_test: 5203.9502	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48804.1719	loss_val: 48804.2578	loss_test: 48804.1680	accuracy_train: 0.5941	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 19104.1973	loss_val: 19104.2637	loss_test: 19104.2031	accuracy_train: 0.5563	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1322.1934	loss_val: 1322.2258	loss_test: 1322.2095	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 68617.3203	loss_val: 68620.2344	loss_test: 68617.4141	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8800.3604	loss_val: 8800.2832	loss_test: 8800.3506	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3872.3086	loss_val: 3872.3477	loss_test: 3872.3569	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34901.2148	loss_val: 34901.4102	loss_test: 34901.6836	accuracy_train: 0.7966	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 257550.1094	loss_val: 257550.2031	loss_test: 257550.4062	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 12198.9521	loss_val: 12198.9678	loss_test: 12199.0186	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1234.5360	loss_val: 1234.5681	loss_test: 1234.6169	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9454.9990	loss_val: 9455.4141	loss_test: 9455.6309	accuracy_train: 0.9286	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 19498.7793	loss_val: 19498.8359	loss_test: 19498.8711	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13905.8838	loss_val: 13905.9375	loss_test: 13906.0020	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1478.5048	loss_val: 1478.5079	loss_test: 1478.5266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 43	curr_val_accuracy: 0.6873	curr_test_accuracy: 0.6915
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38438.3203	loss_val: 38438.3359	loss_test: 38438.4180	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21760.2383	loss_val: 21760.2480	loss_test: 21760.3379	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 63482.4727	loss_val: 63482.9805	loss_test: 63483.0156	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 12645.4629	loss_val: 12645.4355	loss_test: 12645.4961	accuracy_train: 0.4245	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5616.5972	loss_val: 5616.7075	loss_test: 5616.7354	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5101.8730	loss_val: 5101.9458	loss_test: 5102.0527	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48303.0859	loss_val: 48303.1797	loss_test: 48303.0859	accuracy_train: 0.5882	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 19328.9922	loss_val: 19329.0605	loss_test: 19329.0000	accuracy_train: 0.5634	accuracy_val: 0.4722	accuracy_test: 0.5405
[client 8]	loss_train: 1319.2200	loss_val: 1319.2516	loss_test: 1319.2372	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 65769.4922	loss_val: 65772.6016	loss_test: 65769.5938	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8738.5781	loss_val: 8738.5010	loss_test: 8738.5654	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3873.2056	loss_val: 3873.2444	loss_test: 3873.2625	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34995.7188	loss_val: 34995.9219	loss_test: 34996.2070	accuracy_train: 0.8051	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 257765.7656	loss_val: 257765.8594	loss_test: 257766.0781	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 12207.2100	loss_val: 12207.2354	loss_test: 12207.2773	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1233.1412	loss_val: 1233.1743	loss_test: 1233.2223	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9513.5557	loss_val: 9513.9805	loss_test: 9514.1885	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19554.7109	loss_val: 19554.7695	loss_test: 19554.8125	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13340.7666	loss_val: 13340.8174	loss_test: 13340.8848	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1467.9379	loss_val: 1467.9410	loss_test: 1467.9601	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 44	curr_val_accuracy: 0.6910	curr_test_accuracy: 0.6915
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38526.1367	loss_val: 38526.1523	loss_test: 38526.2383	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22602.8242	loss_val: 22602.8379	loss_test: 22602.9238	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 61634.0234	loss_val: 61634.5781	loss_test: 61634.5781	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 12992.9229	loss_val: 12992.8994	loss_test: 12992.9541	accuracy_train: 0.4245	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5673.0742	loss_val: 5673.1851	loss_test: 5673.2021	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5608.4604	loss_val: 5608.5327	loss_test: 5608.6450	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48068.9688	loss_val: 48069.0703	loss_test: 48068.9727	accuracy_train: 0.5882	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 19073.7324	loss_val: 19073.8066	loss_test: 19073.7402	accuracy_train: 0.5739	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1322.2032	loss_val: 1322.2339	loss_test: 1322.2208	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61285.5703	loss_val: 61288.8242	loss_test: 61285.6641	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8983.2031	loss_val: 8983.1240	loss_test: 8983.1924	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3927.8152	loss_val: 3927.8530	loss_test: 3927.8735	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34957.7500	loss_val: 34957.9609	loss_test: 34958.2500	accuracy_train: 0.8051	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 266280.3750	loss_val: 266280.4688	loss_test: 266280.6875	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11909.1084	loss_val: 11909.1455	loss_test: 11909.1758	accuracy_train: 0.3287	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1231.7996	loss_val: 1231.8330	loss_test: 1231.8802	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9607.2510	loss_val: 9607.6836	loss_test: 9607.8848	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19671.4863	loss_val: 19671.5469	loss_test: 19671.6016	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13106.0010	loss_val: 13106.0518	loss_test: 13106.1172	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1466.4810	loss_val: 1466.4841	loss_test: 1466.5031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 45	curr_val_accuracy: 0.6930	curr_test_accuracy: 0.6897
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38356.6172	loss_val: 38356.6328	loss_test: 38356.7227	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22422.3965	loss_val: 22422.4121	loss_test: 22422.4922	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 61182.1445	loss_val: 61182.7266	loss_test: 61182.7070	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 13088.9824	loss_val: 13088.9639	loss_test: 13089.0107	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5526.8379	loss_val: 5526.9609	loss_test: 5526.9556	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5374.3804	loss_val: 5374.4556	loss_test: 5374.5679	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48125.6758	loss_val: 48125.7852	loss_test: 48125.6836	accuracy_train: 0.5882	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 17740.3633	loss_val: 17740.4473	loss_test: 17740.3711	accuracy_train: 0.5775	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1317.9908	loss_val: 1318.0209	loss_test: 1318.0082	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60950.5391	loss_val: 60953.9844	loss_test: 60950.6289	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9107.4102	loss_val: 9107.3291	loss_test: 9107.4053	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3917.8821	loss_val: 3917.9211	loss_test: 3917.9387	accuracy_train: 0.6235	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34772.7500	loss_val: 34772.9727	loss_test: 34773.2617	accuracy_train: 0.7966	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 274692.9688	loss_val: 274693.0625	loss_test: 274693.2812	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11676.7852	loss_val: 11676.8340	loss_test: 11676.8516	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1228.9546	loss_val: 1228.9884	loss_test: 1229.0341	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9706.2441	loss_val: 9706.6865	loss_test: 9706.8828	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19789.6230	loss_val: 19789.6836	loss_test: 19789.7480	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13741.5566	loss_val: 13741.6084	loss_test: 13741.6689	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1450.8474	loss_val: 1450.8507	loss_test: 1450.8687	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 46	curr_val_accuracy: 0.6930	curr_test_accuracy: 0.6897
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38531.7852	loss_val: 38531.8008	loss_test: 38531.8984	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22197.5684	loss_val: 22197.5918	loss_test: 22197.6641	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 64481.4180	loss_val: 64482.0156	loss_test: 64481.9883	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 12337.0352	loss_val: 12337.0186	loss_test: 12337.0625	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5533.7256	loss_val: 5533.8564	loss_test: 5533.8423	accuracy_train: 0.6294	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 5272.3545	loss_val: 5272.4346	loss_test: 5272.5469	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48439.8008	loss_val: 48439.9102	loss_test: 48439.8086	accuracy_train: 0.5941	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 16811.2773	loss_val: 16811.3672	loss_test: 16811.2832	accuracy_train: 0.5810	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1317.0222	loss_val: 1317.0520	loss_test: 1317.0392	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59465.2461	loss_val: 59468.8984	loss_test: 59465.3359	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9008.5586	loss_val: 9008.4756	loss_test: 9008.5576	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3938.8865	loss_val: 3938.9270	loss_test: 3938.9429	accuracy_train: 0.6235	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35312.8047	loss_val: 35313.0391	loss_test: 35313.3359	accuracy_train: 0.7966	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 275045.5625	loss_val: 275045.6875	loss_test: 275045.9062	accuracy_train: 0.9337	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11489.4463	loss_val: 11489.5098	loss_test: 11489.5137	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1231.1268	loss_val: 1231.1593	loss_test: 1231.2048	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9849.8174	loss_val: 9850.2686	loss_test: 9850.4580	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20375.9199	loss_val: 20375.9805	loss_test: 20376.0488	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13873.7256	loss_val: 13873.7773	loss_test: 13873.8320	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1440.8627	loss_val: 1440.8661	loss_test: 1440.8833	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 47	curr_val_accuracy: 0.6930	curr_test_accuracy: 0.6897
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38724.0625	loss_val: 38724.0781	loss_test: 38724.1719	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21736.8418	loss_val: 21736.8652	loss_test: 21736.9414	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 67663.9453	loss_val: 67664.5625	loss_test: 67664.5312	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11739.6045	loss_val: 11739.5850	loss_test: 11739.6318	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5525.4678	loss_val: 5525.5830	loss_test: 5525.5889	accuracy_train: 0.6294	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 5308.2734	loss_val: 5308.3564	loss_test: 5308.4712	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48769.7344	loss_val: 48769.8516	loss_test: 48769.7422	accuracy_train: 0.5941	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 16725.2832	loss_val: 16725.3750	loss_test: 16725.2832	accuracy_train: 0.5669	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1329.2971	loss_val: 1329.3276	loss_test: 1329.3136	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60361.9570	loss_val: 60365.8203	loss_test: 60362.0430	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8873.1045	loss_val: 8873.0186	loss_test: 8873.1035	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4038.7280	loss_val: 4038.7668	loss_test: 4038.7854	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35744.3008	loss_val: 35744.5508	loss_test: 35744.8516	accuracy_train: 0.7966	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 270040.6562	loss_val: 270040.7812	loss_test: 270041.0000	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11169.3369	loss_val: 11169.4131	loss_test: 11169.4092	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1229.4080	loss_val: 1229.4392	loss_test: 1229.4845	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9923.6045	loss_val: 9924.0635	loss_test: 9924.2451	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20751.6816	loss_val: 20751.7441	loss_test: 20751.8125	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13637.8438	loss_val: 13637.8955	loss_test: 13637.9492	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1437.3976	loss_val: 1437.4015	loss_test: 1437.4177	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 48	curr_val_accuracy: 0.6910	curr_test_accuracy: 0.6916
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39351.5703	loss_val: 39351.5859	loss_test: 39351.6797	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21676.9922	loss_val: 21677.0195	loss_test: 21677.0957	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 70320.0312	loss_val: 70320.6797	loss_test: 70320.6250	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11629.2188	loss_val: 11629.1963	loss_test: 11629.2451	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5600.6821	loss_val: 5600.7803	loss_test: 5600.8076	accuracy_train: 0.6294	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5200.4526	loss_val: 5200.5356	loss_test: 5200.6460	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48348.9258	loss_val: 48349.0469	loss_test: 48348.9258	accuracy_train: 0.5941	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 7]	loss_train: 17945.1191	loss_val: 17945.2168	loss_test: 17945.1191	accuracy_train: 0.5599	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1349.3372	loss_val: 1349.3680	loss_test: 1349.3536	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62294.5547	loss_val: 62298.6602	loss_test: 62294.6445	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8884.3467	loss_val: 8884.2559	loss_test: 8884.3428	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4092.9360	loss_val: 4092.9756	loss_test: 4092.9968	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35623.1367	loss_val: 35623.4023	loss_test: 35623.6992	accuracy_train: 0.8051	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 263051.1250	loss_val: 263051.2188	loss_test: 263051.4375	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10537.4443	loss_val: 10537.5371	loss_test: 10537.5225	accuracy_train: 0.3566	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1232.1901	loss_val: 1232.2202	loss_test: 1232.2649	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9898.5459	loss_val: 9899.0107	loss_test: 9899.1855	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20898.9023	loss_val: 20898.9648	loss_test: 20899.0332	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13198.8418	loss_val: 13198.8945	loss_test: 13198.9502	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1439.5649	loss_val: 1439.5691	loss_test: 1439.5841	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 49	curr_val_accuracy: 0.6910	curr_test_accuracy: 0.6954
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38576.7461	loss_val: 38576.7656	loss_test: 38576.8555	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21791.0918	loss_val: 21791.1172	loss_test: 21791.1973	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 71544.5078	loss_val: 71545.1641	loss_test: 71545.1094	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 12217.4580	loss_val: 12217.4336	loss_test: 12217.4854	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5688.1191	loss_val: 5688.2051	loss_test: 5688.2407	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5247.8438	loss_val: 5247.9263	loss_test: 5248.0312	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47001.9023	loss_val: 47002.0234	loss_test: 47001.8984	accuracy_train: 0.5941	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 7]	loss_train: 18144.2559	loss_val: 18144.3555	loss_test: 18144.2559	accuracy_train: 0.5634	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1352.4125	loss_val: 1352.4440	loss_test: 1352.4288	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63443.9023	loss_val: 63448.2773	loss_test: 63443.9883	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9012.1201	loss_val: 9012.0254	loss_test: 9012.1143	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4052.0198	loss_val: 4052.0627	loss_test: 4052.0852	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36509.3750	loss_val: 36509.6562	loss_test: 36509.9492	accuracy_train: 0.8051	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 251911.2656	loss_val: 251911.3750	loss_test: 251911.6094	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10541.7646	loss_val: 10541.8672	loss_test: 10541.8496	accuracy_train: 0.3566	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1226.8916	loss_val: 1226.9204	loss_test: 1226.9648	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9990.7090	loss_val: 9991.1797	loss_test: 9991.3525	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20776.4941	loss_val: 20776.5566	loss_test: 20776.6289	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12956.3066	loss_val: 12956.3604	loss_test: 12956.4219	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1432.2922	loss_val: 1432.2968	loss_test: 1432.3108	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 50	curr_val_accuracy: 0.6930	curr_test_accuracy: 0.6972
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38041.2617	loss_val: 38041.2773	loss_test: 38041.3555	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22177.8965	loss_val: 22177.9238	loss_test: 22178.0059	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 70695.1562	loss_val: 70695.8281	loss_test: 70695.7734	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 12290.5615	loss_val: 12290.5381	loss_test: 12290.5898	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5681.2002	loss_val: 5681.2896	loss_test: 5681.3198	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4769.6167	loss_val: 4769.6987	loss_test: 4769.8037	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46905.4844	loss_val: 46905.6094	loss_test: 46905.4766	accuracy_train: 0.5941	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 7]	loss_train: 18572.7852	loss_val: 18572.8906	loss_test: 18572.7871	accuracy_train: 0.5599	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1347.4836	loss_val: 1347.5154	loss_test: 1347.5002	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 65307.8320	loss_val: 65312.4805	loss_test: 65307.9180	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9071.4912	loss_val: 9071.3945	loss_test: 9071.4834	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4016.7058	loss_val: 4016.7502	loss_test: 4016.7766	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36875.7109	loss_val: 36876.0117	loss_test: 36876.3047	accuracy_train: 0.8051	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 243300.7031	loss_val: 243300.7969	loss_test: 243301.0469	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 10326.1074	loss_val: 10326.2168	loss_test: 10326.2002	accuracy_train: 0.3706	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1220.4385	loss_val: 1220.4658	loss_test: 1220.5100	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10028.5664	loss_val: 10029.0420	loss_test: 10029.2148	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20758.7930	loss_val: 20758.8516	loss_test: 20758.9316	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12870.1738	loss_val: 12870.2295	loss_test: 12870.2910	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1428.5714	loss_val: 1428.5759	loss_test: 1428.5895	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 51	curr_val_accuracy: 0.6952	curr_test_accuracy: 0.6972
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38045.0547	loss_val: 38045.0703	loss_test: 38045.1445	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23537.8867	loss_val: 23537.9141	loss_test: 23537.9941	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 67566.9219	loss_val: 67567.6016	loss_test: 67567.5391	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11770.5225	loss_val: 11770.5020	loss_test: 11770.5508	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5630.4253	loss_val: 5630.5044	loss_test: 5630.5488	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5251.2993	loss_val: 5251.3843	loss_test: 5251.4829	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47298.7617	loss_val: 47298.8906	loss_test: 47298.7500	accuracy_train: 0.5882	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 7]	loss_train: 18825.2188	loss_val: 18825.3320	loss_test: 18825.2266	accuracy_train: 0.5599	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1341.8839	loss_val: 1341.9141	loss_test: 1341.9004	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64809.3828	loss_val: 64814.2539	loss_test: 64809.4688	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8875.1318	loss_val: 8875.0352	loss_test: 8875.1211	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4007.7437	loss_val: 4007.7856	loss_test: 4007.8203	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 37510.8203	loss_val: 37511.1367	loss_test: 37511.4297	accuracy_train: 0.8051	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 236628.3125	loss_val: 236628.4062	loss_test: 236628.6562	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10083.8760	loss_val: 10083.9883	loss_test: 10083.9717	accuracy_train: 0.3706	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1211.1670	loss_val: 1211.1935	loss_test: 1211.2377	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10039.2441	loss_val: 10039.7256	loss_test: 10039.8965	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20721.4668	loss_val: 20721.5215	loss_test: 20721.6055	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12406.2471	loss_val: 12406.3076	loss_test: 12406.3691	accuracy_train: 0.4412	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1439.0046	loss_val: 1439.0090	loss_test: 1439.0225	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 52	curr_val_accuracy: 0.6932	curr_test_accuracy: 0.6954
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36887.3672	loss_val: 36887.3867	loss_test: 36887.4570	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22790.1230	loss_val: 22790.1445	loss_test: 22790.2266	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 66371.0469	loss_val: 66371.7500	loss_test: 66371.6719	accuracy_train: 0.9157	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11008.2188	loss_val: 11008.2041	loss_test: 11008.2432	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5608.8203	loss_val: 5608.8740	loss_test: 5608.9482	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4564.8374	loss_val: 4564.9224	loss_test: 4565.0186	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49077.3711	loss_val: 49077.5117	loss_test: 49077.3633	accuracy_train: 0.5882	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 7]	loss_train: 18558.3477	loss_val: 18558.4609	loss_test: 18558.3574	accuracy_train: 0.5599	accuracy_val: 0.4722	accuracy_test: 0.5405
[client 8]	loss_train: 1340.8647	loss_val: 1340.8939	loss_test: 1340.8812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63672.6797	loss_val: 63677.7891	loss_test: 63672.7656	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8537.6582	loss_val: 8537.5645	loss_test: 8537.6494	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3998.4873	loss_val: 3998.5261	loss_test: 3998.5737	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36792.0898	loss_val: 36792.4258	loss_test: 36792.7148	accuracy_train: 0.8051	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 236186.7812	loss_val: 236186.8750	loss_test: 236187.1250	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9827.2383	loss_val: 9827.3486	loss_test: 9827.3408	accuracy_train: 0.3566	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1210.6932	loss_val: 1210.7190	loss_test: 1210.7634	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9994.9131	loss_val: 9995.3994	loss_test: 9995.5684	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20715.7910	loss_val: 20715.8438	loss_test: 20715.9355	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12213.2266	loss_val: 12213.2910	loss_test: 12213.3525	accuracy_train: 0.4301	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1433.8060	loss_val: 1433.8102	loss_test: 1433.8237	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 53	curr_val_accuracy: 0.6932	curr_test_accuracy: 0.6954
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36016.8281	loss_val: 36016.8477	loss_test: 36016.9141	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21908.7324	loss_val: 21908.7520	loss_test: 21908.8379	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 66524.6094	loss_val: 66525.3359	loss_test: 66525.2266	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11235.3770	loss_val: 11235.3652	loss_test: 11235.3965	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5682.7324	loss_val: 5682.7666	loss_test: 5682.8706	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4770.7422	loss_val: 4770.8291	loss_test: 4770.9233	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51158.1094	loss_val: 51158.2539	loss_test: 51158.1016	accuracy_train: 0.5765	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 7]	loss_train: 18929.2754	loss_val: 18929.3848	loss_test: 18929.2793	accuracy_train: 0.5669	accuracy_val: 0.4722	accuracy_test: 0.5405
[client 8]	loss_train: 1325.4965	loss_val: 1325.5242	loss_test: 1325.5128	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 65007.0547	loss_val: 65012.3672	loss_test: 65007.1250	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8386.1055	loss_val: 8386.0127	loss_test: 8386.1006	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4078.3806	loss_val: 4078.4160	loss_test: 4078.4773	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35689.1523	loss_val: 35689.5078	loss_test: 35689.7891	accuracy_train: 0.8136	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 232900.0938	loss_val: 232900.1719	loss_test: 232900.4375	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9606.2461	loss_val: 9606.3555	loss_test: 9606.3545	accuracy_train: 0.3427	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1211.2401	loss_val: 1211.2654	loss_test: 1211.3099	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9975.7070	loss_val: 9976.1973	loss_test: 9976.3633	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20542.8320	loss_val: 20542.8848	loss_test: 20542.9824	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12392.9023	loss_val: 12392.9688	loss_test: 12393.0322	accuracy_train: 0.4191	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1415.8518	loss_val: 1415.8555	loss_test: 1415.8696	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 54	curr_val_accuracy: 0.6932	curr_test_accuracy: 0.6954
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35974.7500	loss_val: 35974.7734	loss_test: 35974.8320	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21827.2969	loss_val: 21827.3145	loss_test: 21827.4023	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 68308.5391	loss_val: 68309.2969	loss_test: 68309.1562	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 10864.8662	loss_val: 10864.8555	loss_test: 10864.8828	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5935.3730	loss_val: 5935.4536	loss_test: 5935.5225	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5083.2456	loss_val: 5083.3252	loss_test: 5083.4219	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51795.9922	loss_val: 51796.1289	loss_test: 51795.9805	accuracy_train: 0.5588	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 7]	loss_train: 19408.6445	loss_val: 19408.7539	loss_test: 19408.6504	accuracy_train: 0.5669	accuracy_val: 0.5000	accuracy_test: 0.5135
[client 8]	loss_train: 1309.5723	loss_val: 1309.5992	loss_test: 1309.5881	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63240.9805	loss_val: 63246.5508	loss_test: 63241.0664	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8592.5996	loss_val: 8592.5049	loss_test: 8592.5967	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4094.6975	loss_val: 4094.7322	loss_test: 4094.8027	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35270.4648	loss_val: 35270.8398	loss_test: 35271.1016	accuracy_train: 0.8220	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 237579.3594	loss_val: 237579.4219	loss_test: 237579.7031	accuracy_train: 0.9286	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9700.2148	loss_val: 9700.3262	loss_test: 9700.3262	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1205.5083	loss_val: 1205.5333	loss_test: 1205.5785	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10008.8350	loss_val: 10009.3281	loss_test: 10009.4873	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20514.6426	loss_val: 20514.6934	loss_test: 20514.8066	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12549.9873	loss_val: 12550.0508	loss_test: 12550.1172	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1410.8739	loss_val: 1410.8774	loss_test: 1410.8922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 55	curr_val_accuracy: 0.6950	curr_test_accuracy: 0.6934
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35470.5664	loss_val: 35470.5859	loss_test: 35470.6367	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21725.3047	loss_val: 21725.3223	loss_test: 21725.4062	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 68573.4297	loss_val: 68574.2344	loss_test: 68574.0469	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11205.4512	loss_val: 11205.4365	loss_test: 11205.4678	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5739.8193	loss_val: 5739.9712	loss_test: 5739.9580	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4842.1821	loss_val: 4842.2544	loss_test: 4842.3555	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51399.8398	loss_val: 51399.9727	loss_test: 51399.8359	accuracy_train: 0.5706	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 19432.8164	loss_val: 19432.9258	loss_test: 19432.8242	accuracy_train: 0.5669	accuracy_val: 0.4722	accuracy_test: 0.5405
[client 8]	loss_train: 1290.1301	loss_val: 1290.1566	loss_test: 1290.1454	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60057.8164	loss_val: 60063.6133	loss_test: 60057.8984	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9100.8086	loss_val: 9100.7109	loss_test: 9100.8027	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4078.0579	loss_val: 4078.0952	loss_test: 4078.1667	accuracy_train: 0.6235	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34914.0977	loss_val: 34914.4883	loss_test: 34914.7383	accuracy_train: 0.8305	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 255397.2500	loss_val: 255397.3281	loss_test: 255397.6250	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9638.7295	loss_val: 9638.8389	loss_test: 9638.8467	accuracy_train: 0.3287	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1198.1440	loss_val: 1198.1688	loss_test: 1198.2136	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10089.8330	loss_val: 10090.3291	loss_test: 10090.4844	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20072.7383	loss_val: 20072.7930	loss_test: 20072.9062	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11936.9385	loss_val: 11937.0020	loss_test: 11937.0684	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1413.0487	loss_val: 1413.0520	loss_test: 1413.0673	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 56	curr_val_accuracy: 0.6930	curr_test_accuracy: 0.6951
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34344.2617	loss_val: 34344.2812	loss_test: 34344.3242	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22193.4570	loss_val: 22193.4746	loss_test: 22193.5586	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 67221.0938	loss_val: 67221.9609	loss_test: 67221.7188	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 12214.9805	loss_val: 12214.9619	loss_test: 12214.9961	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5794.1763	loss_val: 5794.3535	loss_test: 5794.3062	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 4927.8208	loss_val: 4927.8989	loss_test: 4928.0044	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51058.1016	loss_val: 51058.2422	loss_test: 51058.1094	accuracy_train: 0.5706	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 18651.4375	loss_val: 18651.5488	loss_test: 18651.4473	accuracy_train: 0.5563	accuracy_val: 0.4444	accuracy_test: 0.5676
[client 8]	loss_train: 1275.3076	loss_val: 1275.3342	loss_test: 1275.3217	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61241.6758	loss_val: 61247.5938	loss_test: 61241.7578	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9126.4971	loss_val: 9126.3984	loss_test: 9126.4893	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4083.3374	loss_val: 4083.3816	loss_test: 4083.4463	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34277.4102	loss_val: 34277.8125	loss_test: 34278.0469	accuracy_train: 0.8220	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 262619.0625	loss_val: 262619.1562	loss_test: 262619.4688	accuracy_train: 0.9235	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 9613.8867	loss_val: 9614.0020	loss_test: 9614.0107	accuracy_train: 0.3287	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1193.6533	loss_val: 1193.6782	loss_test: 1193.7225	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10096.5859	loss_val: 10097.0830	loss_test: 10097.2354	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19920.8047	loss_val: 19920.8613	loss_test: 19920.9707	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11286.0000	loss_val: 11286.0615	loss_test: 11286.1279	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1409.5862	loss_val: 1409.5896	loss_test: 1409.6045	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 57	curr_val_accuracy: 0.6890	curr_test_accuracy: 0.7007
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33495.2109	loss_val: 33495.2344	loss_test: 33495.2578	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23061.6016	loss_val: 23061.6211	loss_test: 23061.7051	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 65356.5469	loss_val: 65357.4648	loss_test: 65357.1797	accuracy_train: 0.9398	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11882.0195	loss_val: 11881.9971	loss_test: 11882.0361	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5824.9941	loss_val: 5825.1802	loss_test: 5825.1265	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 5323.3188	loss_val: 5323.4019	loss_test: 5323.5103	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50813.3047	loss_val: 50813.4648	loss_test: 50813.3242	accuracy_train: 0.5706	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 18001.3789	loss_val: 18001.4902	loss_test: 18001.3965	accuracy_train: 0.5599	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1254.6432	loss_val: 1254.6694	loss_test: 1254.6567	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62674.7656	loss_val: 62680.6953	loss_test: 62674.8477	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9015.5518	loss_val: 9015.4502	loss_test: 9015.5410	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4072.3167	loss_val: 4072.3694	loss_test: 4072.4238	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 34051.0508	loss_val: 34051.4648	loss_test: 34051.6836	accuracy_train: 0.8220	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 267350.5938	loss_val: 267350.7188	loss_test: 267351.0625	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9792.3262	loss_val: 9792.4375	loss_test: 9792.4561	accuracy_train: 0.3287	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1194.8514	loss_val: 1194.8759	loss_test: 1194.9202	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10105.3096	loss_val: 10105.8105	loss_test: 10105.9590	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19943.9277	loss_val: 19943.9844	loss_test: 19944.0918	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 10582.2695	loss_val: 10582.3311	loss_test: 10582.3984	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1407.0848	loss_val: 1407.0884	loss_test: 1407.1025	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 58	curr_val_accuracy: 0.6870	curr_test_accuracy: 0.7008
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32937.7578	loss_val: 32937.7812	loss_test: 32937.7930	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22845.2969	loss_val: 22845.3164	loss_test: 22845.4043	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 63417.2188	loss_val: 63418.1836	loss_test: 63417.8594	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11673.3965	loss_val: 11673.3711	loss_test: 11673.4170	accuracy_train: 0.4340	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5849.9609	loss_val: 5850.1260	loss_test: 5850.0913	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 5]	loss_train: 5234.3667	loss_val: 5234.4502	loss_test: 5234.5576	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50673.4766	loss_val: 50673.6523	loss_test: 50673.5039	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 17942.7148	loss_val: 17942.8223	loss_test: 17942.7383	accuracy_train: 0.5775	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1229.9780	loss_val: 1230.0044	loss_test: 1229.9907	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64093.8242	loss_val: 64099.8125	loss_test: 64093.9062	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 9016.5684	loss_val: 9016.4648	loss_test: 9016.5566	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4083.9409	loss_val: 4084.0012	loss_test: 4084.0381	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 34015.1680	loss_val: 34015.5977	loss_test: 34015.8008	accuracy_train: 0.8220	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 276258.7188	loss_val: 276258.8750	loss_test: 276259.1875	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9927.4062	loss_val: 9927.5107	loss_test: 9927.5352	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1192.9939	loss_val: 1193.0177	loss_test: 1193.0621	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10102.2998	loss_val: 10102.8047	loss_test: 10102.9443	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 19857.7246	loss_val: 19857.7812	loss_test: 19857.8887	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 10204.0225	loss_val: 10204.0840	loss_test: 10204.1543	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1409.1593	loss_val: 1409.1628	loss_test: 1409.1769	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 59	curr_val_accuracy: 0.6891	curr_test_accuracy: 0.7008
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33138.7305	loss_val: 33138.7539	loss_test: 33138.7578	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22886.4121	loss_val: 22886.4336	loss_test: 22886.5273	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 58720.2539	loss_val: 58721.2383	loss_test: 58720.9023	accuracy_train: 0.9277	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11897.2256	loss_val: 11897.1953	loss_test: 11897.2480	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5883.3057	loss_val: 5883.4048	loss_test: 5883.4229	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4702.6865	loss_val: 4702.7720	loss_test: 4702.8813	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50548.3594	loss_val: 50548.5430	loss_test: 50548.3867	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 18697.3926	loss_val: 18697.4902	loss_test: 18697.4199	accuracy_train: 0.5775	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1223.3741	loss_val: 1223.4003	loss_test: 1223.3861	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62556.1211	loss_val: 62562.0156	loss_test: 62556.2070	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 8966.3203	loss_val: 8966.2148	loss_test: 8966.3066	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4148.4922	loss_val: 4148.5566	loss_test: 4148.5864	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 34950.4297	loss_val: 34950.7891	loss_test: 34950.9805	accuracy_train: 0.8220	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 277184.8125	loss_val: 277184.9688	loss_test: 277185.3125	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 10251.5742	loss_val: 10251.6729	loss_test: 10251.6973	accuracy_train: 0.3287	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1188.0870	loss_val: 1188.1104	loss_test: 1188.1545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10060.7949	loss_val: 10061.3027	loss_test: 10061.4336	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20165.1211	loss_val: 20165.1758	loss_test: 20165.2891	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 10017.8867	loss_val: 10017.9482	loss_test: 10018.0264	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1404.4944	loss_val: 1404.4979	loss_test: 1404.5121	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 60	curr_val_accuracy: 0.6891	curr_test_accuracy: 0.6971
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33592.2148	loss_val: 33592.2383	loss_test: 33592.2422	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22843.0762	loss_val: 22843.0938	loss_test: 22843.1953	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 57813.9336	loss_val: 57814.9688	loss_test: 57814.5820	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 12688.0029	loss_val: 12687.9688	loss_test: 12688.0264	accuracy_train: 0.4340	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5982.1523	loss_val: 5982.2329	loss_test: 5982.2671	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4899.8252	loss_val: 4899.9141	loss_test: 4900.0259	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50182.0977	loss_val: 50182.2852	loss_test: 50182.1250	accuracy_train: 0.5706	accuracy_val: 0.5000	accuracy_test: 0.5909
[client 7]	loss_train: 19578.1035	loss_val: 19578.1973	loss_test: 19578.1309	accuracy_train: 0.5810	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1210.3741	loss_val: 1210.4003	loss_test: 1210.3859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61826.4961	loss_val: 61832.4414	loss_test: 61826.5859	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 8848.3291	loss_val: 8848.2227	loss_test: 8848.3154	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4166.4600	loss_val: 4166.5269	loss_test: 4166.5562	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 32357.5684	loss_val: 32358.0215	loss_test: 32358.2031	accuracy_train: 0.8390	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 278394.7500	loss_val: 278394.9062	loss_test: 278395.2500	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 10390.9775	loss_val: 10391.0840	loss_test: 10391.0918	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1181.1376	loss_val: 1181.1599	loss_test: 1181.2037	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10019.9043	loss_val: 10020.4150	loss_test: 10020.5400	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20181.2383	loss_val: 20181.2930	loss_test: 20181.4102	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 10161.5449	loss_val: 10161.6064	loss_test: 10161.6895	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1409.1882	loss_val: 1409.1920	loss_test: 1409.2059	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 61	curr_val_accuracy: 0.6871	curr_test_accuracy: 0.6989
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34144.9102	loss_val: 34144.9336	loss_test: 34144.9336	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21102.0859	loss_val: 21102.0977	loss_test: 21102.2070	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 59947.7695	loss_val: 59948.8828	loss_test: 59948.4180	accuracy_train: 0.9398	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 13694.2236	loss_val: 13694.1865	loss_test: 13694.2490	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5833.9390	loss_val: 5833.9956	loss_test: 5834.0562	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5479.7329	loss_val: 5479.8203	loss_test: 5479.9297	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50065.5586	loss_val: 50065.7500	loss_test: 50065.5820	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 19969.6289	loss_val: 19969.7227	loss_test: 19969.6602	accuracy_train: 0.5704	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1214.4534	loss_val: 1214.4792	loss_test: 1214.4646	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61610.2422	loss_val: 61616.1094	loss_test: 61610.3359	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 8878.4688	loss_val: 8878.3623	loss_test: 8878.4570	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4158.4644	loss_val: 4158.5303	loss_test: 4158.5625	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 37344.7070	loss_val: 37345.1758	loss_test: 37345.3477	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 283525.9375	loss_val: 283526.0938	loss_test: 283526.4688	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 10548.6514	loss_val: 10548.7627	loss_test: 10548.7588	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1176.5654	loss_val: 1176.5870	loss_test: 1176.6315	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10010.2607	loss_val: 10010.7783	loss_test: 10010.8994	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20636.9004	loss_val: 20636.9609	loss_test: 20637.0781	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 10885.9150	loss_val: 10885.9775	loss_test: 10886.0605	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1413.1017	loss_val: 1413.1055	loss_test: 1413.1185	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 62	curr_val_accuracy: 0.6833	curr_test_accuracy: 0.6988
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34740.1523	loss_val: 34740.1797	loss_test: 34740.1797	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20522.9082	loss_val: 20522.9199	loss_test: 20523.0371	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 62308.7812	loss_val: 62309.9648	loss_test: 62309.4414	accuracy_train: 0.9398	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 14294.3076	loss_val: 14294.2686	loss_test: 14294.3330	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5593.6626	loss_val: 5593.7368	loss_test: 5593.7915	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5027.4165	loss_val: 5027.5000	loss_test: 5027.6191	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49737.0391	loss_val: 49737.2383	loss_test: 49737.0625	accuracy_train: 0.5706	accuracy_val: 0.4091	accuracy_test: 0.5909
[client 7]	loss_train: 19082.9746	loss_val: 19083.0703	loss_test: 19083.0059	accuracy_train: 0.5669	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1218.0995	loss_val: 1218.1244	loss_test: 1218.1102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61510.0195	loss_val: 61515.8633	loss_test: 61510.1172	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8858.3809	loss_val: 8858.2744	loss_test: 8858.3701	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4161.9375	loss_val: 4162.0029	loss_test: 4162.0400	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 41343.9609	loss_val: 41344.4297	loss_test: 41344.6055	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 285203.2812	loss_val: 285203.4062	loss_test: 285203.8125	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 10823.6650	loss_val: 10823.7744	loss_test: 10823.7734	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1180.0216	loss_val: 1180.0426	loss_test: 1180.0883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9921.3281	loss_val: 9921.8535	loss_test: 9921.9707	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 21138.1426	loss_val: 21138.2031	loss_test: 21138.3223	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11587.9277	loss_val: 11587.9912	loss_test: 11588.0723	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1398.1517	loss_val: 1398.1554	loss_test: 1398.1677	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 63	curr_val_accuracy: 0.6794	curr_test_accuracy: 0.6988
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34373.4805	loss_val: 34373.5195	loss_test: 34373.5156	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20079.1055	loss_val: 20079.1309	loss_test: 20079.2461	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 62332.9531	loss_val: 62334.2070	loss_test: 62333.6250	accuracy_train: 0.9398	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 14402.9209	loss_val: 14402.8828	loss_test: 14402.9463	accuracy_train: 0.4245	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5523.9302	loss_val: 5524.0493	loss_test: 5524.0752	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5021.4219	loss_val: 5021.5151	loss_test: 5021.6401	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49130.7852	loss_val: 49130.9961	loss_test: 49130.8125	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 18175.8184	loss_val: 18175.9160	loss_test: 18175.8438	accuracy_train: 0.5845	accuracy_val: 0.5000	accuracy_test: 0.5405
[client 8]	loss_train: 1220.1045	loss_val: 1220.1284	loss_test: 1220.1150	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63188.9141	loss_val: 63194.8242	loss_test: 63189.0195	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8871.8203	loss_val: 8871.7148	loss_test: 8871.8125	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4140.0142	loss_val: 4140.0820	loss_test: 4140.1167	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 43232.2188	loss_val: 43232.6992	loss_test: 43232.8867	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 286158.5312	loss_val: 286158.6562	loss_test: 286159.0938	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 11046.4160	loss_val: 11046.5156	loss_test: 11046.5273	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1176.0699	loss_val: 1176.0903	loss_test: 1176.1367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9961.4346	loss_val: 9961.9648	loss_test: 9962.0830	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6250
[client 17]	loss_train: 20579.7578	loss_val: 20579.8223	loss_test: 20579.9492	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12556.3281	loss_val: 12556.3926	loss_test: 12556.4727	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1387.1796	loss_val: 1387.1832	loss_test: 1387.1951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 64	curr_val_accuracy: 0.6854	curr_test_accuracy: 0.6949
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36509.1602	loss_val: 36509.1914	loss_test: 36509.1797	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20489.9082	loss_val: 20489.9434	loss_test: 20490.0547	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 60323.4492	loss_val: 60324.7461	loss_test: 60324.1406	accuracy_train: 0.9518	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 13486.3965	loss_val: 13486.3594	loss_test: 13486.4199	accuracy_train: 0.4214	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5301.1260	loss_val: 5301.2500	loss_test: 5301.2700	accuracy_train: 0.6176	accuracy_val: 0.7143	accuracy_test: 0.6250
[client 5]	loss_train: 5253.2500	loss_val: 5253.3472	loss_test: 5253.4771	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49208.0742	loss_val: 49208.2930	loss_test: 49208.1094	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 17974.1270	loss_val: 17974.2324	loss_test: 17974.1523	accuracy_train: 0.5880	accuracy_val: 0.5000	accuracy_test: 0.5405
[client 8]	loss_train: 1242.9050	loss_val: 1242.9286	loss_test: 1242.9158	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63296.3555	loss_val: 63302.3867	loss_test: 63296.4648	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8896.6855	loss_val: 8896.5801	loss_test: 8896.6787	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4142.2983	loss_val: 4142.3662	loss_test: 4142.3975	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 43142.6172	loss_val: 43143.1094	loss_test: 43143.3125	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 287811.0938	loss_val: 287811.2188	loss_test: 287811.6562	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8077
[client 14]	loss_train: 10871.8525	loss_val: 10871.9473	loss_test: 10871.9609	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1176.1049	loss_val: 1176.1249	loss_test: 1176.1718	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9961.2256	loss_val: 9961.7627	loss_test: 9961.8838	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 20112.8047	loss_val: 20112.8691	loss_test: 20113.0039	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13611.1328	loss_val: 13611.2021	loss_test: 13611.2783	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1375.9680	loss_val: 1375.9716	loss_test: 1375.9833	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 65	curr_val_accuracy: 0.6895	curr_test_accuracy: 0.6912
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34808.4141	loss_val: 34808.4805	loss_test: 34808.4492	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21475.7012	loss_val: 21475.7441	loss_test: 21475.8477	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 59366.6328	loss_val: 59367.9805	loss_test: 59367.3320	accuracy_train: 0.9639	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 12775.0088	loss_val: 12774.9756	loss_test: 12775.0283	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5318.8218	loss_val: 5318.9092	loss_test: 5318.9683	accuracy_train: 0.6176	accuracy_val: 0.7143	accuracy_test: 0.6250
[client 5]	loss_train: 4813.0991	loss_val: 4813.1890	loss_test: 4813.3325	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48248.3672	loss_val: 48248.5820	loss_test: 48248.3984	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 17705.3516	loss_val: 17705.4629	loss_test: 17705.3828	accuracy_train: 0.5669	accuracy_val: 0.5000	accuracy_test: 0.5676
[client 8]	loss_train: 1249.6676	loss_val: 1249.6912	loss_test: 1249.6788	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60390.3906	loss_val: 60396.5312	loss_test: 60390.4961	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9050.3125	loss_val: 9050.2080	loss_test: 9050.3076	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4202.1743	loss_val: 4202.2451	loss_test: 4202.2710	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 43773.3828	loss_val: 43773.8867	loss_test: 43774.1016	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 290287.6250	loss_val: 290287.7500	loss_test: 290288.2188	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8077
[client 14]	loss_train: 10512.1797	loss_val: 10512.2842	loss_test: 10512.2852	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1169.0148	loss_val: 1169.0347	loss_test: 1169.0813	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9904.9512	loss_val: 9905.4961	loss_test: 9905.6221	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 19705.7441	loss_val: 19705.8086	loss_test: 19705.9473	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 13520.8438	loss_val: 13520.9170	loss_test: 13520.9834	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1368.3020	loss_val: 1368.3054	loss_test: 1368.3173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 66	curr_val_accuracy: 0.6875	curr_test_accuracy: 0.6931
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33504.3516	loss_val: 33504.4492	loss_test: 33504.4062	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.8571
[client 1]	loss_train: 21769.8633	loss_val: 21769.9062	loss_test: 21770.0059	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 58868.1992	loss_val: 58869.5977	loss_test: 58868.9141	accuracy_train: 0.9639	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 12228.7646	loss_val: 12228.7324	loss_test: 12228.7803	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5461.7329	loss_val: 5461.8149	loss_test: 5461.8940	accuracy_train: 0.6176	accuracy_val: 0.7143	accuracy_test: 0.5833
[client 5]	loss_train: 5073.9956	loss_val: 5074.0889	loss_test: 5074.2324	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47656.2500	loss_val: 47656.4648	loss_test: 47656.2852	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 17780.9492	loss_val: 17781.0684	loss_test: 17780.9824	accuracy_train: 0.5563	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1259.5846	loss_val: 1259.6078	loss_test: 1259.5958	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61424.5234	loss_val: 61430.8320	loss_test: 61424.6289	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8855.6758	loss_val: 8855.5684	loss_test: 8855.6689	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4217.4541	loss_val: 4217.5278	loss_test: 4217.5508	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 44536.5859	loss_val: 44537.1016	loss_test: 44537.3242	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 289151.9688	loss_val: 289152.1250	loss_test: 289152.5625	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8077
[client 14]	loss_train: 10433.7305	loss_val: 10433.8477	loss_test: 10433.8369	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1166.5344	loss_val: 1166.5544	loss_test: 1166.6001	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9938.7568	loss_val: 9939.3076	loss_test: 9939.4395	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 18742.0840	loss_val: 18742.1465	loss_test: 18742.2812	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12882.5488	loss_val: 12882.6152	loss_test: 12882.6807	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1364.7671	loss_val: 1364.7705	loss_test: 1364.7822	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 67	curr_val_accuracy: 0.6796	curr_test_accuracy: 0.6856
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31931.9707	loss_val: 31932.0957	loss_test: 31932.0391	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22049.8848	loss_val: 22049.9297	loss_test: 22050.0293	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 58708.0625	loss_val: 58709.5078	loss_test: 58708.7891	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 11829.2021	loss_val: 11829.1680	loss_test: 11829.2168	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5608.2876	loss_val: 5608.4409	loss_test: 5608.4580	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5417
[client 5]	loss_train: 4774.8296	loss_val: 4774.9199	loss_test: 4775.0557	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47915.3594	loss_val: 47915.5703	loss_test: 47915.3945	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 18029.8516	loss_val: 18029.9727	loss_test: 18029.8789	accuracy_train: 0.5669	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1252.3975	loss_val: 1252.4200	loss_test: 1252.4092	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59718.3281	loss_val: 59724.8398	loss_test: 59718.4414	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8708.5273	loss_val: 8708.4180	loss_test: 8708.5186	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4225.5674	loss_val: 4225.6426	loss_test: 4225.6680	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 45867.9883	loss_val: 45868.5234	loss_test: 45868.7383	accuracy_train: 0.8390	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 286314.5625	loss_val: 286314.7500	loss_test: 286315.2188	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8077
[client 14]	loss_train: 10480.6084	loss_val: 10480.7334	loss_test: 10480.7217	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1163.9790	loss_val: 1163.9991	loss_test: 1164.0444	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9920.3701	loss_val: 9920.9268	loss_test: 9921.0674	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 19931.8945	loss_val: 19931.9551	loss_test: 19932.0957	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 12302.8379	loss_val: 12302.8965	loss_test: 12302.9668	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1368.5547	loss_val: 1368.5583	loss_test: 1368.5698	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 68	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6837
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31359.9141	loss_val: 31360.0273	loss_test: 31359.9590	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21981.8809	loss_val: 21981.9277	loss_test: 21982.0234	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 58287.9258	loss_val: 58289.4102	loss_test: 58288.6562	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 11432.3330	loss_val: 11432.2979	loss_test: 11432.3486	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5675.5083	loss_val: 5675.6406	loss_test: 5675.6616	accuracy_train: 0.6176	accuracy_val: 0.7143	accuracy_test: 0.6250
[client 5]	loss_train: 4903.2612	loss_val: 4903.3516	loss_test: 4903.4858	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49105.8125	loss_val: 49106.0273	loss_test: 49105.8516	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 18606.1113	loss_val: 18606.2324	loss_test: 18606.1367	accuracy_train: 0.5704	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1253.1953	loss_val: 1253.2173	loss_test: 1253.2073	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60166.9609	loss_val: 60173.6992	loss_test: 60167.0781	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8402.6904	loss_val: 8402.5771	loss_test: 8402.6807	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4226.0698	loss_val: 4226.1445	loss_test: 4226.1802	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 45226.5664	loss_val: 45227.1172	loss_test: 45227.3203	accuracy_train: 0.8390	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 285544.8750	loss_val: 285545.0625	loss_test: 285545.5625	accuracy_train: 0.9184	accuracy_val: 0.8400	accuracy_test: 0.8077
[client 14]	loss_train: 10203.7920	loss_val: 10203.9326	loss_test: 10203.9141	accuracy_train: 0.3427	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1164.9473	loss_val: 1164.9674	loss_test: 1165.0122	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9892.4521	loss_val: 9893.0127	loss_test: 9893.1553	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 20384.9707	loss_val: 20385.0371	loss_test: 20385.1699	accuracy_train: 0.6170	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11842.6309	loss_val: 11842.6865	loss_test: 11842.7627	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1381.8784	loss_val: 1381.8822	loss_test: 1381.8934	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 69	curr_val_accuracy: 0.6876	curr_test_accuracy: 0.6875
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34487.8555	loss_val: 34487.9141	loss_test: 34487.8320	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 21339.9941	loss_val: 21340.0449	loss_test: 21340.1367	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 58525.3203	loss_val: 58526.8477	loss_test: 58526.0508	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 11280.6016	loss_val: 11280.5693	loss_test: 11280.6201	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5787.5820	loss_val: 5787.7188	loss_test: 5787.7358	accuracy_train: 0.6176	accuracy_val: 0.7143	accuracy_test: 0.6250
[client 5]	loss_train: 5051.5635	loss_val: 5051.6489	loss_test: 5051.7876	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49721.5703	loss_val: 49721.7852	loss_test: 49721.6094	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 19373.2969	loss_val: 19373.4160	loss_test: 19373.3223	accuracy_train: 0.5739	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1246.0961	loss_val: 1246.1176	loss_test: 1246.1085	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59682.1797	loss_val: 59689.1289	loss_test: 59682.3008	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8102.6045	loss_val: 8102.4873	loss_test: 8102.5933	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4264.1523	loss_val: 4264.2275	loss_test: 4264.2720	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 44885.4180	loss_val: 44885.9883	loss_test: 44886.1719	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 293069.6875	loss_val: 293069.8438	loss_test: 293070.3750	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8077
[client 14]	loss_train: 10239.0762	loss_val: 10239.2256	loss_test: 10239.2080	accuracy_train: 0.3427	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1154.5021	loss_val: 1154.5221	loss_test: 1154.5662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9797.0391	loss_val: 9797.6045	loss_test: 9797.7451	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 20545.2266	loss_val: 20545.2949	loss_test: 20545.4199	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11529.3936	loss_val: 11529.4502	loss_test: 11529.5283	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1386.3553	loss_val: 1386.3591	loss_test: 1386.3704	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 70	curr_val_accuracy: 0.6876	curr_test_accuracy: 0.6952
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37268.9922	loss_val: 37269.0430	loss_test: 37268.9492	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20813.9414	loss_val: 20813.9961	loss_test: 20814.0859	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 57794.8945	loss_val: 57796.4727	loss_test: 57795.6172	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 11173.6631	loss_val: 11173.6328	loss_test: 11173.6836	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5835.6147	loss_val: 5835.7637	loss_test: 5835.7822	accuracy_train: 0.6235	accuracy_val: 0.7143	accuracy_test: 0.5833
[client 5]	loss_train: 4824.9585	loss_val: 4825.0444	loss_test: 4825.1943	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50448.2773	loss_val: 50448.5000	loss_test: 50448.3203	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 19925.3906	loss_val: 19925.5098	loss_test: 19925.4160	accuracy_train: 0.5810	accuracy_val: 0.4722	accuracy_test: 0.5405
[client 8]	loss_train: 1228.6271	loss_val: 1228.6482	loss_test: 1228.6399	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61803.3945	loss_val: 61810.5508	loss_test: 61803.5195	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 7788.2510	loss_val: 7788.1299	loss_test: 7788.2388	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4231.2397	loss_val: 4231.3149	loss_test: 4231.3662	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 43997.2188	loss_val: 43997.8086	loss_test: 43997.9648	accuracy_train: 0.8559	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 287834.5625	loss_val: 287834.7500	loss_test: 287835.2812	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9764.4805	loss_val: 9764.6377	loss_test: 9764.6211	accuracy_train: 0.3427	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1143.9865	loss_val: 1144.0062	loss_test: 1144.0496	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9796.7861	loss_val: 9797.3555	loss_test: 9797.4941	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 20681.2441	loss_val: 20681.3145	loss_test: 20681.4355	accuracy_train: 0.6312	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11364.8877	loss_val: 11364.9443	loss_test: 11365.0303	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1384.6230	loss_val: 1384.6270	loss_test: 1384.6383	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 71	curr_val_accuracy: 0.6855	curr_test_accuracy: 0.6951
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37827.3477	loss_val: 37827.4023	loss_test: 37827.2969	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20405.7090	loss_val: 20405.7598	loss_test: 20405.8613	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 57029.1016	loss_val: 57030.7109	loss_test: 57029.8203	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 11367.6650	loss_val: 11367.6367	loss_test: 11367.6875	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5893.0049	loss_val: 5893.1455	loss_test: 5893.1851	accuracy_train: 0.6235	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 4858.8838	loss_val: 4858.9780	loss_test: 4859.1279	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50462.2031	loss_val: 50462.4336	loss_test: 50462.2500	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 19877.0801	loss_val: 19877.2070	loss_test: 19877.1016	accuracy_train: 0.5669	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1214.9261	loss_val: 1214.9468	loss_test: 1214.9393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63351.8633	loss_val: 63359.2461	loss_test: 63351.9961	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 7870.6821	loss_val: 7870.5581	loss_test: 7870.6689	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4160.6060	loss_val: 4160.6802	loss_test: 4160.7373	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 42953.2500	loss_val: 42953.8633	loss_test: 42954.0039	accuracy_train: 0.8644	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 278303.4062	loss_val: 278303.5938	loss_test: 278304.1562	accuracy_train: 0.9337	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9566.8721	loss_val: 9567.0381	loss_test: 9567.0205	accuracy_train: 0.3497	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1137.7415	loss_val: 1137.7611	loss_test: 1137.8037	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9805.3848	loss_val: 9805.9590	loss_test: 9806.0957	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 20792.2754	loss_val: 20792.3418	loss_test: 20792.4648	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 10883.8643	loss_val: 10883.9219	loss_test: 10884.0088	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1379.6549	loss_val: 1379.6591	loss_test: 1379.6705	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 72	curr_val_accuracy: 0.6777	curr_test_accuracy: 0.6951
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36685.1094	loss_val: 36685.1758	loss_test: 36685.0586	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20369.6133	loss_val: 20369.6602	loss_test: 20369.7695	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 56273.6641	loss_val: 56275.3008	loss_test: 56274.3867	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 11495.7285	loss_val: 11495.7041	loss_test: 11495.7520	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5881.3398	loss_val: 5881.4072	loss_test: 5881.4761	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.6250
[client 5]	loss_train: 4751.1055	loss_val: 4751.2002	loss_test: 4751.3462	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49795.4492	loss_val: 49795.6992	loss_test: 49795.5039	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 20193.8457	loss_val: 20193.9727	loss_test: 20193.8652	accuracy_train: 0.5634	accuracy_val: 0.4444	accuracy_test: 0.5676
[client 8]	loss_train: 1201.8911	loss_val: 1201.9113	loss_test: 1201.9039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 67424.5391	loss_val: 67431.8594	loss_test: 67424.6719	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 8146.4175	loss_val: 8146.2935	loss_test: 8146.4038	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4110.7749	loss_val: 4110.8506	loss_test: 4110.9092	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 42639.5664	loss_val: 42640.1992	loss_test: 42640.3203	accuracy_train: 0.8644	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 269865.2188	loss_val: 269865.4062	loss_test: 269866.0000	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8462
[client 14]	loss_train: 9500.2959	loss_val: 9500.4648	loss_test: 9500.4502	accuracy_train: 0.3497	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1128.4895	loss_val: 1128.5085	loss_test: 1128.5507	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9753.8711	loss_val: 9754.4502	loss_test: 9754.5840	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 20723.4688	loss_val: 20723.5273	loss_test: 20723.6523	accuracy_train: 0.6028	accuracy_val: 0.5882	accuracy_test: 0.6316
[client 18]	loss_train: 11216.7080	loss_val: 11216.7705	loss_test: 11216.8525	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1383.1340	loss_val: 1383.1384	loss_test: 1383.1498	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 73	curr_val_accuracy: 0.6797	curr_test_accuracy: 0.6988
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34742.3008	loss_val: 34742.3750	loss_test: 34742.2461	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20296.7051	loss_val: 20296.7500	loss_test: 20296.8633	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 55974.8242	loss_val: 55976.4844	loss_test: 55975.5586	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 11826.3584	loss_val: 11826.3359	loss_test: 11826.3818	accuracy_train: 0.4245	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5747.6924	loss_val: 5747.7397	loss_test: 5747.8052	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.6250
[client 5]	loss_train: 4931.0615	loss_val: 4931.1543	loss_test: 4931.2949	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49491.7617	loss_val: 49492.0352	loss_test: 49491.8242	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 18704.3379	loss_val: 18704.4570	loss_test: 18704.3555	accuracy_train: 0.5563	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1175.7489	loss_val: 1175.7686	loss_test: 1175.7612	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64720.7188	loss_val: 64728.2031	loss_test: 64720.8555	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8379.1221	loss_val: 8378.9951	loss_test: 8379.1055	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4084.4170	loss_val: 4084.4905	loss_test: 4084.5562	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 41758.0469	loss_val: 41758.6992	loss_test: 41758.8203	accuracy_train: 0.8814	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 270838.5625	loss_val: 270838.7500	loss_test: 270839.3750	accuracy_train: 0.9286	accuracy_val: 0.8000	accuracy_test: 0.8462
[client 14]	loss_train: 9509.7900	loss_val: 9509.9609	loss_test: 9509.9434	accuracy_train: 0.3497	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1125.7865	loss_val: 1125.8052	loss_test: 1125.8464	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9728.5762	loss_val: 9729.1592	loss_test: 9729.2900	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 20661.3340	loss_val: 20661.3887	loss_test: 20661.5117	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12138.7549	loss_val: 12138.8271	loss_test: 12138.9023	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1375.0249	loss_val: 1375.0293	loss_test: 1375.0405	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 74	curr_val_accuracy: 0.6817	curr_test_accuracy: 0.6934
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32943.3164	loss_val: 32943.3984	loss_test: 32943.2617	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20629.2734	loss_val: 20629.3184	loss_test: 20629.4316	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 56625.5078	loss_val: 56627.1836	loss_test: 56626.2500	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 12191.6123	loss_val: 12191.5859	loss_test: 12191.6348	accuracy_train: 0.4245	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5745.6504	loss_val: 5745.7275	loss_test: 5745.7808	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 5022.0747	loss_val: 5022.1641	loss_test: 5022.2998	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48542.6016	loss_val: 48542.8945	loss_test: 48542.6680	accuracy_train: 0.5529	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 18105.2734	loss_val: 18105.3828	loss_test: 18105.2832	accuracy_train: 0.5634	accuracy_val: 0.5278	accuracy_test: 0.5946
[client 8]	loss_train: 1171.2186	loss_val: 1171.2382	loss_test: 1171.2303	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62762.7930	loss_val: 62770.3789	loss_test: 62762.9375	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8278.6777	loss_val: 8278.5508	loss_test: 8278.6621	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4122.7378	loss_val: 4122.8052	loss_test: 4122.8843	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 41283.0469	loss_val: 41283.7148	loss_test: 41283.8477	accuracy_train: 0.8814	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 271130.7812	loss_val: 271130.9688	loss_test: 271131.6250	accuracy_train: 0.9286	accuracy_val: 0.8000	accuracy_test: 0.8462
[client 14]	loss_train: 9644.0264	loss_val: 9644.1943	loss_test: 9644.1758	accuracy_train: 0.3497	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1120.2424	loss_val: 1120.2606	loss_test: 1120.3014	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9643.1562	loss_val: 9643.7432	loss_test: 9643.8662	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 20713.9883	loss_val: 20714.0430	loss_test: 20714.1680	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12479.4219	loss_val: 12479.4980	loss_test: 12479.5703	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1368.4991	loss_val: 1368.5035	loss_test: 1368.5145	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 75	curr_val_accuracy: 0.6878	curr_test_accuracy: 0.6971
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31564.4023	loss_val: 31564.4902	loss_test: 31564.3496	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 21724.9434	loss_val: 21724.9902	loss_test: 21725.1035	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 56679.7969	loss_val: 56681.4805	loss_test: 56680.5703	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 12376.4766	loss_val: 12376.4561	loss_test: 12376.5000	accuracy_train: 0.4245	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5757.7285	loss_val: 5757.8735	loss_test: 5757.8818	accuracy_train: 0.6235	accuracy_val: 0.6667	accuracy_test: 0.6250
[client 5]	loss_train: 4986.9531	loss_val: 4987.0396	loss_test: 4987.1694	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47639.3828	loss_val: 47639.6992	loss_test: 47639.4570	accuracy_train: 0.5647	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 17344.7539	loss_val: 17344.8652	loss_test: 17344.7656	accuracy_train: 0.5704	accuracy_val: 0.5278	accuracy_test: 0.5946
[client 8]	loss_train: 1175.0436	loss_val: 1175.0631	loss_test: 1175.0548	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59634.2031	loss_val: 59641.9258	loss_test: 59634.3516	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8544.0967	loss_val: 8543.9668	loss_test: 8544.0791	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4166.5889	loss_val: 4166.6509	loss_test: 4166.7349	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 40678.8008	loss_val: 40679.4766	loss_test: 40679.6250	accuracy_train: 0.8898	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 270427.4375	loss_val: 270427.6250	loss_test: 270428.2812	accuracy_train: 0.9337	accuracy_val: 0.8000	accuracy_test: 0.8462
[client 14]	loss_train: 9821.9932	loss_val: 9822.1465	loss_test: 9822.1504	accuracy_train: 0.3566	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1118.6342	loss_val: 1118.6519	loss_test: 1118.6925	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9518.2285	loss_val: 9518.8174	loss_test: 9518.9346	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 21118.0781	loss_val: 21118.1309	loss_test: 21118.2539	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12352.4482	loss_val: 12352.5254	loss_test: 12352.5986	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1354.4924	loss_val: 1354.4968	loss_test: 1354.5074	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 76	curr_val_accuracy: 0.6878	curr_test_accuracy: 0.6953
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32333.8164	loss_val: 32333.9102	loss_test: 32333.7617	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 23992.6836	loss_val: 23992.7324	loss_test: 23992.8320	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 56266.3203	loss_val: 56267.9883	loss_test: 56267.1406	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 12448.3477	loss_val: 12448.3369	loss_test: 12448.3730	accuracy_train: 0.4308	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5810.1455	loss_val: 5810.3735	loss_test: 5810.3042	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5090.1792	loss_val: 5090.2642	loss_test: 5090.3877	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48307.7695	loss_val: 48308.1172	loss_test: 48307.8633	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 16970.3652	loss_val: 16970.4785	loss_test: 16970.3750	accuracy_train: 0.5563	accuracy_val: 0.4722	accuracy_test: 0.5946
[client 8]	loss_train: 1173.5305	loss_val: 1173.5497	loss_test: 1173.5404	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59687.1953	loss_val: 59695.0742	loss_test: 59687.3438	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9308.4824	loss_val: 9308.3525	loss_test: 9308.4658	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4215.7959	loss_val: 4215.8521	loss_test: 4215.9414	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 39787.4453	loss_val: 39788.1289	loss_test: 39788.2930	accuracy_train: 0.8898	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 271315.1562	loss_val: 271315.3438	loss_test: 271316.0000	accuracy_train: 0.9388	accuracy_val: 0.8000	accuracy_test: 0.8462
[client 14]	loss_train: 9844.1514	loss_val: 9844.2803	loss_test: 9844.3145	accuracy_train: 0.3497	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1123.3389	loss_val: 1123.3564	loss_test: 1123.3962	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9337.4121	loss_val: 9338.0029	loss_test: 9338.1191	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 21795.7578	loss_val: 21795.8047	loss_test: 21795.9238	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12036.1309	loss_val: 12036.2119	loss_test: 12036.2822	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1355.4597	loss_val: 1355.4640	loss_test: 1355.4741	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 77	curr_val_accuracy: 0.6777	curr_test_accuracy: 0.6935
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33368.2227	loss_val: 33368.3242	loss_test: 33368.1680	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 24520.8301	loss_val: 24520.8828	loss_test: 24520.9688	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 55799.8867	loss_val: 55801.5547	loss_test: 55800.7422	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 12061.5605	loss_val: 12061.5586	loss_test: 12061.5840	accuracy_train: 0.4308	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5750.4580	loss_val: 5750.6392	loss_test: 5750.6113	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 4827.6011	loss_val: 4827.6855	loss_test: 4827.8052	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48692.3398	loss_val: 48692.7109	loss_test: 48692.4492	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 16935.5859	loss_val: 16935.7012	loss_test: 16935.5977	accuracy_train: 0.5528	accuracy_val: 0.4167	accuracy_test: 0.5676
[client 8]	loss_train: 1172.5247	loss_val: 1172.5437	loss_test: 1172.5337	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60706.0469	loss_val: 60713.9961	loss_test: 60706.2031	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9698.8906	loss_val: 9698.7637	loss_test: 9698.8760	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4266.6865	loss_val: 4266.7373	loss_test: 4266.8306	accuracy_train: 0.6510	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 38583.9883	loss_val: 38584.6797	loss_test: 38584.8672	accuracy_train: 0.8898	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 270751.3125	loss_val: 270751.5000	loss_test: 270752.1250	accuracy_train: 0.9286	accuracy_val: 0.8000	accuracy_test: 0.8462
[client 14]	loss_train: 9723.0049	loss_val: 9723.1152	loss_test: 9723.1572	accuracy_train: 0.3566	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1130.7596	loss_val: 1130.7771	loss_test: 1130.8154	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9167.9756	loss_val: 9168.5674	loss_test: 9168.6865	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 21793.9043	loss_val: 21793.9473	loss_test: 21794.0684	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12034.4756	loss_val: 12034.5615	loss_test: 12034.6279	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1357.7920	loss_val: 1357.7961	loss_test: 1357.8060	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 78	curr_val_accuracy: 0.6760	curr_test_accuracy: 0.6935
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35487.7344	loss_val: 35487.8438	loss_test: 35487.6797	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 26446.9648	loss_val: 26447.0332	loss_test: 26447.1074	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 54924.5391	loss_val: 54926.1992	loss_test: 54925.4219	accuracy_train: 0.9759	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 11462.8740	loss_val: 11462.8779	loss_test: 11462.8955	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5687.8267	loss_val: 5687.9727	loss_test: 5687.9761	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 4802.5137	loss_val: 4802.5977	loss_test: 4802.7192	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49231.0742	loss_val: 49231.4688	loss_test: 49231.1992	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 17584.0098	loss_val: 17584.1289	loss_test: 17584.0312	accuracy_train: 0.5528	accuracy_val: 0.4167	accuracy_test: 0.5676
[client 8]	loss_train: 1180.4585	loss_val: 1180.4779	loss_test: 1180.4673	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60249.7266	loss_val: 60257.8242	loss_test: 60249.8906	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9556.8281	loss_val: 9556.7041	loss_test: 9556.8164	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4250.1294	loss_val: 4250.1777	loss_test: 4250.2690	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 38194.2891	loss_val: 38194.9922	loss_test: 38195.1992	accuracy_train: 0.8898	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 266339.6875	loss_val: 266339.8750	loss_test: 266340.5000	accuracy_train: 0.9082	accuracy_val: 0.8400	accuracy_test: 0.8077
[client 14]	loss_train: 9681.0518	loss_val: 9681.1445	loss_test: 9681.1963	accuracy_train: 0.3566	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1132.1743	loss_val: 1132.1914	loss_test: 1132.2286	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9071.8984	loss_val: 9072.4863	loss_test: 9072.6094	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 21943.8574	loss_val: 21943.9043	loss_test: 21944.0234	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11906.3018	loss_val: 11906.3945	loss_test: 11906.4521	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1366.4413	loss_val: 1366.4454	loss_test: 1366.4548	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 79	curr_val_accuracy: 0.6780	curr_test_accuracy: 0.6897
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38338.5117	loss_val: 38338.6250	loss_test: 38338.4570	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 24327.0391	loss_val: 24327.1172	loss_test: 24327.1855	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 56134.9961	loss_val: 56136.6602	loss_test: 56135.8984	accuracy_train: 0.9759	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 11276.5488	loss_val: 11276.5439	loss_test: 11276.5693	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5611.4575	loss_val: 5611.5894	loss_test: 5611.6108	accuracy_train: 0.6235	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 4899.9897	loss_val: 4900.0757	loss_test: 4900.1953	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48942.0742	loss_val: 48942.4844	loss_test: 48942.2070	accuracy_train: 0.5824	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 18672.6426	loss_val: 18672.7734	loss_test: 18672.6641	accuracy_train: 0.5563	accuracy_val: 0.4167	accuracy_test: 0.5676
[client 8]	loss_train: 1200.6385	loss_val: 1200.6584	loss_test: 1200.6473	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60428.5820	loss_val: 60436.8008	loss_test: 60428.7500	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9502.0439	loss_val: 9501.9258	loss_test: 9502.0332	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4240.3643	loss_val: 4240.4155	loss_test: 4240.4976	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 37422.8398	loss_val: 37423.5586	loss_test: 37423.7891	accuracy_train: 0.8898	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 260034.8438	loss_val: 260035.0469	loss_test: 260035.6719	accuracy_train: 0.9133	accuracy_val: 0.8400	accuracy_test: 0.8077
[client 14]	loss_train: 9410.5918	loss_val: 9410.6719	loss_test: 9410.7363	accuracy_train: 0.3566	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1128.3516	loss_val: 1128.3679	loss_test: 1128.4054	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9088.6533	loss_val: 9089.2402	loss_test: 9089.3672	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 22155.1211	loss_val: 22155.1680	loss_test: 22155.2930	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11942.2188	loss_val: 11942.3076	loss_test: 11942.3594	accuracy_train: 0.4228	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1367.9916	loss_val: 1367.9956	loss_test: 1368.0049	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 80	curr_val_accuracy: 0.6800	curr_test_accuracy: 0.6916
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39383.6797	loss_val: 39383.8008	loss_test: 39383.6289	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 23675.4258	loss_val: 23675.4941	loss_test: 23675.5762	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 57483.0430	loss_val: 57484.7344	loss_test: 57483.9688	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 11050.8662	loss_val: 11050.8525	loss_test: 11050.8848	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5686.4692	loss_val: 5686.6162	loss_test: 5686.6265	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 4783.5557	loss_val: 4783.6475	loss_test: 4783.7612	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48008.0977	loss_val: 48008.5078	loss_test: 48008.2305	accuracy_train: 0.5882	accuracy_val: 0.4545	accuracy_test: 0.5909
[client 7]	loss_train: 19304.9336	loss_val: 19305.0723	loss_test: 19304.9473	accuracy_train: 0.5599	accuracy_val: 0.4167	accuracy_test: 0.5676
[client 8]	loss_train: 1214.3682	loss_val: 1214.3883	loss_test: 1214.3767	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60854.5117	loss_val: 60862.8359	loss_test: 60854.6875	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9402.5771	loss_val: 9402.4609	loss_test: 9402.5664	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4225.0762	loss_val: 4225.1367	loss_test: 4225.2026	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 37147.5156	loss_val: 37148.2461	loss_test: 37148.4961	accuracy_train: 0.8898	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 254814.2969	loss_val: 254814.5000	loss_test: 254815.1406	accuracy_train: 0.9133	accuracy_val: 0.8000	accuracy_test: 0.7692
[client 14]	loss_train: 9090.8008	loss_val: 9090.8838	loss_test: 9090.9570	accuracy_train: 0.3566	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1129.4854	loss_val: 1129.5005	loss_test: 1129.5393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9164.6758	loss_val: 9165.2598	loss_test: 9165.3945	accuracy_train: 0.9464	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 22082.4297	loss_val: 22082.4766	loss_test: 22082.5977	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12259.2109	loss_val: 12259.2998	loss_test: 12259.3467	accuracy_train: 0.4265	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1365.9663	loss_val: 1365.9703	loss_test: 1365.9796	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 81	curr_val_accuracy: 0.6760	curr_test_accuracy: 0.6917
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 41792.7344	loss_val: 41792.8633	loss_test: 41792.6836	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 21995.4141	loss_val: 21995.4805	loss_test: 21995.5820	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 56057.5508	loss_val: 56059.3086	loss_test: 56058.4883	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 10533.4209	loss_val: 10533.4014	loss_test: 10533.4375	accuracy_train: 0.4214	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5756.0454	loss_val: 5756.2109	loss_test: 5756.1987	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4943.7427	loss_val: 4943.8369	loss_test: 4943.9473	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47245.0273	loss_val: 47245.4375	loss_test: 47245.1562	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 18737.4609	loss_val: 18737.5977	loss_test: 18737.4785	accuracy_train: 0.5669	accuracy_val: 0.4167	accuracy_test: 0.5676
[client 8]	loss_train: 1226.8345	loss_val: 1226.8549	loss_test: 1226.8433	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60818.5273	loss_val: 60827.0352	loss_test: 60818.7070	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9331.3613	loss_val: 9331.2480	loss_test: 9331.3516	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4207.1431	loss_val: 4207.2144	loss_test: 4207.2646	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 37217.6289	loss_val: 37218.3789	loss_test: 37218.6406	accuracy_train: 0.9153	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 256616.9375	loss_val: 256617.1406	loss_test: 256617.7969	accuracy_train: 0.8980	accuracy_val: 0.8000	accuracy_test: 0.7692
[client 14]	loss_train: 9111.1250	loss_val: 9111.2246	loss_test: 9111.3008	accuracy_train: 0.3566	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1135.2740	loss_val: 1135.2887	loss_test: 1135.3273	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9296.6172	loss_val: 9297.2041	loss_test: 9297.3428	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22180.7246	loss_val: 22180.7754	loss_test: 22180.8828	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12462.2549	loss_val: 12462.3398	loss_test: 12462.3887	accuracy_train: 0.4375	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1362.1902	loss_val: 1362.1941	loss_test: 1362.2039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 82	curr_val_accuracy: 0.6758	curr_test_accuracy: 0.6915
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 42426.0859	loss_val: 42426.2266	loss_test: 42426.0352	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20783.1387	loss_val: 20783.2012	loss_test: 20783.3184	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 55515.0820	loss_val: 55516.9102	loss_test: 55516.0234	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 10347.3213	loss_val: 10347.2998	loss_test: 10347.3389	accuracy_train: 0.4214	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5852.8096	loss_val: 5852.9790	loss_test: 5852.9604	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4375.3369	loss_val: 4375.4312	loss_test: 4375.5483	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46819.1055	loss_val: 46819.5273	loss_test: 46819.2305	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 18343.1543	loss_val: 18343.2852	loss_test: 18343.1777	accuracy_train: 0.5739	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1226.3761	loss_val: 1226.3964	loss_test: 1226.3853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61224.1758	loss_val: 61232.8750	loss_test: 61224.3555	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 9051.9512	loss_val: 9051.8369	loss_test: 9051.9414	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4222.0493	loss_val: 4222.1338	loss_test: 4222.1719	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 37312.8438	loss_val: 37313.6172	loss_test: 37313.8867	accuracy_train: 0.9237	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 260100.1094	loss_val: 260100.3125	loss_test: 260100.9688	accuracy_train: 0.9082	accuracy_val: 0.8000	accuracy_test: 0.7308
[client 14]	loss_train: 9070.9834	loss_val: 9071.1025	loss_test: 9071.1689	accuracy_train: 0.3636	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1137.2361	loss_val: 1137.2504	loss_test: 1137.2888	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9371.5557	loss_val: 9372.1416	loss_test: 9372.2891	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22252.8105	loss_val: 22252.8633	loss_test: 22252.9668	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12747.2959	loss_val: 12747.3721	loss_test: 12747.4297	accuracy_train: 0.4485	accuracy_val: 0.4118	accuracy_test: 0.4571
[client 19]	loss_train: 1354.1864	loss_val: 1354.1902	loss_test: 1354.2002	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 83	curr_val_accuracy: 0.6778	curr_test_accuracy: 0.6914
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 41371.2930	loss_val: 41371.4414	loss_test: 41371.2461	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 20245.4805	loss_val: 20245.5352	loss_test: 20245.6582	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 55495.2578	loss_val: 55497.1602	loss_test: 55496.1992	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 10725.4473	loss_val: 10725.4199	loss_test: 10725.4688	accuracy_train: 0.4214	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5877.1133	loss_val: 5877.2729	loss_test: 5877.2637	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5017.0659	loss_val: 5017.1616	loss_test: 5017.2881	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46598.9023	loss_val: 46599.3438	loss_test: 46599.0234	accuracy_train: 0.5765	accuracy_val: 0.5000	accuracy_test: 0.5455
[client 7]	loss_train: 17603.5332	loss_val: 17603.6582	loss_test: 17603.5566	accuracy_train: 0.5775	accuracy_val: 0.4722	accuracy_test: 0.5405
[client 8]	loss_train: 1218.5807	loss_val: 1218.6006	loss_test: 1218.5903	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61537.0195	loss_val: 61545.9531	loss_test: 61537.1992	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8943.7998	loss_val: 8943.6816	loss_test: 8943.7900	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4252.5845	loss_val: 4252.6748	loss_test: 4252.7051	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36816.0078	loss_val: 36816.8008	loss_test: 36817.0664	accuracy_train: 0.9322	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 261546.5000	loss_val: 261546.7031	loss_test: 261547.3750	accuracy_train: 0.9031	accuracy_val: 0.7600	accuracy_test: 0.7308
[client 14]	loss_train: 9306.9863	loss_val: 9307.1240	loss_test: 9307.1729	accuracy_train: 0.3706	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1140.3896	loss_val: 1140.4037	loss_test: 1140.4419	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9478.0068	loss_val: 9478.5928	loss_test: 9478.7510	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22468.7832	loss_val: 22468.8320	loss_test: 22468.9336	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12715.2852	loss_val: 12715.3574	loss_test: 12715.4258	accuracy_train: 0.4375	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1342.4720	loss_val: 1342.4757	loss_test: 1342.4863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 84	curr_val_accuracy: 0.6836	curr_test_accuracy: 0.6894
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38885.2578	loss_val: 38885.4180	loss_test: 38885.2109	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 17963.3594	loss_val: 17963.4199	loss_test: 17963.5371	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 60821.1523	loss_val: 60823.0664	loss_test: 60822.1055	accuracy_train: 0.9880	accuracy_val: 0.5455	accuracy_test: 0.6364
[client 3]	loss_train: 10841.6357	loss_val: 10841.6074	loss_test: 10841.6572	accuracy_train: 0.4277	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5845.5342	loss_val: 5845.6851	loss_test: 5845.6904	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4881.7832	loss_val: 4881.8804	loss_test: 4882.0156	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45998.3945	loss_val: 45998.8398	loss_test: 45998.5156	accuracy_train: 0.5765	accuracy_val: 0.5000	accuracy_test: 0.5455
[client 7]	loss_train: 17029.7480	loss_val: 17029.8828	loss_test: 17029.7656	accuracy_train: 0.5775	accuracy_val: 0.4722	accuracy_test: 0.5405
[client 8]	loss_train: 1210.9351	loss_val: 1210.9546	loss_test: 1210.9449	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61523.9844	loss_val: 61533.1172	loss_test: 61524.1602	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8726.3799	loss_val: 8726.2598	loss_test: 8726.3750	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4245.7871	loss_val: 4245.8794	loss_test: 4245.9097	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36090.1406	loss_val: 36090.9570	loss_test: 36091.2266	accuracy_train: 0.9322	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 257500.9688	loss_val: 257501.1719	loss_test: 257501.8594	accuracy_train: 0.8980	accuracy_val: 0.7600	accuracy_test: 0.7692
[client 14]	loss_train: 9575.5859	loss_val: 9575.7461	loss_test: 9575.7812	accuracy_train: 0.3776	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1143.9110	loss_val: 1143.9248	loss_test: 1143.9626	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9606.8857	loss_val: 9607.4697	loss_test: 9607.6338	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 23944.3496	loss_val: 23944.3945	loss_test: 23944.4961	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12858.0254	loss_val: 12858.0938	loss_test: 12858.1650	accuracy_train: 0.4265	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1330.3143	loss_val: 1330.3177	loss_test: 1330.3291	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 85	curr_val_accuracy: 0.6818	curr_test_accuracy: 0.6913
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35645.7031	loss_val: 35645.8711	loss_test: 35645.6602	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 16714.8281	loss_val: 16714.8965	loss_test: 16714.9980	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 65667.9531	loss_val: 65669.8984	loss_test: 65668.9141	accuracy_train: 0.9880	accuracy_val: 0.5455	accuracy_test: 0.6364
[client 3]	loss_train: 11189.2822	loss_val: 11189.2568	loss_test: 11189.3027	accuracy_train: 0.4277	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5816.4219	loss_val: 5816.5698	loss_test: 5816.5874	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4372.4170	loss_val: 4372.5195	loss_test: 4372.6646	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46137.7891	loss_val: 46138.2266	loss_test: 46137.9141	accuracy_train: 0.5765	accuracy_val: 0.5000	accuracy_test: 0.5455
[client 7]	loss_train: 16467.3125	loss_val: 16467.4609	loss_test: 16467.3262	accuracy_train: 0.5669	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1209.6418	loss_val: 1209.6608	loss_test: 1209.6516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61719.4922	loss_val: 61728.8867	loss_test: 61719.6758	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8398.7803	loss_val: 8398.6572	loss_test: 8398.7793	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4224.6978	loss_val: 4224.7920	loss_test: 4224.8179	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.5758
[client 12]	loss_train: 36042.3906	loss_val: 36043.2266	loss_test: 36043.5078	accuracy_train: 0.9322	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 251651.9844	loss_val: 251652.2188	loss_test: 251652.9219	accuracy_train: 0.8929	accuracy_val: 0.7600	accuracy_test: 0.7692
[client 14]	loss_train: 8967.7568	loss_val: 8967.9150	loss_test: 8967.9561	accuracy_train: 0.3706	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1141.8273	loss_val: 1141.8409	loss_test: 1141.8785	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9632.6094	loss_val: 9633.1934	loss_test: 9633.3594	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 24024.6035	loss_val: 24024.6582	loss_test: 24024.7539	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12250.8828	loss_val: 12250.9521	loss_test: 12251.0234	accuracy_train: 0.4228	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1319.4968	loss_val: 1319.5000	loss_test: 1319.5118	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 86	curr_val_accuracy: 0.6778	curr_test_accuracy: 0.6857
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32822.5508	loss_val: 32822.7305	loss_test: 32822.5078	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 16263.4160	loss_val: 16263.4912	loss_test: 16263.5830	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 68979.0156	loss_val: 68980.9844	loss_test: 68979.9844	accuracy_train: 0.9880	accuracy_val: 0.5455	accuracy_test: 0.6364
[client 3]	loss_train: 11208.3584	loss_val: 11208.3340	loss_test: 11208.3818	accuracy_train: 0.4277	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5786.8838	loss_val: 5787.0146	loss_test: 5787.0532	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4418.5181	loss_val: 4418.6299	loss_test: 4418.7749	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47047.6602	loss_val: 47048.0977	loss_test: 47047.7969	accuracy_train: 0.5706	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 7]	loss_train: 16541.0098	loss_val: 16541.1680	loss_test: 16541.0215	accuracy_train: 0.5599	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1219.1570	loss_val: 1219.1760	loss_test: 1219.1666	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59432.1641	loss_val: 59441.9023	loss_test: 59432.3477	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8529.8135	loss_val: 8529.6924	loss_test: 8529.8174	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4207.5786	loss_val: 4207.6714	loss_test: 4207.7007	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34672.7578	loss_val: 34673.6094	loss_test: 34673.8984	accuracy_train: 0.9492	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 244304.3438	loss_val: 244304.5781	loss_test: 244305.2812	accuracy_train: 0.8929	accuracy_val: 0.7600	accuracy_test: 0.7692
[client 14]	loss_train: 8434.2314	loss_val: 8434.3779	loss_test: 8434.4375	accuracy_train: 0.3706	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1136.0055	loss_val: 1136.0192	loss_test: 1136.0566	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9672.5391	loss_val: 9673.1250	loss_test: 9673.2881	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 24507.8652	loss_val: 24507.9336	loss_test: 24508.0254	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11623.2500	loss_val: 11623.3193	loss_test: 11623.3818	accuracy_train: 0.4265	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1316.4681	loss_val: 1316.4712	loss_test: 1316.4829	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 87	curr_val_accuracy: 0.6778	curr_test_accuracy: 0.6876
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31849.3027	loss_val: 31849.4902	loss_test: 31849.2617	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 16271.3037	loss_val: 16271.3799	loss_test: 16271.4668	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 70544.6406	loss_val: 70546.6172	loss_test: 70545.5938	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 11064.6250	loss_val: 11064.5967	loss_test: 11064.6494	accuracy_train: 0.4277	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5599.2935	loss_val: 5599.4390	loss_test: 5599.4546	accuracy_train: 0.6235	accuracy_val: 0.6667	accuracy_test: 0.6250
[client 5]	loss_train: 4693.4482	loss_val: 4693.5610	loss_test: 4693.6982	accuracy_train: 0.8671	accuracy_val: 0.8333	accuracy_test: 0.8649
[client 6]	loss_train: 46789.4102	loss_val: 46789.8438	loss_test: 46789.5625	accuracy_train: 0.5765	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 7]	loss_train: 16417.7246	loss_val: 16417.8828	loss_test: 16417.7344	accuracy_train: 0.5528	accuracy_val: 0.4167	accuracy_test: 0.5676
[client 8]	loss_train: 1207.1638	loss_val: 1207.1824	loss_test: 1207.1733	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57685.0664	loss_val: 57695.1562	loss_test: 57685.2461	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8769.3154	loss_val: 8769.1934	loss_test: 8769.3223	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4241.6450	loss_val: 4241.7354	loss_test: 4241.7715	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34329.7617	loss_val: 34330.6289	loss_test: 34330.9336	accuracy_train: 0.9492	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 240188.7344	loss_val: 240188.9688	loss_test: 240189.6562	accuracy_train: 0.8827	accuracy_val: 0.7600	accuracy_test: 0.7692
[client 14]	loss_train: 8147.9360	loss_val: 8148.0708	loss_test: 8148.1558	accuracy_train: 0.3566	accuracy_val: 0.4118	accuracy_test: 0.3000
[client 15]	loss_train: 1138.3401	loss_val: 1138.3538	loss_test: 1138.3914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9654.3193	loss_val: 9654.9033	loss_test: 9655.0635	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25063.1973	loss_val: 25063.2676	loss_test: 25063.3555	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11680.7588	loss_val: 11680.8350	loss_test: 11680.8867	accuracy_train: 0.4265	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1316.7312	loss_val: 1316.7343	loss_test: 1316.7456	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 88	curr_val_accuracy: 0.6778	curr_test_accuracy: 0.6896
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31376.2695	loss_val: 31376.4648	loss_test: 31376.2305	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 16216.0488	loss_val: 16216.1260	loss_test: 16216.2070	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 71801.8516	loss_val: 71803.8438	loss_test: 71802.7969	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 11139.4561	loss_val: 11139.4277	loss_test: 11139.4814	accuracy_train: 0.4277	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5502.6567	loss_val: 5502.8369	loss_test: 5502.8091	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4489.9429	loss_val: 4490.0498	loss_test: 4490.1831	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47266.6562	loss_val: 47267.0664	loss_test: 47266.8008	accuracy_train: 0.5647	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 7]	loss_train: 16549.5410	loss_val: 16549.6992	loss_test: 16549.5547	accuracy_train: 0.5423	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1195.9343	loss_val: 1195.9523	loss_test: 1195.9429	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55783.1055	loss_val: 55793.5742	loss_test: 55783.2891	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8675.6523	loss_val: 8675.5264	loss_test: 8675.6602	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4294.5581	loss_val: 4294.6460	loss_test: 4294.6821	accuracy_train: 0.6392	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34293.2305	loss_val: 34294.1055	loss_test: 34294.4414	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 240459.1875	loss_val: 240459.4219	loss_test: 240460.1094	accuracy_train: 0.8776	accuracy_val: 0.7600	accuracy_test: 0.7692
[client 14]	loss_train: 8088.0767	loss_val: 8088.1968	loss_test: 8088.3047	accuracy_train: 0.3427	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1138.8058	loss_val: 1138.8193	loss_test: 1138.8571	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9650.0332	loss_val: 9650.6162	loss_test: 9650.7686	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 26271.5781	loss_val: 26271.6426	loss_test: 26271.7285	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12185.4482	loss_val: 12185.5361	loss_test: 12185.5811	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1315.2095	loss_val: 1315.2123	loss_test: 1315.2231	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 89	curr_val_accuracy: 0.6796	curr_test_accuracy: 0.6857
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31943.7832	loss_val: 31943.9863	loss_test: 31943.7441	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 16219.8174	loss_val: 16219.8945	loss_test: 16219.9707	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 71698.2734	loss_val: 71700.2969	loss_test: 71699.1953	accuracy_train: 0.9880	accuracy_val: 0.6364	accuracy_test: 0.6364
[client 3]	loss_train: 11510.3281	loss_val: 11510.3027	loss_test: 11510.3525	accuracy_train: 0.4245	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5446.7168	loss_val: 5446.9282	loss_test: 5446.8711	accuracy_train: 0.6294	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4710.1929	loss_val: 4710.3008	loss_test: 4710.4341	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50068.0781	loss_val: 50068.4492	loss_test: 50068.1992	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 16858.9883	loss_val: 16859.1328	loss_test: 16859.0098	accuracy_train: 0.5458	accuracy_val: 0.4167	accuracy_test: 0.5135
[client 8]	loss_train: 1185.4579	loss_val: 1185.4756	loss_test: 1185.4659	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55691.1680	loss_val: 55701.8086	loss_test: 55691.3477	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8579.1455	loss_val: 8579.0156	loss_test: 8579.1553	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4291.6782	loss_val: 4291.7632	loss_test: 4291.8110	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 34400.2656	loss_val: 34401.1484	loss_test: 34401.5000	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 241823.8750	loss_val: 241824.0938	loss_test: 241824.8125	accuracy_train: 0.8776	accuracy_val: 0.7600	accuracy_test: 0.7308
[client 14]	loss_train: 8455.0488	loss_val: 8455.1562	loss_test: 8455.2734	accuracy_train: 0.3427	accuracy_val: 0.3529	accuracy_test: 0.2500
[client 15]	loss_train: 1139.5419	loss_val: 1139.5554	loss_test: 1139.5928	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9635.2754	loss_val: 9635.8584	loss_test: 9636.0078	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 26597.9258	loss_val: 26597.9863	loss_test: 26598.0703	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11465.5596	loss_val: 11465.6504	loss_test: 11465.6963	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1296.9927	loss_val: 1296.9955	loss_test: 1297.0062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 90	curr_val_accuracy: 0.6758	curr_test_accuracy: 0.6820
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36093.1094	loss_val: 36093.3203	loss_test: 36093.0742	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 16361.8828	loss_val: 16361.9639	loss_test: 16362.0381	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 72581.4297	loss_val: 72583.4844	loss_test: 72582.3281	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 12412.4805	loss_val: 12412.4531	loss_test: 12412.5049	accuracy_train: 0.4214	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5471.8232	loss_val: 5472.0366	loss_test: 5471.9912	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4934.5845	loss_val: 4934.6943	loss_test: 4934.8320	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51847.2070	loss_val: 51847.5625	loss_test: 51847.3203	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5455
[client 7]	loss_train: 17354.7441	loss_val: 17354.8867	loss_test: 17354.7598	accuracy_train: 0.5387	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1192.0443	loss_val: 1192.0618	loss_test: 1192.0519	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55828.4180	loss_val: 55839.3477	loss_test: 55828.5938	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8520.5391	loss_val: 8520.4072	loss_test: 8520.5498	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4261.5703	loss_val: 4261.6484	loss_test: 4261.7124	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35784.9766	loss_val: 35785.8789	loss_test: 35786.2148	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 256807.1406	loss_val: 256807.3594	loss_test: 256808.0625	accuracy_train: 0.8827	accuracy_val: 0.7600	accuracy_test: 0.7308
[client 14]	loss_train: 8723.3877	loss_val: 8723.4805	loss_test: 8723.6025	accuracy_train: 0.3357	accuracy_val: 0.3529	accuracy_test: 0.2500
[client 15]	loss_train: 1140.3771	loss_val: 1140.3905	loss_test: 1140.4272	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9689.2549	loss_val: 9689.8398	loss_test: 9689.9873	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 26642.3672	loss_val: 26642.4434	loss_test: 26642.5254	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11098.8525	loss_val: 11098.9482	loss_test: 11098.9951	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1296.5194	loss_val: 1296.5223	loss_test: 1296.5328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 91	curr_val_accuracy: 0.6777	curr_test_accuracy: 0.6839
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 55082.7109	loss_val: 55082.9336	loss_test: 55082.6797	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 16226.9102	loss_val: 16226.9980	loss_test: 16227.0703	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 72507.7969	loss_val: 72509.8984	loss_test: 72508.6875	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 12674.3408	loss_val: 12674.3115	loss_test: 12674.3682	accuracy_train: 0.4245	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5531.3369	loss_val: 5531.5356	loss_test: 5531.5259	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4715.6470	loss_val: 4715.7563	loss_test: 4715.8970	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 52578.8789	loss_val: 52579.2539	loss_test: 52579.0117	accuracy_train: 0.5765	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 17233.0098	loss_val: 17233.1562	loss_test: 17233.0156	accuracy_train: 0.5423	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1179.1259	loss_val: 1179.1432	loss_test: 1179.1334	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55849.0391	loss_val: 55860.1680	loss_test: 55849.2031	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8458.7480	loss_val: 8458.6162	loss_test: 8458.7559	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4212.7080	loss_val: 4212.7842	loss_test: 4212.8525	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35825.7148	loss_val: 35826.6094	loss_test: 35826.9609	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 268948.5625	loss_val: 268948.7812	loss_test: 268949.5000	accuracy_train: 0.8980	accuracy_val: 0.8400	accuracy_test: 0.7692
[client 14]	loss_train: 8657.8926	loss_val: 8657.9756	loss_test: 8658.1025	accuracy_train: 0.3287	accuracy_val: 0.3529	accuracy_test: 0.2500
[client 15]	loss_train: 1140.5312	loss_val: 1140.5443	loss_test: 1140.5804	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9845.2920	loss_val: 9845.8818	loss_test: 9846.0254	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 26279.4277	loss_val: 26279.5078	loss_test: 26279.5781	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 10833.2021	loss_val: 10833.2949	loss_test: 10833.3555	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1291.6611	loss_val: 1291.6639	loss_test: 1291.6743	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 92	curr_val_accuracy: 0.6797	curr_test_accuracy: 0.6856
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 50124.8164	loss_val: 50125.0469	loss_test: 50124.7891	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 16223.0283	loss_val: 16223.1230	loss_test: 16223.1846	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 71427.6562	loss_val: 71429.7969	loss_test: 71428.5312	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 12602.3604	loss_val: 12602.3281	loss_test: 12602.3906	accuracy_train: 0.4245	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 5596.5103	loss_val: 5596.6909	loss_test: 5596.7090	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4666.8848	loss_val: 4666.9883	loss_test: 4667.1338	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51918.4844	loss_val: 51918.8828	loss_test: 51918.6328	accuracy_train: 0.5824	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 17366.8730	loss_val: 17367.0176	loss_test: 17366.8789	accuracy_train: 0.5458	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1170.8260	loss_val: 1170.8433	loss_test: 1170.8337	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56319.4414	loss_val: 56330.7227	loss_test: 56319.5898	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8329.4248	loss_val: 8329.2959	loss_test: 8329.4307	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4188.4844	loss_val: 4188.5649	loss_test: 4188.6289	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35319.3594	loss_val: 35320.2578	loss_test: 35320.6445	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 275146.4062	loss_val: 275146.5938	loss_test: 275147.3125	accuracy_train: 0.9031	accuracy_val: 0.8400	accuracy_test: 0.7308
[client 14]	loss_train: 8475.2432	loss_val: 8475.3223	loss_test: 8475.4473	accuracy_train: 0.3357	accuracy_val: 0.3529	accuracy_test: 0.2500
[client 15]	loss_train: 1141.4535	loss_val: 1141.4666	loss_test: 1141.5020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 9934.6367	loss_val: 9935.2295	loss_test: 9935.3711	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 26066.3945	loss_val: 26066.4707	loss_test: 26066.5293	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11069.1650	loss_val: 11069.2578	loss_test: 11069.3223	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1286.9312	loss_val: 1286.9338	loss_test: 1286.9441	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 93	curr_val_accuracy: 0.6797	curr_test_accuracy: 0.6837
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36891.2031	loss_val: 36891.4336	loss_test: 36891.1758	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 16782.7227	loss_val: 16782.8242	loss_test: 16782.8770	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 70825.4375	loss_val: 70827.6172	loss_test: 70826.3125	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.7273
[client 3]	loss_train: 12565.1846	loss_val: 12565.1523	loss_test: 12565.2148	accuracy_train: 0.4245	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 5435.0952	loss_val: 5435.2793	loss_test: 5435.2886	accuracy_train: 0.6294	accuracy_val: 0.6667	accuracy_test: 0.6250
[client 5]	loss_train: 4769.8369	loss_val: 4769.9502	loss_test: 4770.0786	accuracy_train: 0.8706	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50636.3359	loss_val: 50636.7461	loss_test: 50636.4922	accuracy_train: 0.5824	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 17481.9473	loss_val: 17482.0938	loss_test: 17481.9512	accuracy_train: 0.5528	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1156.6616	loss_val: 1156.6780	loss_test: 1156.6694	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54610.3594	loss_val: 54621.9297	loss_test: 54610.5117	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8228.1270	loss_val: 8227.9990	loss_test: 8228.1328	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4174.4912	loss_val: 4174.5767	loss_test: 4174.6377	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36036.9336	loss_val: 36037.8359	loss_test: 36038.2305	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 283075.7188	loss_val: 283075.9062	loss_test: 283076.6250	accuracy_train: 0.8980	accuracy_val: 0.8000	accuracy_test: 0.7692
[client 14]	loss_train: 8358.2764	loss_val: 8358.3545	loss_test: 8358.4668	accuracy_train: 0.3357	accuracy_val: 0.3529	accuracy_test: 0.2500
[client 15]	loss_train: 1134.2963	loss_val: 1134.3094	loss_test: 1134.3444	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10049.3584	loss_val: 10049.9541	loss_test: 10050.0967	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25605.6504	loss_val: 25605.7266	loss_test: 25605.7871	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11852.9473	loss_val: 11853.0391	loss_test: 11853.1035	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1287.0548	loss_val: 1287.0575	loss_test: 1287.0675	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 94	curr_val_accuracy: 0.6797	curr_test_accuracy: 0.6875
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33903.4609	loss_val: 33903.6953	loss_test: 33903.4414	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 16619.5723	loss_val: 16619.6797	loss_test: 16619.7246	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 70431.2188	loss_val: 70433.4219	loss_test: 70432.0859	accuracy_train: 0.9880	accuracy_val: 0.8182	accuracy_test: 0.7273
[client 3]	loss_train: 12382.7695	loss_val: 12382.7373	loss_test: 12382.7979	accuracy_train: 0.4245	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5422.6064	loss_val: 5422.8335	loss_test: 5422.8008	accuracy_train: 0.6353	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 4627.3467	loss_val: 4627.4595	loss_test: 4627.5791	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50500.8047	loss_val: 50501.2070	loss_test: 50500.9453	accuracy_train: 0.5824	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 16961.5586	loss_val: 16961.7012	loss_test: 16961.5645	accuracy_train: 0.5528	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1153.9669	loss_val: 1153.9833	loss_test: 1153.9750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57493.2305	loss_val: 57505.0156	loss_test: 57493.3750	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8014.2896	loss_val: 8014.1636	loss_test: 8014.2964	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4236.6465	loss_val: 4236.7334	loss_test: 4236.7974	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36134.7109	loss_val: 36135.6367	loss_test: 36136.0234	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7647
[client 13]	loss_train: 287722.9375	loss_val: 287723.1250	loss_test: 287723.8438	accuracy_train: 0.9082	accuracy_val: 0.8400	accuracy_test: 0.7692
[client 14]	loss_train: 8362.4854	loss_val: 8362.5547	loss_test: 8362.6758	accuracy_train: 0.3357	accuracy_val: 0.3529	accuracy_test: 0.2500
[client 15]	loss_train: 1127.7938	loss_val: 1127.8070	loss_test: 1127.8417	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10112.8115	loss_val: 10113.4131	loss_test: 10113.5557	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 24281.7461	loss_val: 24281.8203	loss_test: 24281.8965	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12272.4785	loss_val: 12272.5625	loss_test: 12272.6279	accuracy_train: 0.4228	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1277.4056	loss_val: 1277.4081	loss_test: 1277.4180	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 95	curr_val_accuracy: 0.6816	curr_test_accuracy: 0.6914
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33747.7070	loss_val: 33747.9492	loss_test: 33747.6953	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 16278.9512	loss_val: 16279.0586	loss_test: 16279.0986	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 69476.7656	loss_val: 69478.9688	loss_test: 69477.6484	accuracy_train: 0.9880	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 12130.0176	loss_val: 12129.9854	loss_test: 12130.0410	accuracy_train: 0.4214	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5404.2461	loss_val: 5404.5327	loss_test: 5404.4517	accuracy_train: 0.6353	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 4627.5347	loss_val: 4627.6436	loss_test: 4627.7603	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51513.1836	loss_val: 51513.5781	loss_test: 51513.3086	accuracy_train: 0.5824	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 16534.9883	loss_val: 16535.1309	loss_test: 16535.0000	accuracy_train: 0.5493	accuracy_val: 0.4444	accuracy_test: 0.5676
[client 8]	loss_train: 1148.8235	loss_val: 1148.8398	loss_test: 1148.8318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60272.2500	loss_val: 60284.1992	loss_test: 60272.3359	accuracy_train: 0.9808	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8084.6650	loss_val: 8084.5396	loss_test: 8084.6714	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4286.3701	loss_val: 4286.4556	loss_test: 4286.5215	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36493.7578	loss_val: 36494.7070	loss_test: 36495.0898	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 292307.4688	loss_val: 292307.6562	loss_test: 292308.3750	accuracy_train: 0.9031	accuracy_val: 0.8000	accuracy_test: 0.7308
[client 14]	loss_train: 8474.2773	loss_val: 8474.3408	loss_test: 8474.4766	accuracy_train: 0.3427	accuracy_val: 0.3529	accuracy_test: 0.2500
[client 15]	loss_train: 1125.5758	loss_val: 1125.5890	loss_test: 1125.6234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10232.5469	loss_val: 10233.1504	loss_test: 10233.2979	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 23912.3242	loss_val: 23912.4004	loss_test: 23912.4844	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12658.2051	loss_val: 12658.2842	loss_test: 12658.3467	accuracy_train: 0.4375	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1279.4850	loss_val: 1279.4875	loss_test: 1279.4968	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 96	curr_val_accuracy: 0.6756	curr_test_accuracy: 0.6859
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33592.0547	loss_val: 33592.3008	loss_test: 33592.0508	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 1]	loss_train: 15198.2754	loss_val: 15198.3770	loss_test: 15198.4199	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 66823.5469	loss_val: 66825.7422	loss_test: 66824.4375	accuracy_train: 0.9880	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11696.0918	loss_val: 11696.0664	loss_test: 11696.1113	accuracy_train: 0.4214	accuracy_val: 0.4000	accuracy_test: 0.4390
[client 4]	loss_train: 5370.0771	loss_val: 5370.4160	loss_test: 5370.2949	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 4778.1768	loss_val: 4778.2773	loss_test: 4778.3945	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51786.0000	loss_val: 51786.3906	loss_test: 51786.1172	accuracy_train: 0.5706	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 16759.2578	loss_val: 16759.3965	loss_test: 16759.2832	accuracy_train: 0.5528	accuracy_val: 0.4444	accuracy_test: 0.5676
[client 8]	loss_train: 1155.4967	loss_val: 1155.5134	loss_test: 1155.5054	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55219.7734	loss_val: 55232.0508	loss_test: 55219.9023	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8205.2822	loss_val: 8205.1553	loss_test: 8205.2891	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4317.7109	loss_val: 4317.7983	loss_test: 4317.8677	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36741.3164	loss_val: 36742.2695	loss_test: 36742.6797	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 293832.3125	loss_val: 293832.5000	loss_test: 293833.2500	accuracy_train: 0.8878	accuracy_val: 0.8000	accuracy_test: 0.6923
[client 14]	loss_train: 8376.8818	loss_val: 8376.9561	loss_test: 8377.0850	accuracy_train: 0.3497	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1121.9210	loss_val: 1121.9341	loss_test: 1121.9683	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10369.7812	loss_val: 10370.3896	loss_test: 10370.5381	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 23990.0332	loss_val: 23990.1270	loss_test: 23990.2148	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12821.3984	loss_val: 12821.4893	loss_test: 12821.5430	accuracy_train: 0.4375	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1291.9563	loss_val: 1291.9589	loss_test: 1291.9680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 97	curr_val_accuracy: 0.6736	curr_test_accuracy: 0.6840
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34945.2969	loss_val: 34945.5469	loss_test: 34945.3047	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 15058.1426	loss_val: 15058.2510	loss_test: 15058.2920	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 64663.1719	loss_val: 64665.3633	loss_test: 64664.0781	accuracy_train: 0.9880	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11333.1436	loss_val: 11333.1250	loss_test: 11333.1602	accuracy_train: 0.4214	accuracy_val: 0.4000	accuracy_test: 0.4390
[client 4]	loss_train: 5253.7842	loss_val: 5254.1631	loss_test: 5254.0103	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 5294.8564	loss_val: 5294.9526	loss_test: 5295.0630	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51630.1641	loss_val: 51630.5586	loss_test: 51630.2734	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 17564.6641	loss_val: 17564.7930	loss_test: 17564.7051	accuracy_train: 0.5599	accuracy_val: 0.4722	accuracy_test: 0.5405
[client 8]	loss_train: 1156.2461	loss_val: 1156.2627	loss_test: 1156.2545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54889.0039	loss_val: 54901.3242	loss_test: 54889.1289	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8256.6113	loss_val: 8256.4824	loss_test: 8256.6221	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4309.8413	loss_val: 4309.9316	loss_test: 4310.0029	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36871.0469	loss_val: 36871.9844	loss_test: 36872.4570	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 289982.6250	loss_val: 289982.8125	loss_test: 289983.5625	accuracy_train: 0.8724	accuracy_val: 0.8000	accuracy_test: 0.6923
[client 14]	loss_train: 8207.2236	loss_val: 8207.3135	loss_test: 8207.4277	accuracy_train: 0.3497	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1126.6470	loss_val: 1126.6598	loss_test: 1126.6938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10451.4463	loss_val: 10452.0537	loss_test: 10452.2051	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 24008.5918	loss_val: 24008.6934	loss_test: 24008.7773	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12331.9307	loss_val: 12332.0322	loss_test: 12332.0850	accuracy_train: 0.4265	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1293.9498	loss_val: 1293.9525	loss_test: 1293.9617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 98	curr_val_accuracy: 0.6735	curr_test_accuracy: 0.6837
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34873.0273	loss_val: 34873.2734	loss_test: 34873.0469	accuracy_train: 0.9806	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 14926.3076	loss_val: 14926.4277	loss_test: 14926.4658	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 63950.5117	loss_val: 63952.7109	loss_test: 63951.4297	accuracy_train: 0.9880	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 11083.8145	loss_val: 11083.8057	loss_test: 11083.8301	accuracy_train: 0.4214	accuracy_val: 0.4250	accuracy_test: 0.4390
[client 4]	loss_train: 5294.6006	loss_val: 5295.0151	loss_test: 5294.8164	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6667
[client 5]	loss_train: 4868.8057	loss_val: 4868.9053	loss_test: 4869.0103	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 51611.8711	loss_val: 51612.2617	loss_test: 51611.9805	accuracy_train: 0.5588	accuracy_val: 0.4545	accuracy_test: 0.5000
[client 7]	loss_train: 17044.6777	loss_val: 17044.8066	loss_test: 17044.7188	accuracy_train: 0.5634	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1140.7423	loss_val: 1140.7587	loss_test: 1140.7505	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54984.7461	loss_val: 54997.0156	loss_test: 54984.8711	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 0.8750
[client 10]	loss_train: 8342.4697	loss_val: 8342.3379	loss_test: 8342.4844	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 4266.6348	loss_val: 4266.7285	loss_test: 4266.7974	accuracy_train: 0.6392	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 35814.3359	loss_val: 35815.2812	loss_test: 35815.7969	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.7059
[client 13]	loss_train: 285371.8125	loss_val: 285372.0000	loss_test: 285372.7188	accuracy_train: 0.8673	accuracy_val: 0.8000	accuracy_test: 0.6923
[client 14]	loss_train: 7858.1504	loss_val: 7858.2510	loss_test: 7858.3491	accuracy_train: 0.3497	accuracy_val: 0.3529	accuracy_test: 0.3000
[client 15]	loss_train: 1120.3018	loss_val: 1120.3146	loss_test: 1120.3483	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 10505.8809	loss_val: 10506.4873	loss_test: 10506.6299	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25645.1230	loss_val: 25645.2188	loss_test: 25645.3242	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11705.9102	loss_val: 11706.0156	loss_test: 11706.0742	accuracy_train: 0.4265	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1290.7223	loss_val: 1290.7251	loss_test: 1290.7344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 99	curr_val_accuracy: 0.6695	curr_test_accuracy: 0.6837
best_round: 27	best_val_accuracy: 0.7072	best_test_accuracy: 0.6859
--------------------------------------------------
