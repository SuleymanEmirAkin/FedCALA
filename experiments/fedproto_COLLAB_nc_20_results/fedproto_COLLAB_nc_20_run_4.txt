GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=492, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=3, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1.0006	loss_val: 0.9542	loss_test: 0.9632	accuracy_train: 0.9029	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 1.6784	loss_val: 1.9001	loss_test: 1.6633	accuracy_train: 0.2752	accuracy_val: 0.2812	accuracy_test: 0.2647
[client 2]	loss_train: 1.0847	loss_val: 1.0251	loss_test: 1.0712	accuracy_train: 0.4337	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 1.0811	loss_val: 1.0667	loss_test: 1.0946	accuracy_train: 0.3396	accuracy_val: 0.3500	accuracy_test: 0.2927
[client 4]	loss_train: 1.4230	loss_val: 1.3651	loss_test: 1.6180	accuracy_train: 0.4059	accuracy_val: 0.5238	accuracy_test: 0.4167
[client 5]	loss_train: 1.0622	loss_val: 1.2214	loss_test: 1.0511	accuracy_train: 0.7378	accuracy_val: 0.6667	accuracy_test: 0.6486
[client 6]	loss_train: 1.0528	loss_val: 1.0780	loss_test: 1.0852	accuracy_train: 0.1588	accuracy_val: 0.2273	accuracy_test: 0.0909
[client 7]	loss_train: 1.1197	loss_val: 1.0840	loss_test: 1.1330	accuracy_train: 0.1620	accuracy_val: 0.1667	accuracy_test: 0.1622
[client 8]	loss_train: 1.0848	loss_val: 1.0925	loss_test: 1.0996	accuracy_train: 0.1719	accuracy_val: 0.1389	accuracy_test: 0.1111
[client 9]	loss_train: 1.0878	loss_val: 1.2096	loss_test: 1.0686	accuracy_train: 0.1154	accuracy_val: 0.1429	accuracy_test: 0.2500
[client 10]	loss_train: 1.0442	loss_val: 1.0044	loss_test: 1.0617	accuracy_train: 0.4927	accuracy_val: 0.5882	accuracy_test: 0.4571
[client 11]	loss_train: 1.0852	loss_val: 1.0857	loss_test: 1.1040	accuracy_train: 0.4157	accuracy_val: 0.4062	accuracy_test: 0.3939
[client 12]	loss_train: 1.0920	loss_val: 1.0791	loss_test: 1.0377	accuracy_train: 0.2034	accuracy_val: 0.1333	accuracy_test: 0.2353
[client 13]	loss_train: 1.3866	loss_val: 1.1428	loss_test: 1.1478	accuracy_train: 0.0306	accuracy_val: 0.0400	accuracy_test: 0.0000
[client 14]	loss_train: 1.0691	loss_val: 1.1731	loss_test: 1.2443	accuracy_train: 0.3147	accuracy_val: 0.1176	accuracy_test: 0.1500
[client 15]	loss_train: 1.1154	loss_val: 1.1057	loss_test: 1.1431	accuracy_train: 0.1667	accuracy_val: 0.1600	accuracy_test: 0.0769
[client 16]	loss_train: 0.8087	loss_val: 0.8491	loss_test: 0.9854	accuracy_train: 0.7679	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 1.1721	loss_val: 1.0479	loss_test: 1.5016	accuracy_train: 0.4539	accuracy_val: 0.4706	accuracy_test: 0.2632
[client 18]	loss_train: 1.3657	loss_val: 1.3833	loss_test: 1.6064	accuracy_train: 0.2684	accuracy_val: 0.3235	accuracy_test: 0.2857
[client 19]	loss_train: 1.0143	loss_val: 1.0400	loss_test: 1.0335	accuracy_train: 0.7735	accuracy_val: 0.7436	accuracy_test: 0.6154
curr_round: 0	curr_val_accuracy: 0.3757	curr_test_accuracy: 0.3258
best_round: 0	best_val_accuracy: 0.3757	best_test_accuracy: 0.3258
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30956.2109	loss_val: 30956.1582	loss_test: 30956.1660	accuracy_train: 0.9029	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 13422.4795	loss_val: 13422.6523	loss_test: 13422.5166	accuracy_train: 0.3798	accuracy_val: 0.2812	accuracy_test: 0.3824
[client 2]	loss_train: 32159.2734	loss_val: 32159.2441	loss_test: 32159.3047	accuracy_train: 0.5422	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 16695.4746	loss_val: 16695.4434	loss_test: 16695.4883	accuracy_train: 0.3585	accuracy_val: 0.3750	accuracy_test: 0.3659
[client 4]	loss_train: 11118.5156	loss_val: 11118.5088	loss_test: 11118.5576	accuracy_train: 0.4176	accuracy_val: 0.4286	accuracy_test: 0.4583
[client 5]	loss_train: 3752.2222	loss_val: 3752.2302	loss_test: 3752.2227	accuracy_train: 0.8566	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 22069.5371	loss_val: 22069.5527	loss_test: 22069.5879	accuracy_train: 0.1529	accuracy_val: 0.0909	accuracy_test: 0.1364
[client 7]	loss_train: 9122.9805	loss_val: 9122.9678	loss_test: 9122.9736	accuracy_train: 0.1549	accuracy_val: 0.1667	accuracy_test: 0.1622
[client 8]	loss_train: 83.9802	loss_val: 83.9791	loss_test: 83.9738	accuracy_train: 0.4246	accuracy_val: 0.3056	accuracy_test: 0.3889
[client 9]	loss_train: 54373.2461	loss_val: 54373.2500	loss_test: 54373.1914	accuracy_train: 0.0962	accuracy_val: 0.1429	accuracy_test: 0.2500
[client 10]	loss_train: 7553.8140	loss_val: 7553.7847	loss_test: 7553.8452	accuracy_train: 0.4781	accuracy_val: 0.5000	accuracy_test: 0.4000
[client 11]	loss_train: 80.8701	loss_val: 80.8807	loss_test: 80.8801	accuracy_train: 0.5176	accuracy_val: 0.4688	accuracy_test: 0.5758
[client 12]	loss_train: 32006.0840	loss_val: 32006.1035	loss_test: 32006.0586	accuracy_train: 0.5678	accuracy_val: 0.5333	accuracy_test: 0.5882
[client 13]	loss_train: 55496.6133	loss_val: 55496.4570	loss_test: 55496.4453	accuracy_train: 0.0255	accuracy_val: 0.0400	accuracy_test: 0.0769
[client 14]	loss_train: 8961.1875	loss_val: 8961.1650	loss_test: 8961.1797	accuracy_train: 0.3287	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 85.3373	loss_val: 85.3328	loss_test: 85.3660	accuracy_train: 0.0833	accuracy_val: 0.1200	accuracy_test: 0.0000
[client 16]	loss_train: 32759.9824	loss_val: 32760.0215	loss_test: 32760.1309	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 12404.4941	loss_val: 12404.4746	loss_test: 12404.4814	accuracy_train: 0.5745	accuracy_val: 0.5882	accuracy_test: 0.5263
[client 18]	loss_train: 6016.4487	loss_val: 6016.4741	loss_test: 6016.5259	accuracy_train: 0.4706	accuracy_val: 0.4412	accuracy_test: 0.4571
[client 19]	loss_train: 78.3865	loss_val: 78.3900	loss_test: 78.4006	accuracy_train: 0.9547	accuracy_val: 1.0000	accuracy_test: 0.9487
curr_round: 1	curr_val_accuracy: 0.4437	curr_test_accuracy: 0.4507
best_round: 1	best_val_accuracy: 0.4437	best_test_accuracy: 0.4507
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23302.7207	loss_val: 23302.6641	loss_test: 23302.6680	accuracy_train: 0.8835	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 12726.5430	loss_val: 12726.6699	loss_test: 12726.5547	accuracy_train: 0.4264	accuracy_val: 0.3125	accuracy_test: 0.4706
[client 2]	loss_train: 23774.7344	loss_val: 23774.7168	loss_test: 23774.7754	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 15451.4229	loss_val: 15451.3643	loss_test: 15451.4414	accuracy_train: 0.3994	accuracy_val: 0.4500	accuracy_test: 0.3902
[client 4]	loss_train: 6810.4561	loss_val: 6810.4546	loss_test: 6810.4517	accuracy_train: 0.4353	accuracy_val: 0.4286	accuracy_test: 0.5417
[client 5]	loss_train: 2818.8770	loss_val: 2818.8591	loss_test: 2818.8845	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 18503.7266	loss_val: 18503.7266	loss_test: 18503.7676	accuracy_train: 0.4059	accuracy_val: 0.4091	accuracy_test: 0.3636
[client 7]	loss_train: 8674.1924	loss_val: 8674.1992	loss_test: 8674.1797	accuracy_train: 0.1831	accuracy_val: 0.1667	accuracy_test: 0.1892
[client 8]	loss_train: 129.6240	loss_val: 129.6299	loss_test: 129.6136	accuracy_train: 0.9018	accuracy_val: 0.9444	accuracy_test: 0.9444
[client 9]	loss_train: 45992.8086	loss_val: 45992.8438	loss_test: 45992.7891	accuracy_train: 0.7692	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 6633.0464	loss_val: 6633.0078	loss_test: 6633.0586	accuracy_train: 0.4891	accuracy_val: 0.5588	accuracy_test: 0.4571
[client 11]	loss_train: 111.8562	loss_val: 111.8715	loss_test: 111.8670	accuracy_train: 0.5725	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 12]	loss_train: 23839.0293	loss_val: 23839.0566	loss_test: 23839.0215	accuracy_train: 0.6271	accuracy_val: 0.4667	accuracy_test: 0.5294
[client 13]	loss_train: 60922.5039	loss_val: 60922.4062	loss_test: 60922.3867	accuracy_train: 0.0561	accuracy_val: 0.0800	accuracy_test: 0.1154
[client 14]	loss_train: 7269.0200	loss_val: 7269.0073	loss_test: 7269.0142	accuracy_train: 0.3846	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 95.9320	loss_val: 95.9303	loss_test: 95.9555	accuracy_train: 0.4020	accuracy_val: 0.4800	accuracy_test: 0.3846
[client 16]	loss_train: 17308.1699	loss_val: 17308.2148	loss_test: 17308.3066	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10049.7588	loss_val: 10049.7578	loss_test: 10049.7109	accuracy_train: 0.5674	accuracy_val: 0.5294	accuracy_test: 0.5263
[client 18]	loss_train: 6477.2710	loss_val: 6477.2886	loss_test: 6477.3281	accuracy_train: 0.4779	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 116.2331	loss_val: 116.2233	loss_test: 116.2462	accuracy_train: 0.9773	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 2	curr_val_accuracy: 0.5370	curr_test_accuracy: 0.5495
best_round: 2	best_val_accuracy: 0.5370	best_test_accuracy: 0.5495
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 22115.4434	loss_val: 22115.3867	loss_test: 22115.3887	accuracy_train: 0.8835	accuracy_val: 0.8571	accuracy_test: 0.9286
[client 1]	loss_train: 12782.1055	loss_val: 12782.1973	loss_test: 12782.1084	accuracy_train: 0.4457	accuracy_val: 0.3125	accuracy_test: 0.5294
[client 2]	loss_train: 18235.5410	loss_val: 18235.5273	loss_test: 18235.5840	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 15823.3457	loss_val: 15823.2773	loss_test: 15823.3672	accuracy_train: 0.4182	accuracy_val: 0.4500	accuracy_test: 0.3659
[client 4]	loss_train: 5473.2212	loss_val: 5473.2207	loss_test: 5473.2041	accuracy_train: 0.4706	accuracy_val: 0.4286	accuracy_test: 0.5833
[client 5]	loss_train: 2922.6221	loss_val: 2922.6047	loss_test: 2922.6321	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 18654.9531	loss_val: 18654.9512	loss_test: 18654.9863	accuracy_train: 0.3765	accuracy_val: 0.4091	accuracy_test: 0.3636
[client 7]	loss_train: 9800.4795	loss_val: 9800.4844	loss_test: 9800.4580	accuracy_train: 0.2746	accuracy_val: 0.2222	accuracy_test: 0.3243
[client 8]	loss_train: 204.5192	loss_val: 204.5370	loss_test: 204.5083	accuracy_train: 0.9579	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 42068.6211	loss_val: 42068.6289	loss_test: 42068.5938	accuracy_train: 0.7500	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 6706.7549	loss_val: 6706.7085	loss_test: 6706.7554	accuracy_train: 0.5146	accuracy_val: 0.6176	accuracy_test: 0.4857
[client 11]	loss_train: 156.6501	loss_val: 156.6685	loss_test: 156.6648	accuracy_train: 0.5922	accuracy_val: 0.5312	accuracy_test: 0.6364
[client 12]	loss_train: 21732.6680	loss_val: 21732.6953	loss_test: 21732.6699	accuracy_train: 0.6610	accuracy_val: 0.4000	accuracy_test: 0.5882
[client 13]	loss_train: 72641.2344	loss_val: 72641.1719	loss_test: 72641.1562	accuracy_train: 0.1735	accuracy_val: 0.1600	accuracy_test: 0.1923
[client 14]	loss_train: 6926.5317	loss_val: 6926.5337	loss_test: 6926.5415	accuracy_train: 0.4056	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 126.0964	loss_val: 126.0932	loss_test: 126.1136	accuracy_train: 0.7647	accuracy_val: 0.8400	accuracy_test: 0.6923
[client 16]	loss_train: 11858.6221	loss_val: 11858.6748	loss_test: 11858.7490	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9211.4336	loss_val: 9211.4668	loss_test: 9211.4004	accuracy_train: 0.5603	accuracy_val: 0.4706	accuracy_test: 0.4211
[client 18]	loss_train: 7513.3760	loss_val: 7513.3877	loss_test: 7513.4131	accuracy_train: 0.5074	accuracy_val: 0.5000	accuracy_test: 0.4286
[client 19]	loss_train: 179.8087	loss_val: 179.7864	loss_test: 179.8185	accuracy_train: 0.9935	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 3	curr_val_accuracy: 0.5733	curr_test_accuracy: 0.5917
best_round: 3	best_val_accuracy: 0.5733	best_test_accuracy: 0.5917
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 19396.5195	loss_val: 19396.4629	loss_test: 19396.4648	accuracy_train: 0.8835	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 13599.4111	loss_val: 13599.4668	loss_test: 13599.3994	accuracy_train: 0.4961	accuracy_val: 0.3750	accuracy_test: 0.5588
[client 2]	loss_train: 17150.6777	loss_val: 17150.6680	loss_test: 17150.7227	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 17373.3672	loss_val: 17373.2988	loss_test: 17373.3906	accuracy_train: 0.4811	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 4895.4072	loss_val: 4895.4092	loss_test: 4895.3804	accuracy_train: 0.6588	accuracy_val: 0.4762	accuracy_test: 0.7083
[client 5]	loss_train: 3178.2095	loss_val: 3178.1958	loss_test: 3178.2231	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 19608.5234	loss_val: 19608.5176	loss_test: 19608.5391	accuracy_train: 0.3706	accuracy_val: 0.4091	accuracy_test: 0.3182
[client 7]	loss_train: 12172.2842	loss_val: 12172.2881	loss_test: 12172.2627	accuracy_train: 0.5775	accuracy_val: 0.5000	accuracy_test: 0.6757
[client 8]	loss_train: 320.2805	loss_val: 320.3105	loss_test: 320.2719	accuracy_train: 0.9930	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43416.5742	loss_val: 43416.5938	loss_test: 43416.5625	accuracy_train: 0.7500	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 7184.4155	loss_val: 7184.3613	loss_test: 7184.4097	accuracy_train: 0.5182	accuracy_val: 0.6176	accuracy_test: 0.5714
[client 11]	loss_train: 215.3859	loss_val: 215.4077	loss_test: 215.4025	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6970
[client 12]	loss_train: 21159.5391	loss_val: 21159.5664	loss_test: 21159.5469	accuracy_train: 0.6780	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 90256.1172	loss_val: 90256.0859	loss_test: 90256.0703	accuracy_train: 0.8265	accuracy_val: 0.8000	accuracy_test: 0.8846
[client 14]	loss_train: 7124.8394	loss_val: 7124.8506	loss_test: 7124.8652	accuracy_train: 0.4196	accuracy_val: 0.2941	accuracy_test: 0.5000
[client 15]	loss_train: 168.8352	loss_val: 168.8296	loss_test: 168.8473	accuracy_train: 0.9069	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 16]	loss_train: 9247.6875	loss_val: 9247.7451	loss_test: 9247.8027	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9331.7832	loss_val: 9331.8291	loss_test: 9331.7607	accuracy_train: 0.5745	accuracy_val: 0.4706	accuracy_test: 0.4737
[client 18]	loss_train: 8710.0713	loss_val: 8710.0752	loss_test: 8710.0869	accuracy_train: 0.5772	accuracy_val: 0.5294	accuracy_test: 0.4571
[client 19]	loss_train: 273.8572	loss_val: 273.8331	loss_test: 273.8667	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 4	curr_val_accuracy: 0.6530	curr_test_accuracy: 0.6835
best_round: 4	best_val_accuracy: 0.6530	best_test_accuracy: 0.6835
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 19087.8086	loss_val: 19087.7559	loss_test: 19087.7578	accuracy_train: 0.8835	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 15655.6094	loss_val: 15655.6621	loss_test: 15655.5928	accuracy_train: 0.5271	accuracy_val: 0.4062	accuracy_test: 0.5588
[client 2]	loss_train: 16663.8398	loss_val: 16663.8301	loss_test: 16663.8867	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 19214.3555	loss_val: 19214.2910	loss_test: 19214.3828	accuracy_train: 0.4969	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 4747.3291	loss_val: 4747.3340	loss_test: 4747.2993	accuracy_train: 0.6882	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 5]	loss_train: 3726.3833	loss_val: 3726.3906	loss_test: 3726.3972	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 21754.5293	loss_val: 21754.5215	loss_test: 21754.5332	accuracy_train: 0.3765	accuracy_val: 0.4091	accuracy_test: 0.3182
[client 7]	loss_train: 14682.2227	loss_val: 14682.2246	loss_test: 14682.1982	accuracy_train: 0.6585	accuracy_val: 0.7222	accuracy_test: 0.6757
[client 8]	loss_train: 481.8224	loss_val: 481.8657	loss_test: 481.8213	accuracy_train: 0.9930	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 43323.3008	loss_val: 43323.3281	loss_test: 43323.2891	accuracy_train: 0.7500	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 8504.6514	loss_val: 8504.5859	loss_test: 8504.6396	accuracy_train: 0.5365	accuracy_val: 0.6471	accuracy_test: 0.5714
[client 11]	loss_train: 289.5905	loss_val: 289.6164	loss_test: 289.6078	accuracy_train: 0.6157	accuracy_val: 0.5938	accuracy_test: 0.7273
[client 12]	loss_train: 21715.5996	loss_val: 21715.6289	loss_test: 21715.6113	accuracy_train: 0.6525	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 105819.3594	loss_val: 105819.3516	loss_test: 105819.3359	accuracy_train: 0.8776	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 7477.1816	loss_val: 7477.1934	loss_test: 7477.2095	accuracy_train: 0.4266	accuracy_val: 0.2941	accuracy_test: 0.5000
[client 15]	loss_train: 228.2554	loss_val: 228.2513	loss_test: 228.2689	accuracy_train: 0.9608	accuracy_val: 0.9600	accuracy_test: 0.9231
[client 16]	loss_train: 7685.3599	loss_val: 7685.4199	loss_test: 7685.4629	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 9781.0986	loss_val: 9781.1377	loss_test: 9781.0781	accuracy_train: 0.5887	accuracy_val: 0.4706	accuracy_test: 0.4737
[client 18]	loss_train: 10193.2588	loss_val: 10193.2549	loss_test: 10193.2773	accuracy_train: 0.5809	accuracy_val: 0.5294	accuracy_test: 0.4857
[client 19]	loss_train: 393.2451	loss_val: 393.2243	loss_test: 393.2566	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 5	curr_val_accuracy: 0.6770	curr_test_accuracy: 0.6948
best_round: 5	best_val_accuracy: 0.6770	best_test_accuracy: 0.6948
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 18698.0430	loss_val: 18697.9922	loss_test: 18697.9941	accuracy_train: 0.8835	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 19334.7871	loss_val: 19334.8457	loss_test: 19334.7695	accuracy_train: 0.5775	accuracy_val: 0.5000	accuracy_test: 0.6176
[client 2]	loss_train: 16977.4746	loss_val: 16977.4648	loss_test: 16977.5215	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 20707.9199	loss_val: 20707.8555	loss_test: 20707.9551	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 4762.3433	loss_val: 4762.3530	loss_test: 4762.3140	accuracy_train: 0.6824	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 4743.4634	loss_val: 4743.4854	loss_test: 4743.4775	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 25346.8398	loss_val: 25346.8281	loss_test: 25346.8398	accuracy_train: 0.3882	accuracy_val: 0.4091	accuracy_test: 0.3636
[client 7]	loss_train: 16850.4707	loss_val: 16850.4707	loss_test: 16850.4453	accuracy_train: 0.6655	accuracy_val: 0.7222	accuracy_test: 0.6757
[client 8]	loss_train: 670.2571	loss_val: 670.3119	loss_test: 670.2648	accuracy_train: 0.9965	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45549.8984	loss_val: 45549.9258	loss_test: 45549.8828	accuracy_train: 0.7692	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 9814.7832	loss_val: 9814.7080	loss_test: 9814.7705	accuracy_train: 0.5693	accuracy_val: 0.7059	accuracy_test: 0.5714
[client 11]	loss_train: 376.9152	loss_val: 376.9441	loss_test: 376.9296	accuracy_train: 0.5961	accuracy_val: 0.5000	accuracy_test: 0.6970
[client 12]	loss_train: 22491.1172	loss_val: 22491.1445	loss_test: 22491.1309	accuracy_train: 0.6610	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 120809.6953	loss_val: 120809.6953	loss_test: 120809.6953	accuracy_train: 0.8980	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 8024.0264	loss_val: 8024.0396	loss_test: 8024.0601	accuracy_train: 0.4336	accuracy_val: 0.2941	accuracy_test: 0.5000
[client 15]	loss_train: 308.3314	loss_val: 308.3336	loss_test: 308.3523	accuracy_train: 0.9804	accuracy_val: 0.9600	accuracy_test: 0.9615
[client 16]	loss_train: 6491.1733	loss_val: 6491.2319	loss_test: 6491.2671	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10137.9609	loss_val: 10137.9863	loss_test: 10137.9346	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11590.8018	loss_val: 11590.8066	loss_test: 11590.8359	accuracy_train: 0.5882	accuracy_val: 0.5000	accuracy_test: 0.4857
[client 19]	loss_train: 530.8375	loss_val: 530.8237	loss_test: 530.8522	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 6	curr_val_accuracy: 0.6852	curr_test_accuracy: 0.7045
best_round: 6	best_val_accuracy: 0.6852	best_test_accuracy: 0.7045
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 19762.7520	loss_val: 19762.7012	loss_test: 19762.7051	accuracy_train: 0.8835	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 21195.4043	loss_val: 21195.4688	loss_test: 21195.3867	accuracy_train: 0.6395	accuracy_val: 0.5312	accuracy_test: 0.6471
[client 2]	loss_train: 17532.4609	loss_val: 17532.4551	loss_test: 17532.5098	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 23080.7852	loss_val: 23080.7227	loss_test: 23080.8242	accuracy_train: 0.5031	accuracy_val: 0.5250	accuracy_test: 0.4634
[client 4]	loss_train: 4893.7515	loss_val: 4893.7651	loss_test: 4893.7256	accuracy_train: 0.6588	accuracy_val: 0.6190	accuracy_test: 0.7500
[client 5]	loss_train: 5802.8335	loss_val: 5802.8496	loss_test: 5802.8530	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 28785.2910	loss_val: 28785.2754	loss_test: 28785.2910	accuracy_train: 0.3824	accuracy_val: 0.4091	accuracy_test: 0.3636
[client 7]	loss_train: 19023.4258	loss_val: 19023.4180	loss_test: 19023.3984	accuracy_train: 0.6690	accuracy_val: 0.6944	accuracy_test: 0.6486
[client 8]	loss_train: 852.7994	loss_val: 852.8623	loss_test: 852.8100	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47773.1602	loss_val: 47773.1914	loss_test: 47773.1445	accuracy_train: 0.7692	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 10564.9277	loss_val: 10564.8438	loss_test: 10564.9189	accuracy_train: 0.5766	accuracy_val: 0.7353	accuracy_test: 0.5714
[client 11]	loss_train: 479.4011	loss_val: 479.4336	loss_test: 479.4086	accuracy_train: 0.6431	accuracy_val: 0.5000	accuracy_test: 0.6061
[client 12]	loss_train: 23350.4180	loss_val: 23350.4453	loss_test: 23350.4336	accuracy_train: 0.6695	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 133308.1250	loss_val: 133308.1250	loss_test: 133308.1406	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.9231
[client 14]	loss_train: 8669.3037	loss_val: 8669.3105	loss_test: 8669.3359	accuracy_train: 0.4336	accuracy_val: 0.2941	accuracy_test: 0.5000
[client 15]	loss_train: 407.6636	loss_val: 407.6754	loss_test: 407.6906	accuracy_train: 0.9853	accuracy_val: 0.9600	accuracy_test: 1.0000
[client 16]	loss_train: 5755.6489	loss_val: 5755.7109	loss_test: 5755.7407	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 10864.5068	loss_val: 10864.5205	loss_test: 10864.4668	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12909.8730	loss_val: 12909.8887	loss_test: 12909.9170	accuracy_train: 0.6066	accuracy_val: 0.5588	accuracy_test: 0.5143
[client 19]	loss_train: 667.4962	loss_val: 667.4892	loss_test: 667.5181	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 7	curr_val_accuracy: 0.6973	curr_test_accuracy: 0.7063
best_round: 7	best_val_accuracy: 0.6973	best_test_accuracy: 0.7063
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 20520.5742	loss_val: 20520.5254	loss_test: 20520.5293	accuracy_train: 0.8835	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 23679.8965	loss_val: 23679.9629	loss_test: 23679.8809	accuracy_train: 0.6860	accuracy_val: 0.5938	accuracy_test: 0.6471
[client 2]	loss_train: 18150.9102	loss_val: 18150.9082	loss_test: 18150.9609	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 24920.0156	loss_val: 24919.9551	loss_test: 24920.0527	accuracy_train: 0.5000	accuracy_val: 0.4750	accuracy_test: 0.4634
[client 4]	loss_train: 4962.6064	loss_val: 4962.6255	loss_test: 4962.5815	accuracy_train: 0.6471	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 6485.5894	loss_val: 6485.6143	loss_test: 6485.6123	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 32130.8359	loss_val: 32130.8164	loss_test: 32130.8359	accuracy_train: 0.3941	accuracy_val: 0.4545	accuracy_test: 0.3636
[client 7]	loss_train: 20890.2383	loss_val: 20890.2207	loss_test: 20890.2109	accuracy_train: 0.6690	accuracy_val: 0.7500	accuracy_test: 0.6757
[client 8]	loss_train: 1002.4106	loss_val: 1002.4764	loss_test: 1002.4191	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51445.1250	loss_val: 51445.1602	loss_test: 51445.1094	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 10731.6367	loss_val: 10731.5459	loss_test: 10731.6299	accuracy_train: 0.5803	accuracy_val: 0.7353	accuracy_test: 0.5714
[client 11]	loss_train: 595.9457	loss_val: 595.9813	loss_test: 595.9439	accuracy_train: 0.6667	accuracy_val: 0.6562	accuracy_test: 0.5758
[client 12]	loss_train: 22787.2344	loss_val: 22787.2598	loss_test: 22787.2520	accuracy_train: 0.6695	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 147982.4688	loss_val: 147982.4844	loss_test: 147982.5000	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 9443.1494	loss_val: 9443.1504	loss_test: 9443.1768	accuracy_train: 0.4336	accuracy_val: 0.2941	accuracy_test: 0.5000
[client 15]	loss_train: 521.8767	loss_val: 521.8974	loss_test: 521.9117	accuracy_train: 1.0000	accuracy_val: 0.9600	accuracy_test: 1.0000
[client 16]	loss_train: 5291.8047	loss_val: 5291.8682	loss_test: 5291.9009	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 12008.3652	loss_val: 12008.3701	loss_test: 12008.3203	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14136.6689	loss_val: 14136.6904	loss_test: 14136.7158	accuracy_train: 0.5110	accuracy_val: 0.5000	accuracy_test: 0.3714
[client 19]	loss_train: 794.6396	loss_val: 794.6373	loss_test: 794.6685	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 8	curr_val_accuracy: 0.7113	curr_test_accuracy: 0.6929
best_round: 8	best_val_accuracy: 0.7113	best_test_accuracy: 0.6929
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 21656.9473	loss_val: 21656.9004	loss_test: 21656.9062	accuracy_train: 0.8932	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 24485.4219	loss_val: 24485.4883	loss_test: 24485.4180	accuracy_train: 0.7984	accuracy_val: 0.7812	accuracy_test: 0.7059
[client 2]	loss_train: 19776.9609	loss_val: 19776.9668	loss_test: 19777.0156	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 25259.5977	loss_val: 25259.5410	loss_test: 25259.6328	accuracy_train: 0.5000	accuracy_val: 0.4500	accuracy_test: 0.4634
[client 4]	loss_train: 4999.6660	loss_val: 4999.6929	loss_test: 4999.6387	accuracy_train: 0.6471	accuracy_val: 0.6667	accuracy_test: 0.6667
[client 5]	loss_train: 7286.4751	loss_val: 7286.5015	loss_test: 7286.4990	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 35860.3008	loss_val: 35860.2773	loss_test: 35860.3008	accuracy_train: 0.3941	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 21761.1191	loss_val: 21761.0977	loss_test: 21761.0898	accuracy_train: 0.6761	accuracy_val: 0.7500	accuracy_test: 0.6757
[client 8]	loss_train: 1107.6610	loss_val: 1107.7269	loss_test: 1107.6675	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55339.8750	loss_val: 55339.9180	loss_test: 55339.8555	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 10892.6201	loss_val: 10892.5234	loss_test: 10892.6172	accuracy_train: 0.6387	accuracy_val: 0.7353	accuracy_test: 0.6571
[client 11]	loss_train: 713.0510	loss_val: 713.0898	loss_test: 713.0420	accuracy_train: 0.6706	accuracy_val: 0.7188	accuracy_test: 0.6667
[client 12]	loss_train: 23148.9180	loss_val: 23148.9414	loss_test: 23148.9375	accuracy_train: 0.6695	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 163334.5469	loss_val: 163334.5781	loss_test: 163334.5938	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.9231
[client 14]	loss_train: 10103.6562	loss_val: 10103.6533	loss_test: 10103.6758	accuracy_train: 0.4406	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 655.3309	loss_val: 655.3609	loss_test: 655.3763	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4943.9248	loss_val: 4943.9927	loss_test: 4944.0264	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 12653.2588	loss_val: 12653.2637	loss_test: 12653.2168	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15236.7256	loss_val: 15236.7510	loss_test: 15236.7725	accuracy_train: 0.3860	accuracy_val: 0.3824	accuracy_test: 0.3429
[client 19]	loss_train: 927.5865	loss_val: 927.5906	loss_test: 927.6234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 9	curr_val_accuracy: 0.7215	curr_test_accuracy: 0.7066
best_round: 9	best_val_accuracy: 0.7215	best_test_accuracy: 0.7066
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23309.3613	loss_val: 23309.3164	loss_test: 23309.3203	accuracy_train: 0.8932	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 26520.0781	loss_val: 26520.1426	loss_test: 26520.0801	accuracy_train: 0.8333	accuracy_val: 0.8750	accuracy_test: 0.7059
[client 2]	loss_train: 21497.5840	loss_val: 21497.5977	loss_test: 21497.6426	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 26340.0898	loss_val: 26340.0332	loss_test: 26340.1250	accuracy_train: 0.5000	accuracy_val: 0.4750	accuracy_test: 0.4878
[client 4]	loss_train: 5362.9048	loss_val: 5362.9385	loss_test: 5362.8765	accuracy_train: 0.6471	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8022.2231	loss_val: 8022.2490	loss_test: 8022.2490	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39224.3984	loss_val: 39224.3711	loss_test: 39224.4023	accuracy_train: 0.3824	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 23040.8633	loss_val: 23040.8398	loss_test: 23040.8340	accuracy_train: 0.6514	accuracy_val: 0.7222	accuracy_test: 0.7568
[client 8]	loss_train: 1185.0060	loss_val: 1185.0725	loss_test: 1185.0134	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58129.6523	loss_val: 58129.7109	loss_test: 58129.6367	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11076.6289	loss_val: 11076.5273	loss_test: 11076.6309	accuracy_train: 0.6569	accuracy_val: 0.6765	accuracy_test: 0.7714
[client 11]	loss_train: 852.2981	loss_val: 852.3386	loss_test: 852.2811	accuracy_train: 0.6824	accuracy_val: 0.7500	accuracy_test: 0.6667
[client 12]	loss_train: 23634.5957	loss_val: 23634.6191	loss_test: 23634.6152	accuracy_train: 0.6695	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 179794.2031	loss_val: 179794.2344	loss_test: 179794.2656	accuracy_train: 0.9184	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10452.1201	loss_val: 10452.1123	loss_test: 10452.1367	accuracy_train: 0.4406	accuracy_val: 0.2941	accuracy_test: 0.4500
[client 15]	loss_train: 802.2405	loss_val: 802.2784	loss_test: 802.2958	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4819.5347	loss_val: 4819.6118	loss_test: 4819.6475	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 13539.3994	loss_val: 13539.4072	loss_test: 13539.3594	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16438.6895	loss_val: 16438.7148	loss_test: 16438.7305	accuracy_train: 0.3934	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1051.0747	loss_val: 1051.0864	loss_test: 1051.1173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 10	curr_val_accuracy: 0.7255	curr_test_accuracy: 0.7223
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 23833.8242	loss_val: 23833.7812	loss_test: 23833.7871	accuracy_train: 0.8932	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 27498.7441	loss_val: 27498.8047	loss_test: 27498.7559	accuracy_train: 0.8643	accuracy_val: 0.8750	accuracy_test: 0.7059
[client 2]	loss_train: 23488.4980	loss_val: 23488.5176	loss_test: 23488.5605	accuracy_train: 0.6024	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 27966.3027	loss_val: 27966.2500	loss_test: 27966.3379	accuracy_train: 0.5000	accuracy_val: 0.4750	accuracy_test: 0.4878
[client 4]	loss_train: 5974.3608	loss_val: 5974.4023	loss_test: 5974.3311	accuracy_train: 0.6588	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8291.1162	loss_val: 8291.1406	loss_test: 8291.1406	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42356.8516	loss_val: 42356.8164	loss_test: 42356.8633	accuracy_train: 0.3824	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 24076.0254	loss_val: 24076.0020	loss_test: 24075.9961	accuracy_train: 0.6549	accuracy_val: 0.7500	accuracy_test: 0.7297
[client 8]	loss_train: 1235.7649	loss_val: 1235.8328	loss_test: 1235.7756	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58841.6211	loss_val: 58841.6914	loss_test: 58841.6094	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11118.5596	loss_val: 11118.4561	loss_test: 11118.5664	accuracy_train: 0.6606	accuracy_val: 0.6471	accuracy_test: 0.7429
[client 11]	loss_train: 1001.8438	loss_val: 1001.8873	loss_test: 1001.8201	accuracy_train: 0.6627	accuracy_val: 0.7500	accuracy_test: 0.6364
[client 12]	loss_train: 23940.9297	loss_val: 23940.9531	loss_test: 23940.9512	accuracy_train: 0.6695	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 193005.1719	loss_val: 193005.2031	loss_test: 193005.2344	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 10732.5830	loss_val: 10732.5703	loss_test: 10732.6006	accuracy_train: 0.4266	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 942.9313	loss_val: 942.9758	loss_test: 942.9986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4780.8052	loss_val: 4780.8867	loss_test: 4780.9307	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 14708.0752	loss_val: 14708.0869	loss_test: 14708.0361	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17349.5176	loss_val: 17349.5449	loss_test: 17349.5566	accuracy_train: 0.3971	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1133.6218	loss_val: 1133.6379	loss_test: 1133.6670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 11	curr_val_accuracy: 0.7255	curr_test_accuracy: 0.7146
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24483.3027	loss_val: 24483.2637	loss_test: 24483.2695	accuracy_train: 0.9029	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29235.1602	loss_val: 29235.2168	loss_test: 29235.1777	accuracy_train: 0.8643	accuracy_val: 0.8750	accuracy_test: 0.7353
[client 2]	loss_train: 25364.6719	loss_val: 25364.6992	loss_test: 25364.7402	accuracy_train: 0.6024	accuracy_val: 0.5455	accuracy_test: 0.5455
[client 3]	loss_train: 30139.3496	loss_val: 30139.2969	loss_test: 30139.3848	accuracy_train: 0.5031	accuracy_val: 0.4750	accuracy_test: 0.5122
[client 4]	loss_train: 6467.2231	loss_val: 6467.2729	loss_test: 6467.1948	accuracy_train: 0.6588	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 8117.3086	loss_val: 8117.3320	loss_test: 8117.3325	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 44636.6797	loss_val: 44636.6445	loss_test: 44636.7070	accuracy_train: 0.3824	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 24446.0234	loss_val: 24445.9961	loss_test: 24445.9941	accuracy_train: 0.6514	accuracy_val: 0.6944	accuracy_test: 0.7027
[client 8]	loss_train: 1270.2578	loss_val: 1270.3256	loss_test: 1270.2704	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57471.2812	loss_val: 57471.3711	loss_test: 57471.2734	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11370.2910	loss_val: 11370.1875	loss_test: 11370.2988	accuracy_train: 0.6460	accuracy_val: 0.7059	accuracy_test: 0.6857
[client 11]	loss_train: 1163.7837	loss_val: 1163.8295	loss_test: 1163.7523	accuracy_train: 0.6471	accuracy_val: 0.7188	accuracy_test: 0.6364
[client 12]	loss_train: 24085.2246	loss_val: 24085.2461	loss_test: 24085.2441	accuracy_train: 0.6780	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 197710.3125	loss_val: 197710.3281	loss_test: 197710.3750	accuracy_train: 0.9133	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11045.7314	loss_val: 11045.7158	loss_test: 11045.7529	accuracy_train: 0.4126	accuracy_val: 0.2941	accuracy_test: 0.4000
[client 15]	loss_train: 1091.1289	loss_val: 1091.1782	loss_test: 1091.2075	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4702.0664	loss_val: 4702.1533	loss_test: 4702.2051	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 15728.0410	loss_val: 15728.0596	loss_test: 15728.0039	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17561.7109	loss_val: 17561.7383	loss_test: 17561.7480	accuracy_train: 0.3971	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1195.1056	loss_val: 1195.1235	loss_test: 1195.1510	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 12	curr_val_accuracy: 0.7235	curr_test_accuracy: 0.7145
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 24803.3711	loss_val: 24803.3359	loss_test: 24803.3438	accuracy_train: 0.9126	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29044.3203	loss_val: 29044.3750	loss_test: 29044.3477	accuracy_train: 0.8760	accuracy_val: 0.8750	accuracy_test: 0.7059
[client 2]	loss_train: 27413.8242	loss_val: 27413.8633	loss_test: 27413.9004	accuracy_train: 0.6506	accuracy_val: 0.5455	accuracy_test: 0.6364
[client 3]	loss_train: 29512.5195	loss_val: 29512.4707	loss_test: 29512.5586	accuracy_train: 0.5126	accuracy_val: 0.4750	accuracy_test: 0.5122
[client 4]	loss_train: 6898.1899	loss_val: 6898.2485	loss_test: 6898.1655	accuracy_train: 0.6647	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 7876.3887	loss_val: 7876.4131	loss_test: 7876.4106	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46507.8906	loss_val: 46507.8516	loss_test: 46507.9297	accuracy_train: 0.3882	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 25318.7988	loss_val: 25318.7754	loss_test: 25318.7695	accuracy_train: 0.6514	accuracy_val: 0.6944	accuracy_test: 0.7027
[client 8]	loss_train: 1292.3053	loss_val: 1292.3722	loss_test: 1292.3182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57238.2266	loss_val: 57238.3398	loss_test: 57238.2227	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11405.6475	loss_val: 11405.5459	loss_test: 11405.6582	accuracy_train: 0.6314	accuracy_val: 0.6471	accuracy_test: 0.5714
[client 11]	loss_train: 1309.6631	loss_val: 1309.7095	loss_test: 1309.6266	accuracy_train: 0.6549	accuracy_val: 0.7188	accuracy_test: 0.6364
[client 12]	loss_train: 23765.4434	loss_val: 23765.4668	loss_test: 23765.4648	accuracy_train: 0.6780	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 199428.1719	loss_val: 199428.1875	loss_test: 199428.2500	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 11562.1143	loss_val: 11562.0977	loss_test: 11562.1436	accuracy_train: 0.4056	accuracy_val: 0.2941	accuracy_test: 0.3500
[client 15]	loss_train: 1229.8892	loss_val: 1229.9402	loss_test: 1229.9744	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4663.2622	loss_val: 4663.3574	loss_test: 4663.4170	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 16705.1152	loss_val: 16705.1406	loss_test: 16705.0801	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17771.1777	loss_val: 17771.2070	loss_test: 17771.2148	accuracy_train: 0.3971	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1232.5529	loss_val: 1232.5703	loss_test: 1232.5977	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 13	curr_val_accuracy: 0.7215	curr_test_accuracy: 0.7049
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25469.5840	loss_val: 25469.5527	loss_test: 25469.5625	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28726.5859	loss_val: 28726.6328	loss_test: 28726.6230	accuracy_train: 0.8837	accuracy_val: 0.8750	accuracy_test: 0.7353
[client 2]	loss_train: 30254.0820	loss_val: 30254.1309	loss_test: 30254.1660	accuracy_train: 0.7590	accuracy_val: 0.5455	accuracy_test: 0.4545
[client 3]	loss_train: 27901.7910	loss_val: 27901.7500	loss_test: 27901.8281	accuracy_train: 0.5094	accuracy_val: 0.4750	accuracy_test: 0.5122
[client 4]	loss_train: 7162.7861	loss_val: 7162.8540	loss_test: 7162.7666	accuracy_train: 0.6765	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 7700.7764	loss_val: 7700.8032	loss_test: 7700.7974	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48705.6953	loss_val: 48705.6523	loss_test: 48705.7383	accuracy_train: 0.3941	accuracy_val: 0.4545	accuracy_test: 0.4091
[client 7]	loss_train: 26427.8652	loss_val: 26427.8496	loss_test: 26427.8320	accuracy_train: 0.6514	accuracy_val: 0.6667	accuracy_test: 0.6757
[client 8]	loss_train: 1320.3713	loss_val: 1320.4368	loss_test: 1320.3853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60236.2578	loss_val: 60236.3867	loss_test: 60236.2539	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11514.6035	loss_val: 11514.5039	loss_test: 11514.6172	accuracy_train: 0.5876	accuracy_val: 0.6471	accuracy_test: 0.5714
[client 11]	loss_train: 1451.3807	loss_val: 1451.4264	loss_test: 1451.3387	accuracy_train: 0.6392	accuracy_val: 0.6875	accuracy_test: 0.6364
[client 12]	loss_train: 23631.2598	loss_val: 23631.2832	loss_test: 23631.2832	accuracy_train: 0.6780	accuracy_val: 0.7333	accuracy_test: 0.6471
[client 13]	loss_train: 201247.0781	loss_val: 201247.1094	loss_test: 201247.1719	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12031.5967	loss_val: 12031.5762	loss_test: 12031.6318	accuracy_train: 0.3706	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1362.1476	loss_val: 1362.1974	loss_test: 1362.2358	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4700.7798	loss_val: 4700.8813	loss_test: 4700.9497	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 17737.1426	loss_val: 17737.1738	loss_test: 17737.1094	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17917.4785	loss_val: 17917.5039	loss_test: 17917.5098	accuracy_train: 0.3971	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1247.3855	loss_val: 1247.4001	loss_test: 1247.4292	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 14	curr_val_accuracy: 0.7175	curr_test_accuracy: 0.6992
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26110.7988	loss_val: 26110.7695	loss_test: 26110.7793	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28799.7129	loss_val: 28799.7520	loss_test: 28799.7578	accuracy_train: 0.8876	accuracy_val: 0.8750	accuracy_test: 0.7353
[client 2]	loss_train: 32641.1035	loss_val: 32641.1641	loss_test: 32641.1953	accuracy_train: 0.7590	accuracy_val: 0.5455	accuracy_test: 0.4545
[client 3]	loss_train: 25724.0195	loss_val: 25723.9844	loss_test: 25724.0547	accuracy_train: 0.5157	accuracy_val: 0.4750	accuracy_test: 0.5122
[client 4]	loss_train: 7275.3774	loss_val: 7275.4546	loss_test: 7275.3652	accuracy_train: 0.6706	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 7719.9375	loss_val: 7719.9639	loss_test: 7719.9585	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49855.0547	loss_val: 49855.0078	loss_test: 49855.0938	accuracy_train: 0.4000	accuracy_val: 0.4091	accuracy_test: 0.4091
[client 7]	loss_train: 26968.1152	loss_val: 26968.1055	loss_test: 26968.0820	accuracy_train: 0.6585	accuracy_val: 0.6667	accuracy_test: 0.7027
[client 8]	loss_train: 1362.0952	loss_val: 1362.1581	loss_test: 1362.1112	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59537.8906	loss_val: 59538.0469	loss_test: 59537.8945	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11355.1777	loss_val: 11355.0820	loss_test: 11355.1924	accuracy_train: 0.5876	accuracy_val: 0.6176	accuracy_test: 0.5714
[client 11]	loss_train: 1571.3325	loss_val: 1571.3773	loss_test: 1571.2865	accuracy_train: 0.6275	accuracy_val: 0.6875	accuracy_test: 0.6061
[client 12]	loss_train: 23935.8477	loss_val: 23935.8730	loss_test: 23935.8770	accuracy_train: 0.6864	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 202873.7031	loss_val: 202873.7188	loss_test: 202873.7969	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12281.4053	loss_val: 12281.3809	loss_test: 12281.4453	accuracy_train: 0.3357	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1478.7179	loss_val: 1478.7654	loss_test: 1478.8057	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4780.9272	loss_val: 4781.0376	loss_test: 4781.1128	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 18108.2695	loss_val: 18108.3066	loss_test: 18108.2402	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17969.6445	loss_val: 17969.6660	loss_test: 17969.6719	accuracy_train: 0.3971	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1260.2306	loss_val: 1260.2437	loss_test: 1260.2722	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 15	curr_val_accuracy: 0.7135	curr_test_accuracy: 0.6975
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26375.4004	loss_val: 26375.3750	loss_test: 26375.3867	accuracy_train: 0.9417	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29151.7695	loss_val: 29151.8027	loss_test: 29151.8223	accuracy_train: 0.8876	accuracy_val: 0.8750	accuracy_test: 0.7353
[client 2]	loss_train: 34466.2344	loss_val: 34466.3047	loss_test: 34466.3359	accuracy_train: 0.7952	accuracy_val: 0.5455	accuracy_test: 0.4545
[client 3]	loss_train: 23528.7051	loss_val: 23528.6797	loss_test: 23528.7422	accuracy_train: 0.5157	accuracy_val: 0.4500	accuracy_test: 0.5122
[client 4]	loss_train: 7166.0728	loss_val: 7166.1592	loss_test: 7166.0698	accuracy_train: 0.6647	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 7825.4199	loss_val: 7825.4453	loss_test: 7825.4414	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 50108.8125	loss_val: 50108.7656	loss_test: 50108.8555	accuracy_train: 0.4059	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 26330.1992	loss_val: 26330.1973	loss_test: 26330.1660	accuracy_train: 0.6373	accuracy_val: 0.6389	accuracy_test: 0.7027
[client 8]	loss_train: 1401.9240	loss_val: 1401.9821	loss_test: 1401.9410	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58855.6289	loss_val: 58855.8047	loss_test: 58855.6328	accuracy_train: 0.7885	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11369.2861	loss_val: 11369.1953	loss_test: 11369.3018	accuracy_train: 0.5766	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1672.0164	loss_val: 1672.0594	loss_test: 1671.9666	accuracy_train: 0.6235	accuracy_val: 0.6875	accuracy_test: 0.6061
[client 12]	loss_train: 24124.2305	loss_val: 24124.2539	loss_test: 24124.2637	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 203592.6875	loss_val: 203592.7031	loss_test: 203592.7969	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12649.4180	loss_val: 12649.3906	loss_test: 12649.4590	accuracy_train: 0.3217	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1585.3414	loss_val: 1585.3855	loss_test: 1585.4288	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4879.4204	loss_val: 4879.5386	loss_test: 4879.6221	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 18007.3281	loss_val: 18007.3691	loss_test: 18007.3027	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 18209.1289	loss_val: 18209.1465	loss_test: 18209.1504	accuracy_train: 0.3971	accuracy_val: 0.3824	accuracy_test: 0.3714
[client 19]	loss_train: 1261.4500	loss_val: 1261.4620	loss_test: 1261.4907	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 16	curr_val_accuracy: 0.7075	curr_test_accuracy: 0.6976
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26301.6191	loss_val: 26301.5977	loss_test: 26301.6094	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 29769.1992	loss_val: 29769.2266	loss_test: 29769.2559	accuracy_train: 0.8760	accuracy_val: 0.8750	accuracy_test: 0.7647
[client 2]	loss_train: 36192.9883	loss_val: 36193.0742	loss_test: 36193.0977	accuracy_train: 0.8193	accuracy_val: 0.4545	accuracy_test: 0.4545
[client 3]	loss_train: 22934.1348	loss_val: 22934.1016	loss_test: 22934.1719	accuracy_train: 0.5094	accuracy_val: 0.5000	accuracy_test: 0.5366
[client 4]	loss_train: 6970.1577	loss_val: 6970.2524	loss_test: 6970.1631	accuracy_train: 0.6647	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 7796.8838	loss_val: 7796.9087	loss_test: 7796.9058	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49918.7266	loss_val: 49918.6758	loss_test: 49918.7773	accuracy_train: 0.4118	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 25681.2285	loss_val: 25681.2324	loss_test: 25681.1973	accuracy_train: 0.6232	accuracy_val: 0.5556	accuracy_test: 0.6757
[client 8]	loss_train: 1436.6691	loss_val: 1436.7227	loss_test: 1436.6873	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60167.1211	loss_val: 60167.3320	loss_test: 60167.1289	accuracy_train: 0.8077	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11461.8477	loss_val: 11461.7588	loss_test: 11461.8623	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1757.1969	loss_val: 1757.2411	loss_test: 1757.1459	accuracy_train: 0.6157	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 24237.5664	loss_val: 24237.5918	loss_test: 24237.6094	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 203440.9531	loss_val: 203440.9688	loss_test: 203441.0625	accuracy_train: 0.9031	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12525.2627	loss_val: 12525.2334	loss_test: 12525.3037	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1666.4330	loss_val: 1666.4742	loss_test: 1666.5199	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 4961.5225	loss_val: 4961.6465	loss_test: 4961.7378	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 17777.6719	loss_val: 17777.7148	loss_test: 17777.6504	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 18051.5566	loss_val: 18051.5684	loss_test: 18051.5703	accuracy_train: 0.4154	accuracy_val: 0.4412	accuracy_test: 0.3714
[client 19]	loss_train: 1263.8586	loss_val: 1263.8694	loss_test: 1263.8982	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 17	curr_val_accuracy: 0.7057	curr_test_accuracy: 0.6996
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26789.3262	loss_val: 26789.3066	loss_test: 26789.3184	accuracy_train: 0.9515	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 28150.8418	loss_val: 28150.8633	loss_test: 28150.8984	accuracy_train: 0.8915	accuracy_val: 0.8750	accuracy_test: 0.7647
[client 2]	loss_train: 38302.4258	loss_val: 38302.5195	loss_test: 38302.5391	accuracy_train: 0.8193	accuracy_val: 0.6364	accuracy_test: 0.4545
[client 3]	loss_train: 23493.7734	loss_val: 23493.7363	loss_test: 23493.8145	accuracy_train: 0.5000	accuracy_val: 0.4750	accuracy_test: 0.5366
[client 4]	loss_train: 6876.0073	loss_val: 6876.1079	loss_test: 6876.0225	accuracy_train: 0.6588	accuracy_val: 0.6190	accuracy_test: 0.6667
[client 5]	loss_train: 7578.0293	loss_val: 7578.0557	loss_test: 7578.0537	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49696.5664	loss_val: 49696.5234	loss_test: 49696.6250	accuracy_train: 0.4176	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 25130.1875	loss_val: 25130.1855	loss_test: 25130.1621	accuracy_train: 0.6021	accuracy_val: 0.5556	accuracy_test: 0.6486
[client 8]	loss_train: 1437.1586	loss_val: 1437.2074	loss_test: 1437.1779	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60768.2578	loss_val: 60768.4961	loss_test: 60768.2734	accuracy_train: 0.8269	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 11601.3408	loss_val: 11601.2568	loss_test: 11601.3555	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1832.1525	loss_val: 1832.1963	loss_test: 1832.1033	accuracy_train: 0.6157	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 24692.8125	loss_val: 24692.8379	loss_test: 24692.8613	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 205041.8281	loss_val: 205041.8438	loss_test: 205041.9375	accuracy_train: 0.9031	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12491.6709	loss_val: 12491.6416	loss_test: 12491.7129	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1748.4757	loss_val: 1748.5144	loss_test: 1748.5605	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5088.2490	loss_val: 5088.3804	loss_test: 5088.4795	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 17578.5098	loss_val: 17578.5566	loss_test: 17578.4922	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17655.8359	loss_val: 17655.8457	loss_test: 17655.8438	accuracy_train: 0.4522	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1268.0891	loss_val: 1268.0992	loss_test: 1268.1273	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 18	curr_val_accuracy: 0.7075	curr_test_accuracy: 0.7015
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26035.6348	loss_val: 26035.6152	loss_test: 26035.6309	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 27426.1387	loss_val: 27426.1543	loss_test: 27426.1953	accuracy_train: 0.8915	accuracy_val: 0.8750	accuracy_test: 0.7647
[client 2]	loss_train: 40446.9258	loss_val: 40447.0352	loss_test: 40447.0508	accuracy_train: 0.7952	accuracy_val: 0.6364	accuracy_test: 0.5455
[client 3]	loss_train: 24648.2559	loss_val: 24648.2129	loss_test: 24648.2969	accuracy_train: 0.5000	accuracy_val: 0.4750	accuracy_test: 0.5122
[client 4]	loss_train: 7089.4336	loss_val: 7089.5400	loss_test: 7089.4585	accuracy_train: 0.6412	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 7453.1978	loss_val: 7453.2251	loss_test: 7453.2236	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49224.7031	loss_val: 49224.6602	loss_test: 49224.7617	accuracy_train: 0.4235	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 24811.2539	loss_val: 24811.2656	loss_test: 24811.2285	accuracy_train: 0.6021	accuracy_val: 0.5556	accuracy_test: 0.6216
[client 8]	loss_train: 1439.7625	loss_val: 1439.8097	loss_test: 1439.7831	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62426.5312	loss_val: 62426.8086	loss_test: 62426.5508	accuracy_train: 0.8269	accuracy_val: 0.5714	accuracy_test: 0.7500
[client 10]	loss_train: 10886.9346	loss_val: 10886.8564	loss_test: 10886.9512	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1900.3077	loss_val: 1900.3516	loss_test: 1900.2612	accuracy_train: 0.6275	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 25724.8438	loss_val: 25724.8691	loss_test: 25724.9023	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 209963.7188	loss_val: 209963.7344	loss_test: 209963.8438	accuracy_train: 0.9031	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12188.5254	loss_val: 12188.4961	loss_test: 12188.5684	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1802.4456	loss_val: 1802.4819	loss_test: 1802.5277	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5238.4707	loss_val: 5238.6094	loss_test: 5238.7148	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 17610.7598	loss_val: 17610.8105	loss_test: 17610.7461	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17325.4355	loss_val: 17325.4473	loss_test: 17325.4434	accuracy_train: 0.5368	accuracy_val: 0.5000	accuracy_test: 0.4286
[client 19]	loss_train: 1273.0022	loss_val: 1273.0133	loss_test: 1273.0394	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 19	curr_val_accuracy: 0.7115	curr_test_accuracy: 0.6997
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25603.7168	loss_val: 25603.6973	loss_test: 25603.7148	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 27871.1309	loss_val: 27871.1445	loss_test: 27871.1934	accuracy_train: 0.8953	accuracy_val: 0.8750	accuracy_test: 0.7647
[client 2]	loss_train: 42008.3594	loss_val: 42008.4844	loss_test: 42008.4961	accuracy_train: 0.8072	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 24467.7383	loss_val: 24467.6934	loss_test: 24467.7812	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5122
[client 4]	loss_train: 7320.7065	loss_val: 7320.8169	loss_test: 7320.7422	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 7465.5435	loss_val: 7465.5713	loss_test: 7465.5713	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 49561.3086	loss_val: 49561.2734	loss_test: 49561.3633	accuracy_train: 0.4294	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 23915.0039	loss_val: 23915.0371	loss_test: 23914.9746	accuracy_train: 0.6056	accuracy_val: 0.5556	accuracy_test: 0.5946
[client 8]	loss_train: 1414.6953	loss_val: 1414.7406	loss_test: 1414.7162	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64892.0859	loss_val: 64892.4102	loss_test: 64892.1094	accuracy_train: 0.8462	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10725.4336	loss_val: 10725.3613	loss_test: 10725.4512	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 1968.3422	loss_val: 1968.3855	loss_test: 1968.2996	accuracy_train: 0.6314	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 26905.9883	loss_val: 26906.0117	loss_test: 26906.0547	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 217875.2656	loss_val: 217875.2656	loss_test: 217875.3906	accuracy_train: 0.9031	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12126.3691	loss_val: 12126.3389	loss_test: 12126.4121	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1831.9690	loss_val: 1832.0040	loss_test: 1832.0496	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5417.7197	loss_val: 5417.8667	loss_test: 5417.9775	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 17814.7578	loss_val: 17814.8086	loss_test: 17814.7461	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17066.0742	loss_val: 17066.0898	loss_test: 17066.0859	accuracy_train: 0.5147	accuracy_val: 0.5000	accuracy_test: 0.4000
[client 19]	loss_train: 1261.3014	loss_val: 1261.3124	loss_test: 1261.3381	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 20	curr_val_accuracy: 0.7133	curr_test_accuracy: 0.6975
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25490.3945	loss_val: 25490.3750	loss_test: 25490.3984	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 26623.1816	loss_val: 26623.1953	loss_test: 26623.2520	accuracy_train: 0.9070	accuracy_val: 0.8750	accuracy_test: 0.7647
[client 2]	loss_train: 43624.5742	loss_val: 43624.7148	loss_test: 43624.7227	accuracy_train: 0.8072	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 23365.6816	loss_val: 23365.6328	loss_test: 23365.7246	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5122
[client 4]	loss_train: 7320.6260	loss_val: 7320.7402	loss_test: 7320.6704	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 7431.6665	loss_val: 7431.6953	loss_test: 7431.6958	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 48459.5469	loss_val: 48459.5156	loss_test: 48459.6016	accuracy_train: 0.4353	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 24852.4746	loss_val: 24852.5215	loss_test: 24852.4453	accuracy_train: 0.6056	accuracy_val: 0.5556	accuracy_test: 0.6216
[client 8]	loss_train: 1384.2511	loss_val: 1384.2947	loss_test: 1384.2725	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66352.6797	loss_val: 66353.0625	loss_test: 66352.7109	accuracy_train: 0.8654	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11124.2383	loss_val: 11124.1719	loss_test: 11124.2568	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2046.9213	loss_val: 2046.9630	loss_test: 2046.8818	accuracy_train: 0.6314	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 29572.6875	loss_val: 29572.7090	loss_test: 29572.7617	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 223875.9219	loss_val: 223875.9219	loss_test: 223876.0469	accuracy_train: 0.9031	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 12516.8730	loss_val: 12516.8447	loss_test: 12516.9219	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1837.9912	loss_val: 1838.0259	loss_test: 1838.0713	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5513.8716	loss_val: 5514.0303	loss_test: 5514.1475	accuracy_train: 0.8036	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 18337.4785	loss_val: 18337.5332	loss_test: 18337.4688	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 17042.5430	loss_val: 17042.5586	loss_test: 17042.5605	accuracy_train: 0.5074	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1259.9725	loss_val: 1259.9833	loss_test: 1260.0092	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 21	curr_val_accuracy: 0.7093	curr_test_accuracy: 0.6994
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 25876.6855	loss_val: 25876.6660	loss_test: 25876.6934	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 24190.2930	loss_val: 24190.3066	loss_test: 24190.3672	accuracy_train: 0.8953	accuracy_val: 0.9062	accuracy_test: 0.7647
[client 2]	loss_train: 44578.2656	loss_val: 44578.4258	loss_test: 44578.4297	accuracy_train: 0.8193	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 24406.1348	loss_val: 24406.0898	loss_test: 24406.1816	accuracy_train: 0.5000	accuracy_val: 0.4750	accuracy_test: 0.5122
[client 4]	loss_train: 7262.7632	loss_val: 7262.8804	loss_test: 7262.8184	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 7432.8374	loss_val: 7432.8667	loss_test: 7432.8672	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47868.9336	loss_val: 47868.9023	loss_test: 47868.9844	accuracy_train: 0.4588	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 25834.6250	loss_val: 25834.6758	loss_test: 25834.5996	accuracy_train: 0.6092	accuracy_val: 0.5278	accuracy_test: 0.5946
[client 8]	loss_train: 1366.8624	loss_val: 1366.9041	loss_test: 1366.8835	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64938.9062	loss_val: 64939.3555	loss_test: 64938.9414	accuracy_train: 0.8846	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11143.8232	loss_val: 11143.7617	loss_test: 11143.8428	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2107.1782	loss_val: 2107.2188	loss_test: 2107.1423	accuracy_train: 0.6314	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 31954.9355	loss_val: 31954.9570	loss_test: 31955.0176	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 226606.1250	loss_val: 226606.1406	loss_test: 226606.2812	accuracy_train: 0.9031	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 13075.1025	loss_val: 13075.0771	loss_test: 13075.1562	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1833.5359	loss_val: 1833.5702	loss_test: 1833.6146	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5680.3950	loss_val: 5680.5635	loss_test: 5680.6885	accuracy_train: 0.8393	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 18533.7109	loss_val: 18533.7695	loss_test: 18533.7070	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 16465.3398	loss_val: 16465.3574	loss_test: 16465.3652	accuracy_train: 0.4853	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1257.8356	loss_val: 1257.8456	loss_test: 1257.8713	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 22	curr_val_accuracy: 0.7073	curr_test_accuracy: 0.6975
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26327.0664	loss_val: 26327.0449	loss_test: 26327.0781	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 22232.0566	loss_val: 22232.0703	loss_test: 22232.1328	accuracy_train: 0.8837	accuracy_val: 0.9062	accuracy_test: 0.7059
[client 2]	loss_train: 45029.9141	loss_val: 45030.0938	loss_test: 45030.0898	accuracy_train: 0.8193	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 24983.0527	loss_val: 24983.0098	loss_test: 24983.0996	accuracy_train: 0.4906	accuracy_val: 0.4500	accuracy_test: 0.5122
[client 4]	loss_train: 7158.8872	loss_val: 7159.0088	loss_test: 7158.9492	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7345.6621	loss_val: 7345.6924	loss_test: 7345.6948	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 47232.7695	loss_val: 47232.7461	loss_test: 47232.8125	accuracy_train: 0.4471	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 26619.3203	loss_val: 26619.3613	loss_test: 26619.2930	accuracy_train: 0.6162	accuracy_val: 0.5556	accuracy_test: 0.5676
[client 8]	loss_train: 1362.4238	loss_val: 1362.4641	loss_test: 1362.4438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 62390.3516	loss_val: 62390.8672	loss_test: 62390.3945	accuracy_train: 0.8846	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 10304.5098	loss_val: 10304.4512	loss_test: 10304.5312	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2160.2981	loss_val: 2160.3374	loss_test: 2160.2637	accuracy_train: 0.6314	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 33729.1562	loss_val: 33729.1836	loss_test: 33729.2500	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 227643.4062	loss_val: 227643.4219	loss_test: 227643.5469	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 13764.4268	loss_val: 13764.4053	loss_test: 13764.4854	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1838.7218	loss_val: 1838.7557	loss_test: 1838.7979	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 5903.9453	loss_val: 5904.1211	loss_test: 5904.2544	accuracy_train: 0.8571	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 18879.2598	loss_val: 18879.3203	loss_test: 18879.2598	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15920.9170	loss_val: 15920.9365	loss_test: 15920.9434	accuracy_train: 0.4816	accuracy_val: 0.5000	accuracy_test: 0.4000
[client 19]	loss_train: 1246.7346	loss_val: 1246.7435	loss_test: 1246.7703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 23	curr_val_accuracy: 0.7094	curr_test_accuracy: 0.6900
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 26545.1875	loss_val: 26545.1660	loss_test: 26545.2070	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 21863.4570	loss_val: 21863.4746	loss_test: 21863.5371	accuracy_train: 0.8682	accuracy_val: 0.9375	accuracy_test: 0.6765
[client 2]	loss_train: 45909.4961	loss_val: 45909.6992	loss_test: 45909.6875	accuracy_train: 0.8193	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 25030.5625	loss_val: 25030.5137	loss_test: 25030.6113	accuracy_train: 0.4811	accuracy_val: 0.4500	accuracy_test: 0.4878
[client 4]	loss_train: 6985.5518	loss_val: 6985.6821	loss_test: 6985.6162	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 7250.1489	loss_val: 7250.1816	loss_test: 7250.1855	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 46533.8438	loss_val: 46533.8203	loss_test: 46533.8672	accuracy_train: 0.4471	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 27811.1230	loss_val: 27811.1680	loss_test: 27811.0938	accuracy_train: 0.5986	accuracy_val: 0.5556	accuracy_test: 0.5676
[client 8]	loss_train: 1350.1422	loss_val: 1350.1816	loss_test: 1350.1616	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61194.7305	loss_val: 61195.3242	loss_test: 61194.7852	accuracy_train: 0.8846	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 9713.8750	loss_val: 9713.8193	loss_test: 9713.8994	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2180.6501	loss_val: 2180.6897	loss_test: 2180.6204	accuracy_train: 0.6235	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 34100.2539	loss_val: 34100.2812	loss_test: 34100.3594	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 230136.8125	loss_val: 230136.8281	loss_test: 230136.9688	accuracy_train: 0.9082	accuracy_val: 0.9200	accuracy_test: 0.8846
[client 14]	loss_train: 14041.1104	loss_val: 14041.0898	loss_test: 14041.1729	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1833.4893	loss_val: 1833.5238	loss_test: 1833.5631	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6040.1089	loss_val: 6040.2930	loss_test: 6040.4336	accuracy_train: 0.8571	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 18805.0684	loss_val: 18805.1348	loss_test: 18805.0742	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 15394.5977	loss_val: 15394.6172	loss_test: 15394.6289	accuracy_train: 0.5037	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1238.2780	loss_val: 1238.2859	loss_test: 1238.3135	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 24	curr_val_accuracy: 0.7095	curr_test_accuracy: 0.6861
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 27910.1484	loss_val: 27910.1250	loss_test: 27910.1758	accuracy_train: 0.9709	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 23444.8633	loss_val: 23444.8809	loss_test: 23444.9434	accuracy_train: 0.8643	accuracy_val: 0.9375	accuracy_test: 0.7647
[client 2]	loss_train: 46290.4648	loss_val: 46290.6875	loss_test: 46290.6680	accuracy_train: 0.8193	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 23818.0234	loss_val: 23817.9707	loss_test: 23818.0762	accuracy_train: 0.4717	accuracy_val: 0.4500	accuracy_test: 0.4878
[client 4]	loss_train: 7248.1689	loss_val: 7248.3125	loss_test: 7248.2383	accuracy_train: 0.6588	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 7231.4146	loss_val: 7231.4521	loss_test: 7231.4551	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 45213.5078	loss_val: 45213.4883	loss_test: 45213.5195	accuracy_train: 0.4471	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 28482.8750	loss_val: 28482.9316	loss_test: 28482.8477	accuracy_train: 0.5986	accuracy_val: 0.5556	accuracy_test: 0.5405
[client 8]	loss_train: 1344.4211	loss_val: 1344.4600	loss_test: 1344.4393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 58437.2383	loss_val: 58437.9062	loss_test: 58437.3008	accuracy_train: 0.8846	accuracy_val: 0.7143	accuracy_test: 0.8750
[client 10]	loss_train: 9663.6143	loss_val: 9663.5596	loss_test: 9663.6387	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2235.3625	loss_val: 2235.4016	loss_test: 2235.3367	accuracy_train: 0.6353	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 34970.0742	loss_val: 34970.1016	loss_test: 34970.1875	accuracy_train: 0.7034	accuracy_val: 0.7333	accuracy_test: 0.5294
[client 13]	loss_train: 228345.9375	loss_val: 228345.9688	loss_test: 228346.1094	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 13332.0088	loss_val: 13331.9893	loss_test: 13332.0752	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1826.4431	loss_val: 1826.4780	loss_test: 1826.5146	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6223.8135	loss_val: 6224.0059	loss_test: 6224.1543	accuracy_train: 0.8571	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 18900.5176	loss_val: 18900.5879	loss_test: 18900.5273	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14859.6318	loss_val: 14859.6514	loss_test: 14859.6670	accuracy_train: 0.5037	accuracy_val: 0.4706	accuracy_test: 0.4000
[client 19]	loss_train: 1230.7550	loss_val: 1230.7617	loss_test: 1230.7902	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 25	curr_val_accuracy: 0.7054	curr_test_accuracy: 0.6917
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 28784.9648	loss_val: 28784.9414	loss_test: 28785.0000	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23721.0176	loss_val: 23721.0371	loss_test: 23721.0957	accuracy_train: 0.8527	accuracy_val: 0.9062	accuracy_test: 0.7941
[client 2]	loss_train: 47865.9297	loss_val: 47866.1836	loss_test: 47866.1523	accuracy_train: 0.8193	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 23104.0625	loss_val: 23104.0078	loss_test: 23104.1172	accuracy_train: 0.4591	accuracy_val: 0.4250	accuracy_test: 0.4878
[client 4]	loss_train: 7669.6729	loss_val: 7669.8262	loss_test: 7669.7490	accuracy_train: 0.6588	accuracy_val: 0.4762	accuracy_test: 0.6250
[client 5]	loss_train: 7080.2256	loss_val: 7080.2681	loss_test: 7080.2715	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43415.9648	loss_val: 43415.9492	loss_test: 43415.9727	accuracy_train: 0.4412	accuracy_val: 0.4091	accuracy_test: 0.4545
[client 7]	loss_train: 28513.4531	loss_val: 28513.5234	loss_test: 28513.4336	accuracy_train: 0.6092	accuracy_val: 0.5556	accuracy_test: 0.5676
[client 8]	loss_train: 1348.2463	loss_val: 1348.2836	loss_test: 1348.2634	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56562.7188	loss_val: 56563.4805	loss_test: 56562.7891	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9840.3115	loss_val: 9840.2598	loss_test: 9840.3350	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2266.2622	loss_val: 2266.3003	loss_test: 2266.2402	accuracy_train: 0.6471	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 35737.9414	loss_val: 35737.9727	loss_test: 35738.0625	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 226143.4531	loss_val: 226143.5000	loss_test: 226143.6406	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 12480.5713	loss_val: 12480.5518	loss_test: 12480.6426	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1814.4535	loss_val: 1814.4885	loss_test: 1814.5243	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6393.2095	loss_val: 6393.4111	loss_test: 6393.5679	accuracy_train: 0.8571	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 19211.6855	loss_val: 19211.7598	loss_test: 19211.6992	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14607.4746	loss_val: 14607.4951	loss_test: 14607.5107	accuracy_train: 0.4669	accuracy_val: 0.4412	accuracy_test: 0.3714
[client 19]	loss_train: 1214.3193	loss_val: 1214.3254	loss_test: 1214.3536	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 26	curr_val_accuracy: 0.6993	curr_test_accuracy: 0.6954
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 29232.7988	loss_val: 29232.7773	loss_test: 29232.8457	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23590.4258	loss_val: 23590.4395	loss_test: 23590.4941	accuracy_train: 0.8023	accuracy_val: 0.8125	accuracy_test: 0.7941
[client 2]	loss_train: 49569.7539	loss_val: 49570.0391	loss_test: 49569.9922	accuracy_train: 0.8313	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 23284.6094	loss_val: 23284.5547	loss_test: 23284.6641	accuracy_train: 0.4528	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7744.2319	loss_val: 7744.3901	loss_test: 7744.3154	accuracy_train: 0.6588	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6957.9990	loss_val: 6958.0459	loss_test: 6958.0513	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42013.3711	loss_val: 42013.3633	loss_test: 42013.3828	accuracy_train: 0.4471	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 26566.5527	loss_val: 26566.6309	loss_test: 26566.5371	accuracy_train: 0.6021	accuracy_val: 0.5833	accuracy_test: 0.5676
[client 8]	loss_train: 1333.4320	loss_val: 1333.4672	loss_test: 1333.4476	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57972.4727	loss_val: 57973.3477	loss_test: 57972.5508	accuracy_train: 0.9038	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10486.6328	loss_val: 10486.5840	loss_test: 10486.6553	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2327.2720	loss_val: 2327.3083	loss_test: 2327.2522	accuracy_train: 0.6471	accuracy_val: 0.6875	accuracy_test: 0.6364
[client 12]	loss_train: 36320.1719	loss_val: 36320.2070	loss_test: 36320.3047	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 225618.7344	loss_val: 225618.7812	loss_test: 225618.9219	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 12334.4961	loss_val: 12334.4775	loss_test: 12334.5713	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1797.1881	loss_val: 1797.2224	loss_test: 1797.2579	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6509.0220	loss_val: 6509.2329	loss_test: 6509.3984	accuracy_train: 0.8750	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 19517.6465	loss_val: 19517.7266	loss_test: 19517.6660	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14413.2578	loss_val: 14413.2783	loss_test: 14413.2959	accuracy_train: 0.4265	accuracy_val: 0.4412	accuracy_test: 0.4286
[client 19]	loss_train: 1196.4038	loss_val: 1196.4097	loss_test: 1196.4387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 27	curr_val_accuracy: 0.6973	curr_test_accuracy: 0.6934
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30347.9121	loss_val: 30347.8887	loss_test: 30347.9668	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 23099.5000	loss_val: 23099.5137	loss_test: 23099.5586	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 50704.6602	loss_val: 50704.9844	loss_test: 50704.9180	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 23064.1387	loss_val: 23064.0859	loss_test: 23064.1914	accuracy_train: 0.4340	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7602.8994	loss_val: 7603.0640	loss_test: 7602.9878	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6916.1245	loss_val: 6916.1758	loss_test: 6916.1831	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41207.5820	loss_val: 41207.5859	loss_test: 41207.5977	accuracy_train: 0.4471	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 25440.5020	loss_val: 25440.5938	loss_test: 25440.4863	accuracy_train: 0.6056	accuracy_val: 0.5278	accuracy_test: 0.5676
[client 8]	loss_train: 1320.4639	loss_val: 1320.4972	loss_test: 1320.4790	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 63211.7852	loss_val: 63212.7852	loss_test: 63211.8711	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9886.4824	loss_val: 9886.4365	loss_test: 9886.5059	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2366.7244	loss_val: 2366.7600	loss_test: 2366.7078	accuracy_train: 0.6471	accuracy_val: 0.6875	accuracy_test: 0.6364
[client 12]	loss_train: 37233.4766	loss_val: 37233.5195	loss_test: 37233.6211	accuracy_train: 0.7034	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 224405.9062	loss_val: 224405.9531	loss_test: 224406.1094	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 12598.5518	loss_val: 12598.5332	loss_test: 12598.6289	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1792.8787	loss_val: 1792.9120	loss_test: 1792.9475	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6589.7588	loss_val: 6589.9775	loss_test: 6590.1528	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 19895.9023	loss_val: 19895.9844	loss_test: 19895.9297	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14093.2412	loss_val: 14093.2637	loss_test: 14093.2764	accuracy_train: 0.4154	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1190.2484	loss_val: 1190.2542	loss_test: 1190.2838	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 28	curr_val_accuracy: 0.6893	curr_test_accuracy: 0.6877
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31505.5996	loss_val: 31505.5762	loss_test: 31505.6582	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 22827.8496	loss_val: 22827.8652	loss_test: 22827.9023	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 50846.4844	loss_val: 50846.8438	loss_test: 50846.7617	accuracy_train: 0.8554	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 21642.5449	loss_val: 21642.4980	loss_test: 21642.5996	accuracy_train: 0.4277	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7558.0654	loss_val: 7558.2314	loss_test: 7558.1567	accuracy_train: 0.6647	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6855.2217	loss_val: 6855.2759	loss_test: 6855.2891	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41538.4805	loss_val: 41538.4922	loss_test: 41538.4922	accuracy_train: 0.4471	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 25557.7852	loss_val: 25557.8887	loss_test: 25557.7676	accuracy_train: 0.5880	accuracy_val: 0.5278	accuracy_test: 0.5676
[client 8]	loss_train: 1305.6643	loss_val: 1305.6968	loss_test: 1305.6785	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66395.0234	loss_val: 66396.1797	loss_test: 66395.1250	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 8944.7852	loss_val: 8944.7402	loss_test: 8944.8105	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2390.9810	loss_val: 2391.0159	loss_test: 2390.9675	accuracy_train: 0.6471	accuracy_val: 0.6875	accuracy_test: 0.6364
[client 12]	loss_train: 36111.1484	loss_val: 36111.1992	loss_test: 36111.3047	accuracy_train: 0.7203	accuracy_val: 0.6667	accuracy_test: 0.5294
[client 13]	loss_train: 223830.5312	loss_val: 223830.5781	loss_test: 223830.7500	accuracy_train: 0.9133	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 13117.6221	loss_val: 13117.6055	loss_test: 13117.7012	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1789.4686	loss_val: 1789.5016	loss_test: 1789.5385	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6577.7646	loss_val: 6577.9897	loss_test: 6578.1772	accuracy_train: 0.8750	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 19826.0527	loss_val: 19826.1367	loss_test: 19826.0840	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13566.2988	loss_val: 13566.3252	loss_test: 13566.3291	accuracy_train: 0.4191	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1183.7598	loss_val: 1183.7650	loss_test: 1183.7955	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 29	curr_val_accuracy: 0.6893	curr_test_accuracy: 0.6877
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33117.4844	loss_val: 33117.4609	loss_test: 33117.5547	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 21462.8281	loss_val: 21462.8457	loss_test: 21462.8770	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 50690.7969	loss_val: 50691.1914	loss_test: 50691.0977	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 20687.1426	loss_val: 20687.0996	loss_test: 20687.1973	accuracy_train: 0.4277	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7592.7720	loss_val: 7592.9341	loss_test: 7592.8691	accuracy_train: 0.6647	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6837.2031	loss_val: 6837.2583	loss_test: 6837.2773	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42355.1914	loss_val: 42355.2109	loss_test: 42355.1992	accuracy_train: 0.4529	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 27713.6992	loss_val: 27713.8027	loss_test: 27713.6719	accuracy_train: 0.5669	accuracy_val: 0.5000	accuracy_test: 0.5676
[client 8]	loss_train: 1288.2109	loss_val: 1288.2418	loss_test: 1288.2246	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 67851.5469	loss_val: 67852.8828	loss_test: 67851.6562	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9005.2344	loss_val: 9005.1895	loss_test: 9005.2598	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2390.5273	loss_val: 2390.5598	loss_test: 2390.5154	accuracy_train: 0.6431	accuracy_val: 0.6875	accuracy_test: 0.6364
[client 12]	loss_train: 35424.0273	loss_val: 35424.0859	loss_test: 35424.1914	accuracy_train: 0.7373	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 216832.1406	loss_val: 216832.2031	loss_test: 216832.3750	accuracy_train: 0.9184	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 13284.2061	loss_val: 13284.1904	loss_test: 13284.2891	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1788.0723	loss_val: 1788.1050	loss_test: 1788.1428	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6660.0342	loss_val: 6660.2642	loss_test: 6660.4634	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 20104.7422	loss_val: 20104.8301	loss_test: 20104.7812	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13070.5986	loss_val: 13070.6279	loss_test: 13070.6289	accuracy_train: 0.4265	accuracy_val: 0.4706	accuracy_test: 0.4286
[client 19]	loss_train: 1195.4648	loss_val: 1195.4700	loss_test: 1195.4999	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 30	curr_val_accuracy: 0.6933	curr_test_accuracy: 0.6914
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32095.1484	loss_val: 32095.1270	loss_test: 32095.2266	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20405.1543	loss_val: 20405.1738	loss_test: 20405.1992	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 52132.1211	loss_val: 52132.5469	loss_test: 52132.4453	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 20402.0273	loss_val: 20401.9824	loss_test: 20402.0840	accuracy_train: 0.4277	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 7710.2354	loss_val: 7710.3862	loss_test: 7710.3394	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6851.8276	loss_val: 6851.8828	loss_test: 6851.9048	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43155.3398	loss_val: 43155.3633	loss_test: 43155.3398	accuracy_train: 0.4471	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 28759.3652	loss_val: 28759.4648	loss_test: 28759.3281	accuracy_train: 0.5317	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1297.2537	loss_val: 1297.2823	loss_test: 1297.2667	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 70102.8047	loss_val: 70104.3359	loss_test: 70102.9297	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9653.8125	loss_val: 9653.7686	loss_test: 9653.8369	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2373.9785	loss_val: 2374.0105	loss_test: 2373.9692	accuracy_train: 0.6392	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 34951.9258	loss_val: 34951.9922	loss_test: 34952.0977	accuracy_train: 0.7712	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 213935.5469	loss_val: 213935.5938	loss_test: 213935.7656	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 12809.5420	loss_val: 12809.5273	loss_test: 12809.6270	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1787.4374	loss_val: 1787.4696	loss_test: 1787.5073	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6712.0449	loss_val: 6712.2769	loss_test: 6712.4897	accuracy_train: 0.8929	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 20551.9551	loss_val: 20552.0410	loss_test: 20552.0000	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12351.4980	loss_val: 12351.5264	loss_test: 12351.5283	accuracy_train: 0.4375	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1198.9236	loss_val: 1198.9283	loss_test: 1198.9586	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 31	curr_val_accuracy: 0.6894	curr_test_accuracy: 0.6894
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31227.8770	loss_val: 31227.8574	loss_test: 31227.9609	accuracy_train: 0.9709	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19858.4258	loss_val: 19858.4473	loss_test: 19858.4688	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 53181.2656	loss_val: 53181.7148	loss_test: 53181.6094	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 19066.9434	loss_val: 19066.8965	loss_test: 19067.0020	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7565.4395	loss_val: 7565.5747	loss_test: 7565.5483	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6826.4673	loss_val: 6826.5234	loss_test: 6826.5459	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43593.2344	loss_val: 43593.2617	loss_test: 43593.2305	accuracy_train: 0.4471	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 28555.7422	loss_val: 28555.8379	loss_test: 28555.6992	accuracy_train: 0.5246	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1286.7998	loss_val: 1286.8269	loss_test: 1286.8125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 69586.3672	loss_val: 69588.1250	loss_test: 69586.5000	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10510.4609	loss_val: 10510.4170	loss_test: 10510.4844	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2333.7969	loss_val: 2333.8284	loss_test: 2333.7908	accuracy_train: 0.6314	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 35210.2695	loss_val: 35210.3477	loss_test: 35210.4531	accuracy_train: 0.7288	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 211939.2031	loss_val: 211939.2500	loss_test: 211939.4219	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 12385.4355	loss_val: 12385.4199	loss_test: 12385.5215	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1775.6366	loss_val: 1775.6686	loss_test: 1775.7063	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6738.5947	loss_val: 6738.8286	loss_test: 6739.0552	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 20478.3281	loss_val: 20478.4102	loss_test: 20478.3750	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11366.4229	loss_val: 11366.4531	loss_test: 11366.4570	accuracy_train: 0.4596	accuracy_val: 0.4412	accuracy_test: 0.3714
[client 19]	loss_train: 1197.6326	loss_val: 1197.6367	loss_test: 1197.6667	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 32	curr_val_accuracy: 0.6914	curr_test_accuracy: 0.6857
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 30631.3359	loss_val: 30631.3184	loss_test: 30631.4277	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20112.7441	loss_val: 20112.7637	loss_test: 20112.7871	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 53953.0430	loss_val: 53953.5156	loss_test: 53953.4102	accuracy_train: 0.8675	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 19262.4473	loss_val: 19262.3984	loss_test: 19262.5059	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7089.9424	loss_val: 7090.0698	loss_test: 7090.0527	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6737.8125	loss_val: 6737.8716	loss_test: 6737.8955	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43272.1133	loss_val: 43272.1367	loss_test: 43272.0938	accuracy_train: 0.4471	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 28054.5176	loss_val: 28054.6152	loss_test: 28054.4785	accuracy_train: 0.5317	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1295.1890	loss_val: 1295.2152	loss_test: 1295.2023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 70928.9375	loss_val: 70930.9453	loss_test: 70929.0781	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11122.7041	loss_val: 11122.6621	loss_test: 11122.7275	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2332.9124	loss_val: 2332.9436	loss_test: 2332.9094	accuracy_train: 0.6275	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 35885.9766	loss_val: 35886.0703	loss_test: 35886.1797	accuracy_train: 0.7712	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 203031.5938	loss_val: 203031.6406	loss_test: 203031.8125	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11908.9424	loss_val: 11908.9268	loss_test: 11909.0293	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1765.6194	loss_val: 1765.6522	loss_test: 1765.6884	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6833.7031	loss_val: 6833.9399	loss_test: 6834.1812	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 20369.0664	loss_val: 20369.1426	loss_test: 20369.1133	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11198.1611	loss_val: 11198.1924	loss_test: 11198.2002	accuracy_train: 0.4375	accuracy_val: 0.4412	accuracy_test: 0.4000
[client 19]	loss_train: 1196.1298	loss_val: 1196.1335	loss_test: 1196.1627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 33	curr_val_accuracy: 0.6914	curr_test_accuracy: 0.6876
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31723.0625	loss_val: 31723.0488	loss_test: 31723.1641	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20323.2695	loss_val: 20323.2910	loss_test: 20323.3105	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 55457.3008	loss_val: 55457.7969	loss_test: 55457.6875	accuracy_train: 0.8795	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 19424.0293	loss_val: 19423.9805	loss_test: 19424.0859	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6899.5527	loss_val: 6899.6851	loss_test: 6899.6665	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6621.2632	loss_val: 6621.3223	loss_test: 6621.3525	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 43036.6484	loss_val: 43036.6719	loss_test: 43036.6250	accuracy_train: 0.4412	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 28172.8867	loss_val: 28172.9941	loss_test: 28172.8496	accuracy_train: 0.5493	accuracy_val: 0.4722	accuracy_test: 0.5676
[client 8]	loss_train: 1282.6882	loss_val: 1282.7140	loss_test: 1282.7024	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 67731.7344	loss_val: 67733.9688	loss_test: 67731.8906	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11173.5010	loss_val: 11173.4609	loss_test: 11173.5225	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2321.7981	loss_val: 2321.8279	loss_test: 2321.7981	accuracy_train: 0.6275	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 36827.6953	loss_val: 36827.8047	loss_test: 36827.9102	accuracy_train: 0.7881	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 196724.7812	loss_val: 196724.8281	loss_test: 196725.0156	accuracy_train: 0.9031	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11746.9482	loss_val: 11746.9316	loss_test: 11747.0352	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1747.3009	loss_val: 1747.3344	loss_test: 1747.3701	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6930.0356	loss_val: 6930.2764	loss_test: 6930.5312	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 21002.7598	loss_val: 21002.8301	loss_test: 21002.8066	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11623.8184	loss_val: 11623.8506	loss_test: 11623.8604	accuracy_train: 0.4301	accuracy_val: 0.4706	accuracy_test: 0.3714
[client 19]	loss_train: 1188.4386	loss_val: 1188.4417	loss_test: 1188.4701	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 34	curr_val_accuracy: 0.6934	curr_test_accuracy: 0.6875
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34021.0195	loss_val: 34021.0039	loss_test: 34021.1250	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20147.6016	loss_val: 20147.6230	loss_test: 20147.6445	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 56901.2852	loss_val: 56901.8086	loss_test: 56901.6953	accuracy_train: 0.8795	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 19178.2031	loss_val: 19178.1543	loss_test: 19178.2578	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7049.6724	loss_val: 7049.8145	loss_test: 7049.7910	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 6460.9829	loss_val: 6461.0371	loss_test: 6461.0801	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42796.7500	loss_val: 42796.7773	loss_test: 42796.7266	accuracy_train: 0.4412	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 28422.6758	loss_val: 28422.7949	loss_test: 28422.6504	accuracy_train: 0.5493	accuracy_val: 0.5000	accuracy_test: 0.5676
[client 8]	loss_train: 1277.4973	loss_val: 1277.5226	loss_test: 1277.5122	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66144.0156	loss_val: 66146.4531	loss_test: 66144.1797	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11112.8193	loss_val: 11112.7793	loss_test: 11112.8418	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2341.6682	loss_val: 2341.6965	loss_test: 2341.6729	accuracy_train: 0.6235	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 36765.7695	loss_val: 36765.8984	loss_test: 36766.0078	accuracy_train: 0.8051	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 193062.5625	loss_val: 193062.6094	loss_test: 193062.7969	accuracy_train: 0.9031	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11692.2207	loss_val: 11692.2031	loss_test: 11692.3076	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1737.2760	loss_val: 1737.3097	loss_test: 1737.3463	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7070.4624	loss_val: 7070.7085	loss_test: 7070.9756	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 22364.3164	loss_val: 22364.3867	loss_test: 22364.3672	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12348.7158	loss_val: 12348.7500	loss_test: 12348.7617	accuracy_train: 0.4301	accuracy_val: 0.4412	accuracy_test: 0.3714
[client 19]	loss_train: 1178.2976	loss_val: 1178.2998	loss_test: 1178.3279	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 35	curr_val_accuracy: 0.6933	curr_test_accuracy: 0.6892
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35758.5742	loss_val: 35758.5586	loss_test: 35758.6836	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19383.8945	loss_val: 19383.9160	loss_test: 19383.9355	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 58296.4180	loss_val: 58296.9609	loss_test: 58296.8477	accuracy_train: 0.8795	accuracy_val: 0.8182	accuracy_test: 0.5455
[client 3]	loss_train: 18737.1309	loss_val: 18737.0801	loss_test: 18737.1855	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7257.4131	loss_val: 7257.5649	loss_test: 7257.5361	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.7083
[client 5]	loss_train: 6724.5991	loss_val: 6724.6509	loss_test: 6724.7070	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42559.5859	loss_val: 42559.6172	loss_test: 42559.5664	accuracy_train: 0.4471	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 27782.6270	loss_val: 27782.7422	loss_test: 27782.6172	accuracy_train: 0.5458	accuracy_val: 0.5000	accuracy_test: 0.5405
[client 8]	loss_train: 1281.8174	loss_val: 1281.8422	loss_test: 1281.8324	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 65470.4258	loss_val: 65473.0586	loss_test: 65470.6016	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11087.4766	loss_val: 11087.4355	loss_test: 11087.5000	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2360.8467	loss_val: 2360.8743	loss_test: 2360.8569	accuracy_train: 0.6235	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 36495.0820	loss_val: 36495.2266	loss_test: 36495.3398	accuracy_train: 0.8305	accuracy_val: 0.8667	accuracy_test: 0.6471
[client 13]	loss_train: 195811.5938	loss_val: 195811.6719	loss_test: 195811.8594	accuracy_train: 0.9082	accuracy_val: 0.8800	accuracy_test: 0.8846
[client 14]	loss_train: 11662.0547	loss_val: 11662.0361	loss_test: 11662.1396	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1735.9875	loss_val: 1736.0219	loss_test: 1736.0593	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7233.1021	loss_val: 7233.3535	loss_test: 7233.6323	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 22658.1855	loss_val: 22658.2559	loss_test: 22658.2402	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13061.6689	loss_val: 13061.7031	loss_test: 13061.7236	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1177.3225	loss_val: 1177.3241	loss_test: 1177.3513	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 36	curr_val_accuracy: 0.6913	curr_test_accuracy: 0.6875
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37926.2734	loss_val: 37926.2617	loss_test: 37926.3984	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18261.0938	loss_val: 18261.1191	loss_test: 18261.1328	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 59030.5234	loss_val: 59031.0742	loss_test: 59030.9688	accuracy_train: 0.8795	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 18141.0859	loss_val: 18141.0332	loss_test: 18141.1406	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7353.3916	loss_val: 7353.5435	loss_test: 7353.5181	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6539.3320	loss_val: 6539.3857	loss_test: 6539.4438	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42024.9766	loss_val: 42025.0156	loss_test: 42024.9609	accuracy_train: 0.4529	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 26639.5801	loss_val: 26639.6855	loss_test: 26639.5645	accuracy_train: 0.5317	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1277.5763	loss_val: 1277.6003	loss_test: 1277.5916	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 67183.3047	loss_val: 67186.1797	loss_test: 67183.4844	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11272.7559	loss_val: 11272.7139	loss_test: 11272.7803	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2377.1460	loss_val: 2377.1724	loss_test: 2377.1606	accuracy_train: 0.6235	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 36118.1055	loss_val: 36118.2695	loss_test: 36118.3828	accuracy_train: 0.8390	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 200981.3594	loss_val: 200981.4375	loss_test: 200981.6406	accuracy_train: 0.9184	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12009.4980	loss_val: 12009.4824	loss_test: 12009.5820	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1716.3856	loss_val: 1716.4202	loss_test: 1716.4581	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7289.9194	loss_val: 7290.1772	loss_test: 7290.4644	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 21936.9414	loss_val: 21937.0117	loss_test: 21937.0000	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13311.2539	loss_val: 13311.2920	loss_test: 13311.3203	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1177.9275	loss_val: 1177.9294	loss_test: 1177.9558	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 37	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6839
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37638.7812	loss_val: 37638.7695	loss_test: 37638.9102	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 17571.4551	loss_val: 17571.4824	loss_test: 17571.4902	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 59681.5039	loss_val: 59682.0547	loss_test: 59681.9688	accuracy_train: 0.8795	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 17822.4785	loss_val: 17822.4297	loss_test: 17822.5312	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7238.4360	loss_val: 7238.5806	loss_test: 7238.5659	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6376.6865	loss_val: 6376.7456	loss_test: 6376.7979	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41615.8008	loss_val: 41615.8477	loss_test: 41615.7891	accuracy_train: 0.4529	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 26352.0352	loss_val: 26352.1367	loss_test: 26352.0117	accuracy_train: 0.5282	accuracy_val: 0.3889	accuracy_test: 0.5405
[client 8]	loss_train: 1277.4805	loss_val: 1277.5039	loss_test: 1277.4955	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 66858.9609	loss_val: 66862.0859	loss_test: 66859.1484	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11537.2305	loss_val: 11537.1885	loss_test: 11537.2529	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2406.0132	loss_val: 2406.0374	loss_test: 2406.0256	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 35913.8906	loss_val: 35914.0781	loss_test: 35914.1875	accuracy_train: 0.8390	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 210018.7812	loss_val: 210018.8750	loss_test: 210019.0781	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11887.9531	loss_val: 11887.9395	loss_test: 11888.0342	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1702.3506	loss_val: 1702.3839	loss_test: 1702.4242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7323.6831	loss_val: 7323.9453	loss_test: 7324.2427	accuracy_train: 0.9107	accuracy_val: 0.6250	accuracy_test: 0.5000
[client 17]	loss_train: 21461.6758	loss_val: 21461.7500	loss_test: 21461.7402	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13102.6035	loss_val: 13102.6416	loss_test: 13102.6768	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1179.2472	loss_val: 1179.2495	loss_test: 1179.2759	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 38	curr_val_accuracy: 0.6775	curr_test_accuracy: 0.6839
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38587.2227	loss_val: 38587.2109	loss_test: 38587.3594	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 17725.6523	loss_val: 17725.6816	loss_test: 17725.6836	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 58772.2266	loss_val: 58772.7695	loss_test: 58772.7148	accuracy_train: 0.8916	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 17200.5176	loss_val: 17200.4707	loss_test: 17200.5723	accuracy_train: 0.4277	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7061.3813	loss_val: 7061.5259	loss_test: 7061.5161	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6337.7070	loss_val: 6337.7729	loss_test: 6337.8184	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41307.4531	loss_val: 41307.5078	loss_test: 41307.4414	accuracy_train: 0.4529	accuracy_val: 0.3636	accuracy_test: 0.4545
[client 7]	loss_train: 27072.6465	loss_val: 27072.7461	loss_test: 27072.6270	accuracy_train: 0.5246	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1257.8866	loss_val: 1257.9092	loss_test: 1257.9012	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 64856.1680	loss_val: 64859.5508	loss_test: 64856.3594	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11052.4639	loss_val: 11052.4219	loss_test: 11052.4863	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2421.1848	loss_val: 2421.2078	loss_test: 2421.1965	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 36607.9219	loss_val: 36608.1367	loss_test: 36608.2344	accuracy_train: 0.8390	accuracy_val: 0.8000	accuracy_test: 0.6471
[client 13]	loss_train: 221344.9219	loss_val: 221345.0156	loss_test: 221345.2031	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11596.2539	loss_val: 11596.2441	loss_test: 11596.3350	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1688.0166	loss_val: 1688.0481	loss_test: 1688.0914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7366.6260	loss_val: 7366.8940	loss_test: 7367.2007	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 20950.0547	loss_val: 20950.1309	loss_test: 20950.1230	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12772.6123	loss_val: 12772.6445	loss_test: 12772.6855	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1185.3938	loss_val: 1185.3962	loss_test: 1185.4229	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 39	curr_val_accuracy: 0.6813	curr_test_accuracy: 0.6839
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39173.1055	loss_val: 39173.0977	loss_test: 39173.2422	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18368.4160	loss_val: 18368.4453	loss_test: 18368.4492	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 58097.6055	loss_val: 58098.1328	loss_test: 58098.1094	accuracy_train: 0.9036	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 16947.3516	loss_val: 16947.3066	loss_test: 16947.4062	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7236.7456	loss_val: 7236.8853	loss_test: 7236.8853	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6291.3296	loss_val: 6291.3970	loss_test: 6291.4399	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40913.4141	loss_val: 40913.4805	loss_test: 40913.4062	accuracy_train: 0.4588	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 28308.2305	loss_val: 28308.3418	loss_test: 28308.2129	accuracy_train: 0.5246	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1264.1260	loss_val: 1264.1469	loss_test: 1264.1404	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 61611.1797	loss_val: 61614.7891	loss_test: 61611.3711	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11058.7246	loss_val: 11058.6826	loss_test: 11058.7471	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2431.0588	loss_val: 2431.0818	loss_test: 2431.0737	accuracy_train: 0.6157	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 37841.0859	loss_val: 37841.3320	loss_test: 37841.4258	accuracy_train: 0.8390	accuracy_val: 0.8000	accuracy_test: 0.5882
[client 13]	loss_train: 230157.3281	loss_val: 230157.4219	loss_test: 230157.6094	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11746.6094	loss_val: 11746.6025	loss_test: 11746.6895	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1671.2980	loss_val: 1671.3274	loss_test: 1671.3734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7399.5845	loss_val: 7399.8599	loss_test: 7400.1758	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21309.1016	loss_val: 21309.1797	loss_test: 21309.1738	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12725.0830	loss_val: 12725.1123	loss_test: 12725.1543	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1169.4167	loss_val: 1169.4192	loss_test: 1169.4473	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 40	curr_val_accuracy: 0.6813	curr_test_accuracy: 0.6841
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38977.5352	loss_val: 38977.5273	loss_test: 38977.6680	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18574.0195	loss_val: 18574.0488	loss_test: 18574.0527	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 57952.6914	loss_val: 57953.2031	loss_test: 57953.2109	accuracy_train: 0.9036	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 16064.0537	loss_val: 16064.0117	loss_test: 16064.1084	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7613.3110	loss_val: 7613.4448	loss_test: 7613.4526	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6476.0635	loss_val: 6476.1304	loss_test: 6476.1729	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41430.0352	loss_val: 41430.1133	loss_test: 41430.0273	accuracy_train: 0.4588	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 29246.0117	loss_val: 29246.1484	loss_test: 29245.9961	accuracy_train: 0.5352	accuracy_val: 0.3611	accuracy_test: 0.5405
[client 8]	loss_train: 1269.7939	loss_val: 1269.8137	loss_test: 1269.8080	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57893.1484	loss_val: 57896.9805	loss_test: 57893.3398	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11046.8662	loss_val: 11046.8252	loss_test: 11046.8887	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2458.8811	loss_val: 2458.9036	loss_test: 2458.8987	accuracy_train: 0.6196	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 38871.6367	loss_val: 38871.9141	loss_test: 38871.9961	accuracy_train: 0.8390	accuracy_val: 0.8000	accuracy_test: 0.5882
[client 13]	loss_train: 238783.1562	loss_val: 238783.2656	loss_test: 238783.4375	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11969.0449	loss_val: 11969.0410	loss_test: 11969.1240	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1644.6788	loss_val: 1644.7068	loss_test: 1644.7546	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7491.2559	loss_val: 7491.5361	loss_test: 7491.8623	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21296.3555	loss_val: 21296.4297	loss_test: 21296.4277	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12746.5127	loss_val: 12746.5400	loss_test: 12746.5820	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1153.9275	loss_val: 1153.9297	loss_test: 1153.9586	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 41	curr_val_accuracy: 0.6773	curr_test_accuracy: 0.6823
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 41207.3047	loss_val: 41207.2969	loss_test: 41207.4336	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18013.4355	loss_val: 18013.4668	loss_test: 18013.4688	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 57565.0586	loss_val: 57565.5469	loss_test: 57565.5898	accuracy_train: 0.9036	accuracy_val: 0.7273	accuracy_test: 0.5455
[client 3]	loss_train: 16596.1875	loss_val: 16596.1426	loss_test: 16596.2422	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7594.2598	loss_val: 7594.3877	loss_test: 7594.4023	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6489.8564	loss_val: 6489.9204	loss_test: 6489.9658	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41383.8516	loss_val: 41383.9375	loss_test: 41383.8438	accuracy_train: 0.4588	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 28722.6211	loss_val: 28722.7734	loss_test: 28722.6133	accuracy_train: 0.5423	accuracy_val: 0.3889	accuracy_test: 0.5135
[client 8]	loss_train: 1273.2078	loss_val: 1273.2257	loss_test: 1273.2214	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54920.4336	loss_val: 54924.4609	loss_test: 54920.6172	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10585.1426	loss_val: 10585.0996	loss_test: 10585.1660	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2479.2556	loss_val: 2479.2749	loss_test: 2479.2793	accuracy_train: 0.6235	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 40458.5664	loss_val: 40458.8789	loss_test: 40458.9453	accuracy_train: 0.8390	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 245737.9688	loss_val: 245738.0781	loss_test: 245738.2344	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12219.9482	loss_val: 12219.9482	loss_test: 12220.0273	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1621.3981	loss_val: 1621.4252	loss_test: 1621.4735	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7594.5786	loss_val: 7594.8647	loss_test: 7595.1997	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21259.0840	loss_val: 21259.1504	loss_test: 21259.1523	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12989.2500	loss_val: 12989.2783	loss_test: 12989.3164	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1142.0936	loss_val: 1142.0955	loss_test: 1142.1240	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 42	curr_val_accuracy: 0.6773	curr_test_accuracy: 0.6803
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 42126.6133	loss_val: 42126.6055	loss_test: 42126.7383	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 17833.5508	loss_val: 17833.5820	loss_test: 17833.5801	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 55707.6367	loss_val: 55708.1055	loss_test: 55708.1836	accuracy_train: 0.9036	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15862.3848	loss_val: 15862.3359	loss_test: 15862.4414	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7355.8867	loss_val: 7356.0117	loss_test: 7356.0278	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6595.8384	loss_val: 6595.8970	loss_test: 6595.9502	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41644.1641	loss_val: 41644.2578	loss_test: 41644.1641	accuracy_train: 0.4588	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 28118.0820	loss_val: 28118.2129	loss_test: 28118.0664	accuracy_train: 0.5176	accuracy_val: 0.3611	accuracy_test: 0.5135
[client 8]	loss_train: 1283.4264	loss_val: 1283.4437	loss_test: 1283.4396	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55070.4531	loss_val: 55074.6289	loss_test: 55070.6250	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10078.9297	loss_val: 10078.8857	loss_test: 10078.9541	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2529.7908	loss_val: 2529.8066	loss_test: 2529.8181	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 41932.4648	loss_val: 41932.8203	loss_test: 41932.8672	accuracy_train: 0.8475	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 249428.5000	loss_val: 249428.6094	loss_test: 249428.7656	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12615.2461	loss_val: 12615.2510	loss_test: 12615.3262	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1606.9430	loss_val: 1606.9691	loss_test: 1607.0177	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7663.0806	loss_val: 7663.3726	loss_test: 7663.7129	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21523.6211	loss_val: 21523.6797	loss_test: 21523.6895	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13581.3516	loss_val: 13581.3828	loss_test: 13581.4160	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1141.8518	loss_val: 1141.8533	loss_test: 1141.8810	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 43	curr_val_accuracy: 0.6753	curr_test_accuracy: 0.6822
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 42025.1133	loss_val: 42025.1094	loss_test: 42025.2266	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 17930.2871	loss_val: 17930.3242	loss_test: 17930.3184	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 54589.9414	loss_val: 54590.3789	loss_test: 54590.4961	accuracy_train: 0.9036	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16894.7930	loss_val: 16894.7441	loss_test: 16894.8477	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7282.5762	loss_val: 7282.6968	loss_test: 7282.7153	accuracy_train: 0.6588	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6340.2515	loss_val: 6340.3086	loss_test: 6340.3672	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42414.8906	loss_val: 42414.9844	loss_test: 42414.8867	accuracy_train: 0.4824	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 28077.1016	loss_val: 28077.2090	loss_test: 28077.0781	accuracy_train: 0.5106	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1295.7446	loss_val: 1295.7622	loss_test: 1295.7574	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56329.0977	loss_val: 56333.3789	loss_test: 56329.2656	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10351.1660	loss_val: 10351.1221	loss_test: 10351.1924	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2583.0242	loss_val: 2583.0388	loss_test: 2583.0540	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 42683.1133	loss_val: 42683.5078	loss_test: 42683.5391	accuracy_train: 0.8475	accuracy_val: 0.7333	accuracy_test: 0.5882
[client 13]	loss_train: 235381.6406	loss_val: 235381.7656	loss_test: 235381.9219	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12349.0244	loss_val: 12349.0312	loss_test: 12349.1055	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1598.8695	loss_val: 1598.8950	loss_test: 1598.9432	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7732.9180	loss_val: 7733.2148	loss_test: 7733.5605	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21855.7617	loss_val: 21855.8086	loss_test: 21855.8320	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13791.9336	loss_val: 13791.9629	loss_test: 13791.9980	accuracy_train: 0.4044	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1138.6504	loss_val: 1138.6519	loss_test: 1138.6771	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 44	curr_val_accuracy: 0.6813	curr_test_accuracy: 0.6822
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 41723.3047	loss_val: 41723.3008	loss_test: 41723.4062	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 17911.9902	loss_val: 17912.0312	loss_test: 17912.0215	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 52336.6406	loss_val: 52337.0469	loss_test: 52337.2070	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 18629.7793	loss_val: 18629.7305	loss_test: 18629.8340	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7359.2476	loss_val: 7359.3662	loss_test: 7359.3848	accuracy_train: 0.6529	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6263.7529	loss_val: 6263.8096	loss_test: 6263.8696	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41881.5742	loss_val: 41881.6719	loss_test: 41881.5703	accuracy_train: 0.4882	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 28398.0898	loss_val: 28398.1895	loss_test: 28398.0645	accuracy_train: 0.5176	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1294.2999	loss_val: 1294.3181	loss_test: 1294.3123	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56191.7148	loss_val: 56195.9727	loss_test: 56191.8789	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10444.1533	loss_val: 10444.1074	loss_test: 10444.1816	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2578.5828	loss_val: 2578.5979	loss_test: 2578.6118	accuracy_train: 0.6235	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 43213.4883	loss_val: 43213.9258	loss_test: 43213.9297	accuracy_train: 0.8475	accuracy_val: 0.6667	accuracy_test: 0.5882
[client 13]	loss_train: 226803.7812	loss_val: 226803.9062	loss_test: 226804.0625	accuracy_train: 0.9184	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11736.0537	loss_val: 11736.0635	loss_test: 11736.1367	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1595.6584	loss_val: 1595.6841	loss_test: 1595.7310	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7724.5483	loss_val: 7724.8496	loss_test: 7725.2026	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21374.3574	loss_val: 21374.3906	loss_test: 21374.4258	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13341.3779	loss_val: 13341.4092	loss_test: 13341.4473	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1130.5447	loss_val: 1130.5460	loss_test: 1130.5695	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 45	curr_val_accuracy: 0.6812	curr_test_accuracy: 0.6822
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 40281.0039	loss_val: 40281.0039	loss_test: 40281.0898	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 17426.9121	loss_val: 17426.9551	loss_test: 17426.9414	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 50978.8555	loss_val: 50979.2500	loss_test: 50979.4258	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 19042.9922	loss_val: 19042.9492	loss_test: 19043.0469	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7408.0347	loss_val: 7408.1455	loss_test: 7408.1680	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 6391.4893	loss_val: 6391.5493	loss_test: 6391.6069	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41219.0586	loss_val: 41219.1562	loss_test: 41219.0547	accuracy_train: 0.4882	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 29259.1328	loss_val: 29259.2344	loss_test: 29259.1055	accuracy_train: 0.5070	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1289.2578	loss_val: 1289.2767	loss_test: 1289.2704	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 57631.4453	loss_val: 57635.7070	loss_test: 57631.5977	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10502.6641	loss_val: 10502.6162	loss_test: 10502.6943	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2541.9390	loss_val: 2541.9565	loss_test: 2541.9641	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 43211.2852	loss_val: 43211.7734	loss_test: 43211.7461	accuracy_train: 0.8390	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 226340.7656	loss_val: 226340.8906	loss_test: 226341.0469	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11339.6885	loss_val: 11339.7061	loss_test: 11339.7744	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1590.0187	loss_val: 1590.0442	loss_test: 1590.0902	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7748.3779	loss_val: 7748.6826	loss_test: 7749.0420	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21236.3750	loss_val: 21236.4004	loss_test: 21236.4473	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12884.3906	loss_val: 12884.4268	loss_test: 12884.4668	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1120.0959	loss_val: 1120.0970	loss_test: 1120.1201	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 46	curr_val_accuracy: 0.6752	curr_test_accuracy: 0.6803
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39323.3320	loss_val: 39323.3320	loss_test: 39323.4102	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 17541.2656	loss_val: 17541.3105	loss_test: 17541.3008	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 49422.3906	loss_val: 49422.7812	loss_test: 49422.9766	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 18731.8555	loss_val: 18731.8145	loss_test: 18731.9121	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7308.1929	loss_val: 7308.2896	loss_test: 7308.3198	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 5666.5591	loss_val: 5666.6191	loss_test: 5666.6689	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40933.7500	loss_val: 40933.8516	loss_test: 40933.7461	accuracy_train: 0.4882	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 29949.7109	loss_val: 29949.8223	loss_test: 29949.6836	accuracy_train: 0.5000	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1278.1279	loss_val: 1278.1467	loss_test: 1278.1403	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 60226.9805	loss_val: 60231.1680	loss_test: 60227.1289	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11166.8320	loss_val: 11166.7852	loss_test: 11166.8613	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2551.6772	loss_val: 2551.6973	loss_test: 2551.6975	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 43407.7969	loss_val: 43408.3398	loss_test: 43408.2773	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 237542.2031	loss_val: 237542.3438	loss_test: 237542.5000	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11026.9902	loss_val: 11027.0098	loss_test: 11027.0742	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1580.5459	loss_val: 1580.5717	loss_test: 1580.6165	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7686.0200	loss_val: 7686.3267	loss_test: 7686.6943	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22259.3398	loss_val: 22259.3652	loss_test: 22259.4199	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12885.9463	loss_val: 12885.9844	loss_test: 12886.0283	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1113.7440	loss_val: 1113.7449	loss_test: 1113.7693	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 47	curr_val_accuracy: 0.6752	curr_test_accuracy: 0.6821
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39506.2344	loss_val: 39506.2383	loss_test: 39506.3008	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18248.4609	loss_val: 18248.5098	loss_test: 18248.5078	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48880.1719	loss_val: 48880.5742	loss_test: 48880.7695	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 19039.0566	loss_val: 19039.0176	loss_test: 19039.1133	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7178.5107	loss_val: 7178.6060	loss_test: 7178.6318	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6081.4253	loss_val: 6081.4883	loss_test: 6081.5356	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40834.2383	loss_val: 40834.3438	loss_test: 40834.2266	accuracy_train: 0.4882	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 30103.0801	loss_val: 30103.2012	loss_test: 30103.0527	accuracy_train: 0.4789	accuracy_val: 0.4167	accuracy_test: 0.4324
[client 8]	loss_train: 1271.4568	loss_val: 1271.4751	loss_test: 1271.4690	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 59607.5000	loss_val: 59611.7461	loss_test: 59607.6445	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11889.8945	loss_val: 11889.8506	loss_test: 11889.9238	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2548.7783	loss_val: 2548.7998	loss_test: 2548.7969	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 43621.6797	loss_val: 43622.2852	loss_test: 43622.1875	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 246499.9062	loss_val: 246500.0469	loss_test: 246500.1875	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10809.0850	loss_val: 10809.1064	loss_test: 10809.1699	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1569.0299	loss_val: 1569.0558	loss_test: 1569.0995	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7569.0518	loss_val: 7569.3613	loss_test: 7569.7373	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22537.4590	loss_val: 22537.4824	loss_test: 22537.5430	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12869.3721	loss_val: 12869.4131	loss_test: 12869.4541	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1100.6512	loss_val: 1100.6516	loss_test: 1100.6774	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 48	curr_val_accuracy: 0.6752	curr_test_accuracy: 0.6782
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39325.2734	loss_val: 39325.2773	loss_test: 39325.3281	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18904.2031	loss_val: 18904.2520	loss_test: 18904.2637	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 49070.3320	loss_val: 49070.7500	loss_test: 49070.9414	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 19061.3945	loss_val: 19061.3555	loss_test: 19061.4492	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7039.4624	loss_val: 7039.5669	loss_test: 7039.5791	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6611.4731	loss_val: 6611.5400	loss_test: 6611.5845	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40718.1914	loss_val: 40718.3086	loss_test: 40718.1875	accuracy_train: 0.4882	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 29355.8477	loss_val: 29355.9766	loss_test: 29355.8125	accuracy_train: 0.4824	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1262.6595	loss_val: 1262.6772	loss_test: 1262.6716	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55617.6055	loss_val: 55621.9180	loss_test: 55617.7461	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11642.0098	loss_val: 11641.9688	loss_test: 11642.0371	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2574.6663	loss_val: 2574.6907	loss_test: 2574.6855	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 43566.6523	loss_val: 43567.3242	loss_test: 43567.1836	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.5882
[client 13]	loss_train: 250474.6094	loss_val: 250474.7656	loss_test: 250474.9062	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10881.1797	loss_val: 10881.2070	loss_test: 10881.2656	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1566.3097	loss_val: 1566.3356	loss_test: 1566.3774	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7401.2905	loss_val: 7401.6021	loss_test: 7401.9844	accuracy_train: 0.9107	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22434.5625	loss_val: 22434.5781	loss_test: 22434.6465	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12941.4268	loss_val: 12941.4697	loss_test: 12941.5000	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1100.6981	loss_val: 1100.6984	loss_test: 1100.7250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 49	curr_val_accuracy: 0.6752	curr_test_accuracy: 0.6821
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 41443.0586	loss_val: 41443.0625	loss_test: 41443.1016	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19217.6211	loss_val: 19217.6660	loss_test: 19217.6914	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 50013.8984	loss_val: 50014.3398	loss_test: 50014.5234	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 18832.7871	loss_val: 18832.7500	loss_test: 18832.8438	accuracy_train: 0.4434	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 6764.4810	loss_val: 6764.5820	loss_test: 6764.5991	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6539.3975	loss_val: 6539.4658	loss_test: 6539.5117	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41220.2461	loss_val: 41220.3750	loss_test: 41220.2422	accuracy_train: 0.4941	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 28233.6348	loss_val: 28233.7676	loss_test: 28233.6016	accuracy_train: 0.4930	accuracy_val: 0.3611	accuracy_test: 0.5135
[client 8]	loss_train: 1258.0183	loss_val: 1258.0356	loss_test: 1258.0306	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52291.6445	loss_val: 52295.9297	loss_test: 52291.7812	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11008.8379	loss_val: 11008.7969	loss_test: 11008.8633	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2593.8755	loss_val: 2593.9011	loss_test: 2593.8989	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 42981.4336	loss_val: 42982.1602	loss_test: 42981.9805	accuracy_train: 0.8475	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 244095.4219	loss_val: 244095.5781	loss_test: 244095.7344	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11414.4033	loss_val: 11414.4336	loss_test: 11414.4873	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1565.9857	loss_val: 1566.0122	loss_test: 1566.0521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7232.5571	loss_val: 7232.8711	loss_test: 7233.2598	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22427.6133	loss_val: 22427.6191	loss_test: 22427.7012	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12854.7637	loss_val: 12854.8105	loss_test: 12854.8301	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1102.3365	loss_val: 1102.3367	loss_test: 1102.3639	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 50	curr_val_accuracy: 0.6692	curr_test_accuracy: 0.6858
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37219.8008	loss_val: 37219.8086	loss_test: 37219.8438	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19437.8262	loss_val: 19437.8672	loss_test: 19437.9082	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 51101.8242	loss_val: 51102.2773	loss_test: 51102.4609	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 18196.6738	loss_val: 18196.6387	loss_test: 18196.7305	accuracy_train: 0.4434	accuracy_val: 0.4250	accuracy_test: 0.4146
[client 4]	loss_train: 6673.2656	loss_val: 6673.3540	loss_test: 6673.3906	accuracy_train: 0.6412	accuracy_val: 0.5238	accuracy_test: 0.5833
[client 5]	loss_train: 6240.0674	loss_val: 6240.1357	loss_test: 6240.1914	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41868.3125	loss_val: 41868.4609	loss_test: 41868.3086	accuracy_train: 0.5000	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 27188.5410	loss_val: 27188.6680	loss_test: 27188.5176	accuracy_train: 0.5035	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1256.8568	loss_val: 1256.8733	loss_test: 1256.8689	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49814.0547	loss_val: 49818.3984	loss_test: 49814.1836	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10402.6494	loss_val: 10402.6104	loss_test: 10402.6748	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2600.0483	loss_val: 2600.0764	loss_test: 2600.0823	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 41583.4219	loss_val: 41584.2031	loss_test: 41583.9844	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 234128.6094	loss_val: 234128.7656	loss_test: 234128.9375	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11831.7783	loss_val: 11831.8105	loss_test: 11831.8613	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1561.2264	loss_val: 1561.2537	loss_test: 1561.2917	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7087.8281	loss_val: 7088.1475	loss_test: 7088.5425	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22783.9434	loss_val: 22783.9512	loss_test: 22784.0410	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13421.2002	loss_val: 13421.2559	loss_test: 13421.2676	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1106.5903	loss_val: 1106.5906	loss_test: 1106.6173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 51	curr_val_accuracy: 0.6752	curr_test_accuracy: 0.6822
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38655.6719	loss_val: 38655.6836	loss_test: 38655.7070	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19121.0859	loss_val: 19121.1289	loss_test: 19121.1816	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 49350.7266	loss_val: 49351.1953	loss_test: 49351.3711	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 16768.3125	loss_val: 16768.2734	loss_test: 16768.3691	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6527.3047	loss_val: 6527.3779	loss_test: 6527.4316	accuracy_train: 0.6294	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 6375.1353	loss_val: 6375.2041	loss_test: 6375.2666	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41961.7461	loss_val: 41961.9180	loss_test: 41961.7461	accuracy_train: 0.5118	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 26766.7031	loss_val: 26766.8242	loss_test: 26766.6836	accuracy_train: 0.5070	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1254.5741	loss_val: 1254.5895	loss_test: 1254.5861	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 48096.1602	loss_val: 48100.6680	loss_test: 48096.2812	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10143.1260	loss_val: 10143.0869	loss_test: 10143.1514	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2607.2507	loss_val: 2607.2795	loss_test: 2607.2930	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 40788.1797	loss_val: 40789.0078	loss_test: 40788.7656	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 227924.0312	loss_val: 227924.1875	loss_test: 227924.3594	accuracy_train: 0.9184	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12303.4463	loss_val: 12303.4814	loss_test: 12303.5322	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1549.0608	loss_val: 1549.0885	loss_test: 1549.1260	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7029.7554	loss_val: 7030.0796	loss_test: 7030.4795	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 22363.3105	loss_val: 22363.3145	loss_test: 22363.4141	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14457.3760	loss_val: 14457.4336	loss_test: 14457.4385	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1107.1649	loss_val: 1107.1653	loss_test: 1107.1910	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 52	curr_val_accuracy: 0.6792	curr_test_accuracy: 0.6822
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37675.8398	loss_val: 37675.8516	loss_test: 37675.8672	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18854.2734	loss_val: 18854.3203	loss_test: 18854.3750	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46032.4336	loss_val: 46032.9375	loss_test: 46033.0859	accuracy_train: 0.9036	accuracy_val: 0.8182	accuracy_test: 0.6364
[client 3]	loss_train: 17032.0000	loss_val: 17031.9570	loss_test: 17032.0605	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6515.2441	loss_val: 6515.3130	loss_test: 6515.3716	accuracy_train: 0.6353	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6675.1094	loss_val: 6675.1802	loss_test: 6675.2397	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 42085.3242	loss_val: 42085.5195	loss_test: 42085.3281	accuracy_train: 0.5059	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 26980.4453	loss_val: 26980.5723	loss_test: 26980.4355	accuracy_train: 0.4930	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1245.1328	loss_val: 1245.1477	loss_test: 1245.1447	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46699.5312	loss_val: 46704.1758	loss_test: 46699.6523	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10432.8262	loss_val: 10432.7842	loss_test: 10432.8506	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2613.9907	loss_val: 2614.0186	loss_test: 2614.0374	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 40561.6133	loss_val: 40562.4883	loss_test: 40562.2227	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 222188.3125	loss_val: 222188.4531	loss_test: 222188.6406	accuracy_train: 0.9184	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 12416.6777	loss_val: 12416.7158	loss_test: 12416.7656	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1539.9412	loss_val: 1539.9692	loss_test: 1540.0067	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 7007.0342	loss_val: 7007.3638	loss_test: 7007.7627	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 21578.4941	loss_val: 21578.5000	loss_test: 21578.6074	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14972.6035	loss_val: 14972.6631	loss_test: 14972.6611	accuracy_train: 0.4081	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1112.3732	loss_val: 1112.3738	loss_test: 1112.3973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 53	curr_val_accuracy: 0.6792	curr_test_accuracy: 0.6821
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35950.5000	loss_val: 35950.5156	loss_test: 35950.5234	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18863.5488	loss_val: 18863.5996	loss_test: 18863.6543	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43574.5117	loss_val: 43575.0742	loss_test: 43575.1719	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17206.9434	loss_val: 17206.8965	loss_test: 17207.0039	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6766.1948	loss_val: 6766.2646	loss_test: 6766.3276	accuracy_train: 0.6353	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6131.4297	loss_val: 6131.4966	loss_test: 6131.5684	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41232.7930	loss_val: 41233.0039	loss_test: 41232.8008	accuracy_train: 0.5176	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 27890.1152	loss_val: 27890.2520	loss_test: 27890.1094	accuracy_train: 0.4683	accuracy_val: 0.3889	accuracy_test: 0.4324
[client 8]	loss_train: 1228.6365	loss_val: 1228.6506	loss_test: 1228.6481	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46435.1250	loss_val: 46439.9062	loss_test: 46435.2461	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10629.5107	loss_val: 10629.4648	loss_test: 10629.5342	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2633.4084	loss_val: 2633.4365	loss_test: 2633.4565	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 40258.1914	loss_val: 40259.1250	loss_test: 40258.8203	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 211371.4219	loss_val: 211371.5625	loss_test: 211371.7500	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11755.4863	loss_val: 11755.5273	loss_test: 11755.5771	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1533.7463	loss_val: 1533.7743	loss_test: 1533.8123	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6948.3623	loss_val: 6948.6987	loss_test: 6949.0957	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21662.1406	loss_val: 21662.1504	loss_test: 21662.2637	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 14738.1670	loss_val: 14738.2324	loss_test: 14738.2227	accuracy_train: 0.4081	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1104.4861	loss_val: 1104.4867	loss_test: 1104.5083	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 54	curr_val_accuracy: 0.6753	curr_test_accuracy: 0.6820
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35507.6523	loss_val: 35507.6719	loss_test: 35507.6836	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18766.9453	loss_val: 18766.9980	loss_test: 18767.0527	accuracy_train: 0.7519	accuracy_val: 0.7500	accuracy_test: 0.7647
[client 2]	loss_train: 43364.2422	loss_val: 43364.8594	loss_test: 43364.9062	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17674.3613	loss_val: 17674.3145	loss_test: 17674.4219	accuracy_train: 0.4371	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7186.3438	loss_val: 7186.4019	loss_test: 7186.4790	accuracy_train: 0.6353	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6056.6465	loss_val: 6056.7119	loss_test: 6056.7949	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40879.2188	loss_val: 40879.4375	loss_test: 40879.2266	accuracy_train: 0.5176	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 28067.9180	loss_val: 28068.0605	loss_test: 28067.9004	accuracy_train: 0.4472	accuracy_val: 0.3889	accuracy_test: 0.4054
[client 8]	loss_train: 1222.9852	loss_val: 1222.9987	loss_test: 1222.9965	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 45569.1758	loss_val: 45574.1094	loss_test: 45569.2969	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10931.3350	loss_val: 10931.2842	loss_test: 10931.3594	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2652.0200	loss_val: 2652.0498	loss_test: 2652.0671	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 39219.4453	loss_val: 39220.4258	loss_test: 39220.0898	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 208892.9062	loss_val: 208893.0469	loss_test: 208893.2031	accuracy_train: 0.9184	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 11134.9424	loss_val: 11134.9854	loss_test: 11135.0352	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1530.1578	loss_val: 1530.1851	loss_test: 1530.2234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6871.6318	loss_val: 6871.9746	loss_test: 6872.3696	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22373.6953	loss_val: 22373.6973	loss_test: 22373.8262	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13823.4385	loss_val: 13823.5117	loss_test: 13823.5000	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1108.3274	loss_val: 1108.3282	loss_test: 1108.3486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 55	curr_val_accuracy: 0.6753	curr_test_accuracy: 0.6819
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35684.8828	loss_val: 35684.9102	loss_test: 35684.9219	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18956.7559	loss_val: 18956.8066	loss_test: 18956.8633	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7647
[client 2]	loss_train: 45144.6641	loss_val: 45145.3438	loss_test: 45145.3398	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 18304.5723	loss_val: 18304.5273	loss_test: 18304.6309	accuracy_train: 0.4371	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6944.4097	loss_val: 6944.4634	loss_test: 6944.5425	accuracy_train: 0.6412	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6076.1982	loss_val: 6076.2588	loss_test: 6076.3491	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41231.8438	loss_val: 41232.0781	loss_test: 41231.8633	accuracy_train: 0.5235	accuracy_val: 0.3636	accuracy_test: 0.6364
[client 7]	loss_train: 27040.1211	loss_val: 27040.2617	loss_test: 27040.1055	accuracy_train: 0.4577	accuracy_val: 0.3889	accuracy_test: 0.4324
[client 8]	loss_train: 1224.7809	loss_val: 1224.7939	loss_test: 1224.7917	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 46494.1641	loss_val: 46499.2578	loss_test: 46494.2852	accuracy_train: 0.9423	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10770.3721	loss_val: 10770.3203	loss_test: 10770.3965	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2669.3784	loss_val: 2669.4065	loss_test: 2669.4243	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 38501.6992	loss_val: 38502.7344	loss_test: 38502.3555	accuracy_train: 0.8559	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 210339.3438	loss_val: 210339.4531	loss_test: 210339.6094	accuracy_train: 0.9184	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10849.2451	loss_val: 10849.2891	loss_test: 10849.3389	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1517.6852	loss_val: 1517.7123	loss_test: 1517.7502	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6776.5679	loss_val: 6776.9155	loss_test: 6777.3086	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22195.7070	loss_val: 22195.6992	loss_test: 22195.8418	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13220.5020	loss_val: 13220.5820	loss_test: 13220.5674	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1100.5879	loss_val: 1100.5887	loss_test: 1100.6090	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 56	curr_val_accuracy: 0.6753	curr_test_accuracy: 0.6878
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35513.5703	loss_val: 35513.6016	loss_test: 35513.6172	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19516.0801	loss_val: 19516.1309	loss_test: 19516.1895	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7647
[client 2]	loss_train: 46021.7578	loss_val: 46022.4922	loss_test: 46022.4453	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 18553.9141	loss_val: 18553.8691	loss_test: 18553.9727	accuracy_train: 0.4371	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6828.4990	loss_val: 6828.5552	loss_test: 6828.6309	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6169.9556	loss_val: 6170.0029	loss_test: 6170.1074	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41150.3047	loss_val: 41150.5547	loss_test: 41150.3203	accuracy_train: 0.5529	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 25933.1094	loss_val: 25933.2461	loss_test: 25933.0957	accuracy_train: 0.4683	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1233.0046	loss_val: 1233.0178	loss_test: 1233.0157	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 47737.5938	loss_val: 47742.8477	loss_test: 47737.7188	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10891.1367	loss_val: 10891.0820	loss_test: 10891.1602	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2704.8621	loss_val: 2704.8838	loss_test: 2704.9065	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 38060.0977	loss_val: 38061.1992	loss_test: 38060.7656	accuracy_train: 0.8644	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 208160.2656	loss_val: 208160.3750	loss_test: 208160.5312	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10707.5381	loss_val: 10707.5830	loss_test: 10707.6328	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1528.8842	loss_val: 1528.9111	loss_test: 1528.9481	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6630.9600	loss_val: 6631.3140	loss_test: 6631.7051	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21839.7363	loss_val: 21839.7090	loss_test: 21839.8770	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13037.7002	loss_val: 13037.7861	loss_test: 13037.7725	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1092.7362	loss_val: 1092.7369	loss_test: 1092.7581	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 57	curr_val_accuracy: 0.6733	curr_test_accuracy: 0.6877
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35389.8047	loss_val: 35389.8398	loss_test: 35389.8594	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19148.0996	loss_val: 19148.1484	loss_test: 19148.2109	accuracy_train: 0.7481	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46240.2227	loss_val: 46241.0117	loss_test: 46240.9141	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17602.0547	loss_val: 17602.0098	loss_test: 17602.1133	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6826.8335	loss_val: 6826.9058	loss_test: 6826.9663	accuracy_train: 0.6529	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 5715.1206	loss_val: 5715.1592	loss_test: 5715.2793	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40557.8477	loss_val: 40558.1133	loss_test: 40557.8672	accuracy_train: 0.5706	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 26104.6191	loss_val: 26104.7559	loss_test: 26104.6016	accuracy_train: 0.4754	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1227.3336	loss_val: 1227.3472	loss_test: 1227.3450	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49544.4062	loss_val: 49549.7773	loss_test: 49544.5312	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10642.7607	loss_val: 10642.7031	loss_test: 10642.7861	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2730.8877	loss_val: 2730.9023	loss_test: 2730.9336	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 37046.4336	loss_val: 37047.6133	loss_test: 37047.1133	accuracy_train: 0.8644	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 208267.8906	loss_val: 208268.0156	loss_test: 208268.1875	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10332.6748	loss_val: 10332.7188	loss_test: 10332.7695	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1537.6774	loss_val: 1537.7037	loss_test: 1537.7400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6515.3564	loss_val: 6515.7153	loss_test: 6516.1021	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21585.6719	loss_val: 21585.6270	loss_test: 21585.8164	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13311.4932	loss_val: 13311.5781	loss_test: 13311.5703	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1074.9937	loss_val: 1074.9941	loss_test: 1075.0159	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 58	curr_val_accuracy: 0.6713	curr_test_accuracy: 0.6839
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35039.6797	loss_val: 35039.7188	loss_test: 35039.7422	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 18743.8652	loss_val: 18743.9121	loss_test: 18743.9766	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46396.5312	loss_val: 46397.3750	loss_test: 46397.2344	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16539.5332	loss_val: 16539.4902	loss_test: 16539.5938	accuracy_train: 0.4371	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6780.1362	loss_val: 6780.2188	loss_test: 6780.2764	accuracy_train: 0.6471	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 5587.0845	loss_val: 5587.1226	loss_test: 5587.2485	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39774.6758	loss_val: 39774.9570	loss_test: 39774.7031	accuracy_train: 0.5765	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 25791.2617	loss_val: 25791.3906	loss_test: 25791.2422	accuracy_train: 0.4824	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1224.1112	loss_val: 1224.1245	loss_test: 1224.1228	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50419.7500	loss_val: 50425.2812	loss_test: 50419.8789	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10058.2656	loss_val: 10058.2041	loss_test: 10058.2910	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2733.3850	loss_val: 2733.3926	loss_test: 2733.4368	accuracy_train: 0.6353	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 38815.8438	loss_val: 38817.0898	loss_test: 38816.5273	accuracy_train: 0.8644	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 214262.0312	loss_val: 214262.1875	loss_test: 214262.3594	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 10328.0371	loss_val: 10328.0811	loss_test: 10328.1299	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1536.7717	loss_val: 1536.7969	loss_test: 1536.8330	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6442.1978	loss_val: 6442.5615	loss_test: 6442.9409	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21660.1504	loss_val: 21660.0957	loss_test: 21660.2988	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13485.2373	loss_val: 13485.3213	loss_test: 13485.3135	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.3714
[client 19]	loss_train: 1061.1339	loss_val: 1061.1339	loss_test: 1061.1564	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 59	curr_val_accuracy: 0.6752	curr_test_accuracy: 0.6858
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 35683.5156	loss_val: 35683.5625	loss_test: 35683.5703	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 18573.8281	loss_val: 18573.8789	loss_test: 18573.9395	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46131.1602	loss_val: 46132.0430	loss_test: 46131.8711	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16639.8750	loss_val: 16639.8301	loss_test: 16639.9414	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6619.8789	loss_val: 6619.9277	loss_test: 6620.0239	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5716.2524	loss_val: 5716.3003	loss_test: 5716.4126	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39683.0820	loss_val: 39683.3750	loss_test: 39683.1133	accuracy_train: 0.5706	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 25966.5000	loss_val: 25966.6367	loss_test: 25966.4824	accuracy_train: 0.5000	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1220.8534	loss_val: 1220.8669	loss_test: 1220.8652	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50498.1836	loss_val: 50503.9180	loss_test: 50498.3086	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 9813.4990	loss_val: 9813.4355	loss_test: 9813.5244	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2747.1768	loss_val: 2747.1790	loss_test: 2747.2380	accuracy_train: 0.6353	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 40979.2461	loss_val: 40980.5117	loss_test: 40979.9336	accuracy_train: 0.8644	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 215384.4688	loss_val: 215384.6094	loss_test: 215384.8125	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 10133.1768	loss_val: 10133.2197	loss_test: 10133.2686	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1530.1737	loss_val: 1530.1974	loss_test: 1530.2336	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6382.4668	loss_val: 6382.8369	loss_test: 6383.2085	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 21250.4023	loss_val: 21250.3438	loss_test: 21250.5605	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13442.3652	loss_val: 13442.4482	loss_test: 13442.4443	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1054.2505	loss_val: 1054.2504	loss_test: 1054.2726	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 60	curr_val_accuracy: 0.6754	curr_test_accuracy: 0.6879
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38664.5078	loss_val: 38664.5586	loss_test: 38664.5586	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 18414.3242	loss_val: 18414.3809	loss_test: 18414.4336	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45490.8594	loss_val: 45491.7930	loss_test: 45491.5859	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17020.9102	loss_val: 17020.8574	loss_test: 17020.9766	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6514.8711	loss_val: 6514.9102	loss_test: 6515.0171	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5956.1909	loss_val: 5956.2402	loss_test: 5956.3428	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39979.3203	loss_val: 39979.6289	loss_test: 39979.3594	accuracy_train: 0.5824	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 26110.1445	loss_val: 26110.2910	loss_test: 26110.1250	accuracy_train: 0.5035	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1226.1594	loss_val: 1226.1727	loss_test: 1226.1711	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55691.6641	loss_val: 55697.5586	loss_test: 55691.7891	accuracy_train: 0.9615	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10114.7676	loss_val: 10114.7012	loss_test: 10114.7900	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2741.0454	loss_val: 2741.0459	loss_test: 2741.1160	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 41716.0078	loss_val: 41717.2969	loss_test: 41716.7070	accuracy_train: 0.8729	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 217257.2969	loss_val: 217257.4375	loss_test: 217257.6562	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 10129.1982	loss_val: 10129.2402	loss_test: 10129.2910	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1521.5388	loss_val: 1521.5614	loss_test: 1521.5977	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6377.5244	loss_val: 6377.9023	loss_test: 6378.2681	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 20307.0293	loss_val: 20306.9707	loss_test: 20307.1934	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13327.7549	loss_val: 13327.8398	loss_test: 13327.8330	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1056.0604	loss_val: 1056.0599	loss_test: 1056.0823	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 61	curr_val_accuracy: 0.6734	curr_test_accuracy: 0.6879
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 83429.8594	loss_val: 83430.1641	loss_test: 83430.1484	accuracy_train: 0.9709	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 1]	loss_train: 18646.0176	loss_val: 18646.0840	loss_test: 18646.1191	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44554.3125	loss_val: 44555.2930	loss_test: 44555.0508	accuracy_train: 0.9277	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16728.2578	loss_val: 16728.2109	loss_test: 16728.3242	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6531.1069	loss_val: 6531.1382	loss_test: 6531.2461	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5959.9648	loss_val: 5960.0161	loss_test: 5960.1201	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40611.7188	loss_val: 40612.0352	loss_test: 40611.7578	accuracy_train: 0.5824	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 26458.3613	loss_val: 26458.5176	loss_test: 26458.3379	accuracy_train: 0.5176	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1234.8322	loss_val: 1234.8446	loss_test: 1234.8438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53034.4414	loss_val: 53040.4102	loss_test: 53034.5664	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10651.1211	loss_val: 10651.0537	loss_test: 10651.1426	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2738.0637	loss_val: 2738.0696	loss_test: 2738.1379	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 41867.7578	loss_val: 41869.0898	loss_test: 41868.4648	accuracy_train: 0.8729	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 211468.3438	loss_val: 211468.4844	loss_test: 211468.7031	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 10200.9053	loss_val: 10200.9434	loss_test: 10200.9980	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1514.7074	loss_val: 1514.7297	loss_test: 1514.7651	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6378.1577	loss_val: 6378.5420	loss_test: 6378.9014	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22991.4531	loss_val: 22991.4043	loss_test: 22991.6250	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 13009.7207	loss_val: 13009.8096	loss_test: 13009.7939	accuracy_train: 0.4338	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1056.6053	loss_val: 1056.6047	loss_test: 1056.6274	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 62	curr_val_accuracy: 0.6696	curr_test_accuracy: 0.6860
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 45452.8516	loss_val: 45452.9219	loss_test: 45452.8867	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 18950.3926	loss_val: 18950.4707	loss_test: 18950.4980	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44213.3164	loss_val: 44214.3516	loss_test: 44214.0742	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16235.9941	loss_val: 16235.9512	loss_test: 16236.0576	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6575.7373	loss_val: 6575.7837	loss_test: 6575.8760	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6014.3340	loss_val: 6014.3862	loss_test: 6014.4927	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40614.1406	loss_val: 40614.4688	loss_test: 40614.1758	accuracy_train: 0.5882	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 25948.5742	loss_val: 25948.7363	loss_test: 25948.5527	accuracy_train: 0.5035	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1235.0948	loss_val: 1235.1072	loss_test: 1235.1062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51299.3594	loss_val: 51305.5586	loss_test: 51299.4883	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10944.1045	loss_val: 10944.0361	loss_test: 10944.1260	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2709.5808	loss_val: 2709.5972	loss_test: 2709.6570	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 41368.9922	loss_val: 41370.3672	loss_test: 41369.7031	accuracy_train: 0.8814	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 215783.2031	loss_val: 215783.3594	loss_test: 215783.5938	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10367.8340	loss_val: 10367.8672	loss_test: 10367.9268	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1505.8982	loss_val: 1505.9208	loss_test: 1505.9553	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6443.6973	loss_val: 6444.0894	loss_test: 6444.4395	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 23960.1016	loss_val: 23960.0605	loss_test: 23960.2676	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12537.5723	loss_val: 12537.6631	loss_test: 12537.6416	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1053.0319	loss_val: 1053.0314	loss_test: 1053.0544	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 63	curr_val_accuracy: 0.6714	curr_test_accuracy: 0.6839
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32044.9824	loss_val: 32045.0566	loss_test: 32045.0059	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 18844.7031	loss_val: 18844.7891	loss_test: 18844.8105	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44377.1992	loss_val: 44378.2734	loss_test: 44377.9766	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16380.4902	loss_val: 16380.4541	loss_test: 16380.5508	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6493.5845	loss_val: 6493.5732	loss_test: 6493.7251	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6007.8506	loss_val: 6007.8979	loss_test: 6008.0078	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40478.6953	loss_val: 40479.0469	loss_test: 40478.7305	accuracy_train: 0.5824	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 25445.8184	loss_val: 25445.9805	loss_test: 25445.8008	accuracy_train: 0.4859	accuracy_val: 0.3889	accuracy_test: 0.4324
[client 8]	loss_train: 1235.2556	loss_val: 1235.2678	loss_test: 1235.2668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50686.8164	loss_val: 50693.3867	loss_test: 50686.9453	accuracy_train: 0.9808	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11190.5889	loss_val: 11190.5205	loss_test: 11190.6113	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2710.0254	loss_val: 2710.0535	loss_test: 2710.0967	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 40854.7461	loss_val: 40856.1680	loss_test: 40855.4570	accuracy_train: 0.8898	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 224389.9062	loss_val: 224390.0781	loss_test: 224390.3125	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10409.8125	loss_val: 10409.8418	loss_test: 10409.9102	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1489.9431	loss_val: 1489.9657	loss_test: 1489.9999	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6494.7100	loss_val: 6495.1089	loss_test: 6495.4492	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 23550.7871	loss_val: 23550.7422	loss_test: 23550.9473	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12017.9502	loss_val: 12018.0400	loss_test: 12018.0166	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1054.8726	loss_val: 1054.8723	loss_test: 1054.8954	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 64	curr_val_accuracy: 0.6694	curr_test_accuracy: 0.6820
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31756.1426	loss_val: 31756.2227	loss_test: 31756.1602	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 18857.0547	loss_val: 18857.1367	loss_test: 18857.1641	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44231.3125	loss_val: 44232.4453	loss_test: 44232.1016	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16693.9746	loss_val: 16693.9473	loss_test: 16694.0332	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6569.0356	loss_val: 6569.0210	loss_test: 6569.1851	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 5986.3594	loss_val: 5986.4019	loss_test: 5986.5156	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39211.4336	loss_val: 39211.8008	loss_test: 39211.4688	accuracy_train: 0.5706	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 25530.6035	loss_val: 25530.7598	loss_test: 25530.5898	accuracy_train: 0.4613	accuracy_val: 0.3611	accuracy_test: 0.4054
[client 8]	loss_train: 1238.4169	loss_val: 1238.4291	loss_test: 1238.4275	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51680.0195	loss_val: 51686.9648	loss_test: 51680.1445	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 11207.6855	loss_val: 11207.6182	loss_test: 11207.7090	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2715.2573	loss_val: 2715.2971	loss_test: 2715.3286	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 40820.3203	loss_val: 40821.7656	loss_test: 40821.0273	accuracy_train: 0.8898	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 232772.2656	loss_val: 232772.4375	loss_test: 232772.6875	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10239.4004	loss_val: 10239.4297	loss_test: 10239.5049	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1482.0944	loss_val: 1482.1162	loss_test: 1482.1503	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6492.7427	loss_val: 6493.1494	loss_test: 6493.4819	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 23141.1602	loss_val: 23141.1133	loss_test: 23141.3184	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11744.2461	loss_val: 11744.3320	loss_test: 11744.3096	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1052.1837	loss_val: 1052.1838	loss_test: 1052.2067	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 65	curr_val_accuracy: 0.6675	curr_test_accuracy: 0.6819
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31575.3770	loss_val: 31575.4590	loss_test: 31575.3906	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 18478.1641	loss_val: 18478.2383	loss_test: 18478.2734	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44714.8906	loss_val: 44716.0898	loss_test: 44715.6914	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17566.7012	loss_val: 17566.6777	loss_test: 17566.7598	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6653.9585	loss_val: 6653.9824	loss_test: 6654.1147	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6052.0137	loss_val: 6052.0542	loss_test: 6052.1597	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 38587.3672	loss_val: 38587.7617	loss_test: 38587.4297	accuracy_train: 0.5647	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 25880.3594	loss_val: 25880.5020	loss_test: 25880.3496	accuracy_train: 0.4718	accuracy_val: 0.4167	accuracy_test: 0.4324
[client 8]	loss_train: 1235.9449	loss_val: 1235.9574	loss_test: 1235.9553	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54456.9219	loss_val: 54464.0898	loss_test: 54457.0469	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10945.0811	loss_val: 10945.0166	loss_test: 10945.1074	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2708.8599	loss_val: 2708.9111	loss_test: 2708.9426	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 40242.3242	loss_val: 40243.7812	loss_test: 40243.0273	accuracy_train: 0.8898	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 237115.4844	loss_val: 237115.6719	loss_test: 237115.9219	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9942.4609	loss_val: 9942.4951	loss_test: 9942.5703	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1480.9285	loss_val: 1480.9501	loss_test: 1480.9838	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6458.2983	loss_val: 6458.7129	loss_test: 6459.0386	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22841.2812	loss_val: 22841.2285	loss_test: 22841.4336	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11648.1025	loss_val: 11648.1895	loss_test: 11648.1641	accuracy_train: 0.4375	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1050.5406	loss_val: 1050.5408	loss_test: 1050.5636	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 66	curr_val_accuracy: 0.6694	curr_test_accuracy: 0.6838
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31928.5020	loss_val: 31928.5859	loss_test: 31928.5117	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 18498.5820	loss_val: 18498.6504	loss_test: 18498.6875	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45502.0508	loss_val: 45503.3281	loss_test: 45502.8633	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 18396.3867	loss_val: 18396.3574	loss_test: 18396.4453	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6619.2305	loss_val: 6619.3115	loss_test: 6619.3911	accuracy_train: 0.6294	accuracy_val: 0.5238	accuracy_test: 0.6250
[client 5]	loss_train: 6005.3442	loss_val: 6005.3784	loss_test: 6005.4912	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 37674.2383	loss_val: 37674.6484	loss_test: 37674.2852	accuracy_train: 0.5588	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 27106.7480	loss_val: 27106.8945	loss_test: 27106.7422	accuracy_train: 0.4754	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1234.7749	loss_val: 1234.7875	loss_test: 1234.7849	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56175.4648	loss_val: 56182.7305	loss_test: 56175.5859	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10711.3789	loss_val: 10711.3145	loss_test: 10711.4072	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2721.9832	loss_val: 2722.0449	loss_test: 2722.0735	accuracy_train: 0.6275	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 40660.3008	loss_val: 40661.7578	loss_test: 40660.9961	accuracy_train: 0.8983	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 237660.7969	loss_val: 237660.9844	loss_test: 237661.2500	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9898.2520	loss_val: 9898.2959	loss_test: 9898.3662	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1478.9064	loss_val: 1478.9282	loss_test: 1478.9615	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6386.4692	loss_val: 6386.8921	loss_test: 6387.2139	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22709.4219	loss_val: 22709.3652	loss_test: 22709.5801	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11914.1992	loss_val: 11914.2959	loss_test: 11914.2627	accuracy_train: 0.4228	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1042.2803	loss_val: 1042.2803	loss_test: 1042.3035	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 67	curr_val_accuracy: 0.6694	curr_test_accuracy: 0.6858
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33127.3594	loss_val: 33127.4453	loss_test: 33127.3711	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 18475.0020	loss_val: 18475.0723	loss_test: 18475.1055	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47032.3867	loss_val: 47033.7383	loss_test: 47033.2148	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 18324.9746	loss_val: 18324.9434	loss_test: 18325.0293	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6443.7866	loss_val: 6443.8691	loss_test: 6443.9458	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 6015.1021	loss_val: 6015.1387	loss_test: 6015.2495	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 36666.0703	loss_val: 36666.5156	loss_test: 36666.1367	accuracy_train: 0.5588	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 28405.6289	loss_val: 28405.7793	loss_test: 28405.6230	accuracy_train: 0.5035	accuracy_val: 0.3889	accuracy_test: 0.4865
[client 8]	loss_train: 1229.3303	loss_val: 1229.3429	loss_test: 1229.3405	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55844.0547	loss_val: 55851.4102	loss_test: 55844.1797	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10387.6270	loss_val: 10387.5625	loss_test: 10387.6562	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2707.2163	loss_val: 2707.2883	loss_test: 2707.3064	accuracy_train: 0.6314	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 40183.5859	loss_val: 40185.0703	loss_test: 40184.2812	accuracy_train: 0.9153	accuracy_val: 0.4667	accuracy_test: 0.6471
[client 13]	loss_train: 237611.6094	loss_val: 237611.7969	loss_test: 237612.0625	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9963.4219	loss_val: 9963.4717	loss_test: 9963.5381	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1476.3552	loss_val: 1476.3772	loss_test: 1476.4105	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6472.7563	loss_val: 6473.1885	loss_test: 6473.5054	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 22897.5938	loss_val: 22897.5332	loss_test: 22897.7578	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12108.8076	loss_val: 12108.9111	loss_test: 12108.8740	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1045.1448	loss_val: 1045.1448	loss_test: 1045.1680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 68	curr_val_accuracy: 0.6694	curr_test_accuracy: 0.6838
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36074.8906	loss_val: 36074.9766	loss_test: 36074.9023	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 18382.7656	loss_val: 18382.8398	loss_test: 18382.8613	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48245.4375	loss_val: 48246.8750	loss_test: 48246.2695	accuracy_train: 0.9398	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17499.0449	loss_val: 17499.0156	loss_test: 17499.0996	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6324.6064	loss_val: 6324.6719	loss_test: 6324.7661	accuracy_train: 0.6235	accuracy_val: 0.5714	accuracy_test: 0.6250
[client 5]	loss_train: 5728.5107	loss_val: 5728.5547	loss_test: 5728.6592	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 35827.1562	loss_val: 35827.6406	loss_test: 35827.2617	accuracy_train: 0.5647	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 29561.2031	loss_val: 29561.3438	loss_test: 29561.1992	accuracy_train: 0.4894	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1221.8096	loss_val: 1221.8223	loss_test: 1221.8201	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55546.1484	loss_val: 55553.5938	loss_test: 55546.2812	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 0.8750
[client 10]	loss_train: 10304.7627	loss_val: 10304.6982	loss_test: 10304.7900	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2683.0718	loss_val: 2683.1514	loss_test: 2683.1575	accuracy_train: 0.6353	accuracy_val: 0.6875	accuracy_test: 0.6364
[client 12]	loss_train: 39709.3555	loss_val: 39710.9023	loss_test: 39710.0391	accuracy_train: 0.9237	accuracy_val: 0.5333	accuracy_test: 0.7059
[client 13]	loss_train: 226992.4375	loss_val: 226992.6250	loss_test: 226992.9062	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10040.1660	loss_val: 10040.2207	loss_test: 10040.2803	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1466.0300	loss_val: 1466.0516	loss_test: 1466.0853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6560.2534	loss_val: 6560.6934	loss_test: 6561.0049	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 23487.9551	loss_val: 23487.8574	loss_test: 23488.1152	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12051.3242	loss_val: 12051.4307	loss_test: 12051.3887	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1047.3101	loss_val: 1047.3101	loss_test: 1047.3331	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 69	curr_val_accuracy: 0.6734	curr_test_accuracy: 0.6856
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 37699.6172	loss_val: 37699.6992	loss_test: 37699.6367	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 1.0000
[client 1]	loss_train: 18535.5469	loss_val: 18535.6250	loss_test: 18535.6387	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48788.3711	loss_val: 48789.8984	loss_test: 48789.2109	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16566.8965	loss_val: 16566.8613	loss_test: 16566.9570	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6472.4146	loss_val: 6472.4707	loss_test: 6472.5801	accuracy_train: 0.6235	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5811.6538	loss_val: 5811.6904	loss_test: 5811.8071	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 35634.8789	loss_val: 35635.3906	loss_test: 35634.9141	accuracy_train: 0.5765	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 29346.4219	loss_val: 29346.5449	loss_test: 29346.4219	accuracy_train: 0.4718	accuracy_val: 0.3889	accuracy_test: 0.4324
[client 8]	loss_train: 1213.0515	loss_val: 1213.0643	loss_test: 1213.0625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55558.1523	loss_val: 55565.6523	loss_test: 55558.3008	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10163.5137	loss_val: 10163.4512	loss_test: 10163.5420	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2683.1057	loss_val: 2683.1863	loss_test: 2683.1863	accuracy_train: 0.6392	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 38816.8125	loss_val: 38818.4414	loss_test: 38817.4883	accuracy_train: 0.9237	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 213397.5781	loss_val: 213397.7656	loss_test: 213398.0781	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9923.4141	loss_val: 9923.4697	loss_test: 9923.5254	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1457.9924	loss_val: 1458.0134	loss_test: 1458.0474	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6598.3960	loss_val: 6598.8447	loss_test: 6599.1533	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 24087.7891	loss_val: 24087.6738	loss_test: 24087.9512	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12069.1025	loss_val: 12069.2129	loss_test: 12069.1660	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1046.7698	loss_val: 1046.7700	loss_test: 1046.7925	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 70	curr_val_accuracy: 0.6735	curr_test_accuracy: 0.6855
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36555.6562	loss_val: 36555.7422	loss_test: 36555.6797	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 18452.5508	loss_val: 18452.6309	loss_test: 18452.6367	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46957.0234	loss_val: 46958.6289	loss_test: 46957.8672	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15894.8408	loss_val: 15894.7988	loss_test: 15894.9043	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6720.7485	loss_val: 6720.7725	loss_test: 6720.9146	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.6250
[client 5]	loss_train: 5809.2275	loss_val: 5809.2622	loss_test: 5809.3896	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 35390.2227	loss_val: 35390.7305	loss_test: 35390.2344	accuracy_train: 0.5882	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 29588.7891	loss_val: 29588.9062	loss_test: 29588.7832	accuracy_train: 0.4754	accuracy_val: 0.3611	accuracy_test: 0.4595
[client 8]	loss_train: 1221.3433	loss_val: 1221.3563	loss_test: 1221.3545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55558.6406	loss_val: 55566.1836	loss_test: 55558.8008	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10142.4219	loss_val: 10142.3613	loss_test: 10142.4512	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2667.3142	loss_val: 2667.3855	loss_test: 2667.3911	accuracy_train: 0.6314	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 38305.0586	loss_val: 38306.7773	loss_test: 38305.7617	accuracy_train: 0.9322	accuracy_val: 0.5333	accuracy_test: 0.6471
[client 13]	loss_train: 207786.4688	loss_val: 207786.6562	loss_test: 207787.0000	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9750.7939	loss_val: 9750.8477	loss_test: 9750.9014	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1458.9259	loss_val: 1458.9462	loss_test: 1458.9802	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6606.3926	loss_val: 6606.8486	loss_test: 6607.1558	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 24884.3379	loss_val: 24884.2227	loss_test: 24884.5156	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12132.5811	loss_val: 12132.6973	loss_test: 12132.6494	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1044.6779	loss_val: 1044.6782	loss_test: 1044.7004	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 71	curr_val_accuracy: 0.6715	curr_test_accuracy: 0.6875
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36293.2891	loss_val: 36293.3750	loss_test: 36293.3242	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 18795.2266	loss_val: 18795.3047	loss_test: 18795.3105	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45970.8281	loss_val: 45972.4961	loss_test: 45971.6953	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14383.3096	loss_val: 14383.2656	loss_test: 14383.3740	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6717.1172	loss_val: 6717.0835	loss_test: 6717.2681	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5874.4951	loss_val: 5874.5312	loss_test: 5874.6592	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 34884.7383	loss_val: 34885.2461	loss_test: 34884.7578	accuracy_train: 0.5941	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 29043.6621	loss_val: 29043.7930	loss_test: 29043.6445	accuracy_train: 0.4859	accuracy_val: 0.3611	accuracy_test: 0.4324
[client 8]	loss_train: 1235.2352	loss_val: 1235.2483	loss_test: 1235.2469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 56135.0195	loss_val: 56142.5938	loss_test: 56135.1875	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10371.9473	loss_val: 10371.8877	loss_test: 10371.9775	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2633.2810	loss_val: 2633.3420	loss_test: 2633.3650	accuracy_train: 0.6275	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 37638.5820	loss_val: 37640.3633	loss_test: 37639.3477	accuracy_train: 0.9322	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 202189.9688	loss_val: 202190.1406	loss_test: 202190.5000	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9951.1045	loss_val: 9951.1514	loss_test: 9951.2031	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1452.1025	loss_val: 1452.1224	loss_test: 1452.1570	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6647.6523	loss_val: 6648.1157	loss_test: 6648.4214	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25466.9629	loss_val: 25466.8477	loss_test: 25467.1484	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12259.5361	loss_val: 12259.6572	loss_test: 12259.6064	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1047.4336	loss_val: 1047.4341	loss_test: 1047.4550	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 72	curr_val_accuracy: 0.6756	curr_test_accuracy: 0.6838
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34088.2969	loss_val: 34088.3789	loss_test: 34088.3438	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 19299.2441	loss_val: 19299.3223	loss_test: 19299.3301	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45317.8477	loss_val: 45319.5586	loss_test: 45318.7383	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 13970.3857	loss_val: 13970.3398	loss_test: 13970.4492	accuracy_train: 0.4465	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6737.0952	loss_val: 6737.0332	loss_test: 6737.2349	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5818.1504	loss_val: 5818.1909	loss_test: 5818.3130	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 34483.4570	loss_val: 34483.9727	loss_test: 34483.4766	accuracy_train: 0.5882	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 28667.0820	loss_val: 28667.2168	loss_test: 28667.0723	accuracy_train: 0.4789	accuracy_val: 0.3889	accuracy_test: 0.4324
[client 8]	loss_train: 1234.2201	loss_val: 1234.2330	loss_test: 1234.2324	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55518.3320	loss_val: 55525.9961	loss_test: 55518.4414	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10298.5684	loss_val: 10298.5078	loss_test: 10298.5947	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2610.3660	loss_val: 2610.4238	loss_test: 2610.4653	accuracy_train: 0.6353	accuracy_val: 0.6562	accuracy_test: 0.6364
[client 12]	loss_train: 36680.5547	loss_val: 36682.4023	loss_test: 36681.3984	accuracy_train: 0.9322	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 205486.0469	loss_val: 205486.2344	loss_test: 205486.6094	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9702.9385	loss_val: 9702.9844	loss_test: 9703.0400	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1444.6497	loss_val: 1444.6693	loss_test: 1444.7048	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6782.9805	loss_val: 6783.4502	loss_test: 6783.7563	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25675.6816	loss_val: 25675.5488	loss_test: 25675.8711	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12150.8564	loss_val: 12150.9795	loss_test: 12150.9258	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1038.6877	loss_val: 1038.6881	loss_test: 1038.7084	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 73	curr_val_accuracy: 0.6775	curr_test_accuracy: 0.6838
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32764.3945	loss_val: 32764.4746	loss_test: 32764.4492	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 19605.7285	loss_val: 19605.8066	loss_test: 19605.8184	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44754.1250	loss_val: 44755.8359	loss_test: 44755.0586	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 13723.6201	loss_val: 13723.5771	loss_test: 13723.6816	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6706.7095	loss_val: 6706.6694	loss_test: 6706.8550	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5769.4873	loss_val: 5769.5347	loss_test: 5769.6523	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 33484.0391	loss_val: 33484.5742	loss_test: 33484.0703	accuracy_train: 0.5647	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 28846.6094	loss_val: 28846.7480	loss_test: 28846.6094	accuracy_train: 0.4683	accuracy_val: 0.4444	accuracy_test: 0.4324
[client 8]	loss_train: 1223.1870	loss_val: 1223.1996	loss_test: 1223.1996	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 55200.0000	loss_val: 55207.6641	loss_test: 55200.1055	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10205.2500	loss_val: 10205.1904	loss_test: 10205.2734	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2650.0618	loss_val: 2650.1169	loss_test: 2650.1763	accuracy_train: 0.6353	accuracy_val: 0.6875	accuracy_test: 0.6061
[client 12]	loss_train: 36918.1211	loss_val: 36920.0352	loss_test: 36919.0508	accuracy_train: 0.9407	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 208740.4844	loss_val: 208740.6719	loss_test: 208741.0625	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10105.8965	loss_val: 10105.9492	loss_test: 10106.0068	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1440.9326	loss_val: 1440.9524	loss_test: 1440.9880	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6851.9014	loss_val: 6852.3765	loss_test: 6852.6870	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25176.9883	loss_val: 25176.8535	loss_test: 25177.1914	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12021.9551	loss_val: 12022.0830	loss_test: 12022.0244	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1032.2924	loss_val: 1032.2925	loss_test: 1032.3118	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 74	curr_val_accuracy: 0.6835	curr_test_accuracy: 0.6818
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31795.1934	loss_val: 31795.2734	loss_test: 31795.2617	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 20048.9316	loss_val: 20049.0098	loss_test: 20049.0254	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44933.8203	loss_val: 44935.5430	loss_test: 44934.7930	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 14436.3281	loss_val: 14436.2822	loss_test: 14436.3896	accuracy_train: 0.4403	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6753.0225	loss_val: 6752.9922	loss_test: 6753.1797	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5629.0020	loss_val: 5629.0508	loss_test: 5629.1670	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 32782.7227	loss_val: 32783.2578	loss_test: 32782.7578	accuracy_train: 0.5353	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 28134.1074	loss_val: 28134.2520	loss_test: 28134.1133	accuracy_train: 0.4648	accuracy_val: 0.4444	accuracy_test: 0.4324
[client 8]	loss_train: 1226.3362	loss_val: 1226.3480	loss_test: 1226.3488	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 54604.7500	loss_val: 54612.4805	loss_test: 54604.8516	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10425.4229	loss_val: 10425.3623	loss_test: 10425.4414	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2690.0334	loss_val: 2690.0850	loss_test: 2690.1543	accuracy_train: 0.6392	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 38072.7266	loss_val: 38074.7148	loss_test: 38073.7344	accuracy_train: 0.9407	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 211253.6719	loss_val: 211253.8438	loss_test: 211254.2500	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10297.8057	loss_val: 10297.8623	loss_test: 10297.9229	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1435.5941	loss_val: 1435.6143	loss_test: 1435.6493	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6844.8843	loss_val: 6845.3667	loss_test: 6845.6802	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 24886.3184	loss_val: 24886.1895	loss_test: 24886.5391	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12100.9648	loss_val: 12101.0996	loss_test: 12101.0352	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1029.0221	loss_val: 1029.0220	loss_test: 1029.0405	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 75	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6818
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31498.2793	loss_val: 31498.3574	loss_test: 31498.3574	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 19803.6680	loss_val: 19803.7441	loss_test: 19803.7578	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45259.1484	loss_val: 45260.8867	loss_test: 45260.1484	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15156.7314	loss_val: 15156.6836	loss_test: 15156.7920	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6583.7476	loss_val: 6583.7329	loss_test: 6583.9019	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5576.0898	loss_val: 5576.1372	loss_test: 5576.2607	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 32924.5703	loss_val: 32925.1289	loss_test: 32924.6094	accuracy_train: 0.5176	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 28828.7480	loss_val: 28828.8945	loss_test: 28828.7480	accuracy_train: 0.5282	accuracy_val: 0.4444	accuracy_test: 0.4865
[client 8]	loss_train: 1215.3789	loss_val: 1215.3901	loss_test: 1215.3912	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53613.7578	loss_val: 53621.5195	loss_test: 53613.8594	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10574.7256	loss_val: 10574.6670	loss_test: 10574.7441	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2749.0127	loss_val: 2749.0659	loss_test: 2749.1384	accuracy_train: 0.6353	accuracy_val: 0.6562	accuracy_test: 0.6061
[client 12]	loss_train: 39054.6680	loss_val: 39056.7188	loss_test: 39055.7305	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 218045.6250	loss_val: 218045.8125	loss_test: 218046.2344	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 9997.4199	loss_val: 9997.4775	loss_test: 9997.5420	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1430.3560	loss_val: 1430.3763	loss_test: 1430.4115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6788.8145	loss_val: 6789.3018	loss_test: 6789.6172	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25527.1074	loss_val: 25526.9707	loss_test: 25527.3477	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12114.6875	loss_val: 12114.8271	loss_test: 12114.7578	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1025.5887	loss_val: 1025.5885	loss_test: 1025.6067	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 76	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6876
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31278.4902	loss_val: 31278.5645	loss_test: 31278.5762	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 19930.9043	loss_val: 19930.9844	loss_test: 19930.9883	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45028.9336	loss_val: 45030.7109	loss_test: 45029.9453	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15564.4629	loss_val: 15564.4150	loss_test: 15564.5244	accuracy_train: 0.4434	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 6732.0400	loss_val: 6732.0205	loss_test: 6732.1982	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5594.4058	loss_val: 5594.4565	loss_test: 5594.5781	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 32953.1445	loss_val: 32953.7305	loss_test: 32953.1914	accuracy_train: 0.5176	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 28704.8574	loss_val: 28705.0059	loss_test: 28704.8477	accuracy_train: 0.5775	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1216.2804	loss_val: 1216.2911	loss_test: 1216.2924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53222.6797	loss_val: 53230.4648	loss_test: 53222.7812	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10681.5518	loss_val: 10681.4912	loss_test: 10681.5703	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2813.7627	loss_val: 2813.8230	loss_test: 2813.8982	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 39593.9570	loss_val: 39596.0625	loss_test: 39595.0586	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 248053.8594	loss_val: 248054.0312	loss_test: 248054.4844	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 9558.1250	loss_val: 9558.1865	loss_test: 9558.2549	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1433.3070	loss_val: 1433.3275	loss_test: 1433.3630	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6740.4492	loss_val: 6740.9448	loss_test: 6741.2607	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 26319.1055	loss_val: 26318.9473	loss_test: 26319.3633	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12044.7461	loss_val: 12044.8848	loss_test: 12044.8145	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1021.4384	loss_val: 1021.4382	loss_test: 1021.4563	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 77	curr_val_accuracy: 0.6775	curr_test_accuracy: 0.6934
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31551.5684	loss_val: 31551.6406	loss_test: 31551.6621	accuracy_train: 0.9806	accuracy_val: 0.9286	accuracy_test: 0.9286
[client 1]	loss_train: 19855.6113	loss_val: 19855.6973	loss_test: 19855.6914	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44441.9453	loss_val: 44443.7773	loss_test: 44442.9688	accuracy_train: 0.9518	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15645.9023	loss_val: 15645.8564	loss_test: 15645.9629	accuracy_train: 0.4434	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6914.5679	loss_val: 6914.5513	loss_test: 6914.7334	accuracy_train: 0.6176	accuracy_val: 0.5714	accuracy_test: 0.5833
[client 5]	loss_train: 5562.0767	loss_val: 5562.1304	loss_test: 5562.2500	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 32809.2305	loss_val: 32809.8047	loss_test: 32809.2695	accuracy_train: 0.4941	accuracy_val: 0.3636	accuracy_test: 0.5909
[client 7]	loss_train: 27099.7207	loss_val: 27099.8730	loss_test: 27099.7129	accuracy_train: 0.6056	accuracy_val: 0.4444	accuracy_test: 0.5405
[client 8]	loss_train: 1217.3174	loss_val: 1217.3276	loss_test: 1217.3290	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52986.8398	loss_val: 52994.6133	loss_test: 52986.9414	accuracy_train: 1.0000	accuracy_val: 0.5714	accuracy_test: 1.0000
[client 10]	loss_train: 10411.5791	loss_val: 10411.5176	loss_test: 10411.6006	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2868.7244	loss_val: 2868.7922	loss_test: 2868.8604	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 39260.8477	loss_val: 39263.0000	loss_test: 39261.9688	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 264710.8125	loss_val: 264710.9688	loss_test: 264711.4375	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 9654.4492	loss_val: 9654.5088	loss_test: 9654.5850	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1430.4015	loss_val: 1430.4218	loss_test: 1430.4585	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6688.5015	loss_val: 6689.0034	loss_test: 6689.3179	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 28230.3086	loss_val: 28230.1309	loss_test: 28230.5684	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12212.0449	loss_val: 12212.1875	loss_test: 12212.1152	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1021.1891	loss_val: 1021.1890	loss_test: 1021.2071	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 78	curr_val_accuracy: 0.6794	curr_test_accuracy: 0.6916
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32102.3613	loss_val: 32102.4277	loss_test: 32102.4668	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19794.3047	loss_val: 19794.3965	loss_test: 19794.3828	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 44447.5273	loss_val: 44449.4102	loss_test: 44448.5586	accuracy_train: 0.9639	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15646.5986	loss_val: 15646.5557	loss_test: 15646.6592	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7132.6318	loss_val: 7132.5996	loss_test: 7132.8032	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5529.5264	loss_val: 5529.5879	loss_test: 5529.7031	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 33174.8633	loss_val: 33175.4453	loss_test: 33174.9062	accuracy_train: 0.4941	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 25919.3086	loss_val: 25919.4805	loss_test: 25919.3008	accuracy_train: 0.6127	accuracy_val: 0.4444	accuracy_test: 0.5946
[client 8]	loss_train: 1215.5448	loss_val: 1215.5549	loss_test: 1215.5563	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 53061.7383	loss_val: 53069.5234	loss_test: 53061.8359	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10257.9365	loss_val: 10257.8721	loss_test: 10257.9600	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2890.4851	loss_val: 2890.5640	loss_test: 2890.6160	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 39282.9609	loss_val: 39285.1562	loss_test: 39284.0938	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 268682.0938	loss_val: 268682.2812	loss_test: 268682.7812	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 10110.4678	loss_val: 10110.5205	loss_test: 10110.6016	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1425.0571	loss_val: 1425.0776	loss_test: 1425.1145	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6629.7441	loss_val: 6630.2515	loss_test: 6630.5635	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 29206.6934	loss_val: 29206.5176	loss_test: 29206.9609	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12090.6270	loss_val: 12090.7695	loss_test: 12090.6963	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1019.8256	loss_val: 1019.8254	loss_test: 1019.8438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 79	curr_val_accuracy: 0.6814	curr_test_accuracy: 0.6916
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31997.2637	loss_val: 31997.3262	loss_test: 31997.3770	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20404.1992	loss_val: 20404.3027	loss_test: 20404.2773	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45296.5352	loss_val: 45298.4961	loss_test: 45297.5781	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15791.4307	loss_val: 15791.3877	loss_test: 15791.4912	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7066.8228	loss_val: 7066.7749	loss_test: 7066.9941	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5555.2627	loss_val: 5555.3271	loss_test: 5555.4399	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 33980.7305	loss_val: 33981.3438	loss_test: 33980.7656	accuracy_train: 0.4941	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 25452.7617	loss_val: 25452.9492	loss_test: 25452.7695	accuracy_train: 0.5986	accuracy_val: 0.3889	accuracy_test: 0.5676
[client 8]	loss_train: 1224.1733	loss_val: 1224.1838	loss_test: 1224.1848	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52660.2812	loss_val: 52668.0117	loss_test: 52660.3789	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10000.3008	loss_val: 10000.2373	loss_test: 10000.3252	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2856.6055	loss_val: 2856.6948	loss_test: 2856.7136	accuracy_train: 0.6314	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 38964.1953	loss_val: 38966.4258	loss_test: 38965.3438	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 268332.7500	loss_val: 268332.9375	loss_test: 268333.4688	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.9231
[client 14]	loss_train: 10136.0537	loss_val: 10136.1035	loss_test: 10136.1885	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1421.6365	loss_val: 1421.6569	loss_test: 1421.6941	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6613.7104	loss_val: 6614.2231	loss_test: 6614.5332	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 28190.0859	loss_val: 28189.9141	loss_test: 28190.3613	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12043.1758	loss_val: 12043.3154	loss_test: 12043.2451	accuracy_train: 0.4118	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1023.0396	loss_val: 1023.0396	loss_test: 1023.0585	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 80	curr_val_accuracy: 0.6754	curr_test_accuracy: 0.6877
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31979.6719	loss_val: 31979.7305	loss_test: 31979.7852	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20251.8535	loss_val: 20251.9648	loss_test: 20251.9297	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45938.9883	loss_val: 45941.0234	loss_test: 45940.0391	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 15759.5889	loss_val: 15759.5430	loss_test: 15759.6475	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6991.0771	loss_val: 6991.0273	loss_test: 6991.2500	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5391.8584	loss_val: 5391.9180	loss_test: 5392.0337	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 34390.0469	loss_val: 34390.6680	loss_test: 34390.0664	accuracy_train: 0.4941	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 26168.4668	loss_val: 26168.6562	loss_test: 26168.4785	accuracy_train: 0.5880	accuracy_val: 0.3889	accuracy_test: 0.5405
[client 8]	loss_train: 1223.5348	loss_val: 1223.5459	loss_test: 1223.5465	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52591.0938	loss_val: 52598.8945	loss_test: 52591.1914	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9791.9346	loss_val: 9791.8740	loss_test: 9791.9619	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2830.4866	loss_val: 2830.5786	loss_test: 2830.5874	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 38740.7461	loss_val: 38743.0312	loss_test: 38741.9180	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 258945.4531	loss_val: 258945.6250	loss_test: 258946.1719	accuracy_train: 0.9286	accuracy_val: 0.8000	accuracy_test: 0.9231
[client 14]	loss_train: 10154.2412	loss_val: 10154.2861	loss_test: 10154.3711	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1434.0626	loss_val: 1434.0828	loss_test: 1434.1205	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6589.0503	loss_val: 6589.5664	loss_test: 6589.8745	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 27941.6250	loss_val: 27941.4629	loss_test: 27941.9102	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12158.2832	loss_val: 12158.4150	loss_test: 12158.3467	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1021.7800	loss_val: 1021.7802	loss_test: 1021.7990	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 81	curr_val_accuracy: 0.6755	curr_test_accuracy: 0.6876
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31799.6465	loss_val: 31799.6992	loss_test: 31799.7539	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19889.3770	loss_val: 19889.4961	loss_test: 19889.4512	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46536.9258	loss_val: 46539.0234	loss_test: 46537.9883	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16106.2197	loss_val: 16106.1709	loss_test: 16106.2764	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6965.1963	loss_val: 6965.1309	loss_test: 6965.3877	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5441.3965	loss_val: 5441.4531	loss_test: 5441.5698	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 35609.9414	loss_val: 35610.5547	loss_test: 35609.9492	accuracy_train: 0.5000	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 28388.1230	loss_val: 28388.3008	loss_test: 28388.1211	accuracy_train: 0.5845	accuracy_val: 0.4722	accuracy_test: 0.5135
[client 8]	loss_train: 1232.4363	loss_val: 1232.4478	loss_test: 1232.4480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51987.1523	loss_val: 51995.0430	loss_test: 51987.2539	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10050.7715	loss_val: 10050.7148	loss_test: 10050.7998	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2852.4500	loss_val: 2852.5408	loss_test: 2852.5491	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 38726.9766	loss_val: 38729.3125	loss_test: 38728.1797	accuracy_train: 0.9407	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 257629.8438	loss_val: 257630.0156	loss_test: 257630.5781	accuracy_train: 0.9286	accuracy_val: 0.8000	accuracy_test: 0.9231
[client 14]	loss_train: 9896.4580	loss_val: 9896.5029	loss_test: 9896.5840	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1441.4377	loss_val: 1441.4581	loss_test: 1441.4951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6556.1260	loss_val: 6556.6440	loss_test: 6556.9502	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 27931.3770	loss_val: 27931.2500	loss_test: 27931.6875	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12257.9355	loss_val: 12258.0664	loss_test: 12258.0000	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1024.5735	loss_val: 1024.5739	loss_test: 1024.5912	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 82	curr_val_accuracy: 0.6794	curr_test_accuracy: 0.6876
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31784.7031	loss_val: 31784.7520	loss_test: 31784.8105	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19620.1758	loss_val: 19620.3047	loss_test: 19620.2500	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46900.1758	loss_val: 46902.3633	loss_test: 46901.2422	accuracy_train: 0.9759	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16322.8633	loss_val: 16322.8154	loss_test: 16322.9180	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 7187.6875	loss_val: 7187.6123	loss_test: 7187.8848	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5408.8008	loss_val: 5408.8569	loss_test: 5408.9746	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 36909.8828	loss_val: 36910.5039	loss_test: 36909.8828	accuracy_train: 0.4941	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 30544.1660	loss_val: 30544.3301	loss_test: 30544.1504	accuracy_train: 0.5775	accuracy_val: 0.4722	accuracy_test: 0.5405
[client 8]	loss_train: 1228.8176	loss_val: 1228.8285	loss_test: 1228.8292	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51782.0820	loss_val: 51790.1055	loss_test: 51782.1797	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10446.4736	loss_val: 10446.4170	loss_test: 10446.5020	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2877.2551	loss_val: 2877.3450	loss_test: 2877.3550	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 37382.1914	loss_val: 37384.6055	loss_test: 37383.4297	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 260201.0469	loss_val: 260201.1875	loss_test: 260201.7812	accuracy_train: 0.9235	accuracy_val: 0.8000	accuracy_test: 0.9231
[client 14]	loss_train: 9704.7148	loss_val: 9704.7568	loss_test: 9704.8379	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1436.4509	loss_val: 1436.4720	loss_test: 1436.5074	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6518.2168	loss_val: 6518.7358	loss_test: 6519.0405	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 27732.9023	loss_val: 27732.8008	loss_test: 27733.2148	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12415.5098	loss_val: 12415.6406	loss_test: 12415.5752	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1026.6620	loss_val: 1026.6624	loss_test: 1026.6786	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 83	curr_val_accuracy: 0.6794	curr_test_accuracy: 0.6895
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31701.0801	loss_val: 31701.1230	loss_test: 31701.1953	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19492.4375	loss_val: 19492.5703	loss_test: 19492.5117	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47119.3125	loss_val: 47121.5781	loss_test: 47120.3789	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16717.5117	loss_val: 16717.4648	loss_test: 16717.5645	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4146
[client 4]	loss_train: 7130.2236	loss_val: 7130.1562	loss_test: 7130.4214	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5425.2998	loss_val: 5425.3569	loss_test: 5425.4751	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 38386.2070	loss_val: 38386.7812	loss_test: 38386.1641	accuracy_train: 0.5000	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 30281.9375	loss_val: 30282.0859	loss_test: 30281.9141	accuracy_train: 0.5669	accuracy_val: 0.4167	accuracy_test: 0.5405
[client 8]	loss_train: 1224.0532	loss_val: 1224.0635	loss_test: 1224.0649	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51945.8242	loss_val: 51953.9766	loss_test: 51945.9180	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10728.6221	loss_val: 10728.5625	loss_test: 10728.6484	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2897.9419	loss_val: 2898.0344	loss_test: 2898.0393	accuracy_train: 0.6314	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 36086.0977	loss_val: 36088.6016	loss_test: 36087.3750	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 244874.7656	loss_val: 244874.9062	loss_test: 244875.5312	accuracy_train: 0.9337	accuracy_val: 0.8000	accuracy_test: 0.9231
[client 14]	loss_train: 9379.5020	loss_val: 9379.5410	loss_test: 9379.6221	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1425.8190	loss_val: 1425.8405	loss_test: 1425.8729	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6455.6631	loss_val: 6456.1860	loss_test: 6456.4897	accuracy_train: 0.9464	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 27641.1543	loss_val: 27641.0762	loss_test: 27641.4629	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12649.2441	loss_val: 12649.3760	loss_test: 12649.3105	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1021.0535	loss_val: 1021.0540	loss_test: 1021.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 84	curr_val_accuracy: 0.6755	curr_test_accuracy: 0.6876
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31807.6309	loss_val: 31807.6719	loss_test: 31807.7559	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19835.3379	loss_val: 19835.4766	loss_test: 19835.4121	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47464.7148	loss_val: 47467.0469	loss_test: 47465.7969	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17230.3398	loss_val: 17230.2930	loss_test: 17230.3945	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 7017.5093	loss_val: 7017.4644	loss_test: 7017.7119	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5454.8320	loss_val: 5454.8799	loss_test: 5455.0122	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40310.6016	loss_val: 40311.1758	loss_test: 40310.5391	accuracy_train: 0.4882	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 30370.7324	loss_val: 30370.8789	loss_test: 30370.7090	accuracy_train: 0.5387	accuracy_val: 0.4167	accuracy_test: 0.5135
[client 8]	loss_train: 1212.5431	loss_val: 1212.5526	loss_test: 1212.5547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51966.3320	loss_val: 51974.6797	loss_test: 51966.4258	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 11010.7695	loss_val: 11010.7080	loss_test: 11010.7979	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2904.7087	loss_val: 2904.8022	loss_test: 2904.8147	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 35122.7812	loss_val: 35125.3984	loss_test: 35124.0664	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 246789.3438	loss_val: 246789.4531	loss_test: 246790.1250	accuracy_train: 0.9184	accuracy_val: 0.8000	accuracy_test: 0.9231
[client 14]	loss_train: 9165.7461	loss_val: 9165.7842	loss_test: 9165.8662	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1410.5193	loss_val: 1410.5406	loss_test: 1410.5708	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6409.4253	loss_val: 6409.9531	loss_test: 6410.2563	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25242.4922	loss_val: 25242.4316	loss_test: 25242.7871	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12669.1328	loss_val: 12669.2686	loss_test: 12669.1963	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1023.0096	loss_val: 1023.0099	loss_test: 1023.0268	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 85	curr_val_accuracy: 0.6755	curr_test_accuracy: 0.6876
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32665.5137	loss_val: 32665.5527	loss_test: 32665.6348	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20255.4434	loss_val: 20255.5723	loss_test: 20255.5195	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47909.7539	loss_val: 47912.1367	loss_test: 47910.8477	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 18471.5586	loss_val: 18471.5039	loss_test: 18471.6094	accuracy_train: 0.4497	accuracy_val: 0.4500	accuracy_test: 0.4390
[client 4]	loss_train: 7059.1152	loss_val: 7059.0591	loss_test: 7059.3369	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5799.1802	loss_val: 5799.2212	loss_test: 5799.3521	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 41400.5117	loss_val: 41401.1016	loss_test: 41400.4336	accuracy_train: 0.4941	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 29609.9688	loss_val: 29610.1172	loss_test: 29609.9473	accuracy_train: 0.5246	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1212.9431	loss_val: 1212.9520	loss_test: 1212.9546	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51860.0273	loss_val: 51868.6172	loss_test: 51860.1172	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 11130.4492	loss_val: 11130.3857	loss_test: 11130.4785	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2884.0796	loss_val: 2884.1697	loss_test: 2884.2056	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 43488.8320	loss_val: 43491.5078	loss_test: 43490.1484	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 232707.7812	loss_val: 232707.8906	loss_test: 232708.5625	accuracy_train: 0.9184	accuracy_val: 0.7600	accuracy_test: 0.9231
[client 14]	loss_train: 9118.1221	loss_val: 9118.1611	loss_test: 9118.2393	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1408.7660	loss_val: 1408.7872	loss_test: 1408.8153	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6353.7358	loss_val: 6354.2686	loss_test: 6354.5703	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 24317.1973	loss_val: 24317.1445	loss_test: 24317.4805	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12290.8281	loss_val: 12290.9648	loss_test: 12290.8896	accuracy_train: 0.4191	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 1015.4589	loss_val: 1015.4594	loss_test: 1015.4764	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 86	curr_val_accuracy: 0.6735	curr_test_accuracy: 0.6857
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34884.8555	loss_val: 34884.8906	loss_test: 34884.9805	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20165.4043	loss_val: 20165.5273	loss_test: 20165.4805	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48604.3711	loss_val: 48606.8086	loss_test: 48605.4805	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 18475.1309	loss_val: 18475.0703	loss_test: 18475.1836	accuracy_train: 0.4528	accuracy_val: 0.5250	accuracy_test: 0.4390
[client 4]	loss_train: 7073.4580	loss_val: 7073.3833	loss_test: 7073.7139	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5433.5967	loss_val: 5433.6475	loss_test: 5433.7749	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40875.0859	loss_val: 40875.6758	loss_test: 40875.0039	accuracy_train: 0.5000	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 28432.8730	loss_val: 28433.0273	loss_test: 28432.8633	accuracy_train: 0.5246	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1202.5814	loss_val: 1202.5900	loss_test: 1202.5927	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51726.5039	loss_val: 51735.2617	loss_test: 51726.5898	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 11089.8535	loss_val: 11089.7900	loss_test: 11089.8818	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2887.9907	loss_val: 2888.0828	loss_test: 2888.1335	accuracy_train: 0.6353	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 53777.4531	loss_val: 53780.0977	loss_test: 53778.7656	accuracy_train: 0.9407	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 205956.2188	loss_val: 205956.3750	loss_test: 205957.0156	accuracy_train: 0.9184	accuracy_val: 0.7600	accuracy_test: 0.9231
[client 14]	loss_train: 9175.3057	loss_val: 9175.3457	loss_test: 9175.4219	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1398.2397	loss_val: 1398.2611	loss_test: 1398.2881	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6335.9136	loss_val: 6336.4502	loss_test: 6336.7524	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 23612.1992	loss_val: 23612.1465	loss_test: 23612.4863	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12017.2598	loss_val: 12017.4004	loss_test: 12017.3193	accuracy_train: 0.4265	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 1003.8675	loss_val: 1003.8679	loss_test: 1003.8853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 87	curr_val_accuracy: 0.6795	curr_test_accuracy: 0.6896
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 38755.3438	loss_val: 38755.3828	loss_test: 38755.4727	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19906.8984	loss_val: 19907.0156	loss_test: 19906.9688	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48842.0000	loss_val: 48844.4805	loss_test: 48843.1367	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 20164.9629	loss_val: 20164.8984	loss_test: 20165.0176	accuracy_train: 0.4591	accuracy_val: 0.5250	accuracy_test: 0.4390
[client 4]	loss_train: 6804.0796	loss_val: 6804.0054	loss_test: 6804.3320	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5428.6597	loss_val: 5428.7354	loss_test: 5428.8633	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40274.5898	loss_val: 40275.1914	loss_test: 40274.5156	accuracy_train: 0.5176	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 28405.2383	loss_val: 28405.3965	loss_test: 28405.2363	accuracy_train: 0.5246	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1195.0420	loss_val: 1195.0505	loss_test: 1195.0531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50898.9023	loss_val: 50907.7188	loss_test: 50898.9805	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10770.6377	loss_val: 10770.5713	loss_test: 10770.6631	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2835.8494	loss_val: 2835.9438	loss_test: 2836.0039	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 57352.6133	loss_val: 57355.2578	loss_test: 57353.9805	accuracy_train: 0.9492	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 199825.9219	loss_val: 199826.0781	loss_test: 199826.6875	accuracy_train: 0.9184	accuracy_val: 0.8000	accuracy_test: 0.8846
[client 14]	loss_train: 9247.1133	loss_val: 9247.1514	loss_test: 9247.2295	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1395.6731	loss_val: 1395.6941	loss_test: 1395.7209	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6355.5786	loss_val: 6356.1196	loss_test: 6356.4214	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 23473.3633	loss_val: 23473.3027	loss_test: 23473.6543	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 11854.7275	loss_val: 11854.8701	loss_test: 11854.7861	accuracy_train: 0.4375	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 989.5969	loss_val: 989.5972	loss_test: 989.6155	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 88	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6857
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 42962.5859	loss_val: 42962.6250	loss_test: 42962.7070	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19865.2012	loss_val: 19865.3105	loss_test: 19865.2695	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48344.0430	loss_val: 48346.5664	loss_test: 48345.2031	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 21362.0879	loss_val: 21362.0254	loss_test: 21362.1445	accuracy_train: 0.4528	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6716.0254	loss_val: 6715.9692	loss_test: 6716.2705	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5648.0259	loss_val: 5648.1050	loss_test: 5648.2358	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 40101.4062	loss_val: 40102.0234	loss_test: 40101.3633	accuracy_train: 0.5294	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 27799.2949	loss_val: 27799.4590	loss_test: 27799.2930	accuracy_train: 0.5282	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1198.6764	loss_val: 1198.6851	loss_test: 1198.6874	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50623.4297	loss_val: 50632.3945	loss_test: 50623.5000	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10514.7803	loss_val: 10514.7100	loss_test: 10514.8018	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2813.6401	loss_val: 2813.7327	loss_test: 2813.7961	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 61825.2969	loss_val: 61827.9141	loss_test: 61826.6289	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 193937.1250	loss_val: 193937.2969	loss_test: 193937.8906	accuracy_train: 0.9235	accuracy_val: 0.8000	accuracy_test: 0.8846
[client 14]	loss_train: 9453.8613	loss_val: 9453.8994	loss_test: 9453.9785	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1400.0741	loss_val: 1400.0951	loss_test: 1400.1227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6416.8340	loss_val: 6417.3823	loss_test: 6417.6821	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 24197.7168	loss_val: 24197.6465	loss_test: 24198.0176	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12024.7119	loss_val: 12024.8613	loss_test: 12024.7744	accuracy_train: 0.4485	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 980.9960	loss_val: 980.9962	loss_test: 981.0151	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 89	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6837
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 39730.3750	loss_val: 39730.4141	loss_test: 39730.4961	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19896.1973	loss_val: 19896.3047	loss_test: 19896.2676	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 48125.3047	loss_val: 48127.8828	loss_test: 48126.4922	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 20010.1562	loss_val: 20010.0996	loss_test: 20010.2129	accuracy_train: 0.4528	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6603.0400	loss_val: 6603.0112	loss_test: 6603.2822	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5368.9185	loss_val: 5368.9951	loss_test: 5369.1265	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39730.9141	loss_val: 39731.5508	loss_test: 39730.8828	accuracy_train: 0.5235	accuracy_val: 0.3636	accuracy_test: 0.5000
[client 7]	loss_train: 27651.6855	loss_val: 27651.8574	loss_test: 27651.6777	accuracy_train: 0.5493	accuracy_val: 0.4167	accuracy_test: 0.4865
[client 8]	loss_train: 1202.6565	loss_val: 1202.6652	loss_test: 1202.6671	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50472.6133	loss_val: 50481.7852	loss_test: 50472.6797	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10470.2744	loss_val: 10470.2021	loss_test: 10470.2939	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2845.6838	loss_val: 2845.7793	loss_test: 2845.8391	accuracy_train: 0.6431	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 64827.5820	loss_val: 64830.1875	loss_test: 64828.8906	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.7059
[client 13]	loss_train: 195447.9531	loss_val: 195448.1094	loss_test: 195448.7188	accuracy_train: 0.9235	accuracy_val: 0.8000	accuracy_test: 0.8846
[client 14]	loss_train: 9759.5752	loss_val: 9759.6250	loss_test: 9759.7021	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1408.9271	loss_val: 1408.9480	loss_test: 1408.9764	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6522.2285	loss_val: 6522.7832	loss_test: 6523.0806	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 24549.4219	loss_val: 24549.3574	loss_test: 24549.7207	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12244.3955	loss_val: 12244.5518	loss_test: 12244.4639	accuracy_train: 0.4265	accuracy_val: 0.4118	accuracy_test: 0.4286
[client 19]	loss_train: 973.6772	loss_val: 973.6772	loss_test: 973.6967	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 90	curr_val_accuracy: 0.6795	curr_test_accuracy: 0.6857
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 36177.3320	loss_val: 36177.3711	loss_test: 36177.4609	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 19665.2344	loss_val: 19665.3438	loss_test: 19665.3027	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47439.5312	loss_val: 47442.1484	loss_test: 47440.7422	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 19204.3457	loss_val: 19204.2910	loss_test: 19204.4023	accuracy_train: 0.4497	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6595.7314	loss_val: 6595.7129	loss_test: 6595.9834	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5311.4580	loss_val: 5311.5283	loss_test: 5311.6675	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 39110.1797	loss_val: 39110.8320	loss_test: 39110.1289	accuracy_train: 0.5176	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 27333.7305	loss_val: 27333.9023	loss_test: 27333.7246	accuracy_train: 0.5704	accuracy_val: 0.4167	accuracy_test: 0.5135
[client 8]	loss_train: 1206.4590	loss_val: 1206.4679	loss_test: 1206.4696	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50163.8867	loss_val: 50173.1484	loss_test: 50163.9492	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10757.5791	loss_val: 10757.5078	loss_test: 10757.5986	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 2955.0454	loss_val: 2955.1433	loss_test: 2955.1943	accuracy_train: 0.6275	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 65692.7812	loss_val: 65695.3984	loss_test: 65694.0703	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 196250.4531	loss_val: 196250.5938	loss_test: 196251.2500	accuracy_train: 0.9235	accuracy_val: 0.8000	accuracy_test: 0.8846
[client 14]	loss_train: 9996.7832	loss_val: 9996.8447	loss_test: 9996.9131	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1420.0016	loss_val: 1420.0215	loss_test: 1420.0511	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6633.4463	loss_val: 6634.0083	loss_test: 6634.3047	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 24499.6836	loss_val: 24499.6270	loss_test: 24499.9824	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12719.4492	loss_val: 12719.6104	loss_test: 12719.5225	accuracy_train: 0.4191	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 976.5952	loss_val: 976.5953	loss_test: 976.6140	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 91	curr_val_accuracy: 0.6775	curr_test_accuracy: 0.6858
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 34609.4258	loss_val: 34609.4648	loss_test: 34609.5625	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20006.8203	loss_val: 20006.9336	loss_test: 20006.8867	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 47408.8789	loss_val: 47411.5703	loss_test: 47410.1211	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 19293.5508	loss_val: 19293.4922	loss_test: 19293.6055	accuracy_train: 0.4497	accuracy_val: 0.5000	accuracy_test: 0.4146
[client 4]	loss_train: 6656.0571	loss_val: 6656.0142	loss_test: 6656.3291	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5467.2720	loss_val: 5467.3369	loss_test: 5467.4814	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 38581.7695	loss_val: 38582.3984	loss_test: 38581.6953	accuracy_train: 0.5235	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 27190.5781	loss_val: 27190.7461	loss_test: 27190.5801	accuracy_train: 0.5810	accuracy_val: 0.4444	accuracy_test: 0.5135
[client 8]	loss_train: 1196.8749	loss_val: 1196.8835	loss_test: 1196.8855	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49288.2852	loss_val: 49297.6914	loss_test: 49288.3516	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10940.3125	loss_val: 10940.2393	loss_test: 10940.3291	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3013.6470	loss_val: 3013.7458	loss_test: 3013.7932	accuracy_train: 0.6314	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 63270.6523	loss_val: 63273.2930	loss_test: 63271.9258	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 193541.9688	loss_val: 193542.1094	loss_test: 193542.8125	accuracy_train: 0.9235	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 10080.8359	loss_val: 10080.9131	loss_test: 10080.9668	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1429.5490	loss_val: 1429.5680	loss_test: 1429.5984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6692.8164	loss_val: 6693.3823	loss_test: 6693.6782	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 24488.1328	loss_val: 24488.0781	loss_test: 24488.4316	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12696.7822	loss_val: 12696.9453	loss_test: 12696.8574	accuracy_train: 0.4191	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 973.8920	loss_val: 973.8920	loss_test: 973.9103	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 92	curr_val_accuracy: 0.6815	curr_test_accuracy: 0.6839
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33960.9609	loss_val: 33961.0039	loss_test: 33961.1016	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20365.0762	loss_val: 20365.1875	loss_test: 20365.1426	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 46917.6680	loss_val: 46920.4102	loss_test: 46918.9336	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 18180.0469	loss_val: 18179.9863	loss_test: 18180.1094	accuracy_train: 0.4497	accuracy_val: 0.4750	accuracy_test: 0.4146
[client 4]	loss_train: 6094.8276	loss_val: 6094.7939	loss_test: 6095.0889	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5402.3750	loss_val: 5402.4390	loss_test: 5402.5850	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 38063.1797	loss_val: 38063.8086	loss_test: 38063.1094	accuracy_train: 0.5294	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 27460.2930	loss_val: 27460.4609	loss_test: 27460.2949	accuracy_train: 0.5775	accuracy_val: 0.4167	accuracy_test: 0.5135
[client 8]	loss_train: 1203.6719	loss_val: 1203.6798	loss_test: 1203.6824	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49523.7734	loss_val: 49533.3398	loss_test: 49523.8359	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10016.9209	loss_val: 10016.8486	loss_test: 10016.9385	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3065.0881	loss_val: 3065.1880	loss_test: 3065.2361	accuracy_train: 0.6392	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 57837.7656	loss_val: 57840.4102	loss_test: 57839.0352	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 190330.2812	loss_val: 190330.4062	loss_test: 190331.1562	accuracy_train: 0.9286	accuracy_val: 0.8400	accuracy_test: 0.8846
[client 14]	loss_train: 9980.0781	loss_val: 9980.1611	loss_test: 9980.2109	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1431.3002	loss_val: 1431.3182	loss_test: 1431.3486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6734.4688	loss_val: 6735.0396	loss_test: 6735.3345	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.3750
[client 17]	loss_train: 24854.8574	loss_val: 24854.7949	loss_test: 24855.1621	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12570.8945	loss_val: 12571.0615	loss_test: 12570.9697	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 974.2488	loss_val: 974.2488	loss_test: 974.2666	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 93	curr_val_accuracy: 0.6775	curr_test_accuracy: 0.6839
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33898.3477	loss_val: 33898.3906	loss_test: 33898.4844	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20441.7031	loss_val: 20441.8125	loss_test: 20441.7676	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 45615.0625	loss_val: 45617.8555	loss_test: 45616.3438	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 17139.6152	loss_val: 17139.5586	loss_test: 17139.6758	accuracy_train: 0.4560	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 6268.5239	loss_val: 6268.4980	loss_test: 6268.7827	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5471.3472	loss_val: 5471.4038	loss_test: 5471.5605	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 37008.7070	loss_val: 37009.3125	loss_test: 37008.6211	accuracy_train: 0.5235	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 27956.0176	loss_val: 27956.1895	loss_test: 27956.0234	accuracy_train: 0.5599	accuracy_val: 0.4167	accuracy_test: 0.5135
[client 8]	loss_train: 1193.9972	loss_val: 1194.0044	loss_test: 1194.0074	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 49918.4688	loss_val: 49928.1016	loss_test: 49918.5352	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9689.9531	loss_val: 9689.8877	loss_test: 9689.9727	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3086.7407	loss_val: 3086.8411	loss_test: 3086.8914	accuracy_train: 0.6392	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 57553.3047	loss_val: 57555.9844	loss_test: 57554.5703	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 186159.1094	loss_val: 186159.2500	loss_test: 186160.0156	accuracy_train: 0.9286	accuracy_val: 0.7600	accuracy_test: 0.8846
[client 14]	loss_train: 9890.0654	loss_val: 9890.1455	loss_test: 9890.2002	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1426.3599	loss_val: 1426.3767	loss_test: 1426.4072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6740.0303	loss_val: 6740.6084	loss_test: 6740.8950	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25248.5039	loss_val: 25248.4570	loss_test: 25248.8262	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12350.9111	loss_val: 12351.0830	loss_test: 12350.9854	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 970.7996	loss_val: 970.7997	loss_test: 970.8171	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 94	curr_val_accuracy: 0.6755	curr_test_accuracy: 0.6876
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 33582.2344	loss_val: 33582.2773	loss_test: 33582.3828	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20514.7832	loss_val: 20514.8965	loss_test: 20514.8516	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 43955.4492	loss_val: 43958.3320	loss_test: 43956.7305	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16867.0234	loss_val: 16866.9707	loss_test: 16867.0879	accuracy_train: 0.4623	accuracy_val: 0.4750	accuracy_test: 0.4390
[client 4]	loss_train: 6528.6714	loss_val: 6528.6577	loss_test: 6528.9331	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5420.7812	loss_val: 5420.8325	loss_test: 5420.9946	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 35795.5117	loss_val: 35796.0938	loss_test: 35795.4141	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 28524.2988	loss_val: 28524.4746	loss_test: 28524.3066	accuracy_train: 0.5458	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1188.0095	loss_val: 1188.0162	loss_test: 1188.0197	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50636.0547	loss_val: 50645.7812	loss_test: 50636.1250	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9490.0732	loss_val: 9490.0127	loss_test: 9490.0938	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3083.6609	loss_val: 3083.7651	loss_test: 3083.8193	accuracy_train: 0.6471	accuracy_val: 0.5938	accuracy_test: 0.6061
[client 12]	loss_train: 57450.0508	loss_val: 57452.7266	loss_test: 57451.2969	accuracy_train: 0.9492	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 185459.6562	loss_val: 185459.8125	loss_test: 185460.5781	accuracy_train: 0.9337	accuracy_val: 0.7600	accuracy_test: 0.8462
[client 14]	loss_train: 9984.2939	loss_val: 9984.3799	loss_test: 9984.4336	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1412.4165	loss_val: 1412.4326	loss_test: 1412.4623	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6641.8574	loss_val: 6642.4424	loss_test: 6642.7241	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25963.4492	loss_val: 25963.4219	loss_test: 25963.7754	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12147.9326	loss_val: 12148.1064	loss_test: 12148.0039	accuracy_train: 0.4191	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 961.6732	loss_val: 961.6732	loss_test: 961.6906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 95	curr_val_accuracy: 0.6755	curr_test_accuracy: 0.6819
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32885.4922	loss_val: 32885.5352	loss_test: 32885.6406	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20668.9258	loss_val: 20669.0430	loss_test: 20668.9941	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 42971.8047	loss_val: 42974.7852	loss_test: 42973.0820	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16836.7109	loss_val: 16836.6543	loss_test: 16836.7734	accuracy_train: 0.4843	accuracy_val: 0.5500	accuracy_test: 0.4390
[client 4]	loss_train: 6496.8159	loss_val: 6496.8169	loss_test: 6497.0923	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5421.4775	loss_val: 5421.5190	loss_test: 5421.6841	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 34905.9766	loss_val: 34906.5234	loss_test: 34905.8906	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 29183.1855	loss_val: 29183.3633	loss_test: 29183.1953	accuracy_train: 0.5458	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1180.9810	loss_val: 1180.9873	loss_test: 1180.9910	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 50789.0703	loss_val: 50798.8398	loss_test: 50789.1406	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9395.8740	loss_val: 9395.8135	loss_test: 9395.8965	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3095.8696	loss_val: 3095.9824	loss_test: 3096.0278	accuracy_train: 0.6431	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 62183.7227	loss_val: 62186.4766	loss_test: 62184.9570	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 191892.1094	loss_val: 191892.2812	loss_test: 191893.0312	accuracy_train: 0.9337	accuracy_val: 0.7600	accuracy_test: 0.8077
[client 14]	loss_train: 9949.5410	loss_val: 9949.6279	loss_test: 9949.6826	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1411.6078	loss_val: 1411.6229	loss_test: 1411.6526	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6558.4082	loss_val: 6559.0015	loss_test: 6559.2788	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 26086.4199	loss_val: 26086.3965	loss_test: 26086.7383	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12323.3535	loss_val: 12323.5283	loss_test: 12323.4180	accuracy_train: 0.4191	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 966.7017	loss_val: 966.7017	loss_test: 966.7187	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 96	curr_val_accuracy: 0.6835	curr_test_accuracy: 0.6800
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32535.5488	loss_val: 32535.5957	loss_test: 32535.7109	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20829.1270	loss_val: 20829.2480	loss_test: 20829.1953	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41792.3828	loss_val: 41795.4492	loss_test: 41793.6680	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16797.4473	loss_val: 16797.3945	loss_test: 16797.5078	accuracy_train: 0.4780	accuracy_val: 0.5500	accuracy_test: 0.4390
[client 4]	loss_train: 6445.4072	loss_val: 6445.4111	loss_test: 6445.6987	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5270.3188	loss_val: 5270.3638	loss_test: 5270.5210	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 34460.5469	loss_val: 34461.0391	loss_test: 34460.4375	accuracy_train: 0.5176	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 29319.6113	loss_val: 29319.7871	loss_test: 29319.6211	accuracy_train: 0.5246	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1168.2493	loss_val: 1168.2556	loss_test: 1168.2592	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 51628.4219	loss_val: 51638.2578	loss_test: 51628.4922	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9484.9541	loss_val: 9484.8887	loss_test: 9484.9775	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3055.4028	loss_val: 3055.5244	loss_test: 3055.5586	accuracy_train: 0.6471	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 66442.9297	loss_val: 66445.7266	loss_test: 66444.1406	accuracy_train: 0.9576	accuracy_val: 0.6000	accuracy_test: 0.6471
[client 13]	loss_train: 200463.0625	loss_val: 200463.2500	loss_test: 200463.9844	accuracy_train: 0.9337	accuracy_val: 0.7600	accuracy_test: 0.8077
[client 14]	loss_train: 9620.3828	loss_val: 9620.4678	loss_test: 9620.5273	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1401.2568	loss_val: 1401.2721	loss_test: 1401.3013	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6474.2886	loss_val: 6474.8911	loss_test: 6475.1631	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25995.0312	loss_val: 25995.0000	loss_test: 25995.3438	accuracy_train: 0.5816	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12489.5977	loss_val: 12489.7734	loss_test: 12489.6582	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 972.4074	loss_val: 972.4075	loss_test: 972.4240	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 97	curr_val_accuracy: 0.6835	curr_test_accuracy: 0.6800
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 32090.1543	loss_val: 32090.2031	loss_test: 32090.3242	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20902.4023	loss_val: 20902.5312	loss_test: 20902.4707	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41521.9258	loss_val: 41525.0117	loss_test: 41523.2188	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16559.0781	loss_val: 16559.0332	loss_test: 16559.1328	accuracy_train: 0.4623	accuracy_val: 0.5250	accuracy_test: 0.4390
[client 4]	loss_train: 6398.6211	loss_val: 6398.6631	loss_test: 6398.9126	accuracy_train: 0.6176	accuracy_val: 0.6667	accuracy_test: 0.5833
[client 5]	loss_train: 5301.0938	loss_val: 5301.1426	loss_test: 5301.2935	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 34259.5938	loss_val: 34260.0586	loss_test: 34259.4883	accuracy_train: 0.4941	accuracy_val: 0.3636	accuracy_test: 0.5455
[client 7]	loss_train: 29072.4902	loss_val: 29072.6680	loss_test: 29072.4863	accuracy_train: 0.5000	accuracy_val: 0.3889	accuracy_test: 0.4595
[client 8]	loss_train: 1176.3864	loss_val: 1176.3928	loss_test: 1176.3961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52392.2500	loss_val: 52402.1953	loss_test: 52392.3242	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 9919.8604	loss_val: 9919.7930	loss_test: 9919.8848	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3023.9351	loss_val: 3024.0630	loss_test: 3024.0884	accuracy_train: 0.6549	accuracy_val: 0.6250	accuracy_test: 0.6061
[client 12]	loss_train: 64471.0508	loss_val: 64473.8320	loss_test: 64472.2500	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 206135.1562	loss_val: 206135.3438	loss_test: 206136.0625	accuracy_train: 0.9388	accuracy_val: 0.7600	accuracy_test: 0.8462
[client 14]	loss_train: 9297.3389	loss_val: 9297.4219	loss_test: 9297.4893	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.3000
[client 15]	loss_train: 1405.0895	loss_val: 1405.1052	loss_test: 1405.1333	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6426.2358	loss_val: 6426.8486	loss_test: 6427.1167	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 25979.3047	loss_val: 25979.2578	loss_test: 25979.6172	accuracy_train: 0.5887	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12452.0127	loss_val: 12452.1895	loss_test: 12452.0723	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 971.1339	loss_val: 971.1340	loss_test: 971.1499	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 98	curr_val_accuracy: 0.6795	curr_test_accuracy: 0.6819
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 31995.9102	loss_val: 31995.9590	loss_test: 31996.0801	accuracy_train: 0.9806	accuracy_val: 1.0000	accuracy_test: 0.9286
[client 1]	loss_train: 20810.0938	loss_val: 20810.2305	loss_test: 20810.1641	accuracy_train: 0.7442	accuracy_val: 0.7500	accuracy_test: 0.7353
[client 2]	loss_train: 41834.0977	loss_val: 41837.2188	loss_test: 41835.4023	accuracy_train: 0.9880	accuracy_val: 0.7273	accuracy_test: 0.6364
[client 3]	loss_train: 16181.4902	loss_val: 16181.4502	loss_test: 16181.5381	accuracy_train: 0.4560	accuracy_val: 0.5000	accuracy_test: 0.4390
[client 4]	loss_train: 6318.3047	loss_val: 6318.3989	loss_test: 6318.5889	accuracy_train: 0.6176	accuracy_val: 0.6190	accuracy_test: 0.5833
[client 5]	loss_train: 5366.3174	loss_val: 5366.3647	loss_test: 5366.5254	accuracy_train: 0.8671	accuracy_val: 0.8611	accuracy_test: 0.8649
[client 6]	loss_train: 33830.1797	loss_val: 33830.5898	loss_test: 33830.0508	accuracy_train: 0.4824	accuracy_val: 0.4091	accuracy_test: 0.5455
[client 7]	loss_train: 28612.1152	loss_val: 28612.2871	loss_test: 28612.1035	accuracy_train: 0.5141	accuracy_val: 0.4167	accuracy_test: 0.4595
[client 8]	loss_train: 1171.1049	loss_val: 1171.1112	loss_test: 1171.1146	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 9]	loss_train: 52561.2656	loss_val: 52571.4453	loss_test: 52561.3359	accuracy_train: 1.0000	accuracy_val: 0.4286	accuracy_test: 1.0000
[client 10]	loss_train: 10455.1777	loss_val: 10455.1104	loss_test: 10455.1992	accuracy_train: 0.5803	accuracy_val: 0.5882	accuracy_test: 0.5714
[client 11]	loss_train: 3009.1814	loss_val: 3009.3169	loss_test: 3009.3408	accuracy_train: 0.6588	accuracy_val: 0.6250	accuracy_test: 0.6364
[client 12]	loss_train: 57416.2891	loss_val: 57418.9688	loss_test: 57417.4961	accuracy_train: 0.9576	accuracy_val: 0.6667	accuracy_test: 0.6471
[client 13]	loss_train: 205832.8125	loss_val: 205833.0156	loss_test: 205833.7656	accuracy_train: 0.9337	accuracy_val: 0.7600	accuracy_test: 0.8462
[client 14]	loss_train: 9362.9395	loss_val: 9363.0195	loss_test: 9363.0898	accuracy_train: 0.3007	accuracy_val: 0.2941	accuracy_test: 0.2500
[client 15]	loss_train: 1403.2784	loss_val: 1403.2937	loss_test: 1403.3219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 16]	loss_train: 6401.4219	loss_val: 6402.0444	loss_test: 6402.3091	accuracy_train: 0.9643	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 17]	loss_train: 27298.8086	loss_val: 27298.7559	loss_test: 27299.1387	accuracy_train: 0.5957	accuracy_val: 0.5882	accuracy_test: 0.5789
[client 18]	loss_train: 12301.8877	loss_val: 12302.0654	loss_test: 12301.9463	accuracy_train: 0.4154	accuracy_val: 0.4118	accuracy_test: 0.4000
[client 19]	loss_train: 968.9093	loss_val: 968.9096	loss_test: 968.9249	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
curr_round: 99	curr_val_accuracy: 0.6794	curr_test_accuracy: 0.6820
best_round: 10	best_val_accuracy: 0.7255	best_test_accuracy: 0.7223
--------------------------------------------------
