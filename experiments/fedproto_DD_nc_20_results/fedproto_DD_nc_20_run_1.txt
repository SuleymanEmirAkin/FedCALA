GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 0.6409	loss_val: 0.6547	loss_test: 0.6516	accuracy_train: 0.6000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 0.7098	loss_val: 0.7043	loss_test: 0.7376	accuracy_train: 0.4000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 0.6762	loss_val: 0.6532	loss_test: 0.6892	accuracy_train: 0.6571	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 3]	loss_train: 1.0422	loss_val: 1.0193	loss_test: 0.9343	accuracy_train: 0.0167	accuracy_val: 0.0000	accuracy_test: 0.1111
[client 4]	loss_train: 0.7125	loss_val: 0.7124	loss_test: 0.7236	accuracy_train: 0.3704	accuracy_val: 0.4000	accuracy_test: 0.3636
[client 5]	loss_train: 0.8235	loss_val: 0.8145	loss_test: 0.8190	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 6]	loss_train: 0.9546	loss_val: 0.9670	loss_test: 0.7959	accuracy_train: 0.0244	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 7]	loss_train: 0.7866	loss_val: 0.7951	loss_test: 0.7540	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 0.5267	loss_val: 0.5764	loss_test: 0.5851	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 0.4987	loss_val: 0.5223	loss_test: 0.4189	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 0.6722	loss_val: 0.7058	loss_test: 0.8334	accuracy_train: 0.7143	accuracy_val: 0.5714	accuracy_test: 0.5714
[client 11]	loss_train: 0.6889	loss_val: 0.7187	loss_test: 0.6704	accuracy_train: 0.6203	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 0.7039	loss_val: 0.7120	loss_test: 0.7272	accuracy_train: 0.4118	accuracy_val: 0.4000	accuracy_test: 0.2000
[client 13]	loss_train: 0.5617	loss_val: 0.5123	loss_test: 0.6065	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 0.6736	loss_val: 0.0000	loss_test: 0.4919	accuracy_train: 0.4286	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 0.6187	loss_val: 0.5341	loss_test: 0.6655	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 0.6069	loss_val: 0.5879	loss_test: 0.6079	accuracy_train: 0.6935	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 0.6455	loss_val: 0.6835	loss_test: 0.6691	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 0.7424	loss_val: 7.1669	loss_test: 0.7341	accuracy_train: 0.3000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 19]	loss_train: 0.8299	loss_val: 0.8022	loss_test: 0.8060	accuracy_train: 0.1939	accuracy_val: 0.1667	accuracy_test: 0.2308
curr_round: 0	curr_val_accuracy: 0.4634	curr_test_accuracy: 0.4644
best_round: 0	best_val_accuracy: 0.4634	best_test_accuracy: 0.4644
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 481.7972	loss_val: 481.7998	loss_test: 481.7983	accuracy_train: 0.6000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 539.2347	loss_val: 539.2249	loss_test: 539.1762	accuracy_train: 0.5333	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 2177.2339	loss_val: 2177.2126	loss_test: 2177.2422	accuracy_train: 0.6571	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 478.9802	loss_val: 478.9749	loss_test: 478.9123	accuracy_train: 0.0667	accuracy_val: 0.0000	accuracy_test: 0.1111
[client 4]	loss_train: 304.0028	loss_val: 304.0075	loss_test: 304.0130	accuracy_train: 0.3827	accuracy_val: 0.4000	accuracy_test: 0.3636
[client 5]	loss_train: 215.8149	loss_val: 215.8061	loss_test: 215.8043	accuracy_train: 0.6800	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 6]	loss_train: 389.2189	loss_val: 389.2758	loss_test: 389.0604	accuracy_train: 0.0244	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 7]	loss_train: 176.9643	loss_val: 176.9837	loss_test: 176.9201	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 294.7613	loss_val: 294.7524	loss_test: 294.8074	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 254.6297	loss_val: 254.6211	loss_test: 254.5852	accuracy_train: 0.2388	accuracy_val: 0.3750	accuracy_test: 0.5556
[client 10]	loss_train: 349.6242	loss_val: 349.6200	loss_test: 349.5267	accuracy_train: 0.8214	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 249.6494	loss_val: 249.6858	loss_test: 249.6379	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 219.1042	loss_val: 219.0993	loss_test: 219.1144	accuracy_train: 0.3235	accuracy_val: 0.2000	accuracy_test: 0.2000
[client 13]	loss_train: 306.6953	loss_val: 306.6904	loss_test: 306.7260	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 174.5177	loss_val: 173.8663	loss_test: 174.4362	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 282.4875	loss_val: 282.3894	loss_test: 282.5141	accuracy_train: 0.6364	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 193.1829	loss_val: 193.1509	loss_test: 193.1714	accuracy_train: 0.2097	accuracy_val: 0.3750	accuracy_test: 0.2500
[client 17]	loss_train: 231.4767	loss_val: 231.5529	loss_test: 231.4696	accuracy_train: 0.7407	accuracy_val: 0.2500	accuracy_test: 0.5000
[client 18]	loss_train: 1629.3726	loss_val: 1638.9305	loss_test: 1629.3328	accuracy_train: 0.2000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 19]	loss_train: 385.1606	loss_val: 385.1406	loss_test: 385.1395	accuracy_train: 0.1837	accuracy_val: 0.1667	accuracy_test: 0.2308
curr_round: 1	curr_val_accuracy: 0.4488	curr_test_accuracy: 0.4954
best_round: 0	best_val_accuracy: 0.4634	best_test_accuracy: 0.4644
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 805.4325	loss_val: 805.4357	loss_test: 805.4536	accuracy_train: 0.6800	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 1029.5642	loss_val: 1029.5750	loss_test: 1029.4448	accuracy_train: 0.7333	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 3420.6086	loss_val: 3420.5930	loss_test: 3420.6167	accuracy_train: 0.5714	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 809.5563	loss_val: 809.5497	loss_test: 809.5197	accuracy_train: 0.3333	accuracy_val: 0.5714	accuracy_test: 0.4444
[client 4]	loss_train: 474.2158	loss_val: 474.2185	loss_test: 474.2273	accuracy_train: 0.7407	accuracy_val: 0.8000	accuracy_test: 0.6364
[client 5]	loss_train: 386.7742	loss_val: 386.7695	loss_test: 386.7668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 543.0108	loss_val: 543.0526	loss_test: 542.8928	accuracy_train: 0.0244	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 7]	loss_train: 293.1847	loss_val: 293.1900	loss_test: 293.1266	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 503.5003	loss_val: 503.4707	loss_test: 503.5462	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 369.4973	loss_val: 369.4664	loss_test: 369.5250	accuracy_train: 0.0746	accuracy_val: 0.0000	accuracy_test: 0.2222
[client 10]	loss_train: 554.2170	loss_val: 554.2070	loss_test: 554.1264	accuracy_train: 0.8750	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 11]	loss_train: 347.5536	loss_val: 347.5927	loss_test: 347.5446	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 347.0371	loss_val: 347.0294	loss_test: 347.0497	accuracy_train: 0.2941	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 13]	loss_train: 372.8337	loss_val: 372.8391	loss_test: 372.8767	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 266.3234	loss_val: 265.6618	loss_test: 266.3051	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 452.4619	loss_val: 452.3542	loss_test: 452.4871	accuracy_train: 0.7727	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 291.2754	loss_val: 291.2534	loss_test: 291.2608	accuracy_train: 0.3387	accuracy_val: 0.3750	accuracy_test: 0.3750
[client 17]	loss_train: 370.2138	loss_val: 370.3081	loss_test: 370.1980	accuracy_train: 0.6667	accuracy_val: 0.2500	accuracy_test: 0.5000
[client 18]	loss_train: 3164.7695	loss_val: 3180.4849	loss_test: 3164.7119	accuracy_train: 0.2000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 19]	loss_train: 730.3421	loss_val: 730.3110	loss_test: 730.3109	accuracy_train: 0.1837	accuracy_val: 0.1667	accuracy_test: 0.2308
curr_round: 2	curr_val_accuracy: 0.5103	curr_test_accuracy: 0.5320
best_round: 2	best_val_accuracy: 0.5103	best_test_accuracy: 0.5320
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1211.8304	loss_val: 1211.8390	loss_test: 1211.8629	accuracy_train: 0.7467	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 1757.1465	loss_val: 1757.1641	loss_test: 1757.0612	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 5141.3716	loss_val: 5141.3545	loss_test: 5141.3833	accuracy_train: 0.5429	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 1250.1591	loss_val: 1250.1576	loss_test: 1250.1522	accuracy_train: 0.9333	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 4]	loss_train: 723.2912	loss_val: 723.2839	loss_test: 723.2994	accuracy_train: 0.7778	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 659.1658	loss_val: 659.1601	loss_test: 659.1606	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 702.0988	loss_val: 702.1307	loss_test: 702.0057	accuracy_train: 0.0244	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 7]	loss_train: 513.2239	loss_val: 513.2363	loss_test: 513.1614	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 773.8469	loss_val: 773.8275	loss_test: 773.8945	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 540.4974	loss_val: 540.4543	loss_test: 540.5530	accuracy_train: 0.1194	accuracy_val: 0.1250	accuracy_test: 0.2222
[client 10]	loss_train: 829.9271	loss_val: 829.9136	loss_test: 829.8424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 510.6259	loss_val: 510.6446	loss_test: 510.6291	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 531.0894	loss_val: 531.0874	loss_test: 531.0935	accuracy_train: 0.4118	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 13]	loss_train: 559.0234	loss_val: 559.0359	loss_test: 559.0765	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 399.6008	loss_val: 398.9498	loss_test: 399.6005	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 685.1323	loss_val: 685.0144	loss_test: 685.1521	accuracy_train: 0.6364	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 417.4568	loss_val: 417.4424	loss_test: 417.4477	accuracy_train: 0.7419	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 17]	loss_train: 579.4261	loss_val: 579.5067	loss_test: 579.4061	accuracy_train: 0.5926	accuracy_val: 0.2500	accuracy_test: 0.7500
[client 18]	loss_train: 5283.2188	loss_val: 5304.7217	loss_test: 5283.2012	accuracy_train: 0.3000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 19]	loss_train: 1185.3572	loss_val: 1185.3136	loss_test: 1185.3234	accuracy_train: 0.2449	accuracy_val: 0.2500	accuracy_test: 0.3077
curr_round: 3	curr_val_accuracy: 0.5885	curr_test_accuracy: 0.6279
best_round: 3	best_val_accuracy: 0.5885	best_test_accuracy: 0.6279
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1669.3979	loss_val: 1669.4166	loss_test: 1669.4349	accuracy_train: 0.7733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 2628.8967	loss_val: 2628.9260	loss_test: 2628.8633	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 7312.7339	loss_val: 7312.7002	loss_test: 7312.7437	accuracy_train: 0.6857	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 1771.9077	loss_val: 1771.9080	loss_test: 1771.9221	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 1021.0002	loss_val: 1020.9844	loss_test: 1021.0060	accuracy_train: 0.7531	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 1003.2684	loss_val: 1003.2657	loss_test: 1003.2553	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 856.4819	loss_val: 856.5058	loss_test: 856.4063	accuracy_train: 0.0244	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 7]	loss_train: 792.9587	loss_val: 792.9695	loss_test: 792.8948	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1056.4628	loss_val: 1056.4536	loss_test: 1056.5143	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 741.4146	loss_val: 741.3621	loss_test: 741.4742	accuracy_train: 0.1642	accuracy_val: 0.2500	accuracy_test: 0.2222
[client 10]	loss_train: 1133.2821	loss_val: 1133.2627	loss_test: 1133.1981	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 713.4206	loss_val: 713.4138	loss_test: 713.4424	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 755.4515	loss_val: 755.4561	loss_test: 755.4478	accuracy_train: 0.4118	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 13]	loss_train: 809.7957	loss_val: 809.8020	loss_test: 809.8570	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 559.1492	loss_val: 558.4972	loss_test: 559.1606	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 969.1108	loss_val: 968.9767	loss_test: 969.1323	accuracy_train: 0.6364	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 582.2225	loss_val: 582.2081	loss_test: 582.2161	accuracy_train: 0.9677	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 856.5856	loss_val: 856.6633	loss_test: 856.5638	accuracy_train: 0.5926	accuracy_val: 0.2500	accuracy_test: 0.7500
[client 18]	loss_train: 7771.8330	loss_val: 7798.0918	loss_test: 7771.8638	accuracy_train: 0.3000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 19]	loss_train: 1707.5807	loss_val: 1707.5254	loss_test: 1707.5496	accuracy_train: 0.4592	accuracy_val: 0.6667	accuracy_test: 0.7692
curr_round: 4	curr_val_accuracy: 0.6663	curr_test_accuracy: 0.6873
best_round: 4	best_val_accuracy: 0.6663	best_test_accuracy: 0.6873
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2160.8347	loss_val: 2160.8623	loss_test: 2160.8755	accuracy_train: 0.7600	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 3608.9741	loss_val: 3609.0032	loss_test: 3608.9817	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 9832.8857	loss_val: 9832.8350	loss_test: 9832.8926	accuracy_train: 0.6857	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 2358.3503	loss_val: 2358.3486	loss_test: 2358.3799	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 1354.2766	loss_val: 1354.2483	loss_test: 1354.2823	accuracy_train: 0.7531	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 1403.0048	loss_val: 1403.0054	loss_test: 1402.9846	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1005.3567	loss_val: 1005.3720	loss_test: 1005.2963	accuracy_train: 0.5610	accuracy_val: 0.4000	accuracy_test: 0.8571
[client 7]	loss_train: 1114.0675	loss_val: 1114.0701	loss_test: 1114.0022	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1360.0737	loss_val: 1360.0674	loss_test: 1360.1255	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 987.9178	loss_val: 987.8596	loss_test: 987.9665	accuracy_train: 0.1940	accuracy_val: 0.2500	accuracy_test: 0.2222
[client 10]	loss_train: 1470.1875	loss_val: 1470.1652	loss_test: 1470.1082	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 945.5525	loss_val: 945.5264	loss_test: 945.5926	accuracy_train: 0.6203	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 1014.7327	loss_val: 1014.7490	loss_test: 1014.7151	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 1107.4656	loss_val: 1107.4694	loss_test: 1107.5402	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 737.7572	loss_val: 737.1031	loss_test: 737.7684	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1261.0985	loss_val: 1260.9415	loss_test: 1261.1234	accuracy_train: 0.6364	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 778.6462	loss_val: 778.6359	loss_test: 778.6414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 1202.3145	loss_val: 1202.3894	loss_test: 1202.2906	accuracy_train: 0.6296	accuracy_val: 0.2500	accuracy_test: 0.7500
[client 18]	loss_train: 10641.4023	loss_val: 10672.1963	loss_test: 10641.4775	accuracy_train: 0.4000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 19]	loss_train: 2266.7798	loss_val: 2266.7114	loss_test: 2266.7539	accuracy_train: 0.6735	accuracy_val: 0.7500	accuracy_test: 0.6923
curr_round: 5	curr_val_accuracy: 0.7179	curr_test_accuracy: 0.7346
best_round: 5	best_val_accuracy: 0.7179	best_test_accuracy: 0.7346
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2691.2944	loss_val: 2691.3293	loss_test: 2691.3391	accuracy_train: 0.7600	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 4710.2783	loss_val: 4710.3013	loss_test: 4710.3208	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 12841.7227	loss_val: 12841.6533	loss_test: 12841.7275	accuracy_train: 0.6857	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 3006.1572	loss_val: 3006.1560	loss_test: 3006.1982	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 1723.9438	loss_val: 1723.9030	loss_test: 1723.9468	accuracy_train: 0.7531	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 1841.9968	loss_val: 1842.0027	loss_test: 1841.9680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1163.5592	loss_val: 1163.5706	loss_test: 1163.5107	accuracy_train: 0.7561	accuracy_val: 0.6000	accuracy_test: 1.0000
[client 7]	loss_train: 1472.6672	loss_val: 1472.6642	loss_test: 1472.6040	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1680.6649	loss_val: 1680.6589	loss_test: 1680.7164	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 1283.3309	loss_val: 1283.2726	loss_test: 1283.3636	accuracy_train: 0.1940	accuracy_val: 0.2500	accuracy_test: 0.3333
[client 10]	loss_train: 1833.5164	loss_val: 1833.4929	loss_test: 1833.4447	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1208.1694	loss_val: 1208.1265	loss_test: 1208.2303	accuracy_train: 0.6456	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 1307.2606	loss_val: 1307.2853	loss_test: 1307.2350	accuracy_train: 0.5882	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 1467.5297	loss_val: 1467.5309	loss_test: 1467.6185	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 932.1134	loss_val: 931.4571	loss_test: 932.1277	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1582.2671	loss_val: 1582.0839	loss_test: 1582.2968	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 999.5970	loss_val: 999.5892	loss_test: 999.5931	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 1590.3821	loss_val: 1590.4602	loss_test: 1590.3578	accuracy_train: 0.7037	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 18]	loss_train: 13780.5586	loss_val: 13815.4346	loss_test: 13780.6660	accuracy_train: 0.6000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 19]	loss_train: 2856.5967	loss_val: 2856.5210	loss_test: 2856.5815	accuracy_train: 0.7041	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 6	curr_val_accuracy: 0.7507	curr_test_accuracy: 0.7564
best_round: 6	best_val_accuracy: 0.7507	best_test_accuracy: 0.7564
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3232.4351	loss_val: 3232.4768	loss_test: 3232.4832	accuracy_train: 0.7600	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 5872.3696	loss_val: 5872.3862	loss_test: 5872.4443	accuracy_train: 0.4667	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 16129.3467	loss_val: 16129.2627	loss_test: 16129.3506	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 3682.7261	loss_val: 3682.7224	loss_test: 3682.7769	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2122.7668	loss_val: 2122.7161	loss_test: 2122.7659	accuracy_train: 0.7531	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 2313.6562	loss_val: 2313.6641	loss_test: 2313.6206	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1335.1570	loss_val: 1335.1661	loss_test: 1335.1165	accuracy_train: 0.8293	accuracy_val: 0.6000	accuracy_test: 1.0000
[client 7]	loss_train: 1868.4009	loss_val: 1868.3903	loss_test: 1868.3425	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2024.4937	loss_val: 2024.4911	loss_test: 2024.5450	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 1616.1764	loss_val: 1616.1198	loss_test: 1616.1858	accuracy_train: 0.1940	accuracy_val: 0.2500	accuracy_test: 0.3333
[client 10]	loss_train: 2224.1404	loss_val: 2224.1189	loss_test: 2224.0720	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1495.0624	loss_val: 1495.0060	loss_test: 1495.1448	accuracy_train: 0.6835	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 1627.8878	loss_val: 1627.9181	loss_test: 1627.8580	accuracy_train: 0.5588	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 1904.2772	loss_val: 1904.2776	loss_test: 1904.3762	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1146.2098	loss_val: 1145.5559	loss_test: 1146.2181	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1931.9091	loss_val: 1931.7012	loss_test: 1931.9423	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 1245.2461	loss_val: 1245.2418	loss_test: 1245.2446	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 2015.4479	loss_val: 2015.5356	loss_test: 2015.4236	accuracy_train: 0.8519	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 18]	loss_train: 17095.8633	loss_val: 17134.1328	loss_test: 17095.9941	accuracy_train: 0.8000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 19]	loss_train: 3472.9861	loss_val: 3472.9043	loss_test: 3472.9800	accuracy_train: 0.7755	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 7	curr_val_accuracy: 0.7591	curr_test_accuracy: 0.7591
best_round: 7	best_val_accuracy: 0.7591	best_test_accuracy: 0.7591
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3826.9753	loss_val: 3827.0259	loss_test: 3827.0261	accuracy_train: 0.7600	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 7152.7471	loss_val: 7152.7593	loss_test: 7152.8555	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 19732.1152	loss_val: 19732.0195	loss_test: 19732.1172	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 4400.0059	loss_val: 4399.9976	loss_test: 4400.0640	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2538.8794	loss_val: 2538.8184	loss_test: 2538.8765	accuracy_train: 0.7531	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 2817.8542	loss_val: 2817.8616	loss_test: 2817.8132	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1526.3640	loss_val: 1526.3722	loss_test: 1526.3350	accuracy_train: 0.8537	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 7]	loss_train: 2291.5481	loss_val: 2291.5286	loss_test: 2291.4944	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2384.3958	loss_val: 2384.3948	loss_test: 2384.4500	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 1994.5183	loss_val: 1994.4650	loss_test: 1994.4977	accuracy_train: 0.2239	accuracy_val: 0.2500	accuracy_test: 0.3333
[client 10]	loss_train: 2629.6423	loss_val: 2629.6208	loss_test: 2629.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1813.6458	loss_val: 1813.5784	loss_test: 1813.7490	accuracy_train: 0.7468	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 1977.4619	loss_val: 1977.4969	loss_test: 1977.4332	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 2416.3506	loss_val: 2416.3518	loss_test: 2416.4617	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1377.3472	loss_val: 1376.6984	loss_test: 1377.3545	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2325.2803	loss_val: 2325.0508	loss_test: 2325.3159	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 1522.7677	loss_val: 1522.7672	loss_test: 1522.7678	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 2478.4810	loss_val: 2478.5828	loss_test: 2478.4604	accuracy_train: 0.8889	accuracy_val: 0.7500	accuracy_test: 1.0000
[client 18]	loss_train: 20677.0059	loss_val: 20719.0293	loss_test: 20677.1602	accuracy_train: 0.9000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 19]	loss_train: 4102.7861	loss_val: 4102.7007	loss_test: 4102.7935	accuracy_train: 0.7653	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 8	curr_val_accuracy: 0.7842	curr_test_accuracy: 0.7607
best_round: 8	best_val_accuracy: 0.7842	best_test_accuracy: 0.7607
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 4464.6484	loss_val: 4464.7095	loss_test: 4464.7012	accuracy_train: 0.7867	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 8452.6289	loss_val: 8452.6406	loss_test: 8452.7627	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 23666.1875	loss_val: 23666.0820	loss_test: 23666.1875	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 5162.2759	loss_val: 5162.2612	loss_test: 5162.3379	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2973.0596	loss_val: 2972.9912	loss_test: 2973.0559	accuracy_train: 0.7531	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 3349.6733	loss_val: 3349.6785	loss_test: 3349.6272	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1733.5131	loss_val: 1733.5197	loss_test: 1733.4912	accuracy_train: 0.8780	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2752.9028	loss_val: 2752.8779	loss_test: 2752.8525	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2754.5764	loss_val: 2754.5789	loss_test: 2754.6340	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 2405.9299	loss_val: 2405.8821	loss_test: 2405.8789	accuracy_train: 0.2388	accuracy_val: 0.2500	accuracy_test: 0.3333
[client 10]	loss_train: 3053.8757	loss_val: 3053.8535	loss_test: 3053.8135	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2163.6367	loss_val: 2163.5620	loss_test: 2163.7629	accuracy_train: 0.7595	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 2341.4463	loss_val: 2341.4863	loss_test: 2341.4177	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 3012.1172	loss_val: 3012.1228	loss_test: 3012.2368	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1597.3821	loss_val: 1596.7441	loss_test: 1597.3911	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2738.3674	loss_val: 2738.1213	loss_test: 2738.4038	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 1814.5305	loss_val: 1814.5312	loss_test: 1814.5306	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 2974.5559	loss_val: 2974.6763	loss_test: 2974.5391	accuracy_train: 0.8519	accuracy_val: 0.7500	accuracy_test: 1.0000
[client 18]	loss_train: 24484.4688	loss_val: 24529.3262	loss_test: 24484.6445	accuracy_train: 0.9000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 4742.9741	loss_val: 4742.8848	loss_test: 4742.9937	accuracy_train: 0.7959	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 9	curr_val_accuracy: 0.8019	curr_test_accuracy: 0.7647
best_round: 9	best_val_accuracy: 0.8019	best_test_accuracy: 0.7647
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5148.6216	loss_val: 5148.6938	loss_test: 5148.6768	accuracy_train: 0.8000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 9784.0781	loss_val: 9784.0840	loss_test: 9784.2305	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 27906.1016	loss_val: 27905.9863	loss_test: 27906.0996	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 5957.3354	loss_val: 5957.3169	loss_test: 5957.4023	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 3428.6650	loss_val: 3428.5908	loss_test: 3428.6609	accuracy_train: 0.7654	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 3896.9268	loss_val: 3896.9307	loss_test: 3896.8767	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1957.5366	loss_val: 1957.5405	loss_test: 1957.5187	accuracy_train: 0.9024	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3230.5654	loss_val: 3230.5374	loss_test: 3230.5203	accuracy_train: 0.2619	accuracy_val: 0.4000	accuracy_test: 0.4286
[client 8]	loss_train: 3129.0669	loss_val: 3129.0718	loss_test: 3129.1279	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 2845.9065	loss_val: 2845.8669	loss_test: 2845.8242	accuracy_train: 0.2836	accuracy_val: 0.2500	accuracy_test: 0.5556
[client 10]	loss_train: 3494.6809	loss_val: 3494.6575	loss_test: 3494.6204	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2537.8296	loss_val: 2537.7498	loss_test: 2537.9773	accuracy_train: 0.7722	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 2722.2310	loss_val: 2722.2749	loss_test: 2722.2046	accuracy_train: 0.6471	accuracy_val: 0.4000	accuracy_test: 1.0000
[client 13]	loss_train: 3658.6597	loss_val: 3658.6689	loss_test: 3658.7883	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1832.5730	loss_val: 1831.9445	loss_test: 1832.5851	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3182.9456	loss_val: 3182.6833	loss_test: 3182.9856	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 2117.9099	loss_val: 2117.9116	loss_test: 2117.9106	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 3497.9060	loss_val: 3498.0405	loss_test: 3497.8967	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 28191.3164	loss_val: 28239.6719	loss_test: 28191.5059	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5369.5918	loss_val: 5369.4995	loss_test: 5369.6221	accuracy_train: 0.7959	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 10	curr_val_accuracy: 0.8111	curr_test_accuracy: 0.7711
best_round: 10	best_val_accuracy: 0.8111	best_test_accuracy: 0.7711
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5863.1250	loss_val: 5863.2095	loss_test: 5863.1821	accuracy_train: 0.8133	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 11115.1768	loss_val: 11115.1816	loss_test: 11115.3633	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 32284.8516	loss_val: 32284.7305	loss_test: 32284.8477	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 6774.9863	loss_val: 6774.9663	loss_test: 6775.0566	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 3898.8306	loss_val: 3898.7542	loss_test: 3898.8276	accuracy_train: 0.7654	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 4449.8916	loss_val: 4449.8950	loss_test: 4449.8384	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2199.5215	loss_val: 2199.5244	loss_test: 2199.5066	accuracy_train: 0.9268	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3723.5332	loss_val: 3723.5015	loss_test: 3723.4907	accuracy_train: 0.2857	accuracy_val: 0.4000	accuracy_test: 0.4286
[client 8]	loss_train: 3511.5425	loss_val: 3511.5488	loss_test: 3511.6074	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3310.4121	loss_val: 3310.3804	loss_test: 3310.3040	accuracy_train: 0.3134	accuracy_val: 0.5000	accuracy_test: 0.5556
[client 10]	loss_train: 3930.9124	loss_val: 3930.8887	loss_test: 3930.8542	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2926.2939	loss_val: 2926.2109	loss_test: 2926.4636	accuracy_train: 0.7595	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 3125.9685	loss_val: 3126.0166	loss_test: 3125.9409	accuracy_train: 0.6471	accuracy_val: 0.4000	accuracy_test: 1.0000
[client 13]	loss_train: 4370.9131	loss_val: 4370.9263	loss_test: 4371.0469	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2060.2222	loss_val: 2059.6069	loss_test: 2060.2332	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3653.5796	loss_val: 3653.3040	loss_test: 3653.6265	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 2420.3125	loss_val: 2420.3145	loss_test: 2420.3137	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 4053.3284	loss_val: 4053.4854	loss_test: 4053.3276	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 31928.1055	loss_val: 31979.0449	loss_test: 31928.3086	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5995.0503	loss_val: 5994.9644	loss_test: 5995.0928	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 11	curr_val_accuracy: 0.8115	curr_test_accuracy: 0.7711
best_round: 11	best_val_accuracy: 0.8115	best_test_accuracy: 0.7711
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6602.1899	loss_val: 6602.2886	loss_test: 6602.2510	accuracy_train: 0.8133	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 12459.6650	loss_val: 12459.6719	loss_test: 12459.9102	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 36682.5430	loss_val: 36682.4219	loss_test: 36682.5430	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 7635.9722	loss_val: 7635.9521	loss_test: 7636.0469	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 4370.6128	loss_val: 4370.5386	loss_test: 4370.6133	accuracy_train: 0.7654	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 5008.5771	loss_val: 5008.5786	loss_test: 5008.5244	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2463.4617	loss_val: 2463.4634	loss_test: 2463.4487	accuracy_train: 0.9512	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4229.8877	loss_val: 4229.8545	loss_test: 4229.8472	accuracy_train: 0.3095	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 3908.7109	loss_val: 3908.7188	loss_test: 3908.7810	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3793.5659	loss_val: 3793.5442	loss_test: 3793.4363	accuracy_train: 0.3433	accuracy_val: 0.5000	accuracy_test: 0.5556
[client 10]	loss_train: 4355.9956	loss_val: 4355.9722	loss_test: 4355.9395	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3330.0366	loss_val: 3329.9517	loss_test: 3330.2275	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 3532.3809	loss_val: 3532.4353	loss_test: 3532.3533	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 1.0000
[client 13]	loss_train: 5152.1240	loss_val: 5152.1372	loss_test: 5152.2607	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2293.1633	loss_val: 2292.5654	loss_test: 2293.1790	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4117.9497	loss_val: 4117.6611	loss_test: 4118.0020	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 2742.3474	loss_val: 2742.3499	loss_test: 2742.3494	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 4607.9932	loss_val: 4608.1650	loss_test: 4608.0015	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 35693.8516	loss_val: 35747.1602	loss_test: 35694.0742	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6585.1772	loss_val: 6585.0972	loss_test: 6585.2310	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 12	curr_val_accuracy: 0.8207	curr_test_accuracy: 0.7795
best_round: 12	best_val_accuracy: 0.8207	best_test_accuracy: 0.7795
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7342.1646	loss_val: 7342.2773	loss_test: 7342.2285	accuracy_train: 0.8400	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13758.0020	loss_val: 13758.0127	loss_test: 13758.3047	accuracy_train: 0.4667	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 41147.5273	loss_val: 41147.3984	loss_test: 41147.5234	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 8521.4014	loss_val: 8521.3799	loss_test: 8521.4805	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 4836.0571	loss_val: 4835.9873	loss_test: 4836.0620	accuracy_train: 0.7531	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 5556.6382	loss_val: 5556.6372	loss_test: 5556.5845	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2741.3987	loss_val: 2741.3994	loss_test: 2741.3860	accuracy_train: 0.9512	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4700.5176	loss_val: 4700.4834	loss_test: 4700.4785	accuracy_train: 0.3571	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 4326.4697	loss_val: 4326.4814	loss_test: 4326.5464	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4290.0435	loss_val: 4290.0322	loss_test: 4289.8975	accuracy_train: 0.3881	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 10]	loss_train: 4766.8159	loss_val: 4766.7935	loss_test: 4766.7612	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3735.8733	loss_val: 3735.7886	loss_test: 3736.0859	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 3940.5503	loss_val: 3940.6138	loss_test: 3940.5225	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 1.0000
[client 13]	loss_train: 5968.9907	loss_val: 5969.0039	loss_test: 5969.1294	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2499.4685	loss_val: 2498.8857	loss_test: 2499.4875	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4590.3638	loss_val: 4590.0669	loss_test: 4590.4233	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 3068.8962	loss_val: 3068.8989	loss_test: 3068.8987	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5161.7397	loss_val: 5161.9233	loss_test: 5161.7578	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 39517.3359	loss_val: 39571.8672	loss_test: 39517.5703	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7157.1157	loss_val: 7157.0459	loss_test: 7157.1792	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 13	curr_val_accuracy: 0.8207	curr_test_accuracy: 0.7950
best_round: 12	best_val_accuracy: 0.8207	best_test_accuracy: 0.7795
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8075.1509	loss_val: 8075.2808	loss_test: 8075.2192	accuracy_train: 0.8267	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 14947.4971	loss_val: 14947.5049	loss_test: 14947.8633	accuracy_train: 0.4667	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 45479.1445	loss_val: 45479.0156	loss_test: 45479.1406	accuracy_train: 0.8286	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 9385.9326	loss_val: 9385.9121	loss_test: 9386.0166	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 5304.9312	loss_val: 5304.8682	loss_test: 5304.9424	accuracy_train: 0.7531	accuracy_val: 1.0000	accuracy_test: 0.8182
[client 5]	loss_train: 6091.8750	loss_val: 6091.8701	loss_test: 6091.8179	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3035.8489	loss_val: 3035.8491	loss_test: 3035.8335	accuracy_train: 0.9512	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5177.3228	loss_val: 5177.2896	loss_test: 5177.2832	accuracy_train: 0.3810	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 4765.3960	loss_val: 4765.4097	loss_test: 4765.4780	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4770.5215	loss_val: 4770.5195	loss_test: 4770.3652	accuracy_train: 0.5672	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 10]	loss_train: 5153.0391	loss_val: 5153.0176	loss_test: 5152.9858	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4139.0498	loss_val: 4138.9658	loss_test: 4139.2832	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 4309.2290	loss_val: 4309.3013	loss_test: 4309.2021	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 1.0000
[client 13]	loss_train: 6822.8657	loss_val: 6822.8765	loss_test: 6823.0054	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2709.7776	loss_val: 2709.2102	loss_test: 2709.8040	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5051.3838	loss_val: 5051.0786	loss_test: 5051.4521	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 3398.7058	loss_val: 3398.7080	loss_test: 3398.7080	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5698.5112	loss_val: 5698.7134	loss_test: 5698.5415	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 43102.2383	loss_val: 43156.9297	loss_test: 43102.4883	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7646.1934	loss_val: 7646.1357	loss_test: 7646.2671	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 14	curr_val_accuracy: 0.8207	curr_test_accuracy: 0.8029
best_round: 12	best_val_accuracy: 0.8207	best_test_accuracy: 0.7795
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8786.8682	loss_val: 8787.0137	loss_test: 8786.9414	accuracy_train: 0.8533	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 16009.3691	loss_val: 16009.3750	loss_test: 16009.7783	accuracy_train: 0.4667	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 49581.5625	loss_val: 49581.4336	loss_test: 49581.5625	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 10269.9355	loss_val: 10269.9160	loss_test: 10270.0244	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 5760.3599	loss_val: 5760.3057	loss_test: 5760.3784	accuracy_train: 0.7654	accuracy_val: 1.0000	accuracy_test: 0.8182
[client 5]	loss_train: 6607.6001	loss_val: 6607.5928	loss_test: 6607.5410	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3350.2988	loss_val: 3350.2981	loss_test: 3350.2793	accuracy_train: 0.9268	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5627.4727	loss_val: 5627.4380	loss_test: 5627.4346	accuracy_train: 0.3810	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 5206.9062	loss_val: 5206.9243	loss_test: 5206.9941	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 5257.0308	loss_val: 5257.0371	loss_test: 5256.8682	accuracy_train: 0.7015	accuracy_val: 0.5000	accuracy_test: 0.8889
[client 10]	loss_train: 5527.6431	loss_val: 5527.6240	loss_test: 5527.5933	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4535.4521	loss_val: 4535.3711	loss_test: 4535.7056	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 4669.1733	loss_val: 4669.2559	loss_test: 4669.1484	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 1.0000
[client 13]	loss_train: 7672.7520	loss_val: 7672.7622	loss_test: 7672.8931	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2916.3906	loss_val: 2915.8394	loss_test: 2916.4241	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5490.9849	loss_val: 5490.6738	loss_test: 5491.0625	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 3726.8301	loss_val: 3726.8315	loss_test: 3726.8318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6218.3750	loss_val: 6218.5889	loss_test: 6218.4160	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 46684.8555	loss_val: 46738.2188	loss_test: 46685.1172	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8096.9292	loss_val: 8096.8872	loss_test: 8097.0132	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 15	curr_val_accuracy: 0.8207	curr_test_accuracy: 0.8103
best_round: 12	best_val_accuracy: 0.8207	best_test_accuracy: 0.7795
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9475.7744	loss_val: 9475.9355	loss_test: 9475.8525	accuracy_train: 0.8533	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 16970.2930	loss_val: 16970.2988	loss_test: 16970.7422	accuracy_train: 0.4667	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 53440.9766	loss_val: 53440.8516	loss_test: 53440.9883	accuracy_train: 0.8286	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 11122.5430	loss_val: 11122.5244	loss_test: 11122.6348	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6184.2188	loss_val: 6184.1743	loss_test: 6184.2432	accuracy_train: 0.7778	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 7074.2974	loss_val: 7074.2881	loss_test: 7074.2373	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3657.6357	loss_val: 3657.6333	loss_test: 3657.6162	accuracy_train: 0.9268	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6054.8921	loss_val: 6054.8574	loss_test: 6054.8545	accuracy_train: 0.4048	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 5625.5566	loss_val: 5625.5830	loss_test: 5625.6533	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 5714.0986	loss_val: 5714.1113	loss_test: 5713.9346	accuracy_train: 0.9701	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5867.7139	loss_val: 5867.6958	loss_test: 5867.6670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4919.1572	loss_val: 4919.0801	loss_test: 4919.4297	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 4981.1289	loss_val: 4981.2227	loss_test: 4981.1069	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 1.0000
[client 13]	loss_train: 8524.3770	loss_val: 8524.3857	loss_test: 8524.5186	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3094.6545	loss_val: 3094.1201	loss_test: 3094.6926	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5914.3755	loss_val: 5914.0605	loss_test: 5914.4585	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4045.9368	loss_val: 4045.9373	loss_test: 4045.9380	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6730.1104	loss_val: 6730.3325	loss_test: 6730.1611	accuracy_train: 0.9259	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 50001.2617	loss_val: 50052.1055	loss_test: 50001.5352	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8459.6416	loss_val: 8459.6191	loss_test: 8459.7363	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 16	curr_val_accuracy: 0.8564	curr_test_accuracy: 0.8104
best_round: 16	best_val_accuracy: 0.8564	best_test_accuracy: 0.8104
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10118.6338	loss_val: 10118.8115	loss_test: 10118.7148	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 17751.5664	loss_val: 17751.5820	loss_test: 17752.0410	accuracy_train: 0.5333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 57015.6367	loss_val: 57015.5156	loss_test: 57015.6602	accuracy_train: 0.8286	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 11939.4102	loss_val: 11939.3936	loss_test: 11939.5049	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6591.6948	loss_val: 6591.6616	loss_test: 6591.7256	accuracy_train: 0.8025	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 7496.0122	loss_val: 7496.0015	loss_test: 7495.9526	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3970.8918	loss_val: 3970.8889	loss_test: 3970.8733	accuracy_train: 0.9268	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6444.6035	loss_val: 6444.5703	loss_test: 6444.5679	accuracy_train: 0.4048	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 6039.8252	loss_val: 6039.8599	loss_test: 6039.9292	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6143.9351	loss_val: 6143.9541	loss_test: 6143.7710	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6175.0122	loss_val: 6174.9961	loss_test: 6174.9683	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5283.2427	loss_val: 5283.1694	loss_test: 5283.5352	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 5262.2690	loss_val: 5262.3745	loss_test: 5262.2524	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 1.0000
[client 13]	loss_train: 9376.0283	loss_val: 9376.0352	loss_test: 9376.1719	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3261.9585	loss_val: 3261.4436	loss_test: 3262.0100	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6283.0898	loss_val: 6282.7710	loss_test: 6283.1797	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4355.1191	loss_val: 4355.1187	loss_test: 4355.1196	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7224.0405	loss_val: 7224.2778	loss_test: 7224.1001	accuracy_train: 0.9630	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 53076.1445	loss_val: 53124.2461	loss_test: 53076.4336	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8771.0049	loss_val: 8770.9980	loss_test: 8771.1094	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 17	curr_val_accuracy: 0.8564	curr_test_accuracy: 0.8045
best_round: 16	best_val_accuracy: 0.8564	best_test_accuracy: 0.8104
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10723.2969	loss_val: 10723.4922	loss_test: 10723.3809	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18484.4648	loss_val: 18484.4844	loss_test: 18484.9668	accuracy_train: 0.5333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 60245.9531	loss_val: 60245.8359	loss_test: 60245.9883	accuracy_train: 0.8286	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 12805.2041	loss_val: 12805.1904	loss_test: 12805.3018	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6958.9067	loss_val: 6958.8848	loss_test: 6958.9424	accuracy_train: 0.8148	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 7845.4331	loss_val: 7845.4224	loss_test: 7845.3745	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4277.7520	loss_val: 4277.7495	loss_test: 4277.7363	accuracy_train: 0.9268	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6795.0913	loss_val: 6795.0586	loss_test: 6795.0586	accuracy_train: 0.4048	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 6441.3003	loss_val: 6441.3452	loss_test: 6441.4136	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6556.0469	loss_val: 6556.0713	loss_test: 6555.8853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6441.2788	loss_val: 6441.2646	loss_test: 6441.2363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5611.5039	loss_val: 5611.4370	loss_test: 5611.8164	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5513.3628	loss_val: 5513.4761	loss_test: 5513.3525	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 1.0000
[client 13]	loss_train: 10180.3604	loss_val: 10180.3633	loss_test: 10180.5078	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3404.8801	loss_val: 3404.3865	loss_test: 3404.9434	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6629.8540	loss_val: 6629.5366	loss_test: 6629.9531	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4627.4976	loss_val: 4627.4956	loss_test: 4627.4971	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7681.6353	loss_val: 7681.8906	loss_test: 7681.7012	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 55873.1641	loss_val: 55918.1953	loss_test: 55873.4688	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 9020.6299	loss_val: 9020.6318	loss_test: 9020.7451	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 18	curr_val_accuracy: 0.8564	curr_test_accuracy: 0.7886
best_round: 16	best_val_accuracy: 0.8564	best_test_accuracy: 0.8104
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11259.8506	loss_val: 11260.0625	loss_test: 11259.9365	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 19038.1895	loss_val: 19038.2109	loss_test: 19038.7031	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 62978.3398	loss_val: 62978.2227	loss_test: 62978.3828	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 13688.4590	loss_val: 13688.4482	loss_test: 13688.5605	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7252.8618	loss_val: 7252.8530	loss_test: 7252.9038	accuracy_train: 0.8148	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8135.6113	loss_val: 8135.5991	loss_test: 8135.5532	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4574.5625	loss_val: 4574.5610	loss_test: 4574.5498	accuracy_train: 0.9268	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7092.4165	loss_val: 7092.3843	loss_test: 7092.3862	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 6796.3560	loss_val: 6796.4136	loss_test: 6796.4795	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6922.5737	loss_val: 6922.6045	loss_test: 6922.4165	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6654.4048	loss_val: 6654.3931	loss_test: 6654.3638	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5920.1069	loss_val: 5920.0469	loss_test: 5920.4385	accuracy_train: 0.8228	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5706.1338	loss_val: 5706.2563	loss_test: 5706.1328	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 10902.5420	loss_val: 10902.5449	loss_test: 10902.6924	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3532.2012	loss_val: 3531.7300	loss_test: 3532.2795	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6889.0039	loss_val: 6888.6870	loss_test: 6889.1123	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4861.6279	loss_val: 4861.6245	loss_test: 4861.6265	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8133.1851	loss_val: 8133.4727	loss_test: 8133.2568	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 58531.9570	loss_val: 58573.3711	loss_test: 58532.2734	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 9188.0605	loss_val: 9188.0713	loss_test: 9188.1855	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 19	curr_val_accuracy: 0.8648	curr_test_accuracy: 0.7818
best_round: 19	best_val_accuracy: 0.8648	best_test_accuracy: 0.7818
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11694.7119	loss_val: 11694.9414	loss_test: 11694.7998	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 19467.6289	loss_val: 19467.6484	loss_test: 19468.1758	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 65129.3711	loss_val: 65129.2617	loss_test: 65129.4297	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 14580.2197	loss_val: 14580.2119	loss_test: 14580.3252	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7512.6978	loss_val: 7512.6997	loss_test: 7512.7432	accuracy_train: 0.8272	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8366.3027	loss_val: 8366.2910	loss_test: 8366.2471	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4855.1655	loss_val: 4855.1660	loss_test: 4855.1602	accuracy_train: 0.9512	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7356.1113	loss_val: 7356.0806	loss_test: 7356.0830	accuracy_train: 0.4762	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 7132.1777	loss_val: 7132.2505	loss_test: 7132.3120	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 7258.6562	loss_val: 7258.6924	loss_test: 7258.5068	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6839.9980	loss_val: 6839.9863	loss_test: 6839.9575	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6166.9258	loss_val: 6166.8726	loss_test: 6167.2769	accuracy_train: 0.8354	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5856.5654	loss_val: 5856.6997	loss_test: 5856.5732	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 11576.2334	loss_val: 11576.2334	loss_test: 11576.3896	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3661.2429	loss_val: 3660.7922	loss_test: 3661.3403	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 7092.3237	loss_val: 7092.0088	loss_test: 7092.4434	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5058.3628	loss_val: 5058.3584	loss_test: 5058.3613	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8542.9297	loss_val: 8543.2539	loss_test: 8543.0068	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 60563.1406	loss_val: 60599.6406	loss_test: 60563.4766	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 9278.4424	loss_val: 9278.4648	loss_test: 9278.5781	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 20	curr_val_accuracy: 0.8648	curr_test_accuracy: 0.7743
best_round: 19	best_val_accuracy: 0.8648	best_test_accuracy: 0.7818
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 12079.6396	loss_val: 12079.8848	loss_test: 12079.7285	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 19692.9688	loss_val: 19692.9941	loss_test: 19693.5312	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 66719.9062	loss_val: 66719.8047	loss_test: 66719.9766	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 15472.7861	loss_val: 15472.7812	loss_test: 15472.8945	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7716.7524	loss_val: 7716.7637	loss_test: 7716.7998	accuracy_train: 0.8642	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8541.9688	loss_val: 8541.9570	loss_test: 8541.9150	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5103.9150	loss_val: 5103.9160	loss_test: 5103.9185	accuracy_train: 0.9512	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7561.7588	loss_val: 7561.7295	loss_test: 7561.7324	accuracy_train: 0.5238	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 7428.6626	loss_val: 7428.7505	loss_test: 7428.8091	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 7559.3174	loss_val: 7559.3564	loss_test: 7559.1758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6968.6118	loss_val: 6968.6006	loss_test: 6968.5718	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6395.9883	loss_val: 6395.9429	loss_test: 6396.3594	accuracy_train: 0.8354	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5955.9624	loss_val: 5956.1094	loss_test: 5955.9829	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 12181.9629	loss_val: 12181.9609	loss_test: 12182.1250	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3759.0439	loss_val: 3758.6196	loss_test: 3759.1538	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 7234.5356	loss_val: 7234.2251	loss_test: 7234.6714	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5208.1074	loss_val: 5208.1021	loss_test: 5208.1055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8907.5732	loss_val: 8907.9375	loss_test: 8907.6611	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 62109.6328	loss_val: 62140.6250	loss_test: 62109.9883	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 9313.4248	loss_val: 9313.4570	loss_test: 9313.5732	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 21	curr_val_accuracy: 0.8648	curr_test_accuracy: 0.7743
best_round: 19	best_val_accuracy: 0.8648	best_test_accuracy: 0.7818
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 12326.9072	loss_val: 12327.1670	loss_test: 12326.9971	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 19834.5742	loss_val: 19834.5996	loss_test: 19835.1660	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 67885.4297	loss_val: 67885.3359	loss_test: 67885.5234	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 16296.1211	loss_val: 16296.1201	loss_test: 16296.2334	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7867.3213	loss_val: 7867.3438	loss_test: 7867.3706	accuracy_train: 0.8889	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8641.0947	loss_val: 8641.0859	loss_test: 8641.0459	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5342.4697	loss_val: 5342.4712	loss_test: 5342.4868	accuracy_train: 0.9512	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7726.4331	loss_val: 7726.4072	loss_test: 7726.4116	accuracy_train: 0.5476	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 7710.7930	loss_val: 7710.8955	loss_test: 7710.9541	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 7826.7139	loss_val: 7826.7559	loss_test: 7826.5796	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7070.7266	loss_val: 7070.7153	loss_test: 7070.6870	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6589.2358	loss_val: 6589.1978	loss_test: 6589.6299	accuracy_train: 0.8354	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 6003.8198	loss_val: 6003.9795	loss_test: 6003.8535	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 12653.5371	loss_val: 12653.5352	loss_test: 12653.7080	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3829.8206	loss_val: 3829.4236	loss_test: 3829.9277	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 7317.0508	loss_val: 7316.7485	loss_test: 7317.2090	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5330.3003	loss_val: 5330.2939	loss_test: 5330.2979	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9230.6777	loss_val: 9231.0742	loss_test: 9230.7832	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 63908.1094	loss_val: 63933.3672	loss_test: 63908.4805	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 9280.3975	loss_val: 9280.4414	loss_test: 9280.5576	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 22	curr_val_accuracy: 0.8648	curr_test_accuracy: 0.7785
best_round: 19	best_val_accuracy: 0.8648	best_test_accuracy: 0.7818
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 12449.2051	loss_val: 12449.4775	loss_test: 12449.2939	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 19766.4863	loss_val: 19766.5156	loss_test: 19767.0859	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 68322.3281	loss_val: 68322.2422	loss_test: 68322.4297	accuracy_train: 0.9143	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 17204.0820	loss_val: 17204.0840	loss_test: 17204.1934	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7980.9756	loss_val: 7981.0112	loss_test: 7981.0273	accuracy_train: 0.8889	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8688.8945	loss_val: 8688.8848	loss_test: 8688.8486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5568.4746	loss_val: 5568.4766	loss_test: 5568.5005	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7825.9043	loss_val: 7825.8838	loss_test: 7825.8877	accuracy_train: 0.5952	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 7935.5425	loss_val: 7935.6621	loss_test: 7935.7202	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8039.5381	loss_val: 8039.5811	loss_test: 8039.4102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7155.0083	loss_val: 7154.9971	loss_test: 7154.9683	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6759.2310	loss_val: 6759.2017	loss_test: 6759.6460	accuracy_train: 0.8354	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 6016.2007	loss_val: 6016.3750	loss_test: 6016.2505	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 13074.1279	loss_val: 13074.1260	loss_test: 13074.3076	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3887.7190	loss_val: 3887.3459	loss_test: 3887.8257	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 7337.6616	loss_val: 7337.3691	loss_test: 7337.8452	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5393.0957	loss_val: 5393.0884	loss_test: 5393.0923	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9502.7803	loss_val: 9503.2031	loss_test: 9502.9062	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65280.0625	loss_val: 65299.0156	loss_test: 65280.4570	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 9180.8691	loss_val: 9180.9189	loss_test: 9181.0400	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 23	curr_val_accuracy: 0.8648	curr_test_accuracy: 0.7785
best_round: 19	best_val_accuracy: 0.8648	best_test_accuracy: 0.7818
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 12506.9736	loss_val: 12507.2568	loss_test: 12507.0596	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 19558.6797	loss_val: 19558.7188	loss_test: 19559.2852	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 68496.8125	loss_val: 68496.7344	loss_test: 68496.9297	accuracy_train: 0.9143	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 18005.0625	loss_val: 18005.0703	loss_test: 18005.1758	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8057.7900	loss_val: 8057.8359	loss_test: 8057.8403	accuracy_train: 0.8889	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8678.2891	loss_val: 8678.2803	loss_test: 8678.2471	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5764.1475	loss_val: 5764.1494	loss_test: 5764.1797	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7886.3486	loss_val: 7886.3369	loss_test: 7886.3408	accuracy_train: 0.7381	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 8146.6694	loss_val: 8146.8066	loss_test: 8146.8628	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8224.5898	loss_val: 8224.6328	loss_test: 8224.4658	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7205.7505	loss_val: 7205.7393	loss_test: 7205.7095	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6877.0103	loss_val: 6876.9907	loss_test: 6877.4482	accuracy_train: 0.8608	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5986.8994	loss_val: 5987.0898	loss_test: 5986.9658	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 13329.3936	loss_val: 13329.3926	loss_test: 13329.5840	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3941.1074	loss_val: 3940.7573	loss_test: 3941.2288	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 7309.4463	loss_val: 7309.1685	loss_test: 7309.6582	accuracy_train: 0.6364	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5415.1982	loss_val: 5415.1899	loss_test: 5415.1943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9735.8643	loss_val: 9736.3057	loss_test: 9736.0137	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66246.7266	loss_val: 66258.6797	loss_test: 66247.1484	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 9039.5342	loss_val: 9039.5898	loss_test: 9039.7168	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 24	curr_val_accuracy: 0.8648	curr_test_accuracy: 0.7785
best_round: 19	best_val_accuracy: 0.8648	best_test_accuracy: 0.7818
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 12514.1992	loss_val: 12514.4932	loss_test: 12514.2842	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 19244.7988	loss_val: 19244.8438	loss_test: 19245.3984	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 68414.6719	loss_val: 68414.6094	loss_test: 68414.8047	accuracy_train: 0.9429	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 18805.9375	loss_val: 18805.9512	loss_test: 18806.0508	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8109.3271	loss_val: 8109.3843	loss_test: 8109.3760	accuracy_train: 0.8889	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8604.5342	loss_val: 8604.5254	loss_test: 8604.4932	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5945.6445	loss_val: 5945.6479	loss_test: 5945.6797	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7911.4995	loss_val: 7911.5000	loss_test: 7911.5024	accuracy_train: 0.7857	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 8295.2412	loss_val: 8295.3936	loss_test: 8295.4502	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8377.8047	loss_val: 8377.8477	loss_test: 8377.6836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7226.1958	loss_val: 7226.1855	loss_test: 7226.1538	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6983.5830	loss_val: 6983.5732	loss_test: 6984.0459	accuracy_train: 0.8861	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5924.1655	loss_val: 5924.3745	loss_test: 5924.2534	accuracy_train: 0.6471	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 13532.0723	loss_val: 13532.0752	loss_test: 13532.2754	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3984.2119	loss_val: 3983.8877	loss_test: 3984.3535	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 7277.1479	loss_val: 7276.8862	loss_test: 7277.3916	accuracy_train: 0.6364	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5411.0991	loss_val: 5411.0898	loss_test: 5411.0942	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9888.9795	loss_val: 9889.4473	loss_test: 9889.1533	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66928.9844	loss_val: 66932.9688	loss_test: 66929.4297	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8865.1523	loss_val: 8865.2090	loss_test: 8865.3457	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 25	curr_val_accuracy: 0.8648	curr_test_accuracy: 0.7785
best_round: 19	best_val_accuracy: 0.8648	best_test_accuracy: 0.7818
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 12455.6592	loss_val: 12455.9639	loss_test: 12455.7461	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18860.9727	loss_val: 18861.0273	loss_test: 18861.5566	accuracy_train: 0.6667	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67812.3281	loss_val: 67812.2812	loss_test: 67812.4766	accuracy_train: 0.9429	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 19660.4277	loss_val: 19660.4453	loss_test: 19660.5430	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8125.3232	loss_val: 8125.3906	loss_test: 8125.3701	accuracy_train: 0.9012	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8477.7461	loss_val: 8477.7363	loss_test: 8477.7061	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6109.7710	loss_val: 6109.7749	loss_test: 6109.8057	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7887.6343	loss_val: 7887.6484	loss_test: 7887.6504	accuracy_train: 0.8095	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 8382.4023	loss_val: 8382.5693	loss_test: 8382.6289	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8479.0000	loss_val: 8479.0420	loss_test: 8478.8809	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7219.4878	loss_val: 7219.4766	loss_test: 7219.4453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7029.6841	loss_val: 7029.6851	loss_test: 7030.1709	accuracy_train: 0.8861	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5837.0781	loss_val: 5837.3086	loss_test: 5837.1836	accuracy_train: 0.6471	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13696.2666	loss_val: 13696.2725	loss_test: 13696.4814	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4006.1230	loss_val: 4005.8215	loss_test: 4006.2810	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 7164.4287	loss_val: 7164.1895	loss_test: 7164.7046	accuracy_train: 0.5909	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5402.0527	loss_val: 5402.0420	loss_test: 5402.0474	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9973.4463	loss_val: 9973.9395	loss_test: 9973.6475	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66973.3047	loss_val: 66973.0703	loss_test: 66973.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8652.5303	loss_val: 8652.5879	loss_test: 8652.7344	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 26	curr_val_accuracy: 0.8926	curr_test_accuracy: 0.7851
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 12321.0273	loss_val: 12321.3447	loss_test: 12321.1191	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18444.5312	loss_val: 18444.5977	loss_test: 18445.1094	accuracy_train: 0.7333	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 66952.0156	loss_val: 66951.9844	loss_test: 66952.1719	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 20491.7266	loss_val: 20491.7500	loss_test: 20491.8398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8129.6724	loss_val: 8129.7510	loss_test: 8129.7188	accuracy_train: 0.9136	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8318.1836	loss_val: 8318.1729	loss_test: 8318.1426	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6246.0264	loss_val: 6246.0283	loss_test: 6246.0610	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7832.6123	loss_val: 7832.6401	loss_test: 7832.6421	accuracy_train: 0.8333	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 8496.8096	loss_val: 8496.9932	loss_test: 8497.0557	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8541.4893	loss_val: 8541.5293	loss_test: 8541.3701	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7200.4595	loss_val: 7200.4473	loss_test: 7200.4170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7008.2178	loss_val: 7008.2314	loss_test: 7008.7261	accuracy_train: 0.9241	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5743.2896	loss_val: 5743.5435	loss_test: 5743.4097	accuracy_train: 0.6765	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13827.6406	loss_val: 13827.6504	loss_test: 13827.8691	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4030.9875	loss_val: 4030.7124	loss_test: 4031.1567	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 7028.7085	loss_val: 7028.4951	loss_test: 7029.0156	accuracy_train: 0.5909	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5374.4316	loss_val: 5374.4189	loss_test: 5374.4248	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 10004.3213	loss_val: 10004.8379	loss_test: 10004.5469	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66619.7812	loss_val: 66619.5469	loss_test: 66620.2656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8421.2207	loss_val: 8421.2744	loss_test: 8421.4346	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 27	curr_val_accuracy: 0.8926	curr_test_accuracy: 0.7851
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 12190.1660	loss_val: 12190.4980	loss_test: 12190.2617	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 17961.6816	loss_val: 17961.7617	loss_test: 17962.2441	accuracy_train: 0.7333	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 65760.5000	loss_val: 65760.4844	loss_test: 65760.6719	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 21290.7227	loss_val: 21290.7520	loss_test: 21290.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8099.5698	loss_val: 8099.6641	loss_test: 8099.6196	accuracy_train: 0.9136	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 8125.9009	loss_val: 8125.8906	loss_test: 8125.8594	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6368.1665	loss_val: 6368.1675	loss_test: 6368.2041	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7785.0376	loss_val: 7785.0786	loss_test: 7785.0830	accuracy_train: 0.8571	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 8575.1836	loss_val: 8575.3838	loss_test: 8575.4502	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8579.0400	loss_val: 8579.0762	loss_test: 8578.9209	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7154.9805	loss_val: 7154.9678	loss_test: 7154.9395	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6952.3906	loss_val: 6952.4170	loss_test: 6952.9160	accuracy_train: 0.9367	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5635.8882	loss_val: 5636.1670	loss_test: 5636.0269	accuracy_train: 0.7059	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13865.1680	loss_val: 13865.1787	loss_test: 13865.4082	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4032.8032	loss_val: 4032.5500	loss_test: 4032.9866	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6881.4326	loss_val: 6881.2451	loss_test: 6881.7656	accuracy_train: 0.5909	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5330.5122	loss_val: 5330.4976	loss_test: 5330.5039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9992.8203	loss_val: 9993.3555	loss_test: 9993.0732	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66460.2734	loss_val: 66460.0547	loss_test: 66460.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8189.0977	loss_val: 8189.1494	loss_test: 8189.3223	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 28	curr_val_accuracy: 0.8842	curr_test_accuracy: 0.7851
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 12044.8721	loss_val: 12045.2236	loss_test: 12044.9785	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 17460.8730	loss_val: 17460.9668	loss_test: 17461.4258	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 64205.5000	loss_val: 64205.5000	loss_test: 64205.6836	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 21992.8633	loss_val: 21992.9004	loss_test: 21992.9766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8114.0903	loss_val: 8114.1997	loss_test: 8114.1431	accuracy_train: 0.9136	accuracy_val: 1.0000	accuracy_test: 0.9091
[client 5]	loss_train: 7914.0425	loss_val: 7914.0322	loss_test: 7913.9990	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6484.9292	loss_val: 6484.9297	loss_test: 6484.9678	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7725.2109	loss_val: 7725.2656	loss_test: 7725.2734	accuracy_train: 0.8571	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 8616.4248	loss_val: 8616.6445	loss_test: 8616.7148	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8645.5264	loss_val: 8645.5586	loss_test: 8645.4092	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7105.1982	loss_val: 7105.1860	loss_test: 7105.1587	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6858.6733	loss_val: 6858.7158	loss_test: 6859.2158	accuracy_train: 0.9367	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5521.3696	loss_val: 5521.6763	loss_test: 5521.5322	accuracy_train: 0.7647	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13808.0684	loss_val: 13808.0830	loss_test: 13808.3223	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4040.6797	loss_val: 4040.4451	loss_test: 4040.8784	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6753.8921	loss_val: 6753.7363	loss_test: 6754.2534	accuracy_train: 0.5909	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5270.2588	loss_val: 5270.2422	loss_test: 5270.2495	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9962.7275	loss_val: 9963.2715	loss_test: 9963.0098	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65859.4609	loss_val: 65859.2500	loss_test: 65859.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7982.7700	loss_val: 7982.8286	loss_test: 7983.0073	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 29	curr_val_accuracy: 0.8842	curr_test_accuracy: 0.8008
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11870.0615	loss_val: 11870.4395	loss_test: 11870.1846	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 16939.3281	loss_val: 16939.4395	loss_test: 16939.8711	accuracy_train: 0.8667	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 62830.4102	loss_val: 62830.4297	loss_test: 62830.6094	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 22839.6777	loss_val: 22839.7266	loss_test: 22839.7910	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8072.6997	loss_val: 8072.8325	loss_test: 8072.7642	accuracy_train: 0.9136	accuracy_val: 1.0000	accuracy_test: 0.9091
[client 5]	loss_train: 7680.7710	loss_val: 7680.7603	loss_test: 7680.7266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6594.1885	loss_val: 6594.1885	loss_test: 6594.2261	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7653.5205	loss_val: 7653.5879	loss_test: 7653.6035	accuracy_train: 0.8571	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 8649.2852	loss_val: 8649.5195	loss_test: 8649.5977	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8738.9229	loss_val: 8738.9492	loss_test: 8738.8086	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7064.2563	loss_val: 7064.2441	loss_test: 7064.2173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6717.6240	loss_val: 6717.6836	loss_test: 6718.1772	accuracy_train: 0.9494	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5420.4751	loss_val: 5420.8091	loss_test: 5420.6646	accuracy_train: 0.8235	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13703.1035	loss_val: 13703.1221	loss_test: 13703.3730	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4037.4932	loss_val: 4037.2783	loss_test: 4037.7063	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6601.0791	loss_val: 6600.9595	loss_test: 6601.4736	accuracy_train: 0.5455	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5199.0781	loss_val: 5199.0591	loss_test: 5199.0674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9879.8066	loss_val: 9880.3584	loss_test: 9880.1172	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64937.2344	loss_val: 64937.0312	loss_test: 64937.7695	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7759.4878	loss_val: 7759.5562	loss_test: 7759.7363	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 30	curr_val_accuracy: 0.8842	curr_test_accuracy: 0.8008
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11686.9434	loss_val: 11687.3555	loss_test: 11687.0879	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 16483.1289	loss_val: 16483.2500	loss_test: 16483.6523	accuracy_train: 0.8667	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 61611.0820	loss_val: 61611.1172	loss_test: 61611.2969	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 23758.7910	loss_val: 23758.8496	loss_test: 23758.9023	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 8033.9546	loss_val: 8034.1143	loss_test: 8034.0352	accuracy_train: 0.9136	accuracy_val: 1.0000	accuracy_test: 0.9091
[client 5]	loss_train: 7424.2026	loss_val: 7424.1909	loss_test: 7424.1562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6712.1445	loss_val: 6712.1440	loss_test: 6712.1841	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7562.3330	loss_val: 7562.4131	loss_test: 7562.4375	accuracy_train: 0.9048	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 8659.3584	loss_val: 8659.6172	loss_test: 8659.6982	accuracy_train: 0.8750	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8828.5947	loss_val: 8828.6162	loss_test: 8828.4834	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6992.2783	loss_val: 6992.2651	loss_test: 6992.2402	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6557.2710	loss_val: 6557.3491	loss_test: 6557.8350	accuracy_train: 0.9494	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5318.0684	loss_val: 5318.4302	loss_test: 5318.2866	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 13543.1504	loss_val: 13543.1729	loss_test: 13543.4355	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4030.4668	loss_val: 4030.2710	loss_test: 4030.6926	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6451.2256	loss_val: 6451.1504	loss_test: 6451.6577	accuracy_train: 0.5455	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5125.2998	loss_val: 5125.2783	loss_test: 5125.2876	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9780.2119	loss_val: 9780.7666	loss_test: 9780.5508	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 63888.7695	loss_val: 63888.5742	loss_test: 63889.3125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7561.9336	loss_val: 7562.0088	loss_test: 7562.1948	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 31	curr_val_accuracy: 0.8841	curr_test_accuracy: 0.8148
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11425.4863	loss_val: 11425.9248	loss_test: 11425.6514	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 16070.3086	loss_val: 16070.4395	loss_test: 16070.8213	accuracy_train: 0.8667	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 59979.1250	loss_val: 59979.1797	loss_test: 59979.3555	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 24839.0449	loss_val: 24839.1113	loss_test: 24839.1523	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 7968.5356	loss_val: 7968.7222	loss_test: 7968.6362	accuracy_train: 0.9259	accuracy_val: 0.9000	accuracy_test: 0.9091
[client 5]	loss_train: 7168.6118	loss_val: 7168.5991	loss_test: 7168.5640	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6823.9199	loss_val: 6823.9199	loss_test: 6823.9624	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7453.7534	loss_val: 7453.8462	loss_test: 7453.8789	accuracy_train: 0.9048	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 8632.8252	loss_val: 8633.1104	loss_test: 8633.1914	accuracy_train: 0.8750	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8880.4463	loss_val: 8880.4619	loss_test: 8880.3340	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6928.7964	loss_val: 6928.7822	loss_test: 6928.7603	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6396.5981	loss_val: 6396.6963	loss_test: 6397.1709	accuracy_train: 0.9620	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5217.1074	loss_val: 5217.4971	loss_test: 5217.3647	accuracy_train: 0.9118	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 13378.3291	loss_val: 13378.3584	loss_test: 13378.6299	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4016.4941	loss_val: 4016.3140	loss_test: 4016.7278	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6308.1382	loss_val: 6308.1050	loss_test: 6308.6084	accuracy_train: 0.5455	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 5058.0381	loss_val: 5058.0132	loss_test: 5058.0249	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9658.2188	loss_val: 9658.7881	loss_test: 9658.5859	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 62760.5039	loss_val: 62760.3125	loss_test: 62761.0469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7377.8149	loss_val: 7377.8950	loss_test: 7378.0864	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 32	curr_val_accuracy: 0.8755	curr_test_accuracy: 0.8083
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11170.7959	loss_val: 11171.2686	loss_test: 11170.9863	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 15690.0361	loss_val: 15690.1768	loss_test: 15690.5342	accuracy_train: 0.8667	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58519.9375	loss_val: 58520.0156	loss_test: 58520.1914	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 25816.7891	loss_val: 25816.8574	loss_test: 25816.8945	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 7858.1802	loss_val: 7858.4004	loss_test: 7858.3076	accuracy_train: 0.9383	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 6914.5566	loss_val: 6914.5430	loss_test: 6914.5073	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6923.4604	loss_val: 6923.4614	loss_test: 6923.5088	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7333.8159	loss_val: 7333.9209	loss_test: 7333.9614	accuracy_train: 0.9048	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 8606.5869	loss_val: 8606.9023	loss_test: 8606.9814	accuracy_train: 0.8958	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8918.9473	loss_val: 8918.9590	loss_test: 8918.8369	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6872.7803	loss_val: 6872.7651	loss_test: 6872.7466	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6139.7505	loss_val: 6139.8750	loss_test: 6140.3276	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5126.5503	loss_val: 5126.9688	loss_test: 5126.8599	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 13220.8574	loss_val: 13220.8945	loss_test: 13221.1758	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4003.4697	loss_val: 4003.3062	loss_test: 4003.7114	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6141.3198	loss_val: 6141.3345	loss_test: 6141.8306	accuracy_train: 0.5909	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4985.3628	loss_val: 4985.3340	loss_test: 4985.3477	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9520.3066	loss_val: 9520.8828	loss_test: 9520.6943	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 61661.2031	loss_val: 61661.0156	loss_test: 61661.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7219.2188	loss_val: 7219.2959	loss_test: 7219.4985	accuracy_train: 0.8469	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 33	curr_val_accuracy: 0.8755	curr_test_accuracy: 0.8061
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10927.3115	loss_val: 10927.8213	loss_test: 10927.5293	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 15315.0537	loss_val: 15315.2041	loss_test: 15315.5449	accuracy_train: 0.8667	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 57323.3906	loss_val: 57323.4844	loss_test: 57323.6641	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 26865.9336	loss_val: 26866.0059	loss_test: 26866.0371	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 7761.9956	loss_val: 7762.2446	loss_test: 7762.1484	accuracy_train: 0.9383	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 6672.3701	loss_val: 6672.3545	loss_test: 6672.3203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7016.2471	loss_val: 7016.2500	loss_test: 7016.3047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7193.1118	loss_val: 7193.2314	loss_test: 7193.2778	accuracy_train: 0.9286	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 8591.6689	loss_val: 8592.0137	loss_test: 8592.0928	accuracy_train: 0.9167	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8978.4951	loss_val: 8978.5020	loss_test: 8978.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6832.1646	loss_val: 6832.1479	loss_test: 6832.1333	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5863.9189	loss_val: 5864.0708	loss_test: 5864.4961	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5043.0498	loss_val: 5043.4937	loss_test: 5043.4111	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 13051.9688	loss_val: 13052.0127	loss_test: 13052.3047	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3989.9438	loss_val: 3989.7947	loss_test: 3990.1987	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5994.9277	loss_val: 5994.9937	loss_test: 5995.4736	accuracy_train: 0.6364	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 16]	loss_train: 4918.3867	loss_val: 4918.3530	loss_test: 4918.3691	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9391.4180	loss_val: 9391.9971	loss_test: 9391.8262	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 61004.6445	loss_val: 61004.4609	loss_test: 61005.1797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7084.3657	loss_val: 7084.4390	loss_test: 7084.6538	accuracy_train: 0.8469	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 34	curr_val_accuracy: 0.8636	curr_test_accuracy: 0.8061
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10707.3926	loss_val: 10707.9512	loss_test: 10707.6426	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 14943.8711	loss_val: 14944.0381	loss_test: 14944.3564	accuracy_train: 0.9333	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 56803.3750	loss_val: 56803.4883	loss_test: 56803.6758	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 27777.8379	loss_val: 27777.9062	loss_test: 27777.9355	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 7679.7729	loss_val: 7680.0518	loss_test: 7679.9517	accuracy_train: 0.9383	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 6451.5967	loss_val: 6451.5796	loss_test: 6451.5488	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7128.1523	loss_val: 7128.1567	loss_test: 7128.2222	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7031.3340	loss_val: 7031.4692	loss_test: 7031.5210	accuracy_train: 0.9286	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 8579.4590	loss_val: 8579.8311	loss_test: 8579.9092	accuracy_train: 0.9167	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9047.4346	loss_val: 9047.4395	loss_test: 9047.3232	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6805.3716	loss_val: 6805.3540	loss_test: 6805.3438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5650.7393	loss_val: 5650.9189	loss_test: 5651.3188	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 4985.1079	loss_val: 4985.5757	loss_test: 4985.5239	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12892.2217	loss_val: 12892.2725	loss_test: 12892.5752	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3978.5308	loss_val: 3978.3950	loss_test: 3978.7935	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5844.8169	loss_val: 5844.9297	loss_test: 5845.3999	accuracy_train: 0.8182	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4863.8433	loss_val: 4863.8052	loss_test: 4863.8228	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9279.2598	loss_val: 9279.8477	loss_test: 9279.6953	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 60389.0273	loss_val: 60388.8438	loss_test: 60389.5547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6970.9302	loss_val: 6970.9985	loss_test: 6971.2261	accuracy_train: 0.8776	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 35	curr_val_accuracy: 0.8830	curr_test_accuracy: 0.8145
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10559.4189	loss_val: 10560.0352	loss_test: 10559.7090	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14629.6240	loss_val: 14629.8105	loss_test: 14630.0938	accuracy_train: 0.9333	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 55053.1641	loss_val: 55053.3164	loss_test: 55053.4766	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 28650.9316	loss_val: 28650.9863	loss_test: 28651.0254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7625.3853	loss_val: 7625.6963	loss_test: 7625.5864	accuracy_train: 0.9383	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 6225.0342	loss_val: 6225.0161	loss_test: 6224.9883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7232.4355	loss_val: 7232.4395	loss_test: 7232.5156	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6876.5205	loss_val: 6876.6699	loss_test: 6876.7275	accuracy_train: 0.9524	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 8574.3545	loss_val: 8574.7617	loss_test: 8574.8311	accuracy_train: 0.9167	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9142.4629	loss_val: 9142.4658	loss_test: 9142.3525	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6773.5684	loss_val: 6773.5493	loss_test: 6773.5415	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5463.1846	loss_val: 5463.3931	loss_test: 5463.7690	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 4929.7852	loss_val: 4930.2725	loss_test: 4930.2686	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12767.6162	loss_val: 12767.6719	loss_test: 12767.9883	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3962.7971	loss_val: 3962.6736	loss_test: 3963.0713	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5713.6543	loss_val: 5713.8159	loss_test: 5714.2759	accuracy_train: 0.9091	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4813.2544	loss_val: 4813.2109	loss_test: 4813.2300	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9153.9297	loss_val: 9154.5078	loss_test: 9154.3926	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 59917.2148	loss_val: 59917.0352	loss_test: 59917.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6896.5225	loss_val: 6896.5801	loss_test: 6896.8232	accuracy_train: 0.8980	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 36	curr_val_accuracy: 0.8845	curr_test_accuracy: 0.8064
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10439.4131	loss_val: 10440.0820	loss_test: 10439.7412	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14415.1475	loss_val: 14415.3467	loss_test: 14415.6133	accuracy_train: 0.9333	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 54179.3555	loss_val: 54179.5391	loss_test: 54179.6836	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 29604.8984	loss_val: 29604.9395	loss_test: 29604.9883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7643.0591	loss_val: 7643.3960	loss_test: 7643.2793	accuracy_train: 0.9630	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 6014.1191	loss_val: 6014.1006	loss_test: 6014.0752	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7341.2734	loss_val: 7341.2788	loss_test: 7341.3604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6734.7583	loss_val: 6734.9209	loss_test: 6734.9844	accuracy_train: 0.9524	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 8584.6484	loss_val: 8585.0850	loss_test: 8585.1484	accuracy_train: 0.9167	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9225.1631	loss_val: 9225.1641	loss_test: 9225.0518	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6755.0542	loss_val: 6755.0332	loss_test: 6755.0288	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5333.4956	loss_val: 5333.7329	loss_test: 5334.0869	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 4896.0234	loss_val: 4896.5259	loss_test: 4896.5771	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12644.2900	loss_val: 12644.3516	loss_test: 12644.6797	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3956.6650	loss_val: 3956.5527	loss_test: 3956.9480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5593.2168	loss_val: 5593.4224	loss_test: 5593.8667	accuracy_train: 0.9091	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4774.6880	loss_val: 4774.6396	loss_test: 4774.6602	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9038.7158	loss_val: 9039.3037	loss_test: 9039.2080	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 59651.6602	loss_val: 59651.4844	loss_test: 59652.1914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6828.8970	loss_val: 6828.9438	loss_test: 6829.2007	accuracy_train: 0.9184	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 37	curr_val_accuracy: 0.8846	curr_test_accuracy: 0.8070
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10288.0010	loss_val: 10288.7129	loss_test: 10288.3623	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14198.2979	loss_val: 14198.5117	loss_test: 14198.7676	accuracy_train: 0.9333	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 53962.5898	loss_val: 53962.7969	loss_test: 53962.9375	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 30467.3379	loss_val: 30467.3633	loss_test: 30467.4219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7697.8398	loss_val: 7698.2026	loss_test: 7698.0840	accuracy_train: 0.9630	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 5836.2549	loss_val: 5836.2368	loss_test: 5836.2139	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7444.3877	loss_val: 7444.3936	loss_test: 7444.4790	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6578.6753	loss_val: 6578.8501	loss_test: 6578.9224	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 8666.8486	loss_val: 8667.3105	loss_test: 8667.3633	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9250.1006	loss_val: 9250.1035	loss_test: 9249.9902	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6734.5146	loss_val: 6734.4922	loss_test: 6734.4907	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5227.5371	loss_val: 5227.8003	loss_test: 5228.1416	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 4883.9438	loss_val: 4884.4634	loss_test: 4884.5669	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12560.3770	loss_val: 12560.4434	loss_test: 12560.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3965.5786	loss_val: 3965.4773	loss_test: 3965.8696	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5486.5742	loss_val: 5486.8223	loss_test: 5487.2520	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4755.9639	loss_val: 4755.9102	loss_test: 4755.9321	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8912.5967	loss_val: 8913.1924	loss_test: 8913.1201	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 59421.0938	loss_val: 59420.9219	loss_test: 59421.6211	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6779.1602	loss_val: 6779.1987	loss_test: 6779.4673	accuracy_train: 0.9490	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 38	curr_val_accuracy: 0.8846	curr_test_accuracy: 0.8008
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9996.3379	loss_val: 9997.0674	loss_test: 9996.7119	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14047.9639	loss_val: 14048.1953	loss_test: 14048.4355	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 54122.8828	loss_val: 54123.1094	loss_test: 54123.2539	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 31436.4609	loss_val: 31436.4688	loss_test: 31436.5430	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7812.2085	loss_val: 7812.5977	loss_test: 7812.4775	accuracy_train: 0.9630	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 5677.6753	loss_val: 5677.6592	loss_test: 5677.6377	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7555.0249	loss_val: 7555.0322	loss_test: 7555.1216	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6442.3511	loss_val: 6442.5400	loss_test: 6442.6230	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 8750.9023	loss_val: 8751.3945	loss_test: 8751.4209	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9294.4980	loss_val: 9294.5029	loss_test: 9294.3887	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6723.7871	loss_val: 6723.7637	loss_test: 6723.7646	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5141.3345	loss_val: 5141.6221	loss_test: 5141.9512	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 4871.3159	loss_val: 4871.8491	loss_test: 4872.0068	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12448.8330	loss_val: 12448.9023	loss_test: 12449.2520	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3957.8818	loss_val: 3957.7891	loss_test: 3958.1772	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5394.1382	loss_val: 5394.4282	loss_test: 5394.8398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4736.6445	loss_val: 4736.5869	loss_test: 4736.6099	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8801.9775	loss_val: 8802.5811	loss_test: 8802.5293	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 59509.9648	loss_val: 59509.7969	loss_test: 59510.4922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6726.9756	loss_val: 6727.0088	loss_test: 6727.2856	accuracy_train: 0.9592	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 39	curr_val_accuracy: 0.8846	curr_test_accuracy: 0.7929
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9658.8896	loss_val: 9659.6348	loss_test: 9659.2686	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13829.9668	loss_val: 13830.2168	loss_test: 13830.4326	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 54785.3906	loss_val: 54785.6367	loss_test: 54785.7930	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 32317.8477	loss_val: 32317.8438	loss_test: 32317.9277	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7969.8887	loss_val: 7970.3018	loss_test: 7970.1860	accuracy_train: 0.9506	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 5548.8691	loss_val: 5548.8550	loss_test: 5548.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7681.9810	loss_val: 7681.9878	loss_test: 7682.0869	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6329.5332	loss_val: 6329.7339	loss_test: 6329.8296	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 8866.7227	loss_val: 8867.2432	loss_test: 8867.2354	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9378.9473	loss_val: 9378.9531	loss_test: 9378.8369	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6724.0405	loss_val: 6724.0156	loss_test: 6724.0190	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5066.6050	loss_val: 5066.9194	loss_test: 5067.2388	accuracy_train: 0.9747	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 4874.5581	loss_val: 4875.1021	loss_test: 4875.3130	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12352.1523	loss_val: 12352.2246	loss_test: 12352.5869	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3979.7546	loss_val: 3979.6694	loss_test: 3980.0542	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5316.3081	loss_val: 5316.6323	loss_test: 5317.0283	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4710.3838	loss_val: 4710.3228	loss_test: 4710.3457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8734.9541	loss_val: 8735.5732	loss_test: 8735.5420	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 59667.6680	loss_val: 59667.5039	loss_test: 59668.1914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6682.0117	loss_val: 6682.0425	loss_test: 6682.3257	accuracy_train: 0.9592	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 40	curr_val_accuracy: 0.8762	curr_test_accuracy: 0.7911
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9273.2666	loss_val: 9274.0059	loss_test: 9273.6309	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13660.6016	loss_val: 13660.8652	loss_test: 13661.0596	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 55500.7188	loss_val: 55500.9766	loss_test: 55501.1523	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 33291.1406	loss_val: 33291.1250	loss_test: 33291.2148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8043.7075	loss_val: 8044.1543	loss_test: 8044.0317	accuracy_train: 0.9506	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 5415.0771	loss_val: 5415.0654	loss_test: 5415.0488	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7811.8003	loss_val: 7811.8081	loss_test: 7811.9155	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6207.0674	loss_val: 6207.2822	loss_test: 6207.3896	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 8998.3291	loss_val: 8998.8760	loss_test: 8998.8203	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9469.0566	loss_val: 9469.0645	loss_test: 9468.9463	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6733.1646	loss_val: 6733.1382	loss_test: 6733.1445	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4988.7822	loss_val: 4989.1323	loss_test: 4989.4331	accuracy_train: 0.9747	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 4880.5352	loss_val: 4881.0894	loss_test: 4881.3271	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12247.1357	loss_val: 12247.2031	loss_test: 12247.5859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3998.3245	loss_val: 3998.2446	loss_test: 3998.6230	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5225.8657	loss_val: 5226.2251	loss_test: 5226.6055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4690.8848	loss_val: 4690.8208	loss_test: 4690.8433	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8627.5732	loss_val: 8628.2236	loss_test: 8628.1982	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 59857.3906	loss_val: 59857.2344	loss_test: 59857.9102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6621.3354	loss_val: 6621.3691	loss_test: 6621.6577	accuracy_train: 0.9694	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 41	curr_val_accuracy: 0.8678	curr_test_accuracy: 0.7911
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8881.0488	loss_val: 8881.7656	loss_test: 8881.3867	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13518.1104	loss_val: 13518.3906	loss_test: 13518.5576	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 56363.1836	loss_val: 56363.4453	loss_test: 56363.6445	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 34311.3633	loss_val: 34311.3438	loss_test: 34311.4414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8068.9062	loss_val: 8069.3955	loss_test: 8069.2534	accuracy_train: 0.9630	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 5285.4761	loss_val: 5285.4673	loss_test: 5285.4521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7934.1240	loss_val: 7934.1338	loss_test: 7934.2505	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6099.1973	loss_val: 6099.4253	loss_test: 6099.5410	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 9112.4395	loss_val: 9113.0127	loss_test: 9112.9121	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9567.7568	loss_val: 9567.7646	loss_test: 9567.6475	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6762.3228	loss_val: 6762.2954	loss_test: 6762.3047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4938.2246	loss_val: 4938.6040	loss_test: 4938.8931	accuracy_train: 0.9747	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 4896.0903	loss_val: 4896.6587	loss_test: 4896.9209	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12152.4014	loss_val: 12152.4639	loss_test: 12152.8682	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4022.8992	loss_val: 4022.8237	loss_test: 4023.1995	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5161.5454	loss_val: 5161.9482	loss_test: 5162.3008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4668.8594	loss_val: 4668.7930	loss_test: 4668.8149	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8509.5059	loss_val: 8510.1826	loss_test: 8510.1777	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 60190.7500	loss_val: 60190.5977	loss_test: 60191.2617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6621.4482	loss_val: 6621.4795	loss_test: 6621.7754	accuracy_train: 0.9796	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 42	curr_val_accuracy: 0.8678	curr_test_accuracy: 0.8042
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8545.9932	loss_val: 8546.6953	loss_test: 8546.3037	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13406.1621	loss_val: 13406.4561	loss_test: 13406.5850	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 57499.6367	loss_val: 57499.9062	loss_test: 57500.1250	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 35319.6641	loss_val: 35319.6406	loss_test: 35319.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8041.2275	loss_val: 8041.7583	loss_test: 8041.5928	accuracy_train: 0.9630	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5178.1338	loss_val: 5178.1270	loss_test: 5178.1143	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8107.2041	loss_val: 8107.2183	loss_test: 8107.3457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5996.8174	loss_val: 5997.0562	loss_test: 5997.1768	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 9222.7070	loss_val: 9223.3008	loss_test: 9223.1680	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9621.4404	loss_val: 9621.4492	loss_test: 9621.3301	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6793.9951	loss_val: 6793.9668	loss_test: 6793.9780	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4912.6919	loss_val: 4913.0977	loss_test: 4913.3794	accuracy_train: 0.9747	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 4911.2271	loss_val: 4911.8081	loss_test: 4912.0815	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12089.0410	loss_val: 12089.1045	loss_test: 12089.5215	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4049.2444	loss_val: 4049.1753	loss_test: 4049.5449	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5098.4761	loss_val: 5098.9214	loss_test: 5099.2520	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4649.9614	loss_val: 4649.8940	loss_test: 4649.9155	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8382.2637	loss_val: 8382.9707	loss_test: 8382.9863	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 60433.4922	loss_val: 60433.3438	loss_test: 60433.9961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6606.0088	loss_val: 6606.0376	loss_test: 6606.3413	accuracy_train: 0.9898	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 43	curr_val_accuracy: 0.8472	curr_test_accuracy: 0.7970
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8320.7100	loss_val: 8321.4258	loss_test: 8321.0078	accuracy_train: 0.9333	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13349.0410	loss_val: 13349.3467	loss_test: 13349.4482	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58775.5547	loss_val: 58775.8359	loss_test: 58776.0781	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 36166.1758	loss_val: 36166.1523	loss_test: 36166.2578	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7982.4365	loss_val: 7983.0137	loss_test: 7982.8154	accuracy_train: 0.9630	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5090.1509	loss_val: 5090.1465	loss_test: 5090.1357	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8312.6367	loss_val: 8312.6572	loss_test: 8312.7959	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5911.4937	loss_val: 5911.7461	loss_test: 5911.8657	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 9320.0928	loss_val: 9320.7217	loss_test: 9320.5527	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 9729.3184	loss_val: 9729.3291	loss_test: 9729.2100	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6824.6069	loss_val: 6824.5781	loss_test: 6824.5903	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4918.9600	loss_val: 4919.3828	loss_test: 4919.6655	accuracy_train: 0.9873	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 4934.4653	loss_val: 4935.0596	loss_test: 4935.3540	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12053.6895	loss_val: 12053.7539	loss_test: 12054.1846	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4082.6021	loss_val: 4082.5386	loss_test: 4082.9019	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5043.8452	loss_val: 5044.3340	loss_test: 5044.6387	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4630.5371	loss_val: 4630.4683	loss_test: 4630.4893	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8279.1514	loss_val: 8279.8994	loss_test: 8279.9375	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 60765.1484	loss_val: 60765.0078	loss_test: 60765.6484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6548.7134	loss_val: 6548.7495	loss_test: 6549.0571	accuracy_train: 0.9898	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 44	curr_val_accuracy: 0.8386	curr_test_accuracy: 0.7970
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8038.1631	loss_val: 8038.8735	loss_test: 8038.4316	accuracy_train: 0.9467	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13289.8359	loss_val: 13290.1572	loss_test: 13290.2188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 60018.9023	loss_val: 60019.1953	loss_test: 60019.4609	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 36963.3242	loss_val: 36963.2969	loss_test: 36963.4062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7869.4238	loss_val: 7870.0503	loss_test: 7869.8105	accuracy_train: 0.9753	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 5016.2432	loss_val: 5016.2402	loss_test: 5016.2314	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8494.4092	loss_val: 8494.4336	loss_test: 8494.5801	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5848.9204	loss_val: 5849.1851	loss_test: 5849.3042	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 9359.1348	loss_val: 9359.7842	loss_test: 9359.6006	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 9773.2773	loss_val: 9773.2900	loss_test: 9773.1699	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6848.4648	loss_val: 6848.4355	loss_test: 6848.4497	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4950.8413	loss_val: 4951.2729	loss_test: 4951.5728	accuracy_train: 0.9873	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 4962.0205	loss_val: 4962.6265	loss_test: 4962.9312	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12026.7285	loss_val: 12026.7910	loss_test: 12027.2363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4109.4106	loss_val: 4109.3511	loss_test: 4109.7173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5009.4019	loss_val: 5009.9336	loss_test: 5010.2158	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4617.2905	loss_val: 4617.2227	loss_test: 4617.2422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8165.4800	loss_val: 8166.2769	loss_test: 8166.3340	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 61228.6836	loss_val: 61228.5508	loss_test: 61229.1758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6504.2017	loss_val: 6504.2432	loss_test: 6504.5557	accuracy_train: 0.9898	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 45	curr_val_accuracy: 0.8473	curr_test_accuracy: 0.8051
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7767.0054	loss_val: 7767.7051	loss_test: 7767.2461	accuracy_train: 0.9467	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13254.8721	loss_val: 13255.2051	loss_test: 13255.2520	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 60929.7539	loss_val: 60930.0586	loss_test: 60930.3398	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 37618.9336	loss_val: 37618.9102	loss_test: 37619.0195	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7763.6274	loss_val: 7764.2964	loss_test: 7764.0215	accuracy_train: 0.9877	accuracy_val: 0.9000	accuracy_test: 0.6364
[client 5]	loss_train: 4949.6416	loss_val: 4949.6401	loss_test: 4949.6328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8666.9346	loss_val: 8666.9619	loss_test: 8667.1191	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5799.0576	loss_val: 5799.3374	loss_test: 5799.4517	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 9421.8096	loss_val: 9422.4619	loss_test: 9422.2764	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 9830.8018	loss_val: 9830.8164	loss_test: 9830.6963	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6879.1240	loss_val: 6879.0952	loss_test: 6879.1108	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5035.2661	loss_val: 5035.6982	loss_test: 5036.0254	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 4988.7393	loss_val: 4989.3550	loss_test: 4989.6904	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12034.7812	loss_val: 12034.8457	loss_test: 12035.2988	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4132.2637	loss_val: 4132.2095	loss_test: 4132.5811	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4992.6621	loss_val: 4993.2393	loss_test: 4993.4966	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4611.8008	loss_val: 4611.7358	loss_test: 4611.7534	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8079.5615	loss_val: 8080.3804	loss_test: 8080.4648	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 61740.5781	loss_val: 61740.4492	loss_test: 61741.0625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6478.4121	loss_val: 6478.4629	loss_test: 6478.7769	accuracy_train: 0.9898	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 46	curr_val_accuracy: 0.8643	curr_test_accuracy: 0.7972
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7567.1992	loss_val: 7567.8975	loss_test: 7567.4224	accuracy_train: 0.9600	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13233.2539	loss_val: 13233.5957	loss_test: 13233.6318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 61969.9766	loss_val: 61970.2930	loss_test: 61970.5898	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 38147.0625	loss_val: 38147.0391	loss_test: 38147.1562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7625.1094	loss_val: 7625.8228	loss_test: 7625.5098	accuracy_train: 1.0000	accuracy_val: 0.9000	accuracy_test: 0.6364
[client 5]	loss_train: 4900.5610	loss_val: 4900.5615	loss_test: 4900.5557	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8823.8271	loss_val: 8823.8574	loss_test: 8824.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5753.6484	loss_val: 5753.9409	loss_test: 5754.0576	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 9524.5645	loss_val: 9525.2100	loss_test: 9525.0352	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 9901.9355	loss_val: 9901.9531	loss_test: 9901.8301	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6908.0591	loss_val: 6908.0308	loss_test: 6908.0474	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5145.6958	loss_val: 5146.1299	loss_test: 5146.4790	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 5007.6436	loss_val: 5008.2651	loss_test: 5008.6289	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12027.9619	loss_val: 12028.0264	loss_test: 12028.4873	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4160.2188	loss_val: 4160.1685	loss_test: 4160.5503	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4971.5938	loss_val: 4972.2065	loss_test: 4972.4390	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4615.4214	loss_val: 4615.3599	loss_test: 4615.3770	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8055.0400	loss_val: 8055.8789	loss_test: 8055.9917	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 62305.1602	loss_val: 62305.0391	loss_test: 62305.6367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6456.2700	loss_val: 6456.3325	loss_test: 6456.6455	accuracy_train: 0.9898	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 47	curr_val_accuracy: 0.8651	curr_test_accuracy: 0.7972
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7326.6533	loss_val: 7327.3398	loss_test: 7326.8652	accuracy_train: 0.9600	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13267.6992	loss_val: 13268.0420	loss_test: 13268.0928	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 63017.6953	loss_val: 63018.0234	loss_test: 63018.3359	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 38691.3711	loss_val: 38691.3477	loss_test: 38691.4727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7487.2876	loss_val: 7488.0469	loss_test: 7487.6958	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4864.9639	loss_val: 4864.9658	loss_test: 4864.9609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8964.3076	loss_val: 8964.3398	loss_test: 8964.5186	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5710.7612	loss_val: 5711.0645	loss_test: 5711.1831	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 9608.6318	loss_val: 9609.2725	loss_test: 9609.1201	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 10046.1416	loss_val: 10046.1602	loss_test: 10046.0400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6948.9414	loss_val: 6948.9146	loss_test: 6948.9312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5196.0112	loss_val: 5196.4580	loss_test: 5196.8145	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 5030.6807	loss_val: 5031.3110	loss_test: 5031.6821	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12041.9258	loss_val: 12041.9893	loss_test: 12042.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4181.6021	loss_val: 4181.5552	loss_test: 4181.9468	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4955.5532	loss_val: 4956.2139	loss_test: 4956.4141	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4631.6885	loss_val: 4631.6328	loss_test: 4631.6489	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8015.5884	loss_val: 8016.4521	loss_test: 8016.5903	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 62888.5000	loss_val: 62888.3828	loss_test: 62888.9688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6409.1387	loss_val: 6409.2222	loss_test: 6409.5288	accuracy_train: 0.9898	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 48	curr_val_accuracy: 0.8564	curr_test_accuracy: 0.8051
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7156.7783	loss_val: 7157.4600	loss_test: 7156.9888	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13324.7715	loss_val: 13325.1162	loss_test: 13325.1846	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 63760.9648	loss_val: 63761.3008	loss_test: 63761.6289	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 39029.8008	loss_val: 39029.7812	loss_test: 39029.9062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7378.0991	loss_val: 7378.8921	loss_test: 7378.5132	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4822.8154	loss_val: 4822.8188	loss_test: 4822.8149	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9120.1934	loss_val: 9120.2266	loss_test: 9120.4199	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5654.1226	loss_val: 5654.4351	loss_test: 5654.5601	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 9689.8232	loss_val: 9690.4668	loss_test: 9690.3340	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 10150.8105	loss_val: 10150.8311	loss_test: 10150.7139	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6971.2466	loss_val: 6971.2207	loss_test: 6971.2393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5221.6714	loss_val: 5222.1362	loss_test: 5222.4980	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 5058.6743	loss_val: 5059.3169	loss_test: 5059.6743	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12022.7031	loss_val: 12022.7715	loss_test: 12023.2480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4214.9844	loss_val: 4214.9399	loss_test: 4215.3345	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4948.1533	loss_val: 4948.8496	loss_test: 4949.0293	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4651.4785	loss_val: 4651.4287	loss_test: 4651.4448	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7974.6123	loss_val: 7975.5186	loss_test: 7975.6670	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 63326.1680	loss_val: 63326.0547	loss_test: 63326.6289	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6389.8242	loss_val: 6389.9272	loss_test: 6390.2275	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 49	curr_val_accuracy: 0.8478	curr_test_accuracy: 0.8110
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7035.6372	loss_val: 7036.3213	loss_test: 7035.8516	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13371.3848	loss_val: 13371.7266	loss_test: 13371.8291	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 64312.0391	loss_val: 64312.3789	loss_test: 64312.7148	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 39519.7734	loss_val: 39519.7578	loss_test: 39519.8867	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7284.5347	loss_val: 7285.3496	loss_test: 7284.9570	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4787.1719	loss_val: 4787.1763	loss_test: 4787.1733	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9252.5459	loss_val: 9252.5791	loss_test: 9252.7842	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5589.4897	loss_val: 5589.8110	loss_test: 5589.9448	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 9715.3906	loss_val: 9716.0322	loss_test: 9715.9453	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 10270.7393	loss_val: 10270.7607	loss_test: 10270.6475	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7004.5342	loss_val: 7004.5107	loss_test: 7004.5278	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5223.6675	loss_val: 5224.1567	loss_test: 5224.5098	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5091.7891	loss_val: 5092.4458	loss_test: 5092.7656	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12020.4629	loss_val: 12020.5381	loss_test: 12021.0186	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4236.2949	loss_val: 4236.2520	loss_test: 4236.6597	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4942.7212	loss_val: 4943.4551	loss_test: 4943.6089	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4660.5454	loss_val: 4660.5005	loss_test: 4660.5156	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7934.2349	loss_val: 7935.1670	loss_test: 7935.3315	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 63766.0664	loss_val: 63765.9609	loss_test: 63766.5273	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6387.7407	loss_val: 6387.8564	loss_test: 6388.1499	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 50	curr_val_accuracy: 0.8394	curr_test_accuracy: 0.8110
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6971.1367	loss_val: 6971.8506	loss_test: 6971.3589	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13448.3506	loss_val: 13448.6934	loss_test: 13448.8125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 64379.5430	loss_val: 64379.8828	loss_test: 64380.2227	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 39873.3125	loss_val: 39873.2969	loss_test: 39873.4336	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7262.9722	loss_val: 7263.7910	loss_test: 7263.4038	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4755.6011	loss_val: 4755.6069	loss_test: 4755.6045	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9375.1152	loss_val: 9375.1475	loss_test: 9375.3662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5549.4072	loss_val: 5549.7334	loss_test: 5549.8799	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 9752.5918	loss_val: 9753.2246	loss_test: 9753.1875	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 10432.6543	loss_val: 10432.6777	loss_test: 10432.5693	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7053.3662	loss_val: 7053.3442	loss_test: 7053.3608	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5226.5405	loss_val: 5227.0562	loss_test: 5227.4058	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5125.3818	loss_val: 5126.0488	loss_test: 5126.3628	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11993.9365	loss_val: 11994.0176	loss_test: 11994.5039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4262.2085	loss_val: 4262.1670	loss_test: 4262.5742	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4941.7148	loss_val: 4942.4741	loss_test: 4942.6113	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4666.8032	loss_val: 4666.7637	loss_test: 4666.7783	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7907.0635	loss_val: 7908.0410	loss_test: 7908.2056	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64533.7227	loss_val: 64533.6211	loss_test: 64534.1797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6384.1973	loss_val: 6384.3242	loss_test: 6384.6118	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 51	curr_val_accuracy: 0.8302	curr_test_accuracy: 0.8110
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6930.6162	loss_val: 6931.3569	loss_test: 6930.8462	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13450.8555	loss_val: 13451.1992	loss_test: 13451.3193	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 64283.0508	loss_val: 64283.3867	loss_test: 64283.7305	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 40112.3359	loss_val: 40112.3242	loss_test: 40112.4688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7307.4971	loss_val: 7308.3096	loss_test: 7307.9414	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4735.9126	loss_val: 4735.9189	loss_test: 4735.9170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9489.6523	loss_val: 9489.6846	loss_test: 9489.9170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5519.1001	loss_val: 5519.4307	loss_test: 5519.5938	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 9795.5381	loss_val: 9796.1641	loss_test: 9796.1758	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 10719.5830	loss_val: 10719.6094	loss_test: 10719.5098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7052.0156	loss_val: 7051.9985	loss_test: 7052.0127	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5176.1260	loss_val: 5176.6753	loss_test: 5177.0044	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5161.0361	loss_val: 5161.7148	loss_test: 5161.9995	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11965.4375	loss_val: 11965.5195	loss_test: 11966.0166	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4277.7271	loss_val: 4277.6870	loss_test: 4278.0957	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4943.5435	loss_val: 4944.3281	loss_test: 4944.4541	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4671.5352	loss_val: 4671.4995	loss_test: 4671.5137	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7857.7847	loss_val: 7858.8174	loss_test: 7858.9707	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64920.4102	loss_val: 64920.3125	loss_test: 64920.8633	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6375.8799	loss_val: 6376.0171	loss_test: 6376.2954	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 52	curr_val_accuracy: 0.8302	curr_test_accuracy: 0.8110
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6957.6733	loss_val: 6958.4624	loss_test: 6957.9160	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13506.5088	loss_val: 13506.8516	loss_test: 13506.9775	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 64410.9375	loss_val: 64411.2656	loss_test: 64411.6211	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 40263.2422	loss_val: 40263.2344	loss_test: 40263.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7389.7949	loss_val: 7390.5991	loss_test: 7390.2505	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4726.8516	loss_val: 4726.8584	loss_test: 4726.8564	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9587.6084	loss_val: 9587.6406	loss_test: 9587.8848	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5480.9414	loss_val: 5481.2676	loss_test: 5481.4531	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 9871.0156	loss_val: 9871.6260	loss_test: 9871.6807	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11002.7471	loss_val: 11002.7744	loss_test: 11002.6855	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7086.5298	loss_val: 7086.5205	loss_test: 7086.5322	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5102.9194	loss_val: 5103.5020	loss_test: 5103.8013	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5204.0591	loss_val: 5204.7510	loss_test: 5205.0205	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11928.4092	loss_val: 11928.4941	loss_test: 11928.9990	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4315.1543	loss_val: 4315.1152	loss_test: 4315.5283	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4945.5381	loss_val: 4946.3506	loss_test: 4946.4707	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4688.0488	loss_val: 4688.0166	loss_test: 4688.0308	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7803.0464	loss_val: 7804.1519	loss_test: 7804.2671	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65531.1094	loss_val: 65531.0156	loss_test: 65531.5625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6373.9312	loss_val: 6374.0737	loss_test: 6374.3477	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 53	curr_val_accuracy: 0.8302	curr_test_accuracy: 0.8110
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6968.0747	loss_val: 6968.8989	loss_test: 6968.3320	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13500.4912	loss_val: 13500.8301	loss_test: 13500.9590	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 64330.2852	loss_val: 64330.5977	loss_test: 64330.9688	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 40394.6602	loss_val: 40394.6523	loss_test: 40394.8047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7493.1851	loss_val: 7493.9746	loss_test: 7493.6562	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4718.4355	loss_val: 4718.4424	loss_test: 4718.4404	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9676.0195	loss_val: 9676.0518	loss_test: 9676.3037	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5450.1494	loss_val: 5450.4717	loss_test: 5450.6777	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 9964.7686	loss_val: 9965.3691	loss_test: 9965.4482	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11334.0830	loss_val: 11334.1094	loss_test: 11334.0322	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7154.7153	loss_val: 7154.7129	loss_test: 7154.7207	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5012.1523	loss_val: 5012.7798	loss_test: 5013.0322	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5236.7295	loss_val: 5237.4375	loss_test: 5237.7021	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11845.4688	loss_val: 11845.5596	loss_test: 11846.0693	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4340.0200	loss_val: 4339.9814	loss_test: 4340.4067	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4943.0991	loss_val: 4943.9336	loss_test: 4944.0527	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4701.4648	loss_val: 4701.4355	loss_test: 4701.4502	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7760.1616	loss_val: 7761.3130	loss_test: 7761.4028	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65891.5938	loss_val: 65891.5000	loss_test: 65892.0391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6423.3901	loss_val: 6423.5205	loss_test: 6423.7905	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 54	curr_val_accuracy: 0.8294	curr_test_accuracy: 0.8110
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6915.0679	loss_val: 6915.8857	loss_test: 6915.3301	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13525.0762	loss_val: 13525.4150	loss_test: 13525.5322	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 64132.8789	loss_val: 64133.1992	loss_test: 64133.5586	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 40469.2422	loss_val: 40469.2344	loss_test: 40469.3945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7635.4009	loss_val: 7636.1807	loss_test: 7635.8848	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6364
[client 5]	loss_train: 4708.6567	loss_val: 4708.6641	loss_test: 4708.6616	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9737.4561	loss_val: 9737.4873	loss_test: 9737.7490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5428.6357	loss_val: 5428.9556	loss_test: 5429.1792	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10046.1309	loss_val: 10046.7207	loss_test: 10046.8271	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11578.5889	loss_val: 11578.6133	loss_test: 11578.5449	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7235.9355	loss_val: 7235.9395	loss_test: 7235.9424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4907.5308	loss_val: 4908.2432	loss_test: 4908.4062	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 12]	loss_train: 5260.6094	loss_val: 5261.3262	loss_test: 5261.6230	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11839.6533	loss_val: 11839.7480	loss_test: 11840.2617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4360.2534	loss_val: 4360.2153	loss_test: 4360.6392	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4942.9385	loss_val: 4943.7935	loss_test: 4943.9165	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4711.8457	loss_val: 4711.8203	loss_test: 4711.8335	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7756.9282	loss_val: 7758.1133	loss_test: 7758.1899	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66085.8750	loss_val: 66085.7891	loss_test: 66086.3281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6498.4834	loss_val: 6498.5952	loss_test: 6498.8618	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 55	curr_val_accuracy: 0.8294	curr_test_accuracy: 0.8116
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6848.3486	loss_val: 6849.1450	loss_test: 6848.6104	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13485.3301	loss_val: 13485.6689	loss_test: 13485.7656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 63999.2930	loss_val: 63999.6055	loss_test: 63999.9766	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 40816.1797	loss_val: 40816.1719	loss_test: 40816.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7663.1006	loss_val: 7663.8633	loss_test: 7663.6064	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6364
[client 5]	loss_train: 4703.7275	loss_val: 4703.7349	loss_test: 4703.7324	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9801.1094	loss_val: 9801.1426	loss_test: 9801.4053	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5412.7046	loss_val: 5413.0205	loss_test: 5413.2632	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10139.8916	loss_val: 10140.4795	loss_test: 10140.6094	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11758.6611	loss_val: 11758.6846	loss_test: 11758.6211	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7301.9102	loss_val: 7301.9175	loss_test: 7301.9185	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4871.6719	loss_val: 4872.4385	loss_test: 4872.5605	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5278.6953	loss_val: 5279.4204	loss_test: 5279.7476	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11828.7646	loss_val: 11828.8613	loss_test: 11829.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4380.2407	loss_val: 4380.2051	loss_test: 4380.6274	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4941.5840	loss_val: 4942.4575	loss_test: 4942.5859	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4720.7427	loss_val: 4720.7197	loss_test: 4720.7310	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7749.8838	loss_val: 7751.0938	loss_test: 7751.1548	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66457.6797	loss_val: 66457.5938	loss_test: 66458.1250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6564.4053	loss_val: 6564.5068	loss_test: 6564.7690	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 56	curr_val_accuracy: 0.8386	curr_test_accuracy: 0.8032
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6780.9595	loss_val: 6781.7188	loss_test: 6781.2231	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13514.4941	loss_val: 13514.8340	loss_test: 13514.9170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 63917.9727	loss_val: 63918.2773	loss_test: 63918.6719	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 41392.0039	loss_val: 41391.9961	loss_test: 41392.1562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7616.3765	loss_val: 7617.1304	loss_test: 7616.9116	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4700.1318	loss_val: 4700.1392	loss_test: 4700.1367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9889.0938	loss_val: 9889.1289	loss_test: 9889.3896	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5394.5459	loss_val: 5394.8604	loss_test: 5395.1182	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10241.0273	loss_val: 10241.6162	loss_test: 10241.7598	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11873.2715	loss_val: 11873.2949	loss_test: 11873.2344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7362.1050	loss_val: 7362.1157	loss_test: 7362.1143	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4862.6006	loss_val: 4863.4033	loss_test: 4863.5039	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5301.5249	loss_val: 5302.2603	loss_test: 5302.6006	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11850.9062	loss_val: 11851.0010	loss_test: 11851.5303	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4405.7959	loss_val: 4405.7612	loss_test: 4406.1899	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4934.0132	loss_val: 4934.8955	loss_test: 4935.0464	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4730.4600	loss_val: 4730.4409	loss_test: 4730.4507	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7722.4741	loss_val: 7723.6880	loss_test: 7723.7422	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66756.8516	loss_val: 66756.7656	loss_test: 66757.2969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6649.1333	loss_val: 6649.2285	loss_test: 6649.4849	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 57	curr_val_accuracy: 0.8560	curr_test_accuracy: 0.8110
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6691.0640	loss_val: 6691.7832	loss_test: 6691.3438	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.9000
[client 1]	loss_train: 13458.5322	loss_val: 13458.8740	loss_test: 13458.9189	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 63910.3984	loss_val: 63910.6953	loss_test: 63911.1211	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 41970.6680	loss_val: 41970.6602	loss_test: 41970.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7588.8350	loss_val: 7589.5952	loss_test: 7589.4087	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6364
[client 5]	loss_train: 4700.8628	loss_val: 4700.8701	loss_test: 4700.8682	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10001.8379	loss_val: 10001.8740	loss_test: 10002.1338	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5387.0400	loss_val: 5387.3530	loss_test: 5387.6260	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10274.2334	loss_val: 10274.8262	loss_test: 10274.9951	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11955.2783	loss_val: 11955.3037	loss_test: 11955.2432	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7419.4922	loss_val: 7419.5049	loss_test: 7419.5020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4861.2520	loss_val: 4862.0854	loss_test: 4862.1685	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5321.9243	loss_val: 5322.6724	loss_test: 5323.0283	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11835.2412	loss_val: 11835.3281	loss_test: 11835.8662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4434.3633	loss_val: 4434.3291	loss_test: 4434.7573	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4939.7515	loss_val: 4940.6426	loss_test: 4940.8076	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4745.0649	loss_val: 4745.0493	loss_test: 4745.0576	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7709.1401	loss_val: 7710.3486	loss_test: 7710.4067	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67295.6953	loss_val: 67295.6094	loss_test: 67296.1406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6735.6729	loss_val: 6735.7651	loss_test: 6736.0098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8462
curr_round: 58	curr_val_accuracy: 0.8721	curr_test_accuracy: 0.8168
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6665.2207	loss_val: 6665.9331	loss_test: 6665.5161	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.9000
[client 1]	loss_train: 13418.8262	loss_val: 13419.1680	loss_test: 13419.1826	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 64044.2812	loss_val: 64044.5703	loss_test: 64045.0273	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 42748.0312	loss_val: 42748.0234	loss_test: 42748.1875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7653.9937	loss_val: 7654.7773	loss_test: 7654.5986	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6364
[client 5]	loss_train: 4706.0894	loss_val: 4706.0967	loss_test: 4706.0942	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10092.1172	loss_val: 10092.1553	loss_test: 10092.4131	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5368.6704	loss_val: 5368.9834	loss_test: 5369.2700	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10306.6475	loss_val: 10307.2305	loss_test: 10307.4219	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 11949.2275	loss_val: 11949.2559	loss_test: 11949.1924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7473.2725	loss_val: 7473.2866	loss_test: 7473.2827	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4863.2861	loss_val: 4864.1597	loss_test: 4864.2197	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5345.4702	loss_val: 5346.2275	loss_test: 5346.5942	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11866.2930	loss_val: 11866.3770	loss_test: 11866.9199	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4469.7153	loss_val: 4469.6816	loss_test: 4470.1147	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4942.8584	loss_val: 4943.7480	loss_test: 4943.9282	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4769.0474	loss_val: 4769.0356	loss_test: 4769.0425	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7701.1631	loss_val: 7702.3643	loss_test: 7702.4263	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67708.1328	loss_val: 67708.0469	loss_test: 67708.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6770.1802	loss_val: 6770.2822	loss_test: 6770.5151	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 59	curr_val_accuracy: 0.8624	curr_test_accuracy: 0.8168
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6633.5327	loss_val: 6634.2549	loss_test: 6633.8398	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13384.1631	loss_val: 13384.5068	loss_test: 13384.4912	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 64008.2422	loss_val: 64008.5312	loss_test: 64009.0039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 43411.2969	loss_val: 43411.2891	loss_test: 43411.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7721.1670	loss_val: 7721.9717	loss_test: 7721.7969	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6364
[client 5]	loss_train: 4719.5308	loss_val: 4719.5386	loss_test: 4719.5352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10175.7158	loss_val: 10175.7578	loss_test: 10176.0117	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5349.8364	loss_val: 5350.1479	loss_test: 5350.4478	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10314.9092	loss_val: 10315.4873	loss_test: 10315.7041	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 11842.5234	loss_val: 11842.5557	loss_test: 11842.4873	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7498.4053	loss_val: 7498.4224	loss_test: 7498.4175	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4863.5547	loss_val: 4864.4414	loss_test: 4864.5112	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5355.3340	loss_val: 5356.0874	loss_test: 5356.5464	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11919.2725	loss_val: 11919.3535	loss_test: 11919.9023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4493.3271	loss_val: 4493.2949	loss_test: 4493.7217	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4940.4023	loss_val: 4941.2905	loss_test: 4941.4976	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4793.4595	loss_val: 4793.4517	loss_test: 4793.4570	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7711.3301	loss_val: 7712.5312	loss_test: 7712.5957	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68099.9688	loss_val: 68099.8828	loss_test: 68100.4062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6755.0854	loss_val: 6755.2021	loss_test: 6755.4229	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 60	curr_val_accuracy: 0.8456	curr_test_accuracy: 0.8047
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6613.2891	loss_val: 6614.0298	loss_test: 6613.6157	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13356.4902	loss_val: 13356.8369	loss_test: 13356.8115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 63740.3438	loss_val: 63740.6328	loss_test: 63741.1211	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 44250.8672	loss_val: 44250.8594	loss_test: 44251.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7836.9619	loss_val: 7837.7915	loss_test: 7837.5977	accuracy_train: 1.0000	accuracy_val: 0.9000	accuracy_test: 0.6364
[client 5]	loss_train: 4737.8408	loss_val: 4737.8491	loss_test: 4737.8447	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10264.4199	loss_val: 10264.4639	loss_test: 10264.7168	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5323.6753	loss_val: 5323.9907	loss_test: 5324.2979	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10375.2441	loss_val: 10375.8291	loss_test: 10376.0391	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 11752.5088	loss_val: 11752.5449	loss_test: 11752.4717	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7534.0742	loss_val: 7534.0928	loss_test: 7534.0874	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4858.6724	loss_val: 4859.5547	loss_test: 4859.6592	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5371.2896	loss_val: 5372.0400	loss_test: 5372.5874	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12007.2617	loss_val: 12007.3408	loss_test: 12007.8936	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4519.0132	loss_val: 4518.9819	loss_test: 4519.4072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4949.6377	loss_val: 4950.5420	loss_test: 4950.7656	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4811.0078	loss_val: 4811.0039	loss_test: 4811.0073	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7731.6533	loss_val: 7732.8359	loss_test: 7732.9160	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68591.9297	loss_val: 68591.8438	loss_test: 68592.3672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6738.1479	loss_val: 6738.2783	loss_test: 6738.4893	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 61	curr_val_accuracy: 0.8543	curr_test_accuracy: 0.8047
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6615.5366	loss_val: 6616.3086	loss_test: 6615.8809	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13375.1279	loss_val: 13375.4785	loss_test: 13375.4414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 63801.2500	loss_val: 63801.5430	loss_test: 63802.0469	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 44923.3750	loss_val: 44923.3672	loss_test: 44923.5273	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7947.9165	loss_val: 7948.7715	loss_test: 7948.5508	accuracy_train: 1.0000	accuracy_val: 0.9000	accuracy_test: 0.6364
[client 5]	loss_train: 4753.8828	loss_val: 4753.8911	loss_test: 4753.8857	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10365.2334	loss_val: 10365.2783	loss_test: 10365.5342	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5307.4766	loss_val: 5307.7993	loss_test: 5308.1060	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10440.7227	loss_val: 10441.3105	loss_test: 10441.5068	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 11711.8848	loss_val: 11711.9229	loss_test: 11711.8486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7544.0859	loss_val: 7544.1069	loss_test: 7544.1011	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4886.3350	loss_val: 4887.1782	loss_test: 4887.3594	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5388.9111	loss_val: 5389.6577	loss_test: 5390.2891	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12040.2246	loss_val: 12040.3018	loss_test: 12040.8555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4545.1372	loss_val: 4545.1069	loss_test: 4545.5200	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4948.5293	loss_val: 4949.4292	loss_test: 4949.6797	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4828.2368	loss_val: 4828.2368	loss_test: 4828.2378	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7754.8525	loss_val: 7756.0327	loss_test: 7756.1157	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68822.3203	loss_val: 68822.2344	loss_test: 68822.7500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6681.4775	loss_val: 6681.6387	loss_test: 6681.8369	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 62	curr_val_accuracy: 0.8553	curr_test_accuracy: 0.8047
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6616.4126	loss_val: 6617.2012	loss_test: 6616.7783	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13451.9434	loss_val: 13452.2891	loss_test: 13452.2529	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 62655.3359	loss_val: 62655.6562	loss_test: 62656.1055	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 45452.9375	loss_val: 45452.9297	loss_test: 45453.0859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8039.0454	loss_val: 8039.9355	loss_test: 8039.6812	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5455
[client 5]	loss_train: 4766.2637	loss_val: 4766.2725	loss_test: 4766.2666	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10470.4121	loss_val: 10470.4580	loss_test: 10470.7217	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5285.1709	loss_val: 5285.5015	loss_test: 5285.8091	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10448.8066	loss_val: 10449.4062	loss_test: 10449.5967	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 11689.9961	loss_val: 11690.0342	loss_test: 11689.9580	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7561.8999	loss_val: 7561.9229	loss_test: 7561.9160	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4986.6494	loss_val: 4987.4326	loss_test: 4987.7290	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5400.6333	loss_val: 5401.3716	loss_test: 5402.0562	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12105.0498	loss_val: 12105.1240	loss_test: 12105.6807	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4559.2632	loss_val: 4559.2334	loss_test: 4559.6445	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4950.2251	loss_val: 4951.1152	loss_test: 4951.3813	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4838.4170	loss_val: 4838.4204	loss_test: 4838.4189	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7777.4868	loss_val: 7778.6714	loss_test: 7778.7578	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69308.4375	loss_val: 69308.3438	loss_test: 69308.8594	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6634.1577	loss_val: 6634.3540	loss_test: 6634.5332	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 63	curr_val_accuracy: 0.8467	curr_test_accuracy: 0.7909
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6602.7490	loss_val: 6603.5508	loss_test: 6603.1396	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13521.2412	loss_val: 13521.5830	loss_test: 13521.5635	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 61792.8477	loss_val: 61793.2070	loss_test: 61793.6016	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 45881.9688	loss_val: 45881.9609	loss_test: 45882.1172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8062.7412	loss_val: 8063.6631	loss_test: 8063.3853	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5455
[client 5]	loss_train: 4776.6475	loss_val: 4776.6558	loss_test: 4776.6499	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10549.0332	loss_val: 10549.0801	loss_test: 10549.3584	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5259.2822	loss_val: 5259.6260	loss_test: 5259.9209	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10474.7480	loss_val: 10475.3721	loss_test: 10475.5234	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 11670.6787	loss_val: 11670.7188	loss_test: 11670.6406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7546.3740	loss_val: 7546.3979	loss_test: 7546.3906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5112.9468	loss_val: 5113.7100	loss_test: 5114.0898	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5403.3594	loss_val: 5404.0859	loss_test: 5404.8149	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12155.8984	loss_val: 12155.9707	loss_test: 12156.5293	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4561.6562	loss_val: 4561.6270	loss_test: 4562.0327	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4948.7109	loss_val: 4949.6001	loss_test: 4949.8843	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4851.2007	loss_val: 4851.2061	loss_test: 4851.2036	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7804.0938	loss_val: 7805.2847	loss_test: 7805.3628	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69625.3984	loss_val: 69625.3047	loss_test: 69625.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6581.3105	loss_val: 6581.5474	loss_test: 6581.7046	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 64	curr_val_accuracy: 0.8551	curr_test_accuracy: 0.7909
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6593.9453	loss_val: 6594.7651	loss_test: 6594.3677	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13553.8486	loss_val: 13554.1855	loss_test: 13554.1650	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 61373.1641	loss_val: 61373.5547	loss_test: 61373.9258	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46162.4961	loss_val: 46162.4883	loss_test: 46162.6406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8059.4849	loss_val: 8060.4351	loss_test: 8060.1372	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5455
[client 5]	loss_train: 4779.0464	loss_val: 4779.0552	loss_test: 4779.0488	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10619.7275	loss_val: 10619.7744	loss_test: 10620.0693	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5240.1084	loss_val: 5240.4683	loss_test: 5240.7402	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10564.1611	loss_val: 10564.8320	loss_test: 10564.9053	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 11642.7402	loss_val: 11642.7812	loss_test: 11642.7021	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7522.3438	loss_val: 7522.3677	loss_test: 7522.3608	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5194.8472	loss_val: 5195.6084	loss_test: 5196.0322	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 5409.7832	loss_val: 5410.5024	loss_test: 5411.2295	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12206.4854	loss_val: 12206.5547	loss_test: 12207.1162	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4562.2563	loss_val: 4562.2275	loss_test: 4562.6401	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4934.4180	loss_val: 4935.3071	loss_test: 4935.5991	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4853.3232	loss_val: 4853.3306	loss_test: 4853.3267	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7828.6641	loss_val: 7829.8418	loss_test: 7829.9297	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69715.0391	loss_val: 69714.9375	loss_test: 69715.4453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6525.4390	loss_val: 6525.7183	loss_test: 6525.8516	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 65	curr_val_accuracy: 0.8381	curr_test_accuracy: 0.7968
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6585.3188	loss_val: 6586.1519	loss_test: 6585.7686	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13574.8506	loss_val: 13575.1836	loss_test: 13575.1533	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 61012.3867	loss_val: 61012.7891	loss_test: 61013.1523	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46365.6523	loss_val: 46365.6445	loss_test: 46365.7969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7975.7603	loss_val: 7976.7603	loss_test: 7976.4277	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5455
[client 5]	loss_train: 4779.7031	loss_val: 4779.7129	loss_test: 4779.7061	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10668.2412	loss_val: 10668.2900	loss_test: 10668.6006	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5203.7041	loss_val: 5204.0718	loss_test: 5204.3286	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10615.9424	loss_val: 10616.6562	loss_test: 10616.6787	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 11786.3145	loss_val: 11786.3525	loss_test: 11786.2803	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7495.8853	loss_val: 7495.9092	loss_test: 7495.9028	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5220.0444	loss_val: 5220.8188	loss_test: 5221.2490	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5413.8467	loss_val: 5414.5542	loss_test: 5415.3066	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12248.1709	loss_val: 12248.2373	loss_test: 12248.8047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4567.3223	loss_val: 4567.2939	loss_test: 4567.6982	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4925.5972	loss_val: 4926.4829	loss_test: 4926.7935	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4850.3301	loss_val: 4850.3379	loss_test: 4850.3335	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7815.2153	loss_val: 7816.3926	loss_test: 7816.4751	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69727.5625	loss_val: 69727.4688	loss_test: 69727.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6495.0259	loss_val: 6495.3345	loss_test: 6495.4512	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 66	curr_val_accuracy: 0.8381	curr_test_accuracy: 0.7804
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6600.7920	loss_val: 6601.6406	loss_test: 6601.2661	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13511.3428	loss_val: 13511.6787	loss_test: 13511.6387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 60627.1172	loss_val: 60627.5234	loss_test: 60627.8867	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46483.6797	loss_val: 46483.6719	loss_test: 46483.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7908.0596	loss_val: 7909.1201	loss_test: 7908.7422	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5455
[client 5]	loss_train: 4776.6904	loss_val: 4776.7002	loss_test: 4776.6934	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10708.4033	loss_val: 10708.4541	loss_test: 10708.7773	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5169.1895	loss_val: 5169.5645	loss_test: 5169.7949	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 10623.3838	loss_val: 10624.1338	loss_test: 10624.1250	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 11930.1572	loss_val: 11930.1934	loss_test: 11930.1279	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7476.0386	loss_val: 7476.0620	loss_test: 7476.0562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5144.6426	loss_val: 5145.4375	loss_test: 5145.8325	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 5413.3267	loss_val: 5414.0264	loss_test: 5414.7871	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12295.7793	loss_val: 12295.8438	loss_test: 12296.4141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4569.4180	loss_val: 4569.3901	loss_test: 4569.7891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4913.8027	loss_val: 4914.6914	loss_test: 4915.0264	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4844.0723	loss_val: 4844.0811	loss_test: 4844.0762	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7812.7031	loss_val: 7813.8813	loss_test: 7813.9546	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69637.6875	loss_val: 69637.5938	loss_test: 69638.1094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6458.0825	loss_val: 6458.4370	loss_test: 6458.5249	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 67	curr_val_accuracy: 0.8381	curr_test_accuracy: 0.7822
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6609.1719	loss_val: 6610.0288	loss_test: 6609.6860	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13494.0488	loss_val: 13494.3877	loss_test: 13494.3340	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 60163.5898	loss_val: 60163.9922	loss_test: 60164.3594	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46272.1406	loss_val: 46272.1367	loss_test: 46272.2812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7867.2812	loss_val: 7868.4014	loss_test: 7867.9663	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5455
[client 5]	loss_train: 4770.0024	loss_val: 4770.0127	loss_test: 4770.0054	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10759.0010	loss_val: 10759.0518	loss_test: 10759.3906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5144.2339	loss_val: 5144.6118	loss_test: 5144.8257	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10620.7139	loss_val: 10621.5068	loss_test: 10621.4707	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 12073.9814	loss_val: 12074.0146	loss_test: 12073.9561	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7463.2764	loss_val: 7463.2998	loss_test: 7463.2935	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5038.9927	loss_val: 5039.8271	loss_test: 5040.1426	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5412.1279	loss_val: 5412.8228	loss_test: 5413.5859	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12320.2969	loss_val: 12320.3623	loss_test: 12320.9375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4564.9399	loss_val: 4564.9121	loss_test: 4565.3125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4891.9170	loss_val: 4892.8188	loss_test: 4893.1763	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4836.0195	loss_val: 4836.0288	loss_test: 4836.0229	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7809.9004	loss_val: 7811.0752	loss_test: 7811.1509	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69446.3438	loss_val: 69446.2578	loss_test: 69446.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6436.5029	loss_val: 6436.8838	loss_test: 6436.9595	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 68	curr_val_accuracy: 0.8207	curr_test_accuracy: 0.7888
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6666.6733	loss_val: 6667.5742	loss_test: 6667.2300	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13439.1953	loss_val: 13439.5371	loss_test: 13439.4688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 59784.6094	loss_val: 59784.9961	loss_test: 59785.3750	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46346.5664	loss_val: 46346.5625	loss_test: 46346.7070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7759.5513	loss_val: 7760.7251	loss_test: 7760.2378	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5455
[client 5]	loss_train: 4768.1953	loss_val: 4768.2061	loss_test: 4768.1982	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10795.1299	loss_val: 10795.1807	loss_test: 10795.5352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5125.9702	loss_val: 5126.3477	loss_test: 5126.5503	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10600.5303	loss_val: 10601.3232	loss_test: 10601.3428	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 12208.2754	loss_val: 12208.3066	loss_test: 12208.2529	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7431.0698	loss_val: 7431.0908	loss_test: 7431.0859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4940.9019	loss_val: 4941.7827	loss_test: 4942.0200	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5412.8652	loss_val: 5413.5557	loss_test: 5414.3115	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12318.9863	loss_val: 12319.0537	loss_test: 12319.6348	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4560.3345	loss_val: 4560.3066	loss_test: 4560.7183	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4888.5239	loss_val: 4889.4531	loss_test: 4889.8286	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4833.2344	loss_val: 4833.2446	loss_test: 4833.2388	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7791.5552	loss_val: 7792.7476	loss_test: 7792.8203	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69180.8906	loss_val: 69180.8125	loss_test: 69181.3281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6459.5845	loss_val: 6459.9385	loss_test: 6460.0444	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 69	curr_val_accuracy: 0.8132	curr_test_accuracy: 0.7888
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6736.6191	loss_val: 6737.5757	loss_test: 6737.2158	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13486.0762	loss_val: 13486.4189	loss_test: 13486.3506	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 59279.2773	loss_val: 59279.6797	loss_test: 59280.0547	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46278.9570	loss_val: 46278.9531	loss_test: 46279.0938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7763.4912	loss_val: 7764.7148	loss_test: 7764.1558	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5455
[client 5]	loss_train: 4759.2285	loss_val: 4759.2393	loss_test: 4759.2319	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10819.0312	loss_val: 10819.0811	loss_test: 10819.4482	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5117.4858	loss_val: 5117.8604	loss_test: 5118.0508	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10631.1279	loss_val: 10631.9229	loss_test: 10631.9990	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 12290.3672	loss_val: 12290.3984	loss_test: 12290.3457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7397.5117	loss_val: 7397.5298	loss_test: 7397.5269	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4851.2915	loss_val: 4852.2563	loss_test: 4852.3877	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5409.3154	loss_val: 5410.0063	loss_test: 5410.7373	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12306.8604	loss_val: 12306.9307	loss_test: 12307.5186	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4553.6548	loss_val: 4553.6270	loss_test: 4554.0552	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4875.4907	loss_val: 4876.4321	loss_test: 4876.8257	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4834.9907	loss_val: 4835.0015	loss_test: 4834.9961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7796.6865	loss_val: 7797.8740	loss_test: 7797.9692	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69195.2266	loss_val: 69195.1484	loss_test: 69195.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6459.9233	loss_val: 6460.2754	loss_test: 6460.3931	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 70	curr_val_accuracy: 0.8126	curr_test_accuracy: 0.7888
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6830.0303	loss_val: 6831.0522	loss_test: 6830.6646	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13502.8477	loss_val: 13503.1934	loss_test: 13503.1191	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 59272.8984	loss_val: 59273.2812	loss_test: 59273.6719	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46065.9258	loss_val: 46065.9219	loss_test: 46066.0586	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7677.9053	loss_val: 7679.1763	loss_test: 7678.5693	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5455
[client 5]	loss_train: 4752.8364	loss_val: 4752.8472	loss_test: 4752.8408	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10849.5459	loss_val: 10849.5967	loss_test: 10849.9736	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5109.9121	loss_val: 5110.2842	loss_test: 5110.4673	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10687.5039	loss_val: 10688.3096	loss_test: 10688.4082	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 12324.7285	loss_val: 12324.7598	loss_test: 12324.7080	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7378.6885	loss_val: 7378.7046	loss_test: 7378.7021	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4800.7515	loss_val: 4801.8086	loss_test: 4801.8398	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5417.4702	loss_val: 5418.1621	loss_test: 5418.9009	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12256.8037	loss_val: 12256.8760	loss_test: 12257.4727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4552.8115	loss_val: 4552.7842	loss_test: 4553.2212	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4881.8716	loss_val: 4882.8320	loss_test: 4883.2505	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4828.6899	loss_val: 4828.7007	loss_test: 4828.6958	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7798.2490	loss_val: 7799.4292	loss_test: 7799.5493	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69353.5078	loss_val: 69353.4375	loss_test: 69353.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6462.0166	loss_val: 6462.3784	loss_test: 6462.4976	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 71	curr_val_accuracy: 0.8126	curr_test_accuracy: 0.7959
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7009.1704	loss_val: 7010.2808	loss_test: 7009.8647	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13479.6270	loss_val: 13479.9727	loss_test: 13479.8906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 59657.0117	loss_val: 59657.3555	loss_test: 59657.7930	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 45926.9492	loss_val: 45926.9453	loss_test: 45927.0820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7669.9497	loss_val: 7671.2495	loss_test: 7670.6084	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5455
[client 5]	loss_train: 4752.2251	loss_val: 4752.2363	loss_test: 4752.2305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10918.7588	loss_val: 10918.8086	loss_test: 10919.1943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5118.7568	loss_val: 5119.1245	loss_test: 5119.3096	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10720.4297	loss_val: 10721.2383	loss_test: 10721.3535	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 12352.4209	loss_val: 12352.4531	loss_test: 12352.4014	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7363.1255	loss_val: 7363.1401	loss_test: 7363.1387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4788.0596	loss_val: 4789.2070	loss_test: 4789.1421	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5411.0981	loss_val: 5411.7925	loss_test: 5412.5210	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12252.5557	loss_val: 12252.6309	loss_test: 12253.2305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4558.5488	loss_val: 4558.5215	loss_test: 4558.9707	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4897.6455	loss_val: 4898.6333	loss_test: 4899.0732	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4822.1958	loss_val: 4822.2065	loss_test: 4822.2021	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7810.5400	loss_val: 7811.7075	loss_test: 7811.8491	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69492.0234	loss_val: 69491.9531	loss_test: 69492.4688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6462.6724	loss_val: 6463.0420	loss_test: 6463.1641	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 72	curr_val_accuracy: 0.8213	curr_test_accuracy: 0.7962
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7140.6636	loss_val: 7141.8228	loss_test: 7141.4131	accuracy_train: 0.9867	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 1]	loss_train: 13496.4521	loss_val: 13496.7988	loss_test: 13496.7090	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 59919.9219	loss_val: 59920.2305	loss_test: 59920.7109	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46090.4102	loss_val: 46090.4102	loss_test: 46090.5469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7656.6172	loss_val: 7657.9404	loss_test: 7657.2734	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5455
[client 5]	loss_train: 4756.3794	loss_val: 4756.3906	loss_test: 4756.3848	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10965.0576	loss_val: 10965.1074	loss_test: 10965.4990	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5124.7866	loss_val: 5125.1484	loss_test: 5125.3472	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10719.2031	loss_val: 10720.0078	loss_test: 10720.1309	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 12467.7715	loss_val: 12467.8018	loss_test: 12467.7539	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7337.7026	loss_val: 7337.7163	loss_test: 7337.7148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4802.2607	loss_val: 4803.5005	loss_test: 4803.3423	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 12]	loss_train: 5408.3423	loss_val: 5409.0415	loss_test: 5409.7329	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12272.1553	loss_val: 12272.2344	loss_test: 12272.8428	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4556.0024	loss_val: 4555.9751	loss_test: 4556.4370	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4933.6587	loss_val: 4934.6743	loss_test: 4935.1304	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4809.2739	loss_val: 4809.2832	loss_test: 4809.2793	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7856.6987	loss_val: 7857.8320	loss_test: 7858.0327	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69333.2891	loss_val: 69333.2266	loss_test: 69333.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6486.8184	loss_val: 6487.1719	loss_test: 6487.3086	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 73	curr_val_accuracy: 0.8046	curr_test_accuracy: 0.7966
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7188.6831	loss_val: 7189.8389	loss_test: 7189.4507	accuracy_train: 0.9867	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13486.5625	loss_val: 13486.9092	loss_test: 13486.8135	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 59872.8750	loss_val: 59873.1562	loss_test: 59873.6719	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 46039.5391	loss_val: 46039.5391	loss_test: 46039.6758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7702.6826	loss_val: 7704.0171	loss_test: 7703.3311	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5455
[client 5]	loss_train: 4761.2734	loss_val: 4761.2852	loss_test: 4761.2788	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11023.2461	loss_val: 11023.2949	loss_test: 11023.6924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5139.2407	loss_val: 5139.6001	loss_test: 5139.8086	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10710.3799	loss_val: 10711.1738	loss_test: 10711.3115	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 12538.3184	loss_val: 12538.3457	loss_test: 12538.3018	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7314.9478	loss_val: 7314.9595	loss_test: 7314.9590	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4802.3711	loss_val: 4803.6543	loss_test: 4803.4619	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 12]	loss_train: 5400.4688	loss_val: 5401.1689	loss_test: 5401.8691	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12271.0146	loss_val: 12271.0957	loss_test: 12271.7109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4563.1123	loss_val: 4563.0854	loss_test: 4563.5601	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4977.0254	loss_val: 4978.0728	loss_test: 4978.5405	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4796.1904	loss_val: 4796.1987	loss_test: 4796.1953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7883.2646	loss_val: 7884.3740	loss_test: 7884.6113	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69301.0703	loss_val: 69301.0078	loss_test: 69301.5312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6491.5049	loss_val: 6491.8657	loss_test: 6492.0000	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 74	curr_val_accuracy: 0.8036	curr_test_accuracy: 0.8047
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7167.4521	loss_val: 7168.5396	loss_test: 7168.1812	accuracy_train: 0.9867	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13453.2324	loss_val: 13453.5859	loss_test: 13453.4746	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 60000.8672	loss_val: 60001.1211	loss_test: 60001.6758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 46129.8555	loss_val: 46129.8555	loss_test: 46129.9961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7768.3828	loss_val: 7769.7173	loss_test: 7769.0288	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4771.4399	loss_val: 4771.4512	loss_test: 4771.4448	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11058.0869	loss_val: 11058.1357	loss_test: 11058.5381	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5155.4917	loss_val: 5155.8423	loss_test: 5156.0728	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10712.7363	loss_val: 10713.5186	loss_test: 10713.6650	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 12691.2910	loss_val: 12691.3164	loss_test: 12691.2754	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7289.7451	loss_val: 7289.7559	loss_test: 7289.7563	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4797.5723	loss_val: 4798.8745	loss_test: 4798.6680	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 12]	loss_train: 5395.1582	loss_val: 5395.8525	loss_test: 5396.5977	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12303.6045	loss_val: 12303.6885	loss_test: 12304.3047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4577.5840	loss_val: 4577.5576	loss_test: 4578.0483	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5007.5996	loss_val: 5008.6719	loss_test: 5009.1538	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4788.1860	loss_val: 4788.1929	loss_test: 4788.1899	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7920.2915	loss_val: 7921.3799	loss_test: 7921.6577	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69329.8125	loss_val: 69329.7500	loss_test: 69330.2734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6475.4272	loss_val: 6475.8335	loss_test: 6475.9326	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 75	curr_val_accuracy: 0.8036	curr_test_accuracy: 0.8125
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7123.1953	loss_val: 7124.2158	loss_test: 7123.8809	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13415.9785	loss_val: 13416.3359	loss_test: 13416.2197	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 59499.0859	loss_val: 59499.3320	loss_test: 59499.8945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 46149.2656	loss_val: 46149.2617	loss_test: 46149.4141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7722.1470	loss_val: 7723.4814	loss_test: 7722.8018	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5455
[client 5]	loss_train: 4774.5137	loss_val: 4774.5254	loss_test: 4774.5186	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11069.1299	loss_val: 11069.1777	loss_test: 11069.5859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5165.0195	loss_val: 5165.3584	loss_test: 5165.6162	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10530.8936	loss_val: 10531.6543	loss_test: 10531.8750	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 12723.1611	loss_val: 12723.1865	loss_test: 12723.1475	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7271.7642	loss_val: 7271.7739	loss_test: 7271.7754	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4776.6514	loss_val: 4777.9551	loss_test: 4777.7559	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5394.7217	loss_val: 5395.4150	loss_test: 5396.1782	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12277.4717	loss_val: 12277.5566	loss_test: 12278.1787	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4576.3760	loss_val: 4576.3501	loss_test: 4576.8491	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5022.2871	loss_val: 5023.3687	loss_test: 5023.8555	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4780.1079	loss_val: 4780.1138	loss_test: 4780.1123	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8012.7588	loss_val: 8013.8086	loss_test: 8014.1177	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 69178.3906	loss_val: 69178.3359	loss_test: 69178.8594	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6438.5986	loss_val: 6439.0908	loss_test: 6439.1250	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 76	curr_val_accuracy: 0.8202	curr_test_accuracy: 0.7962
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7030.0273	loss_val: 7030.9712	loss_test: 7030.6357	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 1]	loss_train: 13352.0098	loss_val: 13352.3730	loss_test: 13352.2441	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 58890.1680	loss_val: 58890.4023	loss_test: 58890.9688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 45920.4688	loss_val: 45920.4688	loss_test: 45920.6289	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7603.2974	loss_val: 7604.6265	loss_test: 7603.9712	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4770.3940	loss_val: 4770.4062	loss_test: 4770.3989	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11092.8594	loss_val: 11092.9082	loss_test: 11093.3203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5180.5425	loss_val: 5180.8662	loss_test: 5181.1572	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10341.8662	loss_val: 10342.6094	loss_test: 10342.8916	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 12732.3125	loss_val: 12732.3379	loss_test: 12732.2988	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7251.6353	loss_val: 7251.6455	loss_test: 7251.6470	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4765.9478	loss_val: 4767.2559	loss_test: 4767.0742	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5390.8970	loss_val: 5391.5933	loss_test: 5392.3667	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12321.1221	loss_val: 12321.2070	loss_test: 12321.8350	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4568.1431	loss_val: 4568.1177	loss_test: 4568.6230	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5027.0410	loss_val: 5028.1284	loss_test: 5028.6084	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4774.3579	loss_val: 4774.3628	loss_test: 4774.3628	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8083.8462	loss_val: 8084.8628	loss_test: 8085.1895	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68931.8281	loss_val: 68931.7734	loss_test: 68932.2969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6404.9072	loss_val: 6405.4741	loss_test: 6405.4502	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 77	curr_val_accuracy: 0.8364	curr_test_accuracy: 0.7966
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6973.0259	loss_val: 6973.9121	loss_test: 6973.5679	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 1]	loss_train: 13361.0732	loss_val: 13361.4385	loss_test: 13361.3145	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 58349.5156	loss_val: 58349.7422	loss_test: 58350.3125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 45727.6602	loss_val: 45727.6602	loss_test: 45727.8242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7561.5142	loss_val: 7562.8457	loss_test: 7562.1997	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4776.3901	loss_val: 4776.4019	loss_test: 4776.3945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11123.8564	loss_val: 11123.9043	loss_test: 11124.3232	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5192.4688	loss_val: 5192.7832	loss_test: 5193.1011	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10206.2822	loss_val: 10207.0127	loss_test: 10207.3486	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12712.3906	loss_val: 12712.4160	loss_test: 12712.3770	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7244.2129	loss_val: 7244.2261	loss_test: 7244.2256	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4759.3315	loss_val: 4760.6250	loss_test: 4760.4907	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5393.9629	loss_val: 5394.6650	loss_test: 5395.4224	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12409.2451	loss_val: 12409.3330	loss_test: 12409.9668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4569.7490	loss_val: 4569.7236	loss_test: 4570.2363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5024.5063	loss_val: 5025.6030	loss_test: 5026.0420	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4769.8750	loss_val: 4769.8784	loss_test: 4769.8799	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8148.7080	loss_val: 8149.7129	loss_test: 8150.0435	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68843.7266	loss_val: 68843.6719	loss_test: 68844.1953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6391.6362	loss_val: 6392.2471	loss_test: 6392.1929	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 78	curr_val_accuracy: 0.8536	curr_test_accuracy: 0.7957
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6918.5220	loss_val: 6919.3838	loss_test: 6919.0166	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13328.3203	loss_val: 13328.6865	loss_test: 13328.5557	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 57580.5273	loss_val: 57580.7617	loss_test: 57581.3164	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 45552.1055	loss_val: 45552.1055	loss_test: 45552.2734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7466.7646	loss_val: 7468.0923	loss_test: 7467.4756	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6364
[client 5]	loss_train: 4773.5024	loss_val: 4773.5142	loss_test: 4773.5068	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11147.6455	loss_val: 11147.6934	loss_test: 11148.1182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5197.1401	loss_val: 5197.4468	loss_test: 5197.7910	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10123.5674	loss_val: 10124.2803	loss_test: 10124.6670	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12684.8799	loss_val: 12684.9053	loss_test: 12684.8662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7253.3857	loss_val: 7253.4033	loss_test: 7253.4009	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4763.4434	loss_val: 4764.7046	loss_test: 4764.6396	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5390.7852	loss_val: 5391.4941	loss_test: 5392.2500	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12469.6201	loss_val: 12469.7100	loss_test: 12470.3457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4559.7241	loss_val: 4559.6987	loss_test: 4560.2256	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 4997.6328	loss_val: 4998.7422	loss_test: 4999.1401	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4762.8623	loss_val: 4762.8633	loss_test: 4762.8657	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8196.1816	loss_val: 8197.1631	loss_test: 8197.5078	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68646.4297	loss_val: 68646.3750	loss_test: 68646.8906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6409.2769	loss_val: 6409.8760	loss_test: 6409.8291	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 79	curr_val_accuracy: 0.8542	curr_test_accuracy: 0.7887
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6869.5479	loss_val: 6870.4141	loss_test: 6870.0269	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13346.5244	loss_val: 13346.8877	loss_test: 13346.7529	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 57004.5156	loss_val: 57004.7852	loss_test: 57005.3047	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 45270.6562	loss_val: 45270.6602	loss_test: 45270.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7402.2666	loss_val: 7403.5957	loss_test: 7403.0029	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6364
[client 5]	loss_train: 4765.2344	loss_val: 4765.2471	loss_test: 4765.2393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11169.8711	loss_val: 11169.9209	loss_test: 11170.3447	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5180.0967	loss_val: 5180.3989	loss_test: 5180.7637	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10072.3604	loss_val: 10073.0576	loss_test: 10073.4824	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12604.7432	loss_val: 12604.7695	loss_test: 12604.7285	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7264.8164	loss_val: 7264.8374	loss_test: 7264.8335	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4779.2886	loss_val: 4780.5347	loss_test: 4780.5132	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5378.5205	loss_val: 5379.2339	loss_test: 5380.0244	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12532.7490	loss_val: 12532.8447	loss_test: 12533.4814	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4557.5234	loss_val: 4557.4980	loss_test: 4558.0396	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4976.8218	loss_val: 4977.9482	loss_test: 4978.2783	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4752.9526	loss_val: 4752.9526	loss_test: 4752.9561	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8224.0693	loss_val: 8225.0498	loss_test: 8225.3975	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68681.1797	loss_val: 68681.1250	loss_test: 68681.6328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6399.4648	loss_val: 6400.0688	loss_test: 6400.0195	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 80	curr_val_accuracy: 0.8466	curr_test_accuracy: 0.7844
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6832.1094	loss_val: 6832.9937	loss_test: 6832.5981	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13342.3887	loss_val: 13342.7480	loss_test: 13342.6094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56769.4531	loss_val: 56769.7656	loss_test: 56770.2539	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 45007.5625	loss_val: 45007.5625	loss_test: 45007.7500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7332.8242	loss_val: 7334.1699	loss_test: 7333.5859	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6364
[client 5]	loss_train: 4758.9136	loss_val: 4758.9263	loss_test: 4758.9185	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11213.5723	loss_val: 11213.6230	loss_test: 11214.0439	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5144.4111	loss_val: 5144.7163	loss_test: 5145.0835	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10062.2773	loss_val: 10062.9678	loss_test: 10063.3984	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12480.9434	loss_val: 12480.9717	loss_test: 12480.9277	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7274.8652	loss_val: 7274.8896	loss_test: 7274.8843	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4799.3047	loss_val: 4800.5376	loss_test: 4800.5493	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5372.7529	loss_val: 5373.4702	loss_test: 5374.2959	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12594.1328	loss_val: 12594.2314	loss_test: 12594.8750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4553.4175	loss_val: 4553.3926	loss_test: 4553.9551	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4929.8262	loss_val: 4930.9609	loss_test: 4931.2354	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4741.5483	loss_val: 4741.5479	loss_test: 4741.5513	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8239.4980	loss_val: 8240.4746	loss_test: 8240.8389	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68646.1328	loss_val: 68646.0781	loss_test: 68646.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6405.2310	loss_val: 6405.7944	loss_test: 6405.7759	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 81	curr_val_accuracy: 0.8466	curr_test_accuracy: 0.7844
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6798.8931	loss_val: 6799.8022	loss_test: 6799.4043	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13300.5605	loss_val: 13300.9189	loss_test: 13300.7754	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56613.5000	loss_val: 56613.8320	loss_test: 56614.2969	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 44913.6602	loss_val: 44913.6602	loss_test: 44913.8555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7280.0532	loss_val: 7281.4155	loss_test: 7280.8262	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6364
[client 5]	loss_train: 4758.2842	loss_val: 4758.2979	loss_test: 4758.2896	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11236.7920	loss_val: 11236.8428	loss_test: 11237.2627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5117.7188	loss_val: 5118.0283	loss_test: 5118.3940	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10081.5752	loss_val: 10082.2617	loss_test: 10082.6875	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12350.5166	loss_val: 12350.5449	loss_test: 12350.4990	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7321.3892	loss_val: 7321.4175	loss_test: 7321.4097	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4858.3389	loss_val: 4859.5479	loss_test: 4859.6128	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5378.4858	loss_val: 5379.2124	loss_test: 5380.0547	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12650.0176	loss_val: 12650.1182	loss_test: 12650.7686	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4550.7720	loss_val: 4550.7480	loss_test: 4551.3149	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4885.4429	loss_val: 4886.5806	loss_test: 4886.8042	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4736.8423	loss_val: 4736.8413	loss_test: 4736.8447	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8203.9062	loss_val: 8204.8818	loss_test: 8205.2686	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68419.9922	loss_val: 68419.9375	loss_test: 68420.4375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6426.5898	loss_val: 6427.1025	loss_test: 6427.1211	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 82	curr_val_accuracy: 0.8466	curr_test_accuracy: 0.7928
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6772.0513	loss_val: 6772.9780	loss_test: 6772.5825	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13226.5576	loss_val: 13226.9131	loss_test: 13226.7588	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56560.3750	loss_val: 56560.7148	loss_test: 56561.1641	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 45015.0547	loss_val: 45015.0547	loss_test: 45015.2539	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7235.1958	loss_val: 7236.5864	loss_test: 7235.9800	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4754.0479	loss_val: 4754.0625	loss_test: 4754.0537	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11253.8848	loss_val: 11253.9336	loss_test: 11254.3613	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5091.8501	loss_val: 5092.1650	loss_test: 5092.5112	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10112.9844	loss_val: 10113.6777	loss_test: 10114.0879	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12193.8936	loss_val: 12193.9229	loss_test: 12193.8760	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7357.1211	loss_val: 7357.1514	loss_test: 7357.1431	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4892.0718	loss_val: 4893.2930	loss_test: 4893.3521	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5374.8242	loss_val: 5375.5527	loss_test: 5376.4365	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12647.1943	loss_val: 12647.2979	loss_test: 12647.9521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4547.6123	loss_val: 4547.5889	loss_test: 4548.1655	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4860.1753	loss_val: 4861.3281	loss_test: 4861.5078	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4734.2832	loss_val: 4734.2827	loss_test: 4734.2861	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8178.1221	loss_val: 8179.0947	loss_test: 8179.4980	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68047.6797	loss_val: 68047.6250	loss_test: 68048.1250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6456.3364	loss_val: 6456.7979	loss_test: 6456.8555	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 83	curr_val_accuracy: 0.8379	curr_test_accuracy: 0.7928
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6765.3711	loss_val: 6766.2983	loss_test: 6765.9551	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13149.6221	loss_val: 13149.9775	loss_test: 13149.8086	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56017.8672	loss_val: 56018.2305	loss_test: 56018.6680	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 45579.4336	loss_val: 45579.4336	loss_test: 45579.6328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7205.8516	loss_val: 7207.2676	loss_test: 7206.6523	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4747.1504	loss_val: 4747.1660	loss_test: 4747.1567	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11272.9209	loss_val: 11272.9697	loss_test: 11273.4014	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5087.3809	loss_val: 5087.7080	loss_test: 5088.0259	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10164.9805	loss_val: 10165.6670	loss_test: 10166.0557	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12079.2158	loss_val: 12079.2471	loss_test: 12079.1973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7406.9004	loss_val: 7406.9326	loss_test: 7406.9238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4886.9209	loss_val: 4888.1846	loss_test: 4888.1914	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5365.2017	loss_val: 5365.9307	loss_test: 5366.8379	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12588.6963	loss_val: 12588.8037	loss_test: 12589.4619	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4554.9609	loss_val: 4554.9380	loss_test: 4555.5552	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4832.4512	loss_val: 4833.5962	loss_test: 4833.7549	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4730.0996	loss_val: 4730.0991	loss_test: 4730.1021	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8156.1758	loss_val: 8157.1445	loss_test: 8157.5635	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67290.0781	loss_val: 67290.0234	loss_test: 67290.5234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6467.8423	loss_val: 6468.2744	loss_test: 6468.3540	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 84	curr_val_accuracy: 0.8379	curr_test_accuracy: 0.7928
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6781.8740	loss_val: 6782.8462	loss_test: 6782.5527	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13096.7764	loss_val: 13097.1357	loss_test: 13096.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 55501.3047	loss_val: 55501.6562	loss_test: 55502.0977	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 45907.6758	loss_val: 45907.6719	loss_test: 45907.8750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7223.7734	loss_val: 7225.1733	loss_test: 7224.5776	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4738.4912	loss_val: 4738.5068	loss_test: 4738.4980	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11322.5176	loss_val: 11322.5664	loss_test: 11323.0020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5081.0532	loss_val: 5081.3945	loss_test: 5081.6821	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 10218.8379	loss_val: 10219.5244	loss_test: 10219.8906	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 11933.4199	loss_val: 11933.4531	loss_test: 11933.4023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7433.2925	loss_val: 7433.3242	loss_test: 7433.3169	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4862.9258	loss_val: 4864.2505	loss_test: 4864.1836	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5359.1094	loss_val: 5359.8457	loss_test: 5360.7573	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12547.8164	loss_val: 12547.9258	loss_test: 12548.5859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4555.1323	loss_val: 4555.1094	loss_test: 4555.7549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4804.4385	loss_val: 4805.5786	loss_test: 4805.7202	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4723.6025	loss_val: 4723.6025	loss_test: 4723.6055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8151.7651	loss_val: 8152.7412	loss_test: 8153.1738	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66813.6797	loss_val: 66813.6250	loss_test: 66814.1094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6465.5605	loss_val: 6465.9912	loss_test: 6466.0703	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 85	curr_val_accuracy: 0.8379	curr_test_accuracy: 0.7782
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6804.8267	loss_val: 6805.8496	loss_test: 6805.5845	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13042.0801	loss_val: 13042.4434	loss_test: 13042.2510	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 55166.2305	loss_val: 55166.5547	loss_test: 55167.0117	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 46222.8438	loss_val: 46222.8438	loss_test: 46223.0469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7222.6162	loss_val: 7224.0005	loss_test: 7223.4390	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4729.7720	loss_val: 4729.7871	loss_test: 4729.7788	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11386.9668	loss_val: 11387.0137	loss_test: 11387.4521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5090.4766	loss_val: 5090.8252	loss_test: 5091.0938	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 10316.8350	loss_val: 10317.5322	loss_test: 10317.8604	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11787.1846	loss_val: 11787.2197	loss_test: 11787.1670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7460.2598	loss_val: 7460.2910	loss_test: 7460.2837	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4821.9028	loss_val: 4823.3076	loss_test: 4823.1299	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5358.6685	loss_val: 5359.4150	loss_test: 5360.3174	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12509.9375	loss_val: 12510.0400	loss_test: 12510.7051	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4559.4419	loss_val: 4559.4189	loss_test: 4560.0835	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4776.4082	loss_val: 4777.5273	loss_test: 4777.6841	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4719.8555	loss_val: 4719.8550	loss_test: 4719.8584	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8107.5376	loss_val: 8108.5254	loss_test: 8108.9551	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66184.2188	loss_val: 66184.1641	loss_test: 66184.6406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6503.5776	loss_val: 6503.9609	loss_test: 6504.0703	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 86	curr_val_accuracy: 0.8293	curr_test_accuracy: 0.7698
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6784.3975	loss_val: 6785.4448	loss_test: 6785.1655	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 12985.0928	loss_val: 12985.4619	loss_test: 12985.2559	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 55222.8281	loss_val: 55223.1250	loss_test: 55223.6133	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 46365.7383	loss_val: 46365.7383	loss_test: 46365.9375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7230.7593	loss_val: 7232.1509	loss_test: 7231.6016	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4718.5923	loss_val: 4718.6069	loss_test: 4718.5991	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11423.8174	loss_val: 11423.8643	loss_test: 11424.3047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5087.1689	loss_val: 5087.5239	loss_test: 5087.7729	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 10438.9834	loss_val: 10439.6914	loss_test: 10439.9766	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 11647.0615	loss_val: 11647.0977	loss_test: 11647.0459	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7478.7153	loss_val: 7478.7451	loss_test: 7478.7378	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4787.2324	loss_val: 4788.7085	loss_test: 4788.4243	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5354.3022	loss_val: 5355.0562	loss_test: 5355.9199	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12431.1250	loss_val: 12431.2178	loss_test: 12431.8896	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4549.9644	loss_val: 4549.9414	loss_test: 4550.6104	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4762.4497	loss_val: 4763.5654	loss_test: 4763.7241	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4711.7817	loss_val: 4711.7822	loss_test: 4711.7861	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8024.2466	loss_val: 8025.2720	loss_test: 8025.6709	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65888.3047	loss_val: 65888.2500	loss_test: 65888.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6524.7583	loss_val: 6525.1167	loss_test: 6525.2373	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 87	curr_val_accuracy: 0.8120	curr_test_accuracy: 0.7639
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6781.8232	loss_val: 6782.9204	loss_test: 6782.6235	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 12940.3740	loss_val: 12940.7500	loss_test: 12940.5371	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 55410.4336	loss_val: 55410.7031	loss_test: 55411.2305	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46544.1523	loss_val: 46544.1523	loss_test: 46544.3516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7219.8086	loss_val: 7221.2197	loss_test: 7220.6743	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4710.3940	loss_val: 4710.4087	loss_test: 4710.4009	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11467.4043	loss_val: 11467.4492	loss_test: 11467.8926	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5095.0820	loss_val: 5095.4453	loss_test: 5095.6802	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4286
[client 8]	loss_train: 10558.8916	loss_val: 10559.6162	loss_test: 10559.8662	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 11499.6592	loss_val: 11499.6953	loss_test: 11499.6455	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7526.2949	loss_val: 7526.3242	loss_test: 7526.3154	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4761.9824	loss_val: 4763.5063	loss_test: 4763.1392	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5361.3159	loss_val: 5362.0757	loss_test: 5362.9326	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12372.4824	loss_val: 12372.5654	loss_test: 12373.2441	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4548.5835	loss_val: 4548.5620	loss_test: 4549.2285	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4750.1714	loss_val: 4751.2661	loss_test: 4751.4336	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4713.7246	loss_val: 4713.7256	loss_test: 4713.7314	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7922.5479	loss_val: 7923.6289	loss_test: 7923.9692	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65477.2656	loss_val: 65477.2148	loss_test: 65477.6797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6537.1758	loss_val: 6537.5151	loss_test: 6537.6450	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 88	curr_val_accuracy: 0.8120	curr_test_accuracy: 0.7650
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6812.3877	loss_val: 6813.5776	loss_test: 6813.2485	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 12916.5059	loss_val: 12916.8838	loss_test: 12916.6719	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 55656.9297	loss_val: 55657.1836	loss_test: 55657.7500	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46393.7266	loss_val: 46393.7227	loss_test: 46393.9258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7219.9351	loss_val: 7221.3550	loss_test: 7220.8247	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 5]	loss_train: 4702.1514	loss_val: 4702.1660	loss_test: 4702.1577	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11473.5479	loss_val: 11473.5918	loss_test: 11474.0371	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5105.2231	loss_val: 5105.6016	loss_test: 5105.8228	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4286
[client 8]	loss_train: 10673.1787	loss_val: 10673.9150	loss_test: 10674.1309	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 11499.3213	loss_val: 11499.3564	loss_test: 11499.3105	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7555.8589	loss_val: 7555.8882	loss_test: 7555.8784	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4739.7119	loss_val: 4741.2500	loss_test: 4740.8486	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5362.7173	loss_val: 5363.4873	loss_test: 5364.2808	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12332.2393	loss_val: 12332.3145	loss_test: 12333.0000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4546.2988	loss_val: 4546.2783	loss_test: 4546.9487	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4743.8320	loss_val: 4744.9141	loss_test: 4745.0957	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4707.8237	loss_val: 4707.8262	loss_test: 4707.8330	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7844.3081	loss_val: 7845.4355	loss_test: 7845.7300	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65112.8828	loss_val: 65112.8359	loss_test: 65113.3008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6501.4087	loss_val: 6501.7593	loss_test: 6501.8770	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 89	curr_val_accuracy: 0.7947	curr_test_accuracy: 0.7808
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6811.5273	loss_val: 6812.7759	loss_test: 6812.4185	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 12938.1289	loss_val: 12938.5088	loss_test: 12938.2949	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 55857.7656	loss_val: 55858.0039	loss_test: 55858.6133	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 46184.2109	loss_val: 46184.2109	loss_test: 46184.4062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7223.6050	loss_val: 7225.0181	loss_test: 7224.5093	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4697.8525	loss_val: 4697.8667	loss_test: 4697.8589	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11464.2412	loss_val: 11464.2842	loss_test: 11464.7305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5130.4648	loss_val: 5130.8608	loss_test: 5131.0659	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4286
[client 8]	loss_train: 10590.3184	loss_val: 10591.0576	loss_test: 10591.2783	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 11732.4463	loss_val: 11732.4795	loss_test: 11732.4395	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7571.6450	loss_val: 7571.6738	loss_test: 7571.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4725.7075	loss_val: 4727.2461	loss_test: 4726.8252	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5376.5439	loss_val: 5377.3320	loss_test: 5378.0264	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12295.3447	loss_val: 12295.4180	loss_test: 12296.1045	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4535.5200	loss_val: 4535.5000	loss_test: 4536.1821	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4727.9521	loss_val: 4729.0117	loss_test: 4729.2100	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4715.4741	loss_val: 4715.4775	loss_test: 4715.4858	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7767.8823	loss_val: 7769.0352	loss_test: 7769.3096	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64765.0508	loss_val: 64765.0078	loss_test: 64765.4766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6461.5703	loss_val: 6461.9478	loss_test: 6462.0435	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 90	curr_val_accuracy: 0.8039	curr_test_accuracy: 0.7728
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6803.1162	loss_val: 6804.4028	loss_test: 6804.0234	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 12920.3203	loss_val: 12920.7070	loss_test: 12920.4834	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56221.7812	loss_val: 56222.0000	loss_test: 56222.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 45746.1016	loss_val: 45746.1016	loss_test: 45746.2930	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7262.3413	loss_val: 7263.7354	loss_test: 7263.2476	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4693.5864	loss_val: 4693.6006	loss_test: 4693.5918	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11471.8281	loss_val: 11471.8701	loss_test: 11472.3184	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5187.3345	loss_val: 5187.7402	loss_test: 5187.9341	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4286
[client 8]	loss_train: 10160.0029	loss_val: 10160.7520	loss_test: 10161.0654	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12035.4551	loss_val: 12035.4844	loss_test: 12035.4492	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7557.4668	loss_val: 7557.4951	loss_test: 7557.4854	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4711.4092	loss_val: 4712.9365	loss_test: 4712.5098	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 12]	loss_train: 5395.7837	loss_val: 5396.5889	loss_test: 5397.2061	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12240.2490	loss_val: 12240.3193	loss_test: 12241.0146	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4547.4917	loss_val: 4547.4717	loss_test: 4548.1606	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4714.1670	loss_val: 4715.2158	loss_test: 4715.4404	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4732.6865	loss_val: 4732.6914	loss_test: 4732.7017	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7692.1304	loss_val: 7693.3140	loss_test: 7693.5654	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64755.6641	loss_val: 64755.6250	loss_test: 64756.1055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6427.7749	loss_val: 6428.1768	loss_test: 6428.2559	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 91	curr_val_accuracy: 0.8288	curr_test_accuracy: 0.7812
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6811.9463	loss_val: 6813.2773	loss_test: 6812.8711	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 12913.9580	loss_val: 12914.3506	loss_test: 12914.1182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56706.8438	loss_val: 56707.0469	loss_test: 56707.7656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 45371.5156	loss_val: 45371.5156	loss_test: 45371.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7294.7759	loss_val: 7296.1523	loss_test: 7295.6724	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4688.3945	loss_val: 4688.4092	loss_test: 4688.4004	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11460.2656	loss_val: 11460.3066	loss_test: 11460.7588	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5260.0942	loss_val: 5260.5122	loss_test: 5260.6934	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 9902.8525	loss_val: 9903.6250	loss_test: 9903.9932	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12312.3369	loss_val: 12312.3633	loss_test: 12312.3320	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7546.1426	loss_val: 7546.1709	loss_test: 7546.1611	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4693.4907	loss_val: 4694.9932	loss_test: 4694.5894	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 12]	loss_train: 5421.2031	loss_val: 5422.0181	loss_test: 5422.6016	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12183.6826	loss_val: 12183.7510	loss_test: 12184.4512	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4540.7065	loss_val: 4540.6875	loss_test: 4541.3662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4688.3687	loss_val: 4689.3906	loss_test: 4689.6519	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4746.1997	loss_val: 4746.2051	loss_test: 4746.2168	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7645.3091	loss_val: 7646.5259	loss_test: 7646.7549	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64887.8086	loss_val: 64887.7695	loss_test: 64888.2617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6329.3081	loss_val: 6329.8218	loss_test: 6329.8179	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 92	curr_val_accuracy: 0.8375	curr_test_accuracy: 0.7877
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6809.8765	loss_val: 6811.2319	loss_test: 6810.8042	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 12859.1133	loss_val: 12859.5107	loss_test: 12859.2725	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 57174.7422	loss_val: 57174.9297	loss_test: 57175.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 45046.6406	loss_val: 45046.6406	loss_test: 45046.8242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7299.2139	loss_val: 7300.5967	loss_test: 7300.1177	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4686.0239	loss_val: 4686.0386	loss_test: 4686.0288	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11458.2988	loss_val: 11458.3398	loss_test: 11458.7939	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5334.6768	loss_val: 5335.1089	loss_test: 5335.2788	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 9741.6650	loss_val: 9742.4629	loss_test: 9742.8604	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12468.8555	loss_val: 12468.8809	loss_test: 12468.8506	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7530.0742	loss_val: 7530.1016	loss_test: 7530.0923	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4671.0210	loss_val: 4672.4478	loss_test: 4672.1245	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5431.6016	loss_val: 5432.4277	loss_test: 5433.0156	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12224.2920	loss_val: 12224.3643	loss_test: 12225.0654	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4551.7031	loss_val: 4551.6846	loss_test: 4552.3501	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4670.5479	loss_val: 4671.5557	loss_test: 4671.8599	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4756.4194	loss_val: 4756.4248	loss_test: 4756.4365	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7591.5664	loss_val: 7592.8257	loss_test: 7593.0195	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64902.5820	loss_val: 64902.5430	loss_test: 64903.0508	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6241.6597	loss_val: 6242.2979	loss_test: 6242.2007	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 93	curr_val_accuracy: 0.8375	curr_test_accuracy: 0.7709
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6807.6348	loss_val: 6809.0024	loss_test: 6808.5547	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 12836.7773	loss_val: 12837.1816	loss_test: 12836.9346	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 57118.1016	loss_val: 57118.2852	loss_test: 57119.0781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 44785.5703	loss_val: 44785.5703	loss_test: 44785.7539	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7310.2002	loss_val: 7311.5918	loss_test: 7311.1045	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4682.4048	loss_val: 4682.4194	loss_test: 4682.4102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11467.0684	loss_val: 11467.1084	loss_test: 11467.5674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5367.9287	loss_val: 5368.3706	loss_test: 5368.5361	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 9644.1768	loss_val: 9644.9883	loss_test: 9645.4062	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12539.5996	loss_val: 12539.6260	loss_test: 12539.5957	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7507.7168	loss_val: 7507.7451	loss_test: 7507.7354	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4670.7554	loss_val: 4672.0884	loss_test: 4671.8862	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5430.4668	loss_val: 5431.2876	loss_test: 5431.9185	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12224.6689	loss_val: 12224.7432	loss_test: 12225.4453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4562.7168	loss_val: 4562.6982	loss_test: 4563.3774	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4659.9834	loss_val: 4660.9619	loss_test: 4661.3125	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4761.8276	loss_val: 4761.8330	loss_test: 4761.8452	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7530.5898	loss_val: 7531.8818	loss_test: 7532.0439	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65054.0469	loss_val: 65054.0078	loss_test: 65054.5273	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6198.4858	loss_val: 6199.2026	loss_test: 6199.0488	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 94	curr_val_accuracy: 0.8375	curr_test_accuracy: 0.7793
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6801.5503	loss_val: 6802.9316	loss_test: 6802.4697	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 12861.6865	loss_val: 12862.0977	loss_test: 12861.8398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56299.6094	loss_val: 56299.8008	loss_test: 56300.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 44487.4297	loss_val: 44487.4297	loss_test: 44487.6172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7316.1963	loss_val: 7317.6084	loss_test: 7317.0942	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4673.3306	loss_val: 4673.3452	loss_test: 4673.3354	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11520.5088	loss_val: 11520.5488	loss_test: 11521.0176	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5392.5684	loss_val: 5393.0244	loss_test: 5393.1870	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 9597.0625	loss_val: 9597.8682	loss_test: 9598.3008	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12583.9824	loss_val: 12584.0098	loss_test: 12583.9785	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7473.7217	loss_val: 7473.7500	loss_test: 7473.7412	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4696.9727	loss_val: 4698.2144	loss_test: 4698.1538	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5427.4351	loss_val: 5428.2515	loss_test: 5428.9380	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12231.5449	loss_val: 12231.6191	loss_test: 12232.3223	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4568.1440	loss_val: 4568.1255	loss_test: 4568.8115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4643.6646	loss_val: 4644.6162	loss_test: 4645.0059	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4772.3628	loss_val: 4772.3687	loss_test: 4772.3799	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7485.4565	loss_val: 7486.7739	loss_test: 7486.9399	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65393.0469	loss_val: 65393.0078	loss_test: 65393.5391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6167.8013	loss_val: 6168.5820	loss_test: 6168.3896	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 95	curr_val_accuracy: 0.8375	curr_test_accuracy: 0.7793
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6833.7856	loss_val: 6835.2173	loss_test: 6834.7402	accuracy_train: 0.9733	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 1]	loss_train: 12854.3711	loss_val: 12854.7871	loss_test: 12854.5225	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 55157.8125	loss_val: 55158.0273	loss_test: 55158.7578	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 44483.2031	loss_val: 44483.2031	loss_test: 44483.3906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7292.1021	loss_val: 7293.5464	loss_test: 7293.0078	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4664.4106	loss_val: 4664.4253	loss_test: 4664.4155	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11581.8516	loss_val: 11581.8916	loss_test: 11582.3711	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5368.8589	loss_val: 5369.3262	loss_test: 5369.4956	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 9619.5713	loss_val: 9620.3643	loss_test: 9620.8193	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12526.2236	loss_val: 12526.2520	loss_test: 12526.2197	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7454.8911	loss_val: 7454.9204	loss_test: 7454.9111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4745.6890	loss_val: 4746.8525	loss_test: 4746.9282	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5442.9668	loss_val: 5443.7734	loss_test: 5444.5098	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12307.3779	loss_val: 12307.4570	loss_test: 12308.1562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4560.5454	loss_val: 4560.5269	loss_test: 4561.2173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4617.5034	loss_val: 4618.4380	loss_test: 4618.8496	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4788.1538	loss_val: 4788.1597	loss_test: 4788.1704	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7440.1270	loss_val: 7441.4678	loss_test: 7441.6313	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65546.6016	loss_val: 65546.5625	loss_test: 65547.1016	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6147.0986	loss_val: 6147.8926	loss_test: 6147.7007	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 96	curr_val_accuracy: 0.8218	curr_test_accuracy: 0.7793
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6744.0679	loss_val: 6745.4351	loss_test: 6744.9595	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 12823.3936	loss_val: 12823.8174	loss_test: 12823.5449	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 54204.0625	loss_val: 54204.3047	loss_test: 54204.9922	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 3]	loss_train: 44599.0117	loss_val: 44599.0117	loss_test: 44599.1992	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7279.7153	loss_val: 7281.1846	loss_test: 7280.6118	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4658.3369	loss_val: 4658.3511	loss_test: 4658.3413	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11626.3184	loss_val: 11626.3584	loss_test: 11626.8467	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5324.5249	loss_val: 5324.9927	loss_test: 5325.1724	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 9622.7832	loss_val: 9623.5635	loss_test: 9624.0264	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12371.4131	loss_val: 12371.4443	loss_test: 12371.4092	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7420.6265	loss_val: 7420.6567	loss_test: 7420.6465	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4800.2812	loss_val: 4801.3940	loss_test: 4801.5776	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5435.5449	loss_val: 5436.3252	loss_test: 5437.1724	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12423.3379	loss_val: 12423.4238	loss_test: 12424.1172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4564.3960	loss_val: 4564.3779	loss_test: 4565.0781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4596.8452	loss_val: 4597.7568	loss_test: 4598.1958	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4799.0571	loss_val: 4799.0630	loss_test: 4799.0737	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7436.4385	loss_val: 7437.7773	loss_test: 7437.9478	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65526.9805	loss_val: 65526.9375	loss_test: 65527.4805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6157.2329	loss_val: 6157.9810	loss_test: 6157.8306	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 97	curr_val_accuracy: 0.8299	curr_test_accuracy: 0.7793
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6648.3647	loss_val: 6649.6069	loss_test: 6649.1655	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 1]	loss_train: 12755.7207	loss_val: 12756.1465	loss_test: 12755.8721	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 53338.0391	loss_val: 53338.3203	loss_test: 53338.9688	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 44537.7852	loss_val: 44537.7852	loss_test: 44537.9727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7252.5483	loss_val: 7254.0249	loss_test: 7253.4185	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4654.5552	loss_val: 4654.5693	loss_test: 4654.5596	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11669.2725	loss_val: 11669.3115	loss_test: 11669.8115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5270.9702	loss_val: 5271.4395	loss_test: 5271.6270	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4286
[client 8]	loss_train: 9628.4883	loss_val: 9629.2412	loss_test: 9629.7070	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12162.0449	loss_val: 12162.0791	loss_test: 12162.0420	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7378.9814	loss_val: 7379.0112	loss_test: 7379.0020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4863.9160	loss_val: 4864.9897	loss_test: 4865.2690	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5437.5884	loss_val: 5438.3467	loss_test: 5439.2734	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12541.6064	loss_val: 12541.6982	loss_test: 12542.3896	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4566.9717	loss_val: 4566.9536	loss_test: 4567.6631	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4588.9116	loss_val: 4589.8110	loss_test: 4590.2690	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4803.6621	loss_val: 4803.6689	loss_test: 4803.6787	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7410.8560	loss_val: 7412.1865	loss_test: 7412.3652	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65370.3516	loss_val: 65370.3086	loss_test: 65370.8555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6211.0400	loss_val: 6211.6548	loss_test: 6211.6089	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 98	curr_val_accuracy: 0.8299	curr_test_accuracy: 0.7456
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6606.6235	loss_val: 6607.7876	loss_test: 6607.3936	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 12750.5830	loss_val: 12751.0049	loss_test: 12750.7363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 52664.9688	loss_val: 52665.2891	loss_test: 52665.8984	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 44987.9375	loss_val: 44987.9375	loss_test: 44988.1250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7223.6001	loss_val: 7225.0972	loss_test: 7224.4595	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4655.8096	loss_val: 4655.8232	loss_test: 4655.8140	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11680.3184	loss_val: 11680.3574	loss_test: 11680.8672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5239.3076	loss_val: 5239.7812	loss_test: 5239.9736	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4286
[client 8]	loss_train: 9636.8428	loss_val: 9637.5723	loss_test: 9638.0479	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 11959.0010	loss_val: 11959.0371	loss_test: 11958.9980	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7364.6895	loss_val: 7364.7202	loss_test: 7364.7109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4883.1958	loss_val: 4884.3345	loss_test: 4884.5815	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5438.1738	loss_val: 5438.9038	loss_test: 5439.9536	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12607.7188	loss_val: 12607.8037	loss_test: 12608.5020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4573.4067	loss_val: 4573.3887	loss_test: 4574.0942	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4586.4062	loss_val: 4587.3052	loss_test: 4587.7842	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4798.6504	loss_val: 4798.6572	loss_test: 4798.6665	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7413.4434	loss_val: 7414.7690	loss_test: 7414.9395	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65428.4141	loss_val: 65428.3672	loss_test: 65428.9141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6279.4072	loss_val: 6279.9092	loss_test: 6279.9502	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 99	curr_val_accuracy: 0.8299	curr_test_accuracy: 0.7537
best_round: 26	best_val_accuracy: 0.8926	best_test_accuracy: 0.7851
--------------------------------------------------
