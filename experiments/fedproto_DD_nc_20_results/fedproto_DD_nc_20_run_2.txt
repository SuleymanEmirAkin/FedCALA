GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 0.5819	loss_val: 0.6346	loss_test: 0.6198	accuracy_train: 0.6667	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 0.6702	loss_val: 0.8210	loss_test: 0.7745	accuracy_train: 0.6000	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 2]	loss_train: 0.7030	loss_val: 0.6745	loss_test: 0.7224	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 0.6790	loss_val: 0.6726	loss_test: 0.6827	accuracy_train: 0.7333	accuracy_val: 1.0000	accuracy_test: 0.5556
[client 4]	loss_train: 0.7236	loss_val: 0.7363	loss_test: 0.7287	accuracy_train: 0.3086	accuracy_val: 0.4000	accuracy_test: 0.4545
[client 5]	loss_train: 0.4818	loss_val: 0.4649	loss_test: 0.4989	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 0.5656	loss_val: 0.5527	loss_test: 0.5747	accuracy_train: 0.9512	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 0.6804	loss_val: 0.6796	loss_test: 0.6678	accuracy_train: 0.6190	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 0.5135	loss_val: 0.6222	loss_test: 0.5403	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 0.6477	loss_val: 0.6930	loss_test: 0.5729	accuracy_train: 0.6716	accuracy_val: 0.7500	accuracy_test: 0.6667
[client 10]	loss_train: 0.6065	loss_val: 0.5720	loss_test: 0.5203	accuracy_train: 0.9643	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 0.6350	loss_val: 0.6113	loss_test: 0.6770	accuracy_train: 0.7595	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 0.6209	loss_val: 0.6490	loss_test: 0.6444	accuracy_train: 0.7647	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 0.3230	loss_val: 0.3026	loss_test: 0.4061	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 0.7546	loss_val: 4.5971	loss_test: 1.0524	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 0.7475	loss_val: 0.8020	loss_test: 0.7053	accuracy_train: 0.3636	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 16]	loss_train: 0.8463	loss_val: 0.8391	loss_test: 0.8396	accuracy_train: 0.0323	accuracy_val: 0.1250	accuracy_test: 0.1250
[client 17]	loss_train: 0.7164	loss_val: 0.6521	loss_test: 0.7317	accuracy_train: 0.4074	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 18]	loss_train: 0.6240	loss_val: 0.0000	loss_test: 0.6830	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 0.7690	loss_val: 0.7108	loss_test: 0.7262	accuracy_train: 0.1939	accuracy_val: 0.1667	accuracy_test: 0.4615
curr_round: 0	curr_val_accuracy: 0.6387	curr_test_accuracy: 0.5750
best_round: 0	best_val_accuracy: 0.6387	best_test_accuracy: 0.5750
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 422.6201	loss_val: 422.6602	loss_test: 422.6489	accuracy_train: 0.8000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 490.5704	loss_val: 490.5679	loss_test: 490.8393	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 1396.6492	loss_val: 1396.6370	loss_test: 1396.6564	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 373.1441	loss_val: 373.1327	loss_test: 373.1385	accuracy_train: 0.3000	accuracy_val: 0.5714	accuracy_test: 0.2222
[client 4]	loss_train: 260.6623	loss_val: 260.6707	loss_test: 260.6689	accuracy_train: 0.3704	accuracy_val: 0.4000	accuracy_test: 0.4545
[client 5]	loss_train: 205.4397	loss_val: 205.4168	loss_test: 205.4555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 215.7633	loss_val: 215.7657	loss_test: 215.7696	accuracy_train: 0.9268	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 229.8069	loss_val: 229.7845	loss_test: 229.7935	accuracy_train: 0.6429	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 410.8905	loss_val: 410.9917	loss_test: 410.9142	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 285.9097	loss_val: 285.9586	loss_test: 285.8051	accuracy_train: 0.3284	accuracy_val: 0.1250	accuracy_test: 0.4444
[client 10]	loss_train: 346.8757	loss_val: 346.8560	loss_test: 346.7789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 233.8067	loss_val: 233.7479	loss_test: 233.8758	accuracy_train: 0.8228	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 157.3193	loss_val: 157.3402	loss_test: 157.3395	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 494.3857	loss_val: 494.3723	loss_test: 494.4701	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 185.2010	loss_val: 186.4666	loss_test: 185.2159	accuracy_train: 0.8571	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 268.9369	loss_val: 268.9480	loss_test: 268.9370	accuracy_train: 0.4091	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 263.1126	loss_val: 263.1261	loss_test: 263.1040	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 361.5903	loss_val: 361.5070	loss_test: 361.6189	accuracy_train: 0.4074	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 1957.1918	loss_val: 1956.5449	loss_test: 1957.2394	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 185.8219	loss_val: 185.8363	loss_test: 185.8434	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 1	curr_val_accuracy: 0.6485	curr_test_accuracy: 0.5879
best_round: 1	best_val_accuracy: 0.6485	best_test_accuracy: 0.5879
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 652.0606	loss_val: 652.1010	loss_test: 652.0858	accuracy_train: 0.7467	accuracy_val: 0.5000	accuracy_test: 0.8000
[client 1]	loss_train: 879.9225	loss_val: 879.8168	loss_test: 880.2810	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 1550.5665	loss_val: 1550.5457	loss_test: 1550.5706	accuracy_train: 0.3714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 620.9098	loss_val: 620.8819	loss_test: 620.8793	accuracy_train: 0.2333	accuracy_val: 0.2857	accuracy_test: 0.2222
[client 4]	loss_train: 417.0973	loss_val: 417.1033	loss_test: 417.1053	accuracy_train: 0.3704	accuracy_val: 0.4000	accuracy_test: 0.3636
[client 5]	loss_train: 321.6068	loss_val: 321.5896	loss_test: 321.6194	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 333.9334	loss_val: 333.9307	loss_test: 333.9569	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 305.2857	loss_val: 305.2773	loss_test: 305.2750	accuracy_train: 0.5714	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 743.1921	loss_val: 743.3430	loss_test: 743.2204	accuracy_train: 0.8125	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 411.1312	loss_val: 411.1812	loss_test: 411.0103	accuracy_train: 0.0597	accuracy_val: 0.0000	accuracy_test: 0.4444
[client 10]	loss_train: 498.3664	loss_val: 498.3505	loss_test: 498.2826	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 446.1581	loss_val: 446.0699	loss_test: 446.2565	accuracy_train: 0.7722	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 291.3534	loss_val: 291.3712	loss_test: 291.3540	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 830.5186	loss_val: 830.5039	loss_test: 830.6068	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 317.7232	loss_val: 317.1098	loss_test: 317.7052	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 388.0156	loss_val: 388.0316	loss_test: 388.0152	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 383.1566	loss_val: 383.1817	loss_test: 383.1452	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 616.1757	loss_val: 616.0771	loss_test: 616.1934	accuracy_train: 0.4074	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 18]	loss_train: 2927.6604	loss_val: 2926.9866	loss_test: 2927.6885	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 350.8891	loss_val: 350.8667	loss_test: 350.9171	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 2	curr_val_accuracy: 0.5972	curr_test_accuracy: 0.5545
best_round: 1	best_val_accuracy: 0.6485	best_test_accuracy: 0.5879
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 897.8328	loss_val: 897.8787	loss_test: 897.8613	accuracy_train: 0.7467	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 1436.3115	loss_val: 1436.1411	loss_test: 1436.7620	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 2068.8682	loss_val: 2068.8359	loss_test: 2068.8635	accuracy_train: 0.3714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 973.2985	loss_val: 973.2643	loss_test: 973.2387	accuracy_train: 0.2667	accuracy_val: 0.5714	accuracy_test: 0.2222
[client 4]	loss_train: 643.2841	loss_val: 643.2861	loss_test: 643.2906	accuracy_train: 0.3704	accuracy_val: 0.4000	accuracy_test: 0.3636
[client 5]	loss_train: 495.5925	loss_val: 495.5771	loss_test: 495.6047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 516.2058	loss_val: 516.1993	loss_test: 516.2437	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 475.7896	loss_val: 475.7851	loss_test: 475.7805	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 1127.9806	loss_val: 1128.1477	loss_test: 1128.0138	accuracy_train: 0.7917	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 587.7214	loss_val: 587.7561	loss_test: 587.6009	accuracy_train: 0.0299	accuracy_val: 0.0000	accuracy_test: 0.2222
[client 10]	loss_train: 718.9196	loss_val: 718.9033	loss_test: 718.8514	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 757.7113	loss_val: 757.5997	loss_test: 757.8480	accuracy_train: 0.7342	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 480.8543	loss_val: 480.8792	loss_test: 480.8391	accuracy_train: 0.5588	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 1251.7836	loss_val: 1251.7733	loss_test: 1251.8762	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 483.2290	loss_val: 482.5694	loss_test: 483.2140	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 541.9265	loss_val: 541.9502	loss_test: 541.9281	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 525.7972	loss_val: 525.8416	loss_test: 525.7877	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 968.7376	loss_val: 968.6467	loss_test: 968.7641	accuracy_train: 0.4074	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 4447.4746	loss_val: 4446.7803	loss_test: 4447.4971	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 612.2787	loss_val: 612.2408	loss_test: 612.3113	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 3	curr_val_accuracy: 0.6237	curr_test_accuracy: 0.5460
best_round: 1	best_val_accuracy: 0.6485	best_test_accuracy: 0.5879
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1162.3136	loss_val: 1162.3636	loss_test: 1162.3448	accuracy_train: 0.7200	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 2060.1646	loss_val: 2059.9658	loss_test: 2060.6624	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 2874.4846	loss_val: 2874.4465	loss_test: 2874.4775	accuracy_train: 0.3714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 1434.9923	loss_val: 1434.9591	loss_test: 1434.9230	accuracy_train: 0.3667	accuracy_val: 0.7143	accuracy_test: 0.4444
[client 4]	loss_train: 924.6002	loss_val: 924.5997	loss_test: 924.6062	accuracy_train: 0.4938	accuracy_val: 0.4000	accuracy_test: 0.3636
[client 5]	loss_train: 722.8438	loss_val: 722.8315	loss_test: 722.8575	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 751.2603	loss_val: 751.2513	loss_test: 751.3125	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 722.6088	loss_val: 722.6018	loss_test: 722.5952	accuracy_train: 0.2381	accuracy_val: 0.4000	accuracy_test: 0.4286
[client 8]	loss_train: 1547.6394	loss_val: 1547.8064	loss_test: 1547.6747	accuracy_train: 0.7917	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 788.2013	loss_val: 788.2184	loss_test: 788.0920	accuracy_train: 0.0149	accuracy_val: 0.0000	accuracy_test: 0.1111
[client 10]	loss_train: 980.5805	loss_val: 980.5585	loss_test: 980.5132	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1133.4071	loss_val: 1133.2756	loss_test: 1133.5795	accuracy_train: 0.7089	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 723.5308	loss_val: 723.5593	loss_test: 723.5184	accuracy_train: 0.6471	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 1741.2954	loss_val: 1741.2887	loss_test: 1741.3945	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 674.2830	loss_val: 673.6258	loss_test: 674.2805	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 729.1262	loss_val: 729.1462	loss_test: 729.1274	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 695.7885	loss_val: 695.8533	loss_test: 695.7889	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 1380.0024	loss_val: 1379.9200	loss_test: 1380.0121	accuracy_train: 0.3704	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 6278.3799	loss_val: 6277.6733	loss_test: 6278.4048	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 932.5831	loss_val: 932.5343	loss_test: 932.6170	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 4	curr_val_accuracy: 0.6318	curr_test_accuracy: 0.5599
best_round: 1	best_val_accuracy: 0.6485	best_test_accuracy: 0.5879
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1444.8298	loss_val: 1444.8855	loss_test: 1444.8650	accuracy_train: 0.7200	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 2749.3154	loss_val: 2749.1040	loss_test: 2749.8486	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 3956.1843	loss_val: 3956.1396	loss_test: 3956.1760	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 2032.0142	loss_val: 2031.9778	loss_test: 2031.9465	accuracy_train: 0.4500	accuracy_val: 0.7143	accuracy_test: 0.4444
[client 4]	loss_train: 1261.9656	loss_val: 1261.9619	loss_test: 1261.9744	accuracy_train: 0.7531	accuracy_val: 0.7000	accuracy_test: 0.5455
[client 5]	loss_train: 986.3548	loss_val: 986.3459	loss_test: 986.3686	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1029.6642	loss_val: 1029.6531	loss_test: 1029.7313	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1021.1908	loss_val: 1021.1880	loss_test: 1021.1747	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2023.2032	loss_val: 2023.3820	loss_test: 2023.2421	accuracy_train: 0.7917	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 1005.5524	loss_val: 1005.5520	loss_test: 1005.4534	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 10]	loss_train: 1275.1925	loss_val: 1275.1631	loss_test: 1275.1198	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1550.7700	loss_val: 1550.6212	loss_test: 1550.9725	accuracy_train: 0.6962	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 1022.1437	loss_val: 1022.1713	loss_test: 1022.1400	accuracy_train: 0.6471	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 2241.8911	loss_val: 2241.8855	loss_test: 2241.9961	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 886.6770	loss_val: 886.0207	loss_test: 886.6767	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 942.0242	loss_val: 942.0289	loss_test: 942.0305	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 898.5420	loss_val: 898.6215	loss_test: 898.5486	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 1866.7490	loss_val: 1866.6755	loss_test: 1866.7489	accuracy_train: 0.2963	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 18]	loss_train: 8343.4434	loss_val: 8342.7314	loss_test: 8343.4727	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 1297.7312	loss_val: 1297.6714	loss_test: 1297.7653	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 5	curr_val_accuracy: 0.6636	curr_test_accuracy: 0.5464
best_round: 5	best_val_accuracy: 0.6636	best_test_accuracy: 0.5464
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1765.6665	loss_val: 1765.7275	loss_test: 1765.7042	accuracy_train: 0.7333	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 3475.4084	loss_val: 3475.1946	loss_test: 3475.9539	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 5260.6836	loss_val: 5260.6250	loss_test: 5260.6733	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 2755.9287	loss_val: 2755.8875	loss_test: 2755.8667	accuracy_train: 0.5333	accuracy_val: 0.7143	accuracy_test: 0.5556
[client 4]	loss_train: 1662.1223	loss_val: 1662.1097	loss_test: 1662.1326	accuracy_train: 0.7654	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 1289.5029	loss_val: 1289.4955	loss_test: 1289.5170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1352.0917	loss_val: 1352.0781	loss_test: 1352.1704	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1362.1898	loss_val: 1362.1917	loss_test: 1362.1705	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2539.8296	loss_val: 2540.0134	loss_test: 2539.8682	accuracy_train: 0.8125	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 1239.1667	loss_val: 1239.1510	loss_test: 1239.0836	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 10]	loss_train: 1592.5463	loss_val: 1592.5166	loss_test: 1592.4772	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2000.5519	loss_val: 2000.3882	loss_test: 2000.7827	accuracy_train: 0.6962	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 1383.7732	loss_val: 1383.7949	loss_test: 1383.7836	accuracy_train: 0.7353	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 2781.0505	loss_val: 2781.0447	loss_test: 2781.1619	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1103.4110	loss_val: 1102.7544	loss_test: 1103.4161	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 1193.2114	loss_val: 1193.2024	loss_test: 1193.2274	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1134.3573	loss_val: 1134.4575	loss_test: 1134.3723	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 2389.1155	loss_val: 2389.0554	loss_test: 2389.1045	accuracy_train: 0.2963	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 10633.1514	loss_val: 10632.4375	loss_test: 10633.1846	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 1705.9801	loss_val: 1705.9088	loss_test: 1706.0139	accuracy_train: 0.8163	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 6	curr_val_accuracy: 0.6828	curr_test_accuracy: 0.5618
best_round: 6	best_val_accuracy: 0.6828	best_test_accuracy: 0.5618
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2116.6948	loss_val: 2116.7654	loss_test: 2116.7349	accuracy_train: 0.7333	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 4232.6523	loss_val: 4232.4385	loss_test: 4233.1821	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 6803.3823	loss_val: 6803.3086	loss_test: 6803.3716	accuracy_train: 0.4571	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 3601.7622	loss_val: 3601.7146	loss_test: 3601.7070	accuracy_train: 0.6167	accuracy_val: 0.7143	accuracy_test: 0.5556
[client 4]	loss_train: 2111.5728	loss_val: 2111.5488	loss_test: 2111.5833	accuracy_train: 0.7531	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 1626.5328	loss_val: 1626.5286	loss_test: 1626.5460	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1702.6207	loss_val: 1702.6046	loss_test: 1702.7135	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1747.7145	loss_val: 1747.7250	loss_test: 1747.6899	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 3109.8113	loss_val: 3109.9958	loss_test: 3109.8538	accuracy_train: 0.8125	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 1498.6152	loss_val: 1498.5876	loss_test: 1498.5463	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 10]	loss_train: 1928.5830	loss_val: 1928.5537	loss_test: 1928.5216	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2480.8547	loss_val: 2480.6755	loss_test: 2481.1140	accuracy_train: 0.6962	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 1797.1541	loss_val: 1797.1735	loss_test: 1797.1821	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 3345.1658	loss_val: 3345.1589	loss_test: 3345.2861	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1342.7529	loss_val: 1342.1024	loss_test: 1342.7548	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 1451.1195	loss_val: 1451.1001	loss_test: 1451.1415	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1396.8987	loss_val: 1397.0161	loss_test: 1396.9209	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 2942.3989	loss_val: 2942.3496	loss_test: 2942.3794	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 13016.0479	loss_val: 13015.3340	loss_test: 13016.0850	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 2151.1560	loss_val: 2151.0740	loss_test: 2151.1899	accuracy_train: 0.8163	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 7	curr_val_accuracy: 0.6915	curr_test_accuracy: 0.5695
best_round: 7	best_val_accuracy: 0.6915	best_test_accuracy: 0.5695
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2502.2371	loss_val: 2502.3164	loss_test: 2502.2776	accuracy_train: 0.7467	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 5026.5493	loss_val: 5026.3335	loss_test: 5027.0649	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 8591.7754	loss_val: 8591.6885	loss_test: 8591.7617	accuracy_train: 0.4571	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 4631.1738	loss_val: 4631.1211	loss_test: 4631.1274	accuracy_train: 0.6333	accuracy_val: 0.7143	accuracy_test: 0.5556
[client 4]	loss_train: 2614.0898	loss_val: 2614.0559	loss_test: 2614.1011	accuracy_train: 0.7778	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 1994.0618	loss_val: 1994.0596	loss_test: 1994.0730	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2085.2310	loss_val: 2085.2126	loss_test: 2085.3335	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2183.1538	loss_val: 2183.1680	loss_test: 2183.1296	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 3707.3059	loss_val: 3707.4856	loss_test: 3707.3555	accuracy_train: 0.7917	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 1764.1112	loss_val: 1764.0746	loss_test: 1764.0511	accuracy_train: 0.0299	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 10]	loss_train: 2283.9802	loss_val: 2283.9509	loss_test: 2283.9258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2999.9529	loss_val: 2999.7598	loss_test: 3000.2390	accuracy_train: 0.6962	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 2243.2556	loss_val: 2243.2742	loss_test: 2243.3000	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 4002.6309	loss_val: 4002.6230	loss_test: 4002.7585	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1590.7130	loss_val: 1590.0706	loss_test: 1590.7102	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 1733.4656	loss_val: 1733.4352	loss_test: 1733.4930	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1686.2745	loss_val: 1686.3954	loss_test: 1686.3013	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 3551.2065	loss_val: 3551.1775	loss_test: 3551.1785	accuracy_train: 0.2963	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 15479.8027	loss_val: 15479.0898	loss_test: 15479.8438	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 2610.2212	loss_val: 2610.1311	loss_test: 2610.2568	accuracy_train: 0.8163	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 8	curr_val_accuracy: 0.6995	curr_test_accuracy: 0.5769
best_round: 8	best_val_accuracy: 0.6995	best_test_accuracy: 0.5769
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2926.7092	loss_val: 2926.7981	loss_test: 2926.7502	accuracy_train: 0.7600	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 5820.7095	loss_val: 5820.4849	loss_test: 5821.2314	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 10576.8379	loss_val: 10576.7383	loss_test: 10576.8242	accuracy_train: 0.4857	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 5739.2100	loss_val: 5739.1572	loss_test: 5739.1753	accuracy_train: 0.6500	accuracy_val: 0.7143	accuracy_test: 0.6667
[client 4]	loss_train: 3163.0364	loss_val: 3162.9951	loss_test: 3163.0483	accuracy_train: 0.7901	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 2379.2100	loss_val: 2379.2085	loss_test: 2379.2190	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2490.9944	loss_val: 2490.9731	loss_test: 2491.1094	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2656.9436	loss_val: 2656.9602	loss_test: 2656.9175	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 4329.7051	loss_val: 4329.8706	loss_test: 4329.7617	accuracy_train: 0.8125	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 2051.7131	loss_val: 2051.6694	loss_test: 2051.6636	accuracy_train: 0.0746	accuracy_val: 0.1250	accuracy_test: 0.2222
[client 10]	loss_train: 2654.1750	loss_val: 2654.1470	loss_test: 2654.1245	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3543.9146	loss_val: 3543.7070	loss_test: 3544.2258	accuracy_train: 0.6962	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 2731.4897	loss_val: 2731.5063	loss_test: 2731.5459	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 4706.0410	loss_val: 4706.0332	loss_test: 4706.1768	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1843.1591	loss_val: 1842.5261	loss_test: 1843.1403	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 2030.7590	loss_val: 2030.7222	loss_test: 2030.7917	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1984.8274	loss_val: 1984.9434	loss_test: 1984.8544	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 4204.5327	loss_val: 4204.5298	loss_test: 4204.4976	accuracy_train: 0.2963	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 18066.5273	loss_val: 18065.8164	loss_test: 18066.5742	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 3079.8538	loss_val: 3079.7554	loss_test: 3079.8914	accuracy_train: 0.8163	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 9	curr_val_accuracy: 0.7084	curr_test_accuracy: 0.6073
best_round: 9	best_val_accuracy: 0.7084	best_test_accuracy: 0.6073
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3391.2424	loss_val: 3391.3413	loss_test: 3391.2849	accuracy_train: 0.7733	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 6626.8018	loss_val: 6626.5747	loss_test: 6627.3477	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 12867.3555	loss_val: 12867.2422	loss_test: 12867.3408	accuracy_train: 0.4857	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 6983.4116	loss_val: 6983.3569	loss_test: 6983.3867	accuracy_train: 0.7000	accuracy_val: 0.7143	accuracy_test: 0.7778
[client 4]	loss_train: 3746.9031	loss_val: 3746.8562	loss_test: 3746.9150	accuracy_train: 0.8025	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 2776.8027	loss_val: 2776.8015	loss_test: 2776.8081	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2923.5947	loss_val: 2923.5708	loss_test: 2923.7258	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3179.5068	loss_val: 3179.5261	loss_test: 3179.4780	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 4984.2295	loss_val: 4984.3872	loss_test: 4984.2910	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 2360.8669	loss_val: 2360.8186	loss_test: 2360.8159	accuracy_train: 0.1194	accuracy_val: 0.1250	accuracy_test: 0.2222
[client 10]	loss_train: 3042.3687	loss_val: 3042.3423	loss_test: 3042.3228	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4121.2603	loss_val: 4121.0381	loss_test: 4121.5981	accuracy_train: 0.6835	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 3252.5781	loss_val: 3252.5916	loss_test: 3252.6475	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 5462.3804	loss_val: 5462.3701	loss_test: 5462.5244	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2115.8896	loss_val: 2115.2666	loss_test: 2115.8652	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 2323.6797	loss_val: 2323.6326	loss_test: 2323.7190	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2298.9753	loss_val: 2299.0828	loss_test: 2298.9993	accuracy_train: 0.0484	accuracy_val: 0.2500	accuracy_test: 0.0000
[client 17]	loss_train: 4902.9180	loss_val: 4902.9258	loss_test: 4902.8735	accuracy_train: 0.2593	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 18]	loss_train: 20804.6016	loss_val: 20803.8926	loss_test: 20804.6504	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 3568.3984	loss_val: 3568.2900	loss_test: 3568.4382	accuracy_train: 0.8163	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 10	curr_val_accuracy: 0.7107	curr_test_accuracy: 0.6145
best_round: 10	best_val_accuracy: 0.7107	best_test_accuracy: 0.6145
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3877.2815	loss_val: 3877.3918	loss_test: 3877.3264	accuracy_train: 0.7733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 7453.2119	loss_val: 7452.9746	loss_test: 7453.7832	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 15251.1104	loss_val: 15250.9844	loss_test: 15251.0967	accuracy_train: 0.4857	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 8300.8867	loss_val: 8300.8301	loss_test: 8300.8721	accuracy_train: 0.7000	accuracy_val: 0.7143	accuracy_test: 0.7778
[client 4]	loss_train: 4346.1973	loss_val: 4346.1465	loss_test: 4346.2090	accuracy_train: 0.8025	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 3189.0527	loss_val: 3189.0518	loss_test: 3189.0535	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3358.6348	loss_val: 3358.6099	loss_test: 3358.7793	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3740.8918	loss_val: 3740.9177	loss_test: 3740.8596	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 5640.5747	loss_val: 5640.7266	loss_test: 5640.6406	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 2669.0903	loss_val: 2669.0400	loss_test: 2669.0352	accuracy_train: 0.1642	accuracy_val: 0.1250	accuracy_test: 0.2222
[client 10]	loss_train: 3447.6497	loss_val: 3447.6265	loss_test: 3447.6094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4704.7446	loss_val: 4704.5068	loss_test: 4705.1108	accuracy_train: 0.6709	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 3800.0388	loss_val: 3800.0466	loss_test: 3800.1272	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 6270.8584	loss_val: 6270.8472	loss_test: 6271.0107	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2379.8887	loss_val: 2379.2783	loss_test: 2379.8547	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 2623.2590	loss_val: 2623.2017	loss_test: 2623.3042	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2612.3774	loss_val: 2612.4822	loss_test: 2612.4023	accuracy_train: 0.1613	accuracy_val: 0.3750	accuracy_test: 0.2500
[client 17]	loss_train: 5636.2837	loss_val: 5636.2959	loss_test: 5636.2358	accuracy_train: 0.2593	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 18]	loss_train: 23535.3867	loss_val: 23534.6816	loss_test: 23535.4434	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 4058.4246	loss_val: 4058.3064	loss_test: 4058.4670	accuracy_train: 0.8163	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 11	curr_val_accuracy: 0.7103	curr_test_accuracy: 0.6470
best_round: 10	best_val_accuracy: 0.7107	best_test_accuracy: 0.6145
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 4414.3433	loss_val: 4414.4668	loss_test: 4414.3931	accuracy_train: 0.8133	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 8278.0996	loss_val: 8277.8604	loss_test: 8278.7012	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 17849.7793	loss_val: 17849.6406	loss_test: 17849.7656	accuracy_train: 0.4857	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 9637.9434	loss_val: 9637.8838	loss_test: 9637.9395	accuracy_train: 0.7333	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 4962.3013	loss_val: 4962.2480	loss_test: 4962.3130	accuracy_train: 0.8148	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 3582.5442	loss_val: 3582.5439	loss_test: 3582.5398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3814.3767	loss_val: 3814.3511	loss_test: 3814.5334	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4329.6235	loss_val: 4329.6582	loss_test: 4329.5874	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 6315.4829	loss_val: 6315.6299	loss_test: 6315.5513	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 2972.1687	loss_val: 2972.1182	loss_test: 2972.1077	accuracy_train: 0.1791	accuracy_val: 0.2500	accuracy_test: 0.2222
[client 10]	loss_train: 3854.6685	loss_val: 3854.6489	loss_test: 3854.6318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5331.1060	loss_val: 5330.8550	loss_test: 5331.5039	accuracy_train: 0.6582	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 4328.9561	loss_val: 4328.9575	loss_test: 4329.0640	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 7091.8921	loss_val: 7091.8813	loss_test: 7092.0522	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2656.1248	loss_val: 2655.5261	loss_test: 2656.0859	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 2929.1211	loss_val: 2929.0532	loss_test: 2929.1699	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2924.6450	loss_val: 2924.7441	loss_test: 2924.6714	accuracy_train: 0.2581	accuracy_val: 0.3750	accuracy_test: 0.3750
[client 17]	loss_train: 6386.8301	loss_val: 6386.8496	loss_test: 6386.7808	accuracy_train: 0.2593	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 18]	loss_train: 26288.5938	loss_val: 26287.9023	loss_test: 26288.6602	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 4552.8403	loss_val: 4552.7129	loss_test: 4552.8857	accuracy_train: 0.8265	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 12	curr_val_accuracy: 0.7285	curr_test_accuracy: 0.6624
best_round: 12	best_val_accuracy: 0.7285	best_test_accuracy: 0.6624
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 4957.3999	loss_val: 4957.5361	loss_test: 4957.4546	accuracy_train: 0.8133	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 9126.2764	loss_val: 9126.0264	loss_test: 9126.9082	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 20552.1113	loss_val: 20551.9629	loss_test: 20552.0996	accuracy_train: 0.4857	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 11067.6934	loss_val: 11067.6338	loss_test: 11067.7002	accuracy_train: 0.7500	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 5598.6616	loss_val: 5598.6099	loss_test: 5598.6748	accuracy_train: 0.8272	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 3973.5425	loss_val: 3973.5435	loss_test: 3973.5339	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4292.0869	loss_val: 4292.0601	loss_test: 4292.2573	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4945.6968	loss_val: 4945.7402	loss_test: 4945.6558	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 6963.7593	loss_val: 6963.8926	loss_test: 6963.8306	accuracy_train: 0.7708	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3280.2322	loss_val: 3280.1838	loss_test: 3280.1594	accuracy_train: 0.2090	accuracy_val: 0.2500	accuracy_test: 0.3333
[client 10]	loss_train: 4287.1655	loss_val: 4287.1489	loss_test: 4287.1313	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5944.2954	loss_val: 5944.0298	loss_test: 5944.7275	accuracy_train: 0.6709	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 4877.7290	loss_val: 4877.7231	loss_test: 4877.8623	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 7958.8877	loss_val: 7958.8730	loss_test: 7959.0566	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2936.5432	loss_val: 2935.9548	loss_test: 2936.5059	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3220.2913	loss_val: 3220.2144	loss_test: 3220.3433	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3225.2996	loss_val: 3225.3926	loss_test: 3225.3247	accuracy_train: 0.4839	accuracy_val: 0.5000	accuracy_test: 0.6250
[client 17]	loss_train: 7102.7974	loss_val: 7102.8169	loss_test: 7102.7524	accuracy_train: 0.2593	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 18]	loss_train: 29067.9512	loss_val: 29067.2734	loss_test: 29068.0273	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 5022.6108	loss_val: 5022.4771	loss_test: 5022.6606	accuracy_train: 0.8265	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 13	curr_val_accuracy: 0.7281	curr_test_accuracy: 0.6746
best_round: 12	best_val_accuracy: 0.7285	best_test_accuracy: 0.6624
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5510.6943	loss_val: 5510.8447	loss_test: 5510.7554	accuracy_train: 0.8267	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 9983.6650	loss_val: 9983.3955	loss_test: 9984.3330	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 23378.9453	loss_val: 23378.7891	loss_test: 23378.9375	accuracy_train: 0.4571	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 12462.9121	loss_val: 12462.8535	loss_test: 12462.9307	accuracy_train: 0.8667	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 6258.1831	loss_val: 6258.1348	loss_test: 6258.2002	accuracy_train: 0.8395	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 4347.6392	loss_val: 4347.6411	loss_test: 4347.6265	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4758.8159	loss_val: 4758.7881	loss_test: 4758.9985	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5554.4800	loss_val: 5554.5327	loss_test: 5554.4316	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 7583.9736	loss_val: 7584.0986	loss_test: 7584.0508	accuracy_train: 0.7708	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3580.2236	loss_val: 3580.1770	loss_test: 3580.1379	accuracy_train: 0.2687	accuracy_val: 0.3750	accuracy_test: 0.5556
[client 10]	loss_train: 4729.0029	loss_val: 4728.9888	loss_test: 4728.9712	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6574.9541	loss_val: 6574.6729	loss_test: 6575.4233	accuracy_train: 0.6456	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 5448.4814	loss_val: 5448.4697	loss_test: 5448.6436	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 8863.3691	loss_val: 8863.3516	loss_test: 8863.5439	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3208.0708	loss_val: 3207.4961	loss_test: 3208.0369	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3491.6235	loss_val: 3491.5366	loss_test: 3491.6794	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3508.9006	loss_val: 3508.9856	loss_test: 3508.9238	accuracy_train: 0.5645	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 7816.1787	loss_val: 7816.1997	loss_test: 7816.1382	accuracy_train: 0.2593	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 18]	loss_train: 31761.8848	loss_val: 31761.2168	loss_test: 31761.9668	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 5481.7739	loss_val: 5481.6338	loss_test: 5481.8267	accuracy_train: 0.8265	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 14	curr_val_accuracy: 0.7453	curr_test_accuracy: 0.6904
best_round: 14	best_val_accuracy: 0.7453	best_test_accuracy: 0.6904
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6066.6572	loss_val: 6066.8193	loss_test: 6066.7256	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 10796.6064	loss_val: 10796.3340	loss_test: 10797.2764	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 26288.9570	loss_val: 26288.7930	loss_test: 26288.9531	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 13826.4922	loss_val: 13826.4326	loss_test: 13826.5225	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6864.2290	loss_val: 6864.1841	loss_test: 6864.2485	accuracy_train: 0.8395	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 4707.0103	loss_val: 4707.0137	loss_test: 4706.9946	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5211.4751	loss_val: 5211.4458	loss_test: 5211.6680	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6161.3506	loss_val: 6161.4102	loss_test: 6161.2935	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 8160.0239	loss_val: 8160.1411	loss_test: 8160.1045	accuracy_train: 0.7708	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3867.3286	loss_val: 3867.2830	loss_test: 3867.2336	accuracy_train: 0.3881	accuracy_val: 0.5000	accuracy_test: 0.5556
[client 10]	loss_train: 5177.7944	loss_val: 5177.7812	loss_test: 5177.7642	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7161.8760	loss_val: 7161.5835	loss_test: 7162.3784	accuracy_train: 0.6582	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 5994.4912	loss_val: 5994.4761	loss_test: 5994.6841	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 9745.2197	loss_val: 9745.1992	loss_test: 9745.4004	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3476.4922	loss_val: 3475.9272	loss_test: 3476.4612	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3746.6860	loss_val: 3746.5933	loss_test: 3746.7461	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3762.7795	loss_val: 3762.8525	loss_test: 3762.7974	accuracy_train: 0.6613	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 8469.8828	loss_val: 8469.8984	loss_test: 8469.8486	accuracy_train: 0.2593	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 18]	loss_train: 34486.6016	loss_val: 34485.9492	loss_test: 34486.6953	accuracy_train: 0.4000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 5891.0298	loss_val: 5890.8853	loss_test: 5891.0864	accuracy_train: 0.8265	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 15	curr_val_accuracy: 0.7634	curr_test_accuracy: 0.6910
best_round: 15	best_val_accuracy: 0.7634	best_test_accuracy: 0.6910
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6613.9419	loss_val: 6614.1177	loss_test: 6614.0190	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11591.5088	loss_val: 11591.2236	loss_test: 11592.2021	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 29002.3027	loss_val: 29002.1348	loss_test: 29002.3047	accuracy_train: 0.4571	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 15183.6143	loss_val: 15183.5547	loss_test: 15183.6572	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7419.9014	loss_val: 7419.8638	loss_test: 7419.9233	accuracy_train: 0.8395	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 5027.4414	loss_val: 5027.4473	loss_test: 5027.4229	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5637.7329	loss_val: 5637.7026	loss_test: 5637.9360	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6772.6255	loss_val: 6772.6909	loss_test: 6772.5571	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 8669.6553	loss_val: 8669.7676	loss_test: 8669.7383	accuracy_train: 0.7708	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4131.2627	loss_val: 4131.2188	loss_test: 4131.1587	accuracy_train: 0.4925	accuracy_val: 0.6250	accuracy_test: 0.6667
[client 10]	loss_train: 5623.8438	loss_val: 5623.8320	loss_test: 5623.8154	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7713.5410	loss_val: 7713.2388	loss_test: 7714.0796	accuracy_train: 0.6582	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 6509.9824	loss_val: 6509.9639	loss_test: 6510.2158	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10611.6338	loss_val: 10611.6104	loss_test: 10611.8203	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3737.9041	loss_val: 3737.3477	loss_test: 3737.8818	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4003.1907	loss_val: 4003.0906	loss_test: 4003.2576	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3985.4946	loss_val: 3985.5583	loss_test: 3985.5081	accuracy_train: 0.8065	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 9087.6338	loss_val: 9087.6523	loss_test: 9087.6123	accuracy_train: 0.2593	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 18]	loss_train: 37170.6992	loss_val: 37170.0625	loss_test: 37170.8008	accuracy_train: 0.4000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 6269.7896	loss_val: 6269.6396	loss_test: 6269.8496	accuracy_train: 0.8163	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 16	curr_val_accuracy: 0.7723	curr_test_accuracy: 0.7072
best_round: 16	best_val_accuracy: 0.7723	best_test_accuracy: 0.7072
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7125.3306	loss_val: 7125.5225	loss_test: 7125.4189	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 12347.5566	loss_val: 12347.2754	loss_test: 12348.2490	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 31632.7109	loss_val: 31632.5410	loss_test: 31632.7227	accuracy_train: 0.4571	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 16442.3652	loss_val: 16442.3086	loss_test: 16442.4199	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7943.1382	loss_val: 7943.1089	loss_test: 7943.1621	accuracy_train: 0.8395	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 5308.2393	loss_val: 5308.2471	loss_test: 5308.2183	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6026.9380	loss_val: 6026.9058	loss_test: 6027.1504	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7361.4390	loss_val: 7361.5112	loss_test: 7361.3555	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9193.0400	loss_val: 9193.1406	loss_test: 9193.1240	accuracy_train: 0.7500	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4381.4556	loss_val: 4381.4146	loss_test: 4381.3447	accuracy_train: 0.6567	accuracy_val: 0.7500	accuracy_test: 0.8889
[client 10]	loss_train: 6061.2920	loss_val: 6061.2817	loss_test: 6061.2661	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 8250.8779	loss_val: 8250.5674	loss_test: 8251.4531	accuracy_train: 0.6456	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 6964.7764	loss_val: 6964.7578	loss_test: 6965.0518	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11419.5752	loss_val: 11419.5479	loss_test: 11419.7695	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3970.2373	loss_val: 3969.6963	loss_test: 3970.2256	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4232.8403	loss_val: 4232.7329	loss_test: 4232.9165	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4186.7090	loss_val: 4186.7642	loss_test: 4186.7173	accuracy_train: 0.8387	accuracy_val: 0.6250	accuracy_test: 0.8750
[client 17]	loss_train: 9639.1426	loss_val: 9639.1572	loss_test: 9639.1357	accuracy_train: 0.2963	accuracy_val: 0.2500	accuracy_test: 0.5000
[client 18]	loss_train: 39503.1055	loss_val: 39502.4805	loss_test: 39503.2148	accuracy_train: 0.4000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 6615.9165	loss_val: 6615.7632	loss_test: 6615.9805	accuracy_train: 0.8163	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 17	curr_val_accuracy: 0.7802	curr_test_accuracy: 0.7231
best_round: 17	best_val_accuracy: 0.7802	best_test_accuracy: 0.7231
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7628.9453	loss_val: 7629.1562	loss_test: 7629.0459	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13029.6904	loss_val: 13029.4180	loss_test: 13030.3701	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 34137.9375	loss_val: 34137.7695	loss_test: 34137.9609	accuracy_train: 0.4571	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 17655.5957	loss_val: 17655.5371	loss_test: 17655.6582	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8382.9805	loss_val: 8382.9600	loss_test: 8383.0068	accuracy_train: 0.8395	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 5527.8872	loss_val: 5527.8975	loss_test: 5527.8657	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6385.3047	loss_val: 6385.2715	loss_test: 6385.5254	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7919.4189	loss_val: 7919.4893	loss_test: 7919.3184	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9653.1484	loss_val: 9653.2441	loss_test: 9653.2334	accuracy_train: 0.7500	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4602.2236	loss_val: 4602.1860	loss_test: 4602.1079	accuracy_train: 0.7164	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 10]	loss_train: 6480.2178	loss_val: 6480.2100	loss_test: 6480.1943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 8713.3203	loss_val: 8713.0059	loss_test: 8713.9307	accuracy_train: 0.6456	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 7387.1558	loss_val: 7387.1338	loss_test: 7387.4819	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12231.3916	loss_val: 12231.3594	loss_test: 12231.5938	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4198.7681	loss_val: 4198.2402	loss_test: 4198.7676	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4440.8403	loss_val: 4440.7222	loss_test: 4440.9307	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4363.7373	loss_val: 4363.7842	loss_test: 4363.7402	accuracy_train: 0.8548	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10090.3398	loss_val: 10090.3516	loss_test: 10090.3486	accuracy_train: 0.3333	accuracy_val: 0.2500	accuracy_test: 0.5000
[client 18]	loss_train: 41591.6133	loss_val: 41591.0039	loss_test: 41591.7305	accuracy_train: 0.5000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 6928.7412	loss_val: 6928.5845	loss_test: 6928.8086	accuracy_train: 0.8163	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 18	curr_val_accuracy: 0.8064	curr_test_accuracy: 0.7231
best_round: 18	best_val_accuracy: 0.8064	best_test_accuracy: 0.7231
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8051.9106	loss_val: 8052.1460	loss_test: 8052.0259	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13599.9854	loss_val: 13599.7266	loss_test: 13600.6738	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 36406.2695	loss_val: 36406.1055	loss_test: 36406.3008	accuracy_train: 0.4857	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 18782.4902	loss_val: 18782.4336	loss_test: 18782.5605	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8748.8760	loss_val: 8748.8672	loss_test: 8748.9053	accuracy_train: 0.8395	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 5703.1230	loss_val: 5703.1362	loss_test: 5703.1011	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6696.3945	loss_val: 6696.3608	loss_test: 6696.6230	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8423.5234	loss_val: 8423.5879	loss_test: 8423.4043	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10037.3604	loss_val: 10037.4512	loss_test: 10037.4492	accuracy_train: 0.7292	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 4806.0098	loss_val: 4805.9771	loss_test: 4805.8921	accuracy_train: 0.8358	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6861.8877	loss_val: 6861.8818	loss_test: 6861.8662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 9110.9258	loss_val: 9110.6084	loss_test: 9111.5723	accuracy_train: 0.6456	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 7733.6851	loss_val: 7733.6611	loss_test: 7734.0566	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12991.8652	loss_val: 12991.8301	loss_test: 12992.0742	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4410.6655	loss_val: 4410.1465	loss_test: 4410.6772	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4628.4053	loss_val: 4628.2734	loss_test: 4628.5122	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4512.8877	loss_val: 4512.9277	loss_test: 4512.8853	accuracy_train: 0.9032	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10506.8584	loss_val: 10506.8613	loss_test: 10506.8857	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 43513.1328	loss_val: 43512.5391	loss_test: 43513.2539	accuracy_train: 0.5000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 7205.8950	loss_val: 7205.7378	loss_test: 7205.9668	accuracy_train: 0.8265	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 19	curr_val_accuracy: 0.8051	curr_test_accuracy: 0.7236
best_round: 18	best_val_accuracy: 0.8064	best_test_accuracy: 0.7231
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8394.1455	loss_val: 8394.4062	loss_test: 8394.2754	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14093.0332	loss_val: 14092.7969	loss_test: 14093.7285	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 38443.5078	loss_val: 38443.3477	loss_test: 38443.5508	accuracy_train: 0.5143	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 19835.2617	loss_val: 19835.2070	loss_test: 19835.3398	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9042.9648	loss_val: 9042.9727	loss_test: 9042.9990	accuracy_train: 0.8519	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 5843.1226	loss_val: 5843.1387	loss_test: 5843.1006	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6936.4927	loss_val: 6936.4590	loss_test: 6936.7271	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8878.4307	loss_val: 8878.4854	loss_test: 8878.2949	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10367.6416	loss_val: 10367.7334	loss_test: 10367.7363	accuracy_train: 0.7292	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 4988.3589	loss_val: 4988.3306	loss_test: 4988.2412	accuracy_train: 0.9701	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7221.3862	loss_val: 7221.3818	loss_test: 7221.3657	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 9435.9521	loss_val: 9435.6348	loss_test: 9436.6348	accuracy_train: 0.6582	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 8046.7764	loss_val: 8046.7480	loss_test: 8047.2085	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 13635.1934	loss_val: 13635.1543	loss_test: 13635.4092	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4604.5889	loss_val: 4604.0840	loss_test: 4604.6216	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4785.2935	loss_val: 4785.1509	loss_test: 4785.4233	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4633.1338	loss_val: 4633.1660	loss_test: 4633.1260	accuracy_train: 0.9516	accuracy_val: 0.7500	accuracy_test: 0.8750
[client 17]	loss_train: 10783.6016	loss_val: 10783.6035	loss_test: 10783.6494	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 44919.8867	loss_val: 44919.3047	loss_test: 44920.0117	accuracy_train: 0.6000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 7433.4580	loss_val: 7433.3013	loss_test: 7433.5361	accuracy_train: 0.8265	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 20	curr_val_accuracy: 0.8051	curr_test_accuracy: 0.7157
best_round: 18	best_val_accuracy: 0.8064	best_test_accuracy: 0.7231
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8748.9648	loss_val: 8749.2578	loss_test: 8749.1162	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14483.6855	loss_val: 14483.4824	loss_test: 14484.3721	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 40370.6875	loss_val: 40370.5352	loss_test: 40370.7422	accuracy_train: 0.5429	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 20685.7891	loss_val: 20685.7344	loss_test: 20685.8730	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9258.9229	loss_val: 9258.9453	loss_test: 9258.9590	accuracy_train: 0.8519	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 5958.6973	loss_val: 5958.7153	loss_test: 5958.6748	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7125.1387	loss_val: 7125.1060	loss_test: 7125.3789	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9285.5938	loss_val: 9285.6357	loss_test: 9285.4307	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10640.9756	loss_val: 10641.0703	loss_test: 10641.0781	accuracy_train: 0.7083	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 5146.5122	loss_val: 5146.4893	loss_test: 5146.3945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7555.1567	loss_val: 7555.1543	loss_test: 7555.1382	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 9696.7969	loss_val: 9696.4814	loss_test: 9697.5176	accuracy_train: 0.6709	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 8288.0869	loss_val: 8288.0576	loss_test: 8288.5918	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 14205.0420	loss_val: 14205.0000	loss_test: 14205.2637	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4750.7554	loss_val: 4750.2622	loss_test: 4750.8149	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4934.3701	loss_val: 4934.2212	loss_test: 4934.5205	accuracy_train: 0.6364	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4724.6196	loss_val: 4724.6440	loss_test: 4724.6064	accuracy_train: 0.9839	accuracy_val: 1.0000	accuracy_test: 0.8750
[client 17]	loss_train: 10990.2100	loss_val: 10990.2061	loss_test: 10990.2812	accuracy_train: 0.3704	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 46335.7070	loss_val: 46335.1406	loss_test: 46335.8320	accuracy_train: 0.7000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7592.4487	loss_val: 7592.2944	loss_test: 7592.5342	accuracy_train: 0.8265	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 21	curr_val_accuracy: 0.8252	curr_test_accuracy: 0.7123
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9015.5166	loss_val: 9015.8428	loss_test: 9015.6875	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14802.2930	loss_val: 14802.1250	loss_test: 14802.9629	accuracy_train: 0.4000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 42126.3711	loss_val: 42126.2305	loss_test: 42126.4414	accuracy_train: 0.5429	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 21373.0547	loss_val: 21373.0039	loss_test: 21373.1465	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9394.3027	loss_val: 9394.3418	loss_test: 9394.3408	accuracy_train: 0.8519	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 6007.3633	loss_val: 6007.3838	loss_test: 6007.3413	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7273.1445	loss_val: 7273.1123	loss_test: 7273.3887	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9612.4531	loss_val: 9612.4717	loss_test: 9612.2646	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10813.9209	loss_val: 10814.0234	loss_test: 10814.0342	accuracy_train: 0.7292	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 5293.0034	loss_val: 5292.9844	loss_test: 5292.8853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7832.2310	loss_val: 7832.2305	loss_test: 7832.2134	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 9883.7402	loss_val: 9883.4307	loss_test: 9884.5039	accuracy_train: 0.6709	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 12]	loss_train: 8473.9033	loss_val: 8473.8730	loss_test: 8474.4854	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 14643.2158	loss_val: 14643.1719	loss_test: 14643.4434	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4893.7734	loss_val: 4893.2949	loss_test: 4893.8594	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5026.7964	loss_val: 5026.6445	loss_test: 5026.9688	accuracy_train: 0.6364	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4795.9668	loss_val: 4795.9844	loss_test: 4795.9482	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 11086.5625	loss_val: 11086.5488	loss_test: 11086.6641	accuracy_train: 0.4444	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 47657.1094	loss_val: 47656.5547	loss_test: 47657.2344	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7675.3936	loss_val: 7675.2432	loss_test: 7675.4878	accuracy_train: 0.8367	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 22	curr_val_accuracy: 0.8081	curr_test_accuracy: 0.7280
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9166.7637	loss_val: 9167.1250	loss_test: 9166.9561	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14946.5664	loss_val: 14946.4395	loss_test: 14947.2119	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 43616.9688	loss_val: 43616.8359	loss_test: 43617.0547	accuracy_train: 0.5714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 22055.7910	loss_val: 22055.7422	loss_test: 22055.8867	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9492.8145	loss_val: 9492.8691	loss_test: 9492.8555	accuracy_train: 0.8519	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 6056.4106	loss_val: 6056.4341	loss_test: 6056.3906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7365.5215	loss_val: 7365.4907	loss_test: 7365.7686	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9850.2969	loss_val: 9850.2871	loss_test: 9850.0859	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10910.0703	loss_val: 10910.1816	loss_test: 10910.1943	accuracy_train: 0.7083	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 5418.3950	loss_val: 5418.3794	loss_test: 5418.2778	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8079.3955	loss_val: 8079.3970	loss_test: 8079.3794	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 10017.3594	loss_val: 10017.0566	loss_test: 10018.1738	accuracy_train: 0.6709	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 8593.3408	loss_val: 8593.3125	loss_test: 8594.0059	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 14994.1504	loss_val: 14994.1035	loss_test: 14994.3828	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5004.0322	loss_val: 5003.5703	loss_test: 5004.1470	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5116.9849	loss_val: 5116.8330	loss_test: 5117.1846	accuracy_train: 0.6364	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4840.6978	loss_val: 4840.7070	loss_test: 4840.6743	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 11088.4775	loss_val: 11088.4541	loss_test: 11088.6104	accuracy_train: 0.5185	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 48524.8594	loss_val: 48524.3242	loss_test: 48524.9883	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7727.7812	loss_val: 7727.6343	loss_test: 7727.8843	accuracy_train: 0.8367	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 23	curr_val_accuracy: 0.8079	curr_test_accuracy: 0.7280
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9178.6826	loss_val: 9179.0723	loss_test: 9178.8916	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15101.8779	loss_val: 15101.7881	loss_test: 15102.5117	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 44864.3281	loss_val: 44864.2031	loss_test: 44864.4297	accuracy_train: 0.5429	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 22556.7129	loss_val: 22556.6660	loss_test: 22556.8145	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9526.0293	loss_val: 9526.1006	loss_test: 9526.0693	accuracy_train: 0.8519	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 6049.2549	loss_val: 6049.2808	loss_test: 6049.2363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7409.6245	loss_val: 7409.5962	loss_test: 7409.8726	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10011.2930	loss_val: 10011.2578	loss_test: 10011.0576	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10880.9854	loss_val: 10881.1240	loss_test: 10881.1211	accuracy_train: 0.7500	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 5538.7217	loss_val: 5538.7070	loss_test: 5538.6055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8272.3545	loss_val: 8272.3584	loss_test: 8272.3398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 10052.9893	loss_val: 10052.6992	loss_test: 10053.8516	accuracy_train: 0.6835	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 8648.4639	loss_val: 8648.4434	loss_test: 8649.2100	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 15232.9248	loss_val: 15232.8760	loss_test: 15233.1631	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5105.2588	loss_val: 5104.8154	loss_test: 5105.4087	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5159.8457	loss_val: 5159.6968	loss_test: 5160.0771	accuracy_train: 0.6818	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4855.6157	loss_val: 4855.6182	loss_test: 4855.5874	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 11003.8916	loss_val: 11003.8701	loss_test: 11004.0566	accuracy_train: 0.5556	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 49124.6016	loss_val: 49124.0820	loss_test: 49124.7344	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7757.1514	loss_val: 7757.0068	loss_test: 7757.2632	accuracy_train: 0.8469	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 24	curr_val_accuracy: 0.8079	curr_test_accuracy: 0.7354
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9086.9258	loss_val: 9087.3398	loss_test: 9087.1436	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15194.4199	loss_val: 15194.3633	loss_test: 15195.0479	accuracy_train: 0.6667	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 45901.7266	loss_val: 45901.6094	loss_test: 45901.8398	accuracy_train: 0.6000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 23095.5195	loss_val: 23095.4746	loss_test: 23095.6250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9488.7217	loss_val: 9488.8115	loss_test: 9488.7607	accuracy_train: 0.8519	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 6018.7681	loss_val: 6018.7969	loss_test: 6018.7524	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7430.9795	loss_val: 7430.9526	loss_test: 7431.2285	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10114.0137	loss_val: 10113.9590	loss_test: 10113.7539	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10853.3662	loss_val: 10853.5342	loss_test: 10853.5137	accuracy_train: 0.7708	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 5641.8965	loss_val: 5641.8833	loss_test: 5641.7822	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8446.9375	loss_val: 8446.9414	loss_test: 8446.9238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 10020.3076	loss_val: 10020.0371	loss_test: 10021.2207	accuracy_train: 0.6962	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 8635.0176	loss_val: 8635.0117	loss_test: 8635.8369	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 15396.8564	loss_val: 15396.8076	loss_test: 15397.0977	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5198.5249	loss_val: 5198.0967	loss_test: 5198.7158	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5191.0864	loss_val: 5190.9434	loss_test: 5191.3560	accuracy_train: 0.7273	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4854.4087	loss_val: 4854.4058	loss_test: 4854.3770	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 10882.2559	loss_val: 10882.2363	loss_test: 10882.4600	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 49865.6680	loss_val: 49865.1641	loss_test: 49865.8008	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7757.1406	loss_val: 7756.9971	loss_test: 7757.2607	accuracy_train: 0.8469	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 25	curr_val_accuracy: 0.8078	curr_test_accuracy: 0.7297
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8965.4453	loss_val: 8965.8760	loss_test: 8965.6670	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15246.9922	loss_val: 15246.9609	loss_test: 15247.6016	accuracy_train: 0.6667	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 46817.4570	loss_val: 46817.3555	loss_test: 46817.5938	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 23639.7910	loss_val: 23639.7480	loss_test: 23639.8984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9392.7109	loss_val: 9392.8223	loss_test: 9392.7480	accuracy_train: 0.8642	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5969.2163	loss_val: 5969.2456	loss_test: 5969.2026	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7433.4775	loss_val: 7433.4526	loss_test: 7433.7275	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10186.7793	loss_val: 10186.7129	loss_test: 10186.4941	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10777.4434	loss_val: 10777.6406	loss_test: 10777.6074	accuracy_train: 0.7708	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 5705.4814	loss_val: 5705.4688	loss_test: 5705.3701	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8545.4648	loss_val: 8545.4697	loss_test: 8545.4521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 9975.2324	loss_val: 9974.9795	loss_test: 9976.2002	accuracy_train: 0.7089	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 8546.9531	loss_val: 8546.9668	loss_test: 8547.8457	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 15497.8604	loss_val: 15497.8115	loss_test: 15498.1064	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5270.5854	loss_val: 5270.1787	loss_test: 5270.8159	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5210.9785	loss_val: 5210.8438	loss_test: 5211.2886	accuracy_train: 0.7273	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4845.0298	loss_val: 4845.0220	loss_test: 4844.9937	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 10693.7920	loss_val: 10693.7949	loss_test: 10694.0342	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 50265.8828	loss_val: 50265.3945	loss_test: 50266.0195	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7726.2944	loss_val: 7726.1519	loss_test: 7726.4238	accuracy_train: 0.8673	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 26	curr_val_accuracy: 0.8078	curr_test_accuracy: 0.7297
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8838.2227	loss_val: 8838.6650	loss_test: 8838.4492	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15207.0459	loss_val: 15207.0420	loss_test: 15207.6309	accuracy_train: 0.7333	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 47470.0000	loss_val: 47469.9102	loss_test: 47470.1602	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 24198.0000	loss_val: 24197.9590	loss_test: 24198.1074	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9273.3154	loss_val: 9273.4492	loss_test: 9273.3516	accuracy_train: 0.8642	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5907.2866	loss_val: 5907.3179	loss_test: 5907.2749	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7419.7690	loss_val: 7419.7461	loss_test: 7420.0176	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10261.7236	loss_val: 10261.6475	loss_test: 10261.4170	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10702.4375	loss_val: 10702.6650	loss_test: 10702.6221	accuracy_train: 0.8125	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 5774.2998	loss_val: 5774.2871	loss_test: 5774.1919	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8601.7705	loss_val: 8601.7773	loss_test: 8601.7598	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 9878.3203	loss_val: 9878.0928	loss_test: 9879.3418	accuracy_train: 0.7342	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 8433.2910	loss_val: 8433.3281	loss_test: 8434.2422	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 15441.2422	loss_val: 15441.1943	loss_test: 15441.4941	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5319.0342	loss_val: 5318.6470	loss_test: 5319.3169	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5212.5039	loss_val: 5212.3823	loss_test: 5212.8545	accuracy_train: 0.8636	accuracy_val: 1.0000	accuracy_test: 0.2500
[client 16]	loss_train: 4802.4478	loss_val: 4802.4360	loss_test: 4802.4092	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 10478.1543	loss_val: 10478.1729	loss_test: 10478.4336	accuracy_train: 0.7778	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 50657.9688	loss_val: 50657.5000	loss_test: 50658.1094	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7680.4268	loss_val: 7680.2856	loss_test: 7680.5645	accuracy_train: 0.8980	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 27	curr_val_accuracy: 0.8078	curr_test_accuracy: 0.7260
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8660.5439	loss_val: 8660.9922	loss_test: 8660.7725	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15086.9727	loss_val: 15086.9922	loss_test: 15087.5342	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 47991.4648	loss_val: 47991.3945	loss_test: 47991.6523	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 24837.8828	loss_val: 24837.8418	loss_test: 24837.9883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9137.1885	loss_val: 9137.3486	loss_test: 9137.2236	accuracy_train: 0.8889	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5822.2554	loss_val: 5822.2886	loss_test: 5822.2461	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7378.7373	loss_val: 7378.7168	loss_test: 7378.9829	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10308.6621	loss_val: 10308.5850	loss_test: 10308.3369	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 10613.5801	loss_val: 10613.8330	loss_test: 10613.7822	accuracy_train: 0.8125	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 5837.8198	loss_val: 5837.8062	loss_test: 5837.7153	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8615.4648	loss_val: 8615.4727	loss_test: 8615.4551	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 9660.1846	loss_val: 9659.9893	loss_test: 9661.2588	accuracy_train: 0.7342	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 8298.0879	loss_val: 8298.1504	loss_test: 8299.0967	accuracy_train: 0.8529	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 15278.5557	loss_val: 15278.5098	loss_test: 15278.8145	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5375.7500	loss_val: 5375.3828	loss_test: 5376.0781	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5210.9536	loss_val: 5210.8481	loss_test: 5211.3467	accuracy_train: 0.8636	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4744.6919	loss_val: 4744.6763	loss_test: 4744.6509	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 10215.5332	loss_val: 10215.5674	loss_test: 10215.8496	accuracy_train: 0.7778	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 50907.0508	loss_val: 50906.6016	loss_test: 50907.1992	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7618.7666	loss_val: 7618.6289	loss_test: 7618.9136	accuracy_train: 0.8980	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 28	curr_val_accuracy: 0.8078	curr_test_accuracy: 0.7319
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8548.8516	loss_val: 8549.3115	loss_test: 8549.0889	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14955.8750	loss_val: 14955.9160	loss_test: 14956.4082	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 48304.6172	loss_val: 48304.5820	loss_test: 48304.8438	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 25555.0020	loss_val: 25554.9629	loss_test: 25555.1055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8999.9639	loss_val: 9000.1475	loss_test: 8999.9980	accuracy_train: 0.9012	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5728.2549	loss_val: 5728.2886	loss_test: 5728.2471	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7316.1812	loss_val: 7316.1631	loss_test: 7316.4263	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10270.7402	loss_val: 10270.6562	loss_test: 10270.3965	accuracy_train: 0.2381	accuracy_val: 0.4000	accuracy_test: 0.2857
[client 8]	loss_train: 10535.7012	loss_val: 10535.9834	loss_test: 10535.9258	accuracy_train: 0.8125	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 5898.1235	loss_val: 5898.1094	loss_test: 5898.0205	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8592.1865	loss_val: 8592.1943	loss_test: 8592.1768	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 9400.6455	loss_val: 9400.4854	loss_test: 9401.7695	accuracy_train: 0.7342	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 8150.3848	loss_val: 8150.4717	loss_test: 8151.4453	accuracy_train: 0.8824	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 15079.9180	loss_val: 15079.8760	loss_test: 15080.1826	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5411.3599	loss_val: 5411.0127	loss_test: 5411.7422	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5216.5088	loss_val: 5216.4214	loss_test: 5216.9502	accuracy_train: 0.9091	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4697.7271	loss_val: 4697.7075	loss_test: 4697.6836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9929.8145	loss_val: 9929.8770	loss_test: 9930.1650	accuracy_train: 0.8148	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 51078.9219	loss_val: 51078.4883	loss_test: 51079.0703	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7551.4141	loss_val: 7551.2793	loss_test: 7551.5679	accuracy_train: 0.9082	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 29	curr_val_accuracy: 0.8169	curr_test_accuracy: 0.7322
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8428.1172	loss_val: 8428.5928	loss_test: 8428.3662	accuracy_train: 0.9333	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14858.5625	loss_val: 14858.6201	loss_test: 14859.0820	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 48535.1797	loss_val: 48535.1641	loss_test: 48535.4375	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 26441.3105	loss_val: 26441.2715	loss_test: 26441.4121	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8852.5645	loss_val: 8852.7715	loss_test: 8852.5996	accuracy_train: 0.9012	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 5619.0430	loss_val: 5619.0771	loss_test: 5619.0366	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7239.1548	loss_val: 7239.1396	loss_test: 7239.3994	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10209.6729	loss_val: 10209.5830	loss_test: 10209.3154	accuracy_train: 0.2619	accuracy_val: 0.4000	accuracy_test: 0.2857
[client 8]	loss_train: 10465.8291	loss_val: 10466.1328	loss_test: 10466.0742	accuracy_train: 0.8125	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 5955.1147	loss_val: 5955.1021	loss_test: 5955.0137	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8539.8828	loss_val: 8539.8916	loss_test: 8539.8740	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 9032.8818	loss_val: 9032.7646	loss_test: 9034.0498	accuracy_train: 0.7468	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 7996.9888	loss_val: 7997.0967	loss_test: 7998.1079	accuracy_train: 0.8824	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 14775.1396	loss_val: 14775.1035	loss_test: 14775.4092	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5432.1167	loss_val: 5431.7944	loss_test: 5432.5532	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5210.6914	loss_val: 5210.6250	loss_test: 5211.1826	accuracy_train: 0.9545	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4644.3970	loss_val: 4644.3740	loss_test: 4644.3511	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9648.2031	loss_val: 9648.2812	loss_test: 9648.5928	accuracy_train: 0.8519	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 51195.4453	loss_val: 51195.0312	loss_test: 51195.5977	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7476.2573	loss_val: 7476.1265	loss_test: 7476.4160	accuracy_train: 0.8980	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 30	curr_val_accuracy: 0.8169	curr_test_accuracy: 0.7457
best_round: 21	best_val_accuracy: 0.8252	best_test_accuracy: 0.7123
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8297.4492	loss_val: 8297.9443	loss_test: 8297.7148	accuracy_train: 0.9333	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14705.8477	loss_val: 14705.9287	loss_test: 14706.3555	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 48882.3320	loss_val: 48882.3477	loss_test: 48882.6289	accuracy_train: 0.8286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 27407.1699	loss_val: 27407.1328	loss_test: 27407.2695	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8706.8857	loss_val: 8707.1250	loss_test: 8706.9238	accuracy_train: 0.9136	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 5503.1729	loss_val: 5503.2070	loss_test: 5503.1680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7159.2368	loss_val: 7159.2246	loss_test: 7159.4805	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10100.5625	loss_val: 10100.4600	loss_test: 10100.1982	accuracy_train: 0.2619	accuracy_val: 0.4000	accuracy_test: 0.2857
[client 8]	loss_train: 10366.9990	loss_val: 10367.3311	loss_test: 10367.2676	accuracy_train: 0.8333	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 6026.8887	loss_val: 6026.8765	loss_test: 6026.7891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8470.1133	loss_val: 8470.1230	loss_test: 8470.1055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 8620.7354	loss_val: 8620.6621	loss_test: 8621.9414	accuracy_train: 0.7975	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 7822.9683	loss_val: 7823.0996	loss_test: 7824.1484	accuracy_train: 0.8824	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 14466.5020	loss_val: 14466.4717	loss_test: 14466.7783	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5434.6509	loss_val: 5434.3521	loss_test: 5435.1372	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5196.0869	loss_val: 5196.0425	loss_test: 5196.6274	accuracy_train: 0.9545	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4586.3945	loss_val: 4586.3687	loss_test: 4586.3457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9337.0859	loss_val: 9337.1973	loss_test: 9337.5107	accuracy_train: 0.9630	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 51564.9961	loss_val: 51564.6016	loss_test: 51565.1523	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7344.0962	loss_val: 7343.9741	loss_test: 7344.2632	accuracy_train: 0.8980	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 31	curr_val_accuracy: 0.8256	curr_test_accuracy: 0.7457
best_round: 31	best_val_accuracy: 0.8256	best_test_accuracy: 0.7457
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8195.8906	loss_val: 8196.4170	loss_test: 8196.1768	accuracy_train: 0.9333	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14528.2285	loss_val: 14528.3369	loss_test: 14528.7119	accuracy_train: 0.8667	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49056.3867	loss_val: 49056.4336	loss_test: 49056.7227	accuracy_train: 0.8286	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 28510.4863	loss_val: 28510.4492	loss_test: 28510.5859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8587.4219	loss_val: 8587.6934	loss_test: 8587.4619	accuracy_train: 0.9136	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 5378.3491	loss_val: 5378.3838	loss_test: 5378.3462	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7086.4111	loss_val: 7086.4033	loss_test: 7086.6562	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9860.9795	loss_val: 9860.8574	loss_test: 9860.6152	accuracy_train: 0.2857	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10127.9756	loss_val: 10128.3584	loss_test: 10128.2764	accuracy_train: 0.8958	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 6126.4873	loss_val: 6126.4761	loss_test: 6126.3892	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8381.3018	loss_val: 8381.3115	loss_test: 8381.2949	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 8193.1602	loss_val: 8193.1348	loss_test: 8194.3955	accuracy_train: 0.8481	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 7652.4580	loss_val: 7652.6123	loss_test: 7653.7021	accuracy_train: 0.8824	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 14071.8936	loss_val: 14071.8711	loss_test: 14072.1787	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5434.3052	loss_val: 5434.0312	loss_test: 5434.8428	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5193.3804	loss_val: 5193.3564	loss_test: 5193.9673	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4535.5972	loss_val: 4535.5693	loss_test: 4535.5459	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9048.7930	loss_val: 9048.9365	loss_test: 9049.2510	accuracy_train: 0.9630	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 52031.9453	loss_val: 52031.5742	loss_test: 52032.1094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7226.5391	loss_val: 7226.4233	loss_test: 7226.7104	accuracy_train: 0.8980	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 32	curr_val_accuracy: 0.8406	curr_test_accuracy: 0.7586
best_round: 32	best_val_accuracy: 0.8406	best_test_accuracy: 0.7586
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8153.2251	loss_val: 8153.7979	loss_test: 8153.5415	accuracy_train: 0.9467	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14308.8115	loss_val: 14308.9482	loss_test: 14309.2773	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49209.2383	loss_val: 49209.3086	loss_test: 49209.6094	accuracy_train: 0.8857	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 29717.8398	loss_val: 29717.8027	loss_test: 29717.9375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8479.3926	loss_val: 8479.6992	loss_test: 8479.4355	accuracy_train: 0.9012	accuracy_val: 0.8000	accuracy_test: 0.9091
[client 5]	loss_train: 5262.6548	loss_val: 5262.6885	loss_test: 5262.6523	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7025.5933	loss_val: 7025.5894	loss_test: 7025.8403	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9572.3115	loss_val: 9572.1846	loss_test: 9571.9619	accuracy_train: 0.2857	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9909.2490	loss_val: 9909.6797	loss_test: 9909.5801	accuracy_train: 0.9375	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6227.6855	loss_val: 6227.6753	loss_test: 6227.5884	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8273.2334	loss_val: 8273.2422	loss_test: 8273.2266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7798.4736	loss_val: 7798.4980	loss_test: 7799.7358	accuracy_train: 0.8861	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 7468.7495	loss_val: 7468.9268	loss_test: 7470.0400	accuracy_train: 0.8824	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 13708.9229	loss_val: 13708.9072	loss_test: 13709.2188	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5440.5854	loss_val: 5440.3354	loss_test: 5441.1733	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5185.8960	loss_val: 5185.8911	loss_test: 5186.5225	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4498.6938	loss_val: 4498.6641	loss_test: 4498.6392	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8764.3447	loss_val: 8764.5312	loss_test: 8764.8281	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 52451.9688	loss_val: 52451.6172	loss_test: 52452.1289	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7124.8267	loss_val: 7124.7178	loss_test: 7125.0029	accuracy_train: 0.9082	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 33	curr_val_accuracy: 0.8493	curr_test_accuracy: 0.7664
best_round: 33	best_val_accuracy: 0.8493	best_test_accuracy: 0.7664
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8013.7178	loss_val: 8014.3335	loss_test: 8014.0547	accuracy_train: 0.9467	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14144.9863	loss_val: 14145.1484	loss_test: 14145.4229	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49337.7969	loss_val: 49337.8906	loss_test: 49338.2031	accuracy_train: 0.9143	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 31204.7715	loss_val: 31204.7344	loss_test: 31204.8672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8381.6494	loss_val: 8381.9961	loss_test: 8381.6943	accuracy_train: 0.9012	accuracy_val: 0.8000	accuracy_test: 0.9091
[client 5]	loss_train: 5152.6968	loss_val: 5152.7310	loss_test: 5152.6953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6964.7920	loss_val: 6964.7920	loss_test: 6965.0425	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9282.3750	loss_val: 9282.2559	loss_test: 9282.0508	accuracy_train: 0.3333	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9707.8164	loss_val: 9708.2969	loss_test: 9708.1777	accuracy_train: 0.9375	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6351.1016	loss_val: 6351.0942	loss_test: 6351.0054	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8153.6855	loss_val: 8153.6948	loss_test: 8153.6807	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7452.7817	loss_val: 7452.8506	loss_test: 7454.0557	accuracy_train: 0.8861	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 7287.5005	loss_val: 7287.7031	loss_test: 7288.8271	accuracy_train: 0.9118	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 13313.1777	loss_val: 13313.1689	loss_test: 13313.4854	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5449.7739	loss_val: 5449.5449	loss_test: 5450.4170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5182.6255	loss_val: 5182.6416	loss_test: 5183.2861	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4465.8589	loss_val: 4465.8281	loss_test: 4465.8018	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8494.0303	loss_val: 8494.2471	loss_test: 8494.5371	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 52667.4531	loss_val: 52667.1367	loss_test: 52667.6211	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7023.2783	loss_val: 7023.1792	loss_test: 7023.4609	accuracy_train: 0.9184	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 34	curr_val_accuracy: 0.8493	curr_test_accuracy: 0.7739
best_round: 33	best_val_accuracy: 0.8493	best_test_accuracy: 0.7664
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7750.0142	loss_val: 7750.6582	loss_test: 7750.3594	accuracy_train: 0.9600	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14023.0332	loss_val: 14023.2168	loss_test: 14023.4561	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49396.2656	loss_val: 49396.3867	loss_test: 49396.7070	accuracy_train: 0.9143	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 32576.4844	loss_val: 32576.4473	loss_test: 32576.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8269.3486	loss_val: 8269.7383	loss_test: 8269.3994	accuracy_train: 0.9136	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 5042.3955	loss_val: 5042.4292	loss_test: 5042.3945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6913.7314	loss_val: 6913.7354	loss_test: 6913.9868	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9004.0996	loss_val: 9003.9902	loss_test: 9003.8057	accuracy_train: 0.3571	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9560.9814	loss_val: 9561.5010	loss_test: 9561.3691	accuracy_train: 0.9792	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6557.2705	loss_val: 6557.2646	loss_test: 6557.1787	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8026.1436	loss_val: 8026.1523	loss_test: 8026.1396	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7102.9468	loss_val: 7103.0576	loss_test: 7104.2295	accuracy_train: 0.9114	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 7121.4229	loss_val: 7121.6484	loss_test: 7122.7700	accuracy_train: 0.9118	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12915.2695	loss_val: 12915.2686	loss_test: 12915.5918	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5456.6782	loss_val: 5456.4653	loss_test: 5457.3701	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5148.4102	loss_val: 5148.4453	loss_test: 5149.1055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4434.2456	loss_val: 4434.2144	loss_test: 4434.1860	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8279.5225	loss_val: 8279.7549	loss_test: 8280.0518	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 52705.4531	loss_val: 52705.1680	loss_test: 52705.6289	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6941.0615	loss_val: 6940.9678	loss_test: 6941.2461	accuracy_train: 0.9184	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 35	curr_val_accuracy: 0.8493	curr_test_accuracy: 0.7660
best_round: 33	best_val_accuracy: 0.8493	best_test_accuracy: 0.7664
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7468.3589	loss_val: 7469.0176	loss_test: 7468.7056	accuracy_train: 0.9600	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13899.1719	loss_val: 13899.3809	loss_test: 13899.5605	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49693.7695	loss_val: 49693.9219	loss_test: 49694.2500	accuracy_train: 0.8857	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 34019.2500	loss_val: 34019.2148	loss_test: 34019.3438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8184.2783	loss_val: 8184.7148	loss_test: 8184.3354	accuracy_train: 0.9136	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 4945.3335	loss_val: 4945.3667	loss_test: 4945.3335	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6870.8228	loss_val: 6870.8311	loss_test: 6871.0806	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8725.9531	loss_val: 8725.8555	loss_test: 8725.7012	accuracy_train: 0.4048	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9477.1777	loss_val: 9477.7188	loss_test: 9477.5850	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6800.8164	loss_val: 6800.8105	loss_test: 6800.7280	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7887.7520	loss_val: 7887.7607	loss_test: 7887.7490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6792.4561	loss_val: 6792.6060	loss_test: 6793.7422	accuracy_train: 0.9241	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 6967.7446	loss_val: 6967.9932	loss_test: 6969.1099	accuracy_train: 0.9412	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12596.3887	loss_val: 12596.3965	loss_test: 12596.7285	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5446.6089	loss_val: 5446.4155	loss_test: 5447.3462	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5121.7412	loss_val: 5121.7954	loss_test: 5122.4683	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4406.5220	loss_val: 4406.4897	loss_test: 4406.4604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8028.9458	loss_val: 8029.2065	loss_test: 8029.4878	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 52898.5000	loss_val: 52898.2461	loss_test: 52898.6797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6903.1196	loss_val: 6903.0308	loss_test: 6903.3062	accuracy_train: 0.8980	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 36	curr_val_accuracy: 0.8493	curr_test_accuracy: 0.7660
best_round: 33	best_val_accuracy: 0.8493	best_test_accuracy: 0.7664
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7160.4175	loss_val: 7161.0767	loss_test: 7160.7568	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13826.4434	loss_val: 13826.6670	loss_test: 13826.8076	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49838.8008	loss_val: 49838.9844	loss_test: 49839.3281	accuracy_train: 0.8857	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 35430.3984	loss_val: 35430.3633	loss_test: 35430.4922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8095.7393	loss_val: 8096.2222	loss_test: 8095.8027	accuracy_train: 0.9136	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 4852.6270	loss_val: 4852.6611	loss_test: 4852.6284	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6841.4351	loss_val: 6841.4478	loss_test: 6841.6978	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8452.7207	loss_val: 8452.6445	loss_test: 8452.5098	accuracy_train: 0.4048	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9364.9033	loss_val: 9365.4590	loss_test: 9365.3359	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 7074.5132	loss_val: 7074.5073	loss_test: 7074.4258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7762.1699	loss_val: 7762.1782	loss_test: 7762.1685	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6620.0356	loss_val: 6620.2197	loss_test: 6621.3457	accuracy_train: 0.9367	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 6820.9312	loss_val: 6821.1992	loss_test: 6822.3115	accuracy_train: 0.9412	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12272.8311	loss_val: 12272.8486	loss_test: 12273.1885	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5440.2607	loss_val: 5440.0845	loss_test: 5441.0439	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5084.0864	loss_val: 5084.1587	loss_test: 5084.8369	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4383.6914	loss_val: 4383.6592	loss_test: 4383.6284	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7801.0166	loss_val: 7801.3105	loss_test: 7801.5664	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 53053.9727	loss_val: 53053.7461	loss_test: 53054.1562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6851.2993	loss_val: 6851.2183	loss_test: 6851.4946	accuracy_train: 0.9082	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 37	curr_val_accuracy: 0.8426	curr_test_accuracy: 0.7584
best_round: 33	best_val_accuracy: 0.8493	best_test_accuracy: 0.7664
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6873.3911	loss_val: 6874.0518	loss_test: 6873.7139	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13727.5020	loss_val: 13727.7373	loss_test: 13727.8584	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49907.0664	loss_val: 49907.2734	loss_test: 49907.6367	accuracy_train: 0.8571	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 36908.5469	loss_val: 36908.5117	loss_test: 36908.6406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7997.8716	loss_val: 7998.3945	loss_test: 7997.9399	accuracy_train: 0.9136	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 4784.4839	loss_val: 4784.5176	loss_test: 4784.4873	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6825.5864	loss_val: 6825.6030	loss_test: 6825.8525	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8211.3262	loss_val: 8211.2822	loss_test: 8211.1582	accuracy_train: 0.4762	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 9286.0391	loss_val: 9286.6084	loss_test: 9286.4941	accuracy_train: 0.9792	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 7363.7686	loss_val: 7363.7637	loss_test: 7363.6831	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7641.3071	loss_val: 7641.3154	loss_test: 7641.3071	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6495.0190	loss_val: 6495.2393	loss_test: 6496.3569	accuracy_train: 0.9367	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6685.3179	loss_val: 6685.6060	loss_test: 6686.7134	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11965.2422	loss_val: 11965.2676	loss_test: 11965.6162	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5439.3516	loss_val: 5439.1919	loss_test: 5440.1890	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5063.0288	loss_val: 5063.1216	loss_test: 5063.8057	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4377.6851	loss_val: 4377.6538	loss_test: 4377.6206	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7601.8062	loss_val: 7602.1230	loss_test: 7602.3667	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 53566.5508	loss_val: 53566.3516	loss_test: 53566.7383	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6806.9053	loss_val: 6806.8301	loss_test: 6807.1094	accuracy_train: 0.9082	accuracy_val: 1.0000	accuracy_test: 0.6923
curr_round: 38	curr_val_accuracy: 0.8426	curr_test_accuracy: 0.7653
best_round: 33	best_val_accuracy: 0.8493	best_test_accuracy: 0.7664
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6612.0898	loss_val: 6612.7466	loss_test: 6612.3940	accuracy_train: 0.9867	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13628.4385	loss_val: 13628.6807	loss_test: 13628.7891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49877.5820	loss_val: 49877.8047	loss_test: 49878.1797	accuracy_train: 0.8571	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 38067.0352	loss_val: 38067.0000	loss_test: 38067.1328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7918.2046	loss_val: 7918.7661	loss_test: 7918.2793	accuracy_train: 0.9136	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 4758.2192	loss_val: 4758.2524	loss_test: 4758.2261	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6849.2393	loss_val: 6849.2598	loss_test: 6849.5137	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8025.5503	loss_val: 8025.5327	loss_test: 8025.4126	accuracy_train: 0.4762	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 9278.0264	loss_val: 9278.6152	loss_test: 9278.4883	accuracy_train: 0.9792	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 7659.3335	loss_val: 7659.3286	loss_test: 7659.2495	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7531.3042	loss_val: 7531.3135	loss_test: 7531.3066	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6356.9741	loss_val: 6357.2339	loss_test: 6358.3232	accuracy_train: 0.9367	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6572.4883	loss_val: 6572.7974	loss_test: 6573.8799	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11694.2383	loss_val: 11694.2705	loss_test: 11694.6318	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5450.3774	loss_val: 5450.2344	loss_test: 5451.2534	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5029.6372	loss_val: 5029.7495	loss_test: 5030.4385	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4375.9219	loss_val: 4375.8911	loss_test: 4375.8569	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7440.5190	loss_val: 7440.8784	loss_test: 7441.0859	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 53895.5039	loss_val: 53895.3242	loss_test: 53895.6875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6797.0903	loss_val: 6797.0166	loss_test: 6797.3013	accuracy_train: 0.8980	accuracy_val: 1.0000	accuracy_test: 0.6923
curr_round: 39	curr_val_accuracy: 0.8506	curr_test_accuracy: 0.7653
best_round: 39	best_val_accuracy: 0.8506	best_test_accuracy: 0.7653
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6446.3203	loss_val: 6446.9648	loss_test: 6446.6113	accuracy_train: 0.9867	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13598.0400	loss_val: 13598.2881	loss_test: 13598.3867	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49709.2031	loss_val: 49709.4414	loss_test: 49709.8242	accuracy_train: 0.8857	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 39305.5820	loss_val: 39305.5469	loss_test: 39305.6797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7870.0137	loss_val: 7870.6167	loss_test: 7870.0957	accuracy_train: 0.9136	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 4727.6416	loss_val: 4727.6724	loss_test: 4727.6499	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6881.5581	loss_val: 6881.5820	loss_test: 6881.8379	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7902.3296	loss_val: 7902.3345	loss_test: 7902.2148	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 9297.0410	loss_val: 9297.6465	loss_test: 9297.5166	accuracy_train: 0.9792	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 7922.1294	loss_val: 7922.1270	loss_test: 7922.0464	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7445.7407	loss_val: 7445.7505	loss_test: 7445.7451	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6174.1006	loss_val: 6174.3989	loss_test: 6175.4380	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6471.5107	loss_val: 6471.8379	loss_test: 6472.9019	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11475.1689	loss_val: 11475.2109	loss_test: 11475.5830	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5446.9468	loss_val: 5446.8218	loss_test: 5447.8667	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5003.0220	loss_val: 5003.1504	loss_test: 5003.8398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4377.1455	loss_val: 4377.1162	loss_test: 4377.0820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7289.6172	loss_val: 7290.0210	loss_test: 7290.1890	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 54406.8867	loss_val: 54406.7227	loss_test: 54407.0664	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6766.1167	loss_val: 6766.0513	loss_test: 6766.3394	accuracy_train: 0.8980	accuracy_val: 1.0000	accuracy_test: 0.6923
curr_round: 40	curr_val_accuracy: 0.8506	curr_test_accuracy: 0.7733
best_round: 39	best_val_accuracy: 0.8506	best_test_accuracy: 0.7653
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6311.1235	loss_val: 6311.7588	loss_test: 6311.4194	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13562.0977	loss_val: 13562.3457	loss_test: 13562.4502	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49308.7773	loss_val: 49309.0312	loss_test: 49309.4102	accuracy_train: 0.9143	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 40434.0352	loss_val: 40434.0039	loss_test: 40434.1328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7837.5464	loss_val: 7838.1953	loss_test: 7837.6372	accuracy_train: 0.9259	accuracy_val: 0.8000	accuracy_test: 0.9091
[client 5]	loss_train: 4713.4604	loss_val: 4713.4893	loss_test: 4713.4702	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6921.5459	loss_val: 6921.5723	loss_test: 6921.8291	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7830.4736	loss_val: 7830.4951	loss_test: 7830.3760	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9371.6328	loss_val: 9372.2441	loss_test: 9372.1162	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 8192.5684	loss_val: 8192.5684	loss_test: 8192.4854	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7358.0532	loss_val: 7358.0635	loss_test: 7358.0591	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5988.4561	loss_val: 5988.7871	loss_test: 5989.7754	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6379.1401	loss_val: 6379.4819	loss_test: 6380.5396	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11268.0654	loss_val: 11268.1133	loss_test: 11268.4990	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5460.1191	loss_val: 5460.0088	loss_test: 5461.0796	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4972.9023	loss_val: 4973.0454	loss_test: 4973.7300	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4374.1538	loss_val: 4374.1250	loss_test: 4374.0928	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7152.3662	loss_val: 7152.8252	loss_test: 7152.9365	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 54942.5430	loss_val: 54942.3945	loss_test: 54942.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6739.3521	loss_val: 6739.2930	loss_test: 6739.5830	accuracy_train: 0.9286	accuracy_val: 1.0000	accuracy_test: 0.6923
curr_round: 41	curr_val_accuracy: 0.8506	curr_test_accuracy: 0.7666
best_round: 39	best_val_accuracy: 0.8506	best_test_accuracy: 0.7653
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6229.1577	loss_val: 6229.7974	loss_test: 6229.4639	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13532.9258	loss_val: 13533.1689	loss_test: 13533.2930	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 48906.5469	loss_val: 48906.8047	loss_test: 48907.1758	accuracy_train: 0.9143	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 41636.0547	loss_val: 41636.0234	loss_test: 41636.1523	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7825.0327	loss_val: 7825.7266	loss_test: 7825.1333	accuracy_train: 0.9259	accuracy_val: 0.8000	accuracy_test: 0.9091
[client 5]	loss_train: 4704.0029	loss_val: 4704.0303	loss_test: 4704.0146	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6983.5938	loss_val: 6983.6211	loss_test: 6983.8799	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7773.0615	loss_val: 7773.1030	loss_test: 7772.9824	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9449.6162	loss_val: 9450.2373	loss_test: 9450.1045	accuracy_train: 0.9375	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 8476.9297	loss_val: 8476.9316	loss_test: 8476.8477	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7287.6494	loss_val: 7287.6611	loss_test: 7287.6572	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5780.6099	loss_val: 5780.9702	loss_test: 5781.8994	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6309.3232	loss_val: 6309.6748	loss_test: 6310.7490	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11119.9062	loss_val: 11119.9580	loss_test: 11120.3574	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5470.8765	loss_val: 5470.7788	loss_test: 5471.8691	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4950.6367	loss_val: 4950.7886	loss_test: 4951.4751	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4389.6436	loss_val: 4389.6162	loss_test: 4389.5850	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7040.5332	loss_val: 7041.0723	loss_test: 7041.1006	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 55815.4414	loss_val: 55815.3086	loss_test: 55815.6133	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6665.5552	loss_val: 6665.5122	loss_test: 6665.8022	accuracy_train: 0.9388	accuracy_val: 1.0000	accuracy_test: 0.6923
curr_round: 42	curr_val_accuracy: 0.8577	curr_test_accuracy: 0.7742
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6174.3511	loss_val: 6175.0078	loss_test: 6174.6685	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13498.2832	loss_val: 13498.5273	loss_test: 13498.6611	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 48561.6211	loss_val: 48561.8711	loss_test: 48562.2344	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 43066.5117	loss_val: 43066.4844	loss_test: 43066.6172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7881.9473	loss_val: 7882.6914	loss_test: 7882.0635	accuracy_train: 0.9259	accuracy_val: 0.8000	accuracy_test: 0.9091
[client 5]	loss_train: 4690.0073	loss_val: 4690.0337	loss_test: 4690.0205	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7060.2559	loss_val: 7060.2842	loss_test: 7060.5449	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7781.8994	loss_val: 7781.9536	loss_test: 7781.8330	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9562.3369	loss_val: 9562.9697	loss_test: 9562.8262	accuracy_train: 0.8958	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 8732.4463	loss_val: 8732.4492	loss_test: 8732.3662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7239.9937	loss_val: 7240.0063	loss_test: 7240.0024	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5590.9434	loss_val: 5591.3276	loss_test: 5592.2021	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6269.5454	loss_val: 6269.8979	loss_test: 6271.0254	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 10976.0088	loss_val: 10976.0635	loss_test: 10976.4785	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5502.6104	loss_val: 5502.5220	loss_test: 5503.6348	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4925.6475	loss_val: 4925.8130	loss_test: 4926.4956	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4412.5244	loss_val: 4412.4990	loss_test: 4412.4697	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6957.8042	loss_val: 6958.4229	loss_test: 6958.3594	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 56738.0586	loss_val: 56737.9336	loss_test: 56738.2188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6613.1680	loss_val: 6613.1406	loss_test: 6613.4272	accuracy_train: 0.9490	accuracy_val: 1.0000	accuracy_test: 0.6923
curr_round: 43	curr_val_accuracy: 0.8496	curr_test_accuracy: 0.7749
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6144.9932	loss_val: 6145.6899	loss_test: 6145.3110	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13530.5742	loss_val: 13530.8145	loss_test: 13530.9668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 48506.4375	loss_val: 48506.6523	loss_test: 48507.0312	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 44283.0195	loss_val: 44282.9922	loss_test: 44283.1250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7942.0747	loss_val: 7942.8652	loss_test: 7942.2070	accuracy_train: 0.9259	accuracy_val: 0.8000	accuracy_test: 0.9091
[client 5]	loss_train: 4688.8779	loss_val: 4688.9038	loss_test: 4688.8921	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7156.8989	loss_val: 7156.9282	loss_test: 7157.1885	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7791.9814	loss_val: 7792.0518	loss_test: 7791.9307	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9732.1143	loss_val: 9732.7510	loss_test: 9732.5986	accuracy_train: 0.8542	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 8971.3564	loss_val: 8971.3633	loss_test: 8971.2803	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7197.7642	loss_val: 7197.7778	loss_test: 7197.7744	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5461.4653	loss_val: 5461.8701	loss_test: 5462.7095	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6275.8892	loss_val: 6276.2349	loss_test: 6277.4927	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 10934.9824	loss_val: 10935.0410	loss_test: 10935.4678	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5534.9321	loss_val: 5534.8521	loss_test: 5535.9937	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4913.1870	loss_val: 4913.3667	loss_test: 4914.0449	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4449.2837	loss_val: 4449.2617	loss_test: 4449.2334	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6923.8584	loss_val: 6924.5376	loss_test: 6924.4019	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 57366.4219	loss_val: 57366.3086	loss_test: 57366.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6604.2188	loss_val: 6604.2021	loss_test: 6604.4863	accuracy_train: 0.9490	accuracy_val: 0.9167	accuracy_test: 0.6923
curr_round: 44	curr_val_accuracy: 0.8409	curr_test_accuracy: 0.7548
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6155.9385	loss_val: 6156.6929	loss_test: 6156.2686	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 1]	loss_train: 13478.5576	loss_val: 13478.7920	loss_test: 13478.9805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 47954.5977	loss_val: 47954.8398	loss_test: 47955.2109	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 45491.4531	loss_val: 45491.4258	loss_test: 45491.5664	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8021.8101	loss_val: 8022.6440	loss_test: 8021.9619	accuracy_train: 0.9259	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 4697.0620	loss_val: 4697.0884	loss_test: 4697.0742	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7254.0347	loss_val: 7254.0669	loss_test: 7254.3247	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7784.4004	loss_val: 7784.4912	loss_test: 7784.3667	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 9878.6016	loss_val: 9879.2568	loss_test: 9879.0850	accuracy_train: 0.8542	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 9151.4336	loss_val: 9151.4443	loss_test: 9151.3594	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7150.9409	loss_val: 7150.9551	loss_test: 7150.9521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5374.2822	loss_val: 5374.7046	loss_test: 5375.5137	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6309.5557	loss_val: 6309.8950	loss_test: 6311.2832	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 10886.6260	loss_val: 10886.6816	loss_test: 10887.1270	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5569.3047	loss_val: 5569.2319	loss_test: 5570.4165	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4909.9521	loss_val: 4910.1426	loss_test: 4910.8159	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4488.0586	loss_val: 4488.0405	loss_test: 4488.0132	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6891.2168	loss_val: 6891.9375	loss_test: 6891.7529	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 58083.8320	loss_val: 58083.7266	loss_test: 58083.9805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6617.2910	loss_val: 6617.2842	loss_test: 6617.5659	accuracy_train: 0.9592	accuracy_val: 0.9167	accuracy_test: 0.6923
curr_round: 45	curr_val_accuracy: 0.8490	curr_test_accuracy: 0.7395
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6205.4146	loss_val: 6206.2544	loss_test: 6205.8110	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13458.5361	loss_val: 13458.7666	loss_test: 13458.9785	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 47873.6758	loss_val: 47873.9336	loss_test: 47874.3047	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 46562.6328	loss_val: 46562.6055	loss_test: 46562.7461	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8114.9043	loss_val: 8115.7866	loss_test: 8115.0781	accuracy_train: 0.9259	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 4700.3325	loss_val: 4700.3599	loss_test: 4700.3428	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7349.2573	loss_val: 7349.2910	loss_test: 7349.5493	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7738.5908	loss_val: 7738.7036	loss_test: 7738.5737	accuracy_train: 0.5238	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10045.5078	loss_val: 10046.1855	loss_test: 10046.0000	accuracy_train: 0.8542	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 9340.1523	loss_val: 9340.1729	loss_test: 9340.0811	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7114.8477	loss_val: 7114.8623	loss_test: 7114.8599	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5298.3545	loss_val: 5298.7954	loss_test: 5299.5698	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6352.5513	loss_val: 6352.8862	loss_test: 6354.3882	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 10864.6377	loss_val: 10864.6943	loss_test: 10865.1514	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5622.6230	loss_val: 5622.5557	loss_test: 5623.7666	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4912.0801	loss_val: 4912.2842	loss_test: 4912.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4533.3418	loss_val: 4533.3267	loss_test: 4533.3008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6882.3145	loss_val: 6883.0737	loss_test: 6882.8472	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 58738.6797	loss_val: 58738.5820	loss_test: 58738.8242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6715.7612	loss_val: 6715.7554	loss_test: 6716.0269	accuracy_train: 0.9388	accuracy_val: 0.9167	accuracy_test: 0.6923
curr_round: 46	curr_val_accuracy: 0.8410	curr_test_accuracy: 0.7535
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6292.1685	loss_val: 6293.1274	loss_test: 6292.6587	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13469.6338	loss_val: 13469.8613	loss_test: 13470.0879	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 48127.6836	loss_val: 48127.9453	loss_test: 48128.3164	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 47867.6406	loss_val: 47867.6172	loss_test: 47867.7617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8210.5850	loss_val: 8211.5244	loss_test: 8210.7852	accuracy_train: 0.9259	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 4707.2314	loss_val: 4707.2593	loss_test: 4707.2402	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7469.5093	loss_val: 7469.5454	loss_test: 7469.8018	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7704.4106	loss_val: 7704.5410	loss_test: 7704.4106	accuracy_train: 0.5714	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10212.1436	loss_val: 10212.8535	loss_test: 10212.6426	accuracy_train: 0.8542	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 9524.0107	loss_val: 9524.0400	loss_test: 9523.9424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7069.8086	loss_val: 7069.8242	loss_test: 7069.8228	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5235.5103	loss_val: 5235.9717	loss_test: 5236.7153	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6428.2778	loss_val: 6428.6074	loss_test: 6430.2314	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 10879.5098	loss_val: 10879.5596	loss_test: 10880.0352	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5680.9580	loss_val: 5680.8945	loss_test: 5682.1328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4925.5801	loss_val: 4925.7983	loss_test: 4926.4575	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4586.3979	loss_val: 4586.3862	loss_test: 4586.3628	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6884.6060	loss_val: 6885.3882	loss_test: 6885.1299	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 59508.4688	loss_val: 59508.3789	loss_test: 59508.6094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6805.6177	loss_val: 6805.6216	loss_test: 6805.8735	accuracy_train: 0.9388	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 47	curr_val_accuracy: 0.8323	curr_test_accuracy: 0.7535
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6315.2393	loss_val: 6316.2515	loss_test: 6315.7568	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13488.5684	loss_val: 13488.7939	loss_test: 13489.0215	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 48736.6641	loss_val: 48736.9102	loss_test: 48737.2969	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 49281.0156	loss_val: 49280.9922	loss_test: 49281.1406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8227.8682	loss_val: 8228.8643	loss_test: 8228.0908	accuracy_train: 0.9383	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 4719.8135	loss_val: 4719.8428	loss_test: 4719.8218	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7578.5640	loss_val: 7578.6025	loss_test: 7578.8560	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7629.9854	loss_val: 7630.1460	loss_test: 7630.0151	accuracy_train: 0.6429	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10392.2324	loss_val: 10392.9727	loss_test: 10392.7324	accuracy_train: 0.8542	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 9721.8809	loss_val: 9721.9180	loss_test: 9721.8145	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7046.8794	loss_val: 7046.8955	loss_test: 7046.8955	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5171.4390	loss_val: 5171.9219	loss_test: 5172.6294	accuracy_train: 0.9873	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 6493.6709	loss_val: 6493.9980	loss_test: 6495.7246	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 10922.0840	loss_val: 10922.1260	loss_test: 10922.6182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5729.5840	loss_val: 5729.5254	loss_test: 5730.7944	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4937.7500	loss_val: 4937.9800	loss_test: 4938.6372	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4631.7153	loss_val: 4631.7070	loss_test: 4631.6860	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6898.9004	loss_val: 6899.6904	loss_test: 6899.4194	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 60182.8359	loss_val: 60182.7500	loss_test: 60182.9727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6874.4565	loss_val: 6874.4736	loss_test: 6874.7075	accuracy_train: 0.9184	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 48	curr_val_accuracy: 0.8239	curr_test_accuracy: 0.7615
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6269.8208	loss_val: 6270.8408	loss_test: 6270.3208	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13520.6094	loss_val: 13520.8340	loss_test: 13521.0674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49489.4414	loss_val: 49489.6680	loss_test: 49490.0820	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 50964.7539	loss_val: 50964.7383	loss_test: 50964.8828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8233.6104	loss_val: 8234.6572	loss_test: 8233.8545	accuracy_train: 0.9383	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 4728.1426	loss_val: 4728.1738	loss_test: 4728.1504	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7688.6523	loss_val: 7688.6934	loss_test: 7688.9468	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7470.2144	loss_val: 7470.4243	loss_test: 7470.2935	accuracy_train: 0.7143	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 10568.5576	loss_val: 10569.3340	loss_test: 10569.0625	accuracy_train: 0.8333	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 9918.5449	loss_val: 9918.5869	loss_test: 9918.4795	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7039.8608	loss_val: 7039.8774	loss_test: 7039.8789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5127.5952	loss_val: 5128.1025	loss_test: 5128.7778	accuracy_train: 0.9873	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 6552.6104	loss_val: 6552.9375	loss_test: 6554.7173	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 10974.8594	loss_val: 10974.8965	loss_test: 10975.4004	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5766.0874	loss_val: 5766.0327	loss_test: 5767.3423	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4953.4336	loss_val: 4953.6768	loss_test: 4954.3398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4679.1440	loss_val: 4679.1392	loss_test: 4679.1201	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6889.8564	loss_val: 6890.6553	loss_test: 6890.3701	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 60861.5508	loss_val: 60861.4688	loss_test: 60861.6797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6891.4390	loss_val: 6891.4863	loss_test: 6891.7007	accuracy_train: 0.9184	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 49	curr_val_accuracy: 0.8158	curr_test_accuracy: 0.7520
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6246.8257	loss_val: 6247.8057	loss_test: 6247.2871	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 13495.8623	loss_val: 13496.0879	loss_test: 13496.2900	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 50245.5312	loss_val: 50245.7305	loss_test: 50246.1758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 52496.4102	loss_val: 52496.3945	loss_test: 52496.5391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8181.1567	loss_val: 8182.2588	loss_test: 8181.4180	accuracy_train: 0.9383	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 4740.0308	loss_val: 4740.0645	loss_test: 4740.0391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7813.2539	loss_val: 7813.2974	loss_test: 7813.5498	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7296.1675	loss_val: 7296.4302	loss_test: 7296.3047	accuracy_train: 0.8810	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10649.1221	loss_val: 10649.9336	loss_test: 10649.6436	accuracy_train: 0.8125	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 10161.8516	loss_val: 10161.8994	loss_test: 10161.7861	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7022.8076	loss_val: 7022.8247	loss_test: 7022.8286	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5144.6040	loss_val: 5145.1294	loss_test: 5145.7998	accuracy_train: 0.9873	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 6611.3955	loss_val: 6611.7256	loss_test: 6613.5449	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11037.0156	loss_val: 11037.0469	loss_test: 11037.5645	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5805.1060	loss_val: 5805.0537	loss_test: 5806.3857	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4965.9810	loss_val: 4966.2344	loss_test: 4966.9062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4725.3896	loss_val: 4725.3867	loss_test: 4725.3716	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6913.8887	loss_val: 6914.6978	loss_test: 6914.3945	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 61565.5547	loss_val: 61565.4766	loss_test: 61565.6758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6895.9429	loss_val: 6896.0195	loss_test: 6896.2178	accuracy_train: 0.9286	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 50	curr_val_accuracy: 0.8234	curr_test_accuracy: 0.7374
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6304.1392	loss_val: 6305.0889	loss_test: 6304.6201	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13461.3535	loss_val: 13461.5830	loss_test: 13461.7637	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 50067.1211	loss_val: 50067.3203	loss_test: 50067.7852	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 54023.3750	loss_val: 54023.3594	loss_test: 54023.5078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8137.3369	loss_val: 8138.5000	loss_test: 8137.6128	accuracy_train: 0.9506	accuracy_val: 0.9000	accuracy_test: 0.8182
[client 5]	loss_train: 4753.9419	loss_val: 4753.9790	loss_test: 4753.9512	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7930.2568	loss_val: 7930.3027	loss_test: 7930.5562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7109.0142	loss_val: 7109.3271	loss_test: 7109.2100	accuracy_train: 0.9048	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 10681.2637	loss_val: 10682.1084	loss_test: 10681.8135	accuracy_train: 0.8333	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 10396.2314	loss_val: 10396.2852	loss_test: 10396.1670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7010.8882	loss_val: 7010.9053	loss_test: 7010.9116	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5192.3965	loss_val: 5192.9424	loss_test: 5193.6167	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 6665.7529	loss_val: 6666.0854	loss_test: 6667.9204	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11081.2500	loss_val: 11081.2783	loss_test: 11081.8047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5833.1562	loss_val: 5833.1064	loss_test: 5834.5122	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4977.6289	loss_val: 4977.8999	loss_test: 4978.5767	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4779.6758	loss_val: 4779.6758	loss_test: 4779.6631	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6942.6357	loss_val: 6943.4604	loss_test: 6943.1323	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 62163.7812	loss_val: 62163.7070	loss_test: 62163.8984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6931.0166	loss_val: 6931.1187	loss_test: 6931.3018	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6923
curr_round: 51	curr_val_accuracy: 0.8147	curr_test_accuracy: 0.7600
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6502.2593	loss_val: 6503.2520	loss_test: 6502.9043	accuracy_train: 0.9600	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13443.7129	loss_val: 13443.9443	loss_test: 13444.1016	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 49790.3672	loss_val: 49790.5625	loss_test: 49791.0430	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 55658.7031	loss_val: 55658.6875	loss_test: 55658.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8118.2153	loss_val: 8119.4375	loss_test: 8118.5083	accuracy_train: 0.9506	accuracy_val: 0.9000	accuracy_test: 0.7273
[client 5]	loss_train: 4762.7285	loss_val: 4762.7681	loss_test: 4762.7388	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8044.7085	loss_val: 8044.7559	loss_test: 8045.0127	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6987.4204	loss_val: 6987.7725	loss_test: 6987.6694	accuracy_train: 0.9286	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 10589.2197	loss_val: 10590.1094	loss_test: 10589.8086	accuracy_train: 0.8750	accuracy_val: 0.0000	accuracy_test: 0.2857
[client 9]	loss_train: 10650.1895	loss_val: 10650.2510	loss_test: 10650.1299	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7009.3218	loss_val: 7009.3394	loss_test: 7009.3481	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5279.7998	loss_val: 5280.3682	loss_test: 5281.0566	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6705.2251	loss_val: 6705.5610	loss_test: 6707.3833	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11132.3047	loss_val: 11132.3320	loss_test: 11132.8613	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5870.4404	loss_val: 5870.3936	loss_test: 5871.8735	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4995.9727	loss_val: 4996.2573	loss_test: 4996.9360	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4824.3130	loss_val: 4824.3154	loss_test: 4824.3047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6981.6953	loss_val: 6982.5283	loss_test: 6982.1851	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 62953.8828	loss_val: 62953.8125	loss_test: 62953.9961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7001.3730	loss_val: 7001.4912	loss_test: 7001.6636	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6923
curr_round: 52	curr_val_accuracy: 0.8145	curr_test_accuracy: 0.7441
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6795.0908	loss_val: 6796.1528	loss_test: 6795.9009	accuracy_train: 0.8267	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 1]	loss_train: 13359.8740	loss_val: 13360.1162	loss_test: 13360.2021	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 49523.9219	loss_val: 49524.1133	loss_test: 49524.6094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 57222.7656	loss_val: 57222.7539	loss_test: 57222.8984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8082.0259	loss_val: 8083.3027	loss_test: 8082.3320	accuracy_train: 0.9506	accuracy_val: 0.9000	accuracy_test: 0.7273
[client 5]	loss_train: 4791.0093	loss_val: 4791.0508	loss_test: 4791.0205	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8157.6133	loss_val: 8157.6631	loss_test: 8157.9233	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6849.3691	loss_val: 6849.7544	loss_test: 6849.6675	accuracy_train: 0.9762	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 10388.1240	loss_val: 10389.0518	loss_test: 10388.7471	accuracy_train: 0.8958	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 10821.3340	loss_val: 10821.3975	loss_test: 10821.2803	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7005.3677	loss_val: 7005.3843	loss_test: 7005.3950	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5317.0381	loss_val: 5317.6235	loss_test: 5318.3115	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6729.7227	loss_val: 6730.0615	loss_test: 6731.8721	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11146.1201	loss_val: 11146.1465	loss_test: 11146.6797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5904.4307	loss_val: 5904.3857	loss_test: 5905.9492	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5013.8975	loss_val: 5014.1870	loss_test: 5014.8716	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4869.2930	loss_val: 4869.2983	loss_test: 4869.2876	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7018.5703	loss_val: 7019.4243	loss_test: 7019.0532	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 63462.2383	loss_val: 63462.1758	loss_test: 63462.3516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7079.9556	loss_val: 7080.0776	loss_test: 7080.2510	accuracy_train: 0.9388	accuracy_val: 0.7500	accuracy_test: 0.6923
curr_round: 53	curr_val_accuracy: 0.8151	curr_test_accuracy: 0.7336
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7056.3442	loss_val: 7057.4844	loss_test: 7057.2588	accuracy_train: 0.7867	accuracy_val: 0.4000	accuracy_test: 0.5000
[client 1]	loss_train: 13327.3350	loss_val: 13327.5869	loss_test: 13327.6318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 49215.2383	loss_val: 49215.4258	loss_test: 49215.9453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 58931.8750	loss_val: 58931.8594	loss_test: 58932.0078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8037.5000	loss_val: 8038.8311	loss_test: 8037.8115	accuracy_train: 0.9506	accuracy_val: 0.9000	accuracy_test: 0.7273
[client 5]	loss_train: 4829.5259	loss_val: 4829.5698	loss_test: 4829.5391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8262.2607	loss_val: 8262.3125	loss_test: 8262.5762	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6764.2808	loss_val: 6764.6895	loss_test: 6764.6147	accuracy_train: 0.9762	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10202.5908	loss_val: 10203.5654	loss_test: 10203.2520	accuracy_train: 0.9792	accuracy_val: 0.3333	accuracy_test: 0.2857
[client 9]	loss_train: 10971.3389	loss_val: 10971.4014	loss_test: 10971.2900	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6996.5576	loss_val: 6996.5742	loss_test: 6996.5864	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5308.0342	loss_val: 5308.6328	loss_test: 5309.3037	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6744.4253	loss_val: 6744.7690	loss_test: 6746.5571	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11169.0635	loss_val: 11169.0928	loss_test: 11169.6279	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5949.5327	loss_val: 5949.4893	loss_test: 5951.1431	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5024.7354	loss_val: 5025.0391	loss_test: 5025.7319	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4914.3496	loss_val: 4914.3574	loss_test: 4914.3477	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7064.1899	loss_val: 7065.0669	loss_test: 7064.6650	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 64139.4375	loss_val: 64139.3789	loss_test: 64139.5469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7169.8535	loss_val: 7169.9766	loss_test: 7170.1504	accuracy_train: 0.9388	accuracy_val: 0.7500	accuracy_test: 0.6923
curr_round: 54	curr_val_accuracy: 0.8156	curr_test_accuracy: 0.7345
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7157.5591	loss_val: 7158.7441	loss_test: 7158.5254	accuracy_train: 0.7467	accuracy_val: 0.4000	accuracy_test: 0.5000
[client 1]	loss_train: 13347.9727	loss_val: 13348.2354	loss_test: 13348.2451	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 48917.5195	loss_val: 48917.7031	loss_test: 48918.2422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 60230.3203	loss_val: 60230.3086	loss_test: 60230.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8079.0347	loss_val: 8080.4102	loss_test: 8079.3564	accuracy_train: 0.9506	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4852.8062	loss_val: 4852.8525	loss_test: 4852.8213	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8361.0400	loss_val: 8361.0938	loss_test: 8361.3604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6715.3794	loss_val: 6715.8076	loss_test: 6715.7368	accuracy_train: 0.9762	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10074.8936	loss_val: 10075.9062	loss_test: 10075.5850	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 11200.2734	loss_val: 11200.3330	loss_test: 11200.2305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6977.4507	loss_val: 6977.4668	loss_test: 6977.4810	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5166.3452	loss_val: 5166.9595	loss_test: 5167.5684	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6736.8867	loss_val: 6737.2422	loss_test: 6738.9824	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11190.7363	loss_val: 11190.7686	loss_test: 11191.3076	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5982.3330	loss_val: 5982.2910	loss_test: 5984.0005	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5037.8042	loss_val: 5038.1187	loss_test: 5038.8159	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4949.2661	loss_val: 4949.2764	loss_test: 4949.2676	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7101.1479	loss_val: 7102.0469	loss_test: 7101.6143	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 64585.0742	loss_val: 64585.0195	loss_test: 64585.1836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7261.7871	loss_val: 7261.9082	loss_test: 7262.0830	accuracy_train: 0.9286	accuracy_val: 0.7500	accuracy_test: 0.6923
curr_round: 55	curr_val_accuracy: 0.8070	curr_test_accuracy: 0.7493
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7091.4497	loss_val: 7092.6553	loss_test: 7092.4243	accuracy_train: 0.7733	accuracy_val: 0.4000	accuracy_test: 0.5000
[client 1]	loss_train: 13323.0957	loss_val: 13323.3701	loss_test: 13323.3486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 48557.8789	loss_val: 48558.0938	loss_test: 48558.6250	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 61827.8906	loss_val: 61827.8828	loss_test: 61828.0312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8105.8975	loss_val: 8107.3203	loss_test: 8106.2295	accuracy_train: 0.9506	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4879.4775	loss_val: 4879.5264	loss_test: 4879.4951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8446.1387	loss_val: 8446.1953	loss_test: 8446.4658	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6686.8369	loss_val: 6687.2808	loss_test: 6687.2119	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9972.8916	loss_val: 9973.9355	loss_test: 9973.6201	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 11380.2578	loss_val: 11380.3135	loss_test: 11380.2178	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6953.4897	loss_val: 6953.5068	loss_test: 6953.5220	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4994.1250	loss_val: 4994.7598	loss_test: 4995.3032	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6729.3809	loss_val: 6729.7520	loss_test: 6731.4414	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11210.9160	loss_val: 11210.9482	loss_test: 11211.4941	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6007.7773	loss_val: 6007.7373	loss_test: 6009.5132	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5057.6094	loss_val: 5057.9346	loss_test: 5058.6377	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4976.3838	loss_val: 4976.3950	loss_test: 4976.3872	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7127.7651	loss_val: 7128.6899	loss_test: 7128.2285	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 64856.6094	loss_val: 64856.5547	loss_test: 64856.7148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7224.4717	loss_val: 7224.5923	loss_test: 7224.7969	accuracy_train: 0.9388	accuracy_val: 0.7500	accuracy_test: 0.6923
curr_round: 56	curr_val_accuracy: 0.8162	curr_test_accuracy: 0.7656
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6982.0903	loss_val: 6983.3247	loss_test: 6983.0552	accuracy_train: 0.8000	accuracy_val: 0.4000	accuracy_test: 0.5000
[client 1]	loss_train: 13289.8555	loss_val: 13290.1445	loss_test: 13290.0947	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 48627.0156	loss_val: 48627.2578	loss_test: 48627.7852	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63166.7656	loss_val: 63166.7539	loss_test: 63166.9023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8094.9409	loss_val: 8096.4131	loss_test: 8095.2803	accuracy_train: 0.9506	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4894.0029	loss_val: 4894.0527	loss_test: 4894.0215	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8517.1924	loss_val: 8517.2480	loss_test: 8517.5244	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6681.8037	loss_val: 6682.2554	loss_test: 6682.1899	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9917.7920	loss_val: 9918.8516	loss_test: 9918.5645	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 11511.3477	loss_val: 11511.4004	loss_test: 11511.3105	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6933.8057	loss_val: 6933.8232	loss_test: 6933.8394	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4835.2920	loss_val: 4835.9478	loss_test: 4836.4351	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6724.6089	loss_val: 6724.9995	loss_test: 6726.6245	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11231.4561	loss_val: 11231.4863	loss_test: 11232.0449	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6032.8608	loss_val: 6032.8223	loss_test: 6034.6870	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5054.6465	loss_val: 5054.9746	loss_test: 5055.6880	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4996.2754	loss_val: 4996.2881	loss_test: 4996.2812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7138.8618	loss_val: 7139.7959	loss_test: 7139.3252	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 65159.5391	loss_val: 65159.4883	loss_test: 65159.6445	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7235.4082	loss_val: 7235.5288	loss_test: 7235.7485	accuracy_train: 0.9490	accuracy_val: 0.7500	accuracy_test: 0.6923
curr_round: 57	curr_val_accuracy: 0.8162	curr_test_accuracy: 0.7656
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6756.1553	loss_val: 6757.3667	loss_test: 6757.0537	accuracy_train: 0.8933	accuracy_val: 0.4000	accuracy_test: 0.5000
[client 1]	loss_train: 13316.1221	loss_val: 13316.4277	loss_test: 13316.3516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 48702.8438	loss_val: 48703.1055	loss_test: 48703.6406	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 64080.2852	loss_val: 64080.2773	loss_test: 64080.4258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8101.2188	loss_val: 8102.7417	loss_test: 8101.5718	accuracy_train: 0.9506	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4901.3174	loss_val: 4901.3677	loss_test: 4901.3374	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8594.0410	loss_val: 8594.0977	loss_test: 8594.3770	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6666.1729	loss_val: 6666.6362	loss_test: 6666.5718	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9884.2148	loss_val: 9885.2930	loss_test: 9885.0225	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 11635.7803	loss_val: 11635.8311	loss_test: 11635.7461	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6926.0669	loss_val: 6926.0845	loss_test: 6926.1016	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4690.3516	loss_val: 4691.0405	loss_test: 4691.4619	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6710.2534	loss_val: 6710.6631	loss_test: 6712.2056	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11276.6328	loss_val: 11276.6631	loss_test: 11277.2256	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6051.9785	loss_val: 6051.9409	loss_test: 6053.8628	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5065.5415	loss_val: 5065.8774	loss_test: 5066.6035	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 5006.1157	loss_val: 5006.1299	loss_test: 5006.1226	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7157.5601	loss_val: 7158.5039	loss_test: 7158.0283	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 65613.2969	loss_val: 65613.2500	loss_test: 65613.3984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7245.2388	loss_val: 7245.3594	loss_test: 7245.5918	accuracy_train: 0.9490	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 58	curr_val_accuracy: 0.8130	curr_test_accuracy: 0.7656
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6591.2183	loss_val: 6592.4209	loss_test: 6592.0449	accuracy_train: 0.9467	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 1]	loss_train: 13338.6611	loss_val: 13338.9727	loss_test: 13338.8887	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 48861.0664	loss_val: 48861.3242	loss_test: 48861.8828	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 65292.4258	loss_val: 65292.4141	loss_test: 65292.5664	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8010.4277	loss_val: 8011.9995	loss_test: 8010.7910	accuracy_train: 0.9753	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4902.6699	loss_val: 4902.7202	loss_test: 4902.6914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8653.3164	loss_val: 8653.3740	loss_test: 8653.6582	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6639.5977	loss_val: 6640.0679	loss_test: 6639.9980	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9856.0459	loss_val: 9857.1348	loss_test: 9856.8887	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 11786.7637	loss_val: 11786.8105	loss_test: 11786.7305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6928.5542	loss_val: 6928.5728	loss_test: 6928.5898	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4581.2632	loss_val: 4581.9858	loss_test: 4582.3442	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6692.4092	loss_val: 6692.8389	loss_test: 6694.2759	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11307.6445	loss_val: 11307.6768	loss_test: 11308.2441	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6053.0361	loss_val: 6052.9990	loss_test: 6054.9922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5055.4761	loss_val: 5055.8091	loss_test: 5056.5576	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 5014.8330	loss_val: 5014.8486	loss_test: 5014.8408	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7205.8931	loss_val: 7206.8350	loss_test: 7206.3730	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 65526.4922	loss_val: 65526.4453	loss_test: 65526.5898	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7177.1567	loss_val: 7177.2808	loss_test: 7177.5400	accuracy_train: 0.9694	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 59	curr_val_accuracy: 0.8211	curr_test_accuracy: 0.7736
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6519.3623	loss_val: 6520.5771	loss_test: 6520.1475	accuracy_train: 0.9733	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 1]	loss_train: 13369.6387	loss_val: 13369.9482	loss_test: 13369.8643	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 49002.9062	loss_val: 49003.1602	loss_test: 49003.7422	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 65727.3359	loss_val: 65727.3281	loss_test: 65727.4766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7926.5723	loss_val: 7928.2012	loss_test: 7926.9409	accuracy_train: 0.9877	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4888.1406	loss_val: 4888.1899	loss_test: 4888.1631	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8712.9873	loss_val: 8713.0439	loss_test: 8713.3369	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6565.8271	loss_val: 6566.3008	loss_test: 6566.2280	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9823.7061	loss_val: 9824.8164	loss_test: 9824.5781	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.4286
[client 9]	loss_train: 11878.8545	loss_val: 11878.8994	loss_test: 11878.8242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6922.1455	loss_val: 6922.1655	loss_test: 6922.1831	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4532.4424	loss_val: 4533.2095	loss_test: 4533.5044	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6680.2388	loss_val: 6680.6890	loss_test: 6682.0034	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11316.4932	loss_val: 11316.5254	loss_test: 11317.0986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6058.3638	loss_val: 6058.3281	loss_test: 6060.3989	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5046.2690	loss_val: 5046.5972	loss_test: 5047.3643	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 5017.7588	loss_val: 5017.7764	loss_test: 5017.7681	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7238.0005	loss_val: 7238.9448	loss_test: 7238.4902	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 65791.0312	loss_val: 65790.9844	loss_test: 65791.1250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7152.8735	loss_val: 7153.0078	loss_test: 7153.2769	accuracy_train: 0.9694	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 60	curr_val_accuracy: 0.8330	curr_test_accuracy: 0.7663
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6431.4478	loss_val: 6432.6436	loss_test: 6432.1724	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13354.0449	loss_val: 13354.3535	loss_test: 13354.2705	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 48830.9062	loss_val: 48831.1719	loss_test: 48831.7695	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 66389.5781	loss_val: 66389.5703	loss_test: 66389.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7865.1670	loss_val: 7866.8525	loss_test: 7865.5444	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4877.2876	loss_val: 4877.3364	loss_test: 4877.3115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8803.4414	loss_val: 8803.4990	loss_test: 8803.7988	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6481.7144	loss_val: 6482.1899	loss_test: 6482.1128	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9845.6436	loss_val: 9846.7559	loss_test: 9846.5293	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.4286
[client 9]	loss_train: 11934.2559	loss_val: 11934.2979	loss_test: 11934.2256	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6904.9810	loss_val: 6905.0020	loss_test: 6905.0190	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4517.2700	loss_val: 4518.0752	loss_test: 4518.3247	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6686.0815	loss_val: 6686.5488	loss_test: 6687.7427	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11330.2090	loss_val: 11330.2451	loss_test: 11330.8213	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6081.1284	loss_val: 6081.0928	loss_test: 6083.2134	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5041.9878	loss_val: 5042.3228	loss_test: 5043.1157	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 5032.2056	loss_val: 5032.2241	loss_test: 5032.2153	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7288.5322	loss_val: 7289.4893	loss_test: 7289.0278	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66126.1406	loss_val: 66126.0938	loss_test: 66126.2344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7156.5459	loss_val: 7156.6938	loss_test: 7156.9541	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 61	curr_val_accuracy: 0.8207	curr_test_accuracy: 0.7664
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6386.6724	loss_val: 6387.8584	loss_test: 6387.3604	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13341.3984	loss_val: 13341.7090	loss_test: 13341.6221	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 48547.2656	loss_val: 48547.5430	loss_test: 48548.1641	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 66839.2188	loss_val: 66839.2188	loss_test: 66839.3672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7761.0952	loss_val: 7762.8369	loss_test: 7761.4790	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4860.8213	loss_val: 4860.8691	loss_test: 4860.8467	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8877.5498	loss_val: 8877.6074	loss_test: 8877.9160	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6445.0986	loss_val: 6445.5752	loss_test: 6445.5034	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9899.7490	loss_val: 9900.8682	loss_test: 9900.6396	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.4286
[client 9]	loss_train: 11957.6387	loss_val: 11957.6807	loss_test: 11957.6104	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6899.8247	loss_val: 6899.8462	loss_test: 6899.8633	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4510.8403	loss_val: 4511.6714	loss_test: 4511.8931	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6681.1748	loss_val: 6681.6592	loss_test: 6682.7534	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11411.3232	loss_val: 11411.3652	loss_test: 11411.9395	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6087.9248	loss_val: 6087.8906	loss_test: 6090.0781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5037.4414	loss_val: 5037.7710	loss_test: 5038.5942	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5034.0356	loss_val: 5034.0562	loss_test: 5034.0464	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7311.7178	loss_val: 7312.7183	loss_test: 7312.2104	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66099.3672	loss_val: 66099.3281	loss_test: 66099.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7144.4785	loss_val: 7144.6382	loss_test: 7144.8979	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 62	curr_val_accuracy: 0.8240	curr_test_accuracy: 0.7605
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6355.8696	loss_val: 6357.0415	loss_test: 6356.5244	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13328.8438	loss_val: 13329.1523	loss_test: 13329.0645	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 48227.2266	loss_val: 48227.5156	loss_test: 48228.1562	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 67428.2891	loss_val: 67428.2891	loss_test: 67428.4375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7625.6260	loss_val: 7627.4111	loss_test: 7626.0073	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4858.5317	loss_val: 4858.5781	loss_test: 4858.5591	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8954.9541	loss_val: 8955.0117	loss_test: 8955.3262	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6410.7793	loss_val: 6411.2598	loss_test: 6411.1924	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9975.3633	loss_val: 9976.4971	loss_test: 9976.2393	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.4286
[client 9]	loss_train: 11999.7607	loss_val: 11999.8037	loss_test: 11999.7324	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6892.7422	loss_val: 6892.7646	loss_test: 6892.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4494.5439	loss_val: 4495.3799	loss_test: 4495.6152	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6683.6357	loss_val: 6684.1436	loss_test: 6685.1411	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11435.9756	loss_val: 11436.0215	loss_test: 11436.5928	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6093.0615	loss_val: 6093.0273	loss_test: 6095.2490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5031.7803	loss_val: 5032.1089	loss_test: 5032.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5031.6333	loss_val: 5031.6533	loss_test: 5031.6440	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7332.5483	loss_val: 7333.5791	loss_test: 7333.0371	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66273.5469	loss_val: 66273.5078	loss_test: 66273.6484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7101.3755	loss_val: 7101.5396	loss_test: 7101.8145	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 63	curr_val_accuracy: 0.8240	curr_test_accuracy: 0.7605
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6346.5176	loss_val: 6347.6753	loss_test: 6347.1685	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13355.3213	loss_val: 13355.6309	loss_test: 13355.5391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 48132.2539	loss_val: 48132.5312	loss_test: 48133.2031	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 68169.8594	loss_val: 68169.8594	loss_test: 68170.0078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7513.5811	loss_val: 7515.4106	loss_test: 7513.9663	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4852.3013	loss_val: 4852.3472	loss_test: 4852.3301	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9040.6201	loss_val: 9040.6797	loss_test: 9041.0000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6396.2192	loss_val: 6396.7070	loss_test: 6396.6445	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10060.7666	loss_val: 10061.9248	loss_test: 10061.6318	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 11991.3164	loss_val: 11991.3633	loss_test: 11991.2900	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6887.2017	loss_val: 6887.2246	loss_test: 6887.2397	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4472.4072	loss_val: 4473.2393	loss_test: 4473.5015	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6687.6948	loss_val: 6688.2227	loss_test: 6689.1416	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 11502.7744	loss_val: 11502.8301	loss_test: 11503.3936	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6101.5796	loss_val: 6101.5459	loss_test: 6103.8130	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5026.6992	loss_val: 5027.0210	loss_test: 5027.8916	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5030.4653	loss_val: 5030.4849	loss_test: 5030.4756	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7357.1289	loss_val: 7358.2041	loss_test: 7357.6128	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66332.8281	loss_val: 66332.7891	loss_test: 66332.9297	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7042.9966	loss_val: 7043.1646	loss_test: 7043.4580	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 64	curr_val_accuracy: 0.8240	curr_test_accuracy: 0.7832
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6340.0552	loss_val: 6341.1948	loss_test: 6340.6890	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13374.7129	loss_val: 13375.0225	loss_test: 13374.9346	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 47893.2109	loss_val: 47893.4805	loss_test: 47894.1836	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 68932.4688	loss_val: 68932.4688	loss_test: 68932.6172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7391.5259	loss_val: 7393.4043	loss_test: 7391.9136	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4851.0508	loss_val: 4851.0962	loss_test: 4851.0811	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9117.0547	loss_val: 9117.1152	loss_test: 9117.4434	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6382.2534	loss_val: 6382.7510	loss_test: 6382.6914	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10144.2129	loss_val: 10145.3682	loss_test: 10145.0693	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 12022.0508	loss_val: 12022.0938	loss_test: 12022.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6882.0625	loss_val: 6882.0864	loss_test: 6882.1006	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4445.4766	loss_val: 4446.2935	loss_test: 4446.6030	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6684.1021	loss_val: 6684.6392	loss_test: 6685.5483	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 11592.2246	loss_val: 11592.2900	loss_test: 11592.8447	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6106.4858	loss_val: 6106.4531	loss_test: 6108.7505	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5017.3315	loss_val: 5017.6445	loss_test: 5018.5464	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5032.1362	loss_val: 5032.1558	loss_test: 5032.1460	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7385.0835	loss_val: 7386.1895	loss_test: 7385.5605	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66679.6250	loss_val: 66679.5859	loss_test: 66679.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7007.4126	loss_val: 7007.5811	loss_test: 7007.8936	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 65	curr_val_accuracy: 0.7980	curr_test_accuracy: 0.7832
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6318.5737	loss_val: 6319.6826	loss_test: 6319.1670	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13373.5127	loss_val: 13373.8252	loss_test: 13373.7344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 47331.4727	loss_val: 47331.7578	loss_test: 47332.4688	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 69209.3984	loss_val: 69209.4062	loss_test: 69209.5547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7290.5410	loss_val: 7292.4688	loss_test: 7290.9292	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4861.6577	loss_val: 4861.7026	loss_test: 4861.6895	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9208.0439	loss_val: 9208.1055	loss_test: 9208.4385	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6308.3613	loss_val: 6308.8721	loss_test: 6308.8120	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10247.6221	loss_val: 10248.7939	loss_test: 10248.4609	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 12059.1406	loss_val: 12059.1807	loss_test: 12059.1143	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6882.0132	loss_val: 6882.0386	loss_test: 6882.0503	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4430.8105	loss_val: 4431.6147	loss_test: 4431.9648	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6673.0947	loss_val: 6673.6328	loss_test: 6674.5479	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 11671.0127	loss_val: 11671.0869	loss_test: 11671.6348	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6122.1909	loss_val: 6122.1587	loss_test: 6124.4814	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5013.7607	loss_val: 5014.0732	loss_test: 5015.0063	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5042.1230	loss_val: 5042.1426	loss_test: 5042.1328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7399.6011	loss_val: 7400.7344	loss_test: 7400.0747	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 67027.8047	loss_val: 67027.7656	loss_test: 67027.8984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7031.5186	loss_val: 7031.6870	loss_test: 7032.0005	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 66	curr_val_accuracy: 0.7980	curr_test_accuracy: 0.7832
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6342.3853	loss_val: 6343.4839	loss_test: 6342.9688	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13371.5039	loss_val: 13371.8086	loss_test: 13371.7275	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 46844.5273	loss_val: 46844.8242	loss_test: 46845.5469	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 69603.6641	loss_val: 69603.6641	loss_test: 69603.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7258.1460	loss_val: 7260.1128	loss_test: 7258.5312	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4875.4927	loss_val: 4875.5371	loss_test: 4875.5254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9303.7549	loss_val: 9303.8164	loss_test: 9304.1582	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6247.1289	loss_val: 6247.6543	loss_test: 6247.5854	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10395.6436	loss_val: 10396.8311	loss_test: 10396.4658	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 12101.7051	loss_val: 12101.7422	loss_test: 12101.6777	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6882.8198	loss_val: 6882.8457	loss_test: 6882.8569	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4443.0327	loss_val: 4443.8101	loss_test: 4444.2402	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6666.8760	loss_val: 6667.4043	loss_test: 6668.3804	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 11735.8262	loss_val: 11735.9082	loss_test: 11736.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6162.2056	loss_val: 6162.1733	loss_test: 6164.5195	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5016.7173	loss_val: 5017.0278	loss_test: 5017.9834	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5047.1860	loss_val: 5047.2046	loss_test: 5047.1948	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7399.8257	loss_val: 7401.0024	loss_test: 7400.3003	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 67319.6016	loss_val: 67319.5625	loss_test: 67319.6953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7046.9766	loss_val: 7047.1440	loss_test: 7047.4604	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 67	curr_val_accuracy: 0.8151	curr_test_accuracy: 0.7832
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6389.1514	loss_val: 6390.2471	loss_test: 6389.7236	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13404.2100	loss_val: 13404.5098	loss_test: 13404.4316	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 46367.7305	loss_val: 46368.0430	loss_test: 46368.7734	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 70165.4219	loss_val: 70165.4219	loss_test: 70165.5859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7304.5190	loss_val: 7306.5356	loss_test: 7304.9053	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4900.2969	loss_val: 4900.3408	loss_test: 4900.3296	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9349.3945	loss_val: 9349.4551	loss_test: 9349.8066	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6219.1802	loss_val: 6219.7158	loss_test: 6219.6348	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10529.8496	loss_val: 10531.0488	loss_test: 10530.6602	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 12124.4541	loss_val: 12124.4902	loss_test: 12124.4277	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6876.5156	loss_val: 6876.5410	loss_test: 6876.5527	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4503.9761	loss_val: 4504.7266	loss_test: 4505.2544	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6677.2539	loss_val: 6677.7725	loss_test: 6678.8281	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11802.9014	loss_val: 11802.9893	loss_test: 11803.5352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6210.3027	loss_val: 6210.2715	loss_test: 6212.6333	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5029.5303	loss_val: 5029.8418	loss_test: 5030.8267	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5057.4995	loss_val: 5057.5171	loss_test: 5057.5078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7409.7363	loss_val: 7410.9370	loss_test: 7410.2061	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67581.9609	loss_val: 67581.9219	loss_test: 67582.0547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7084.6304	loss_val: 7084.8013	loss_test: 7085.1084	accuracy_train: 0.9694	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 68	curr_val_accuracy: 0.8151	curr_test_accuracy: 0.7683
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6434.9507	loss_val: 6436.0576	loss_test: 6435.5181	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13413.4307	loss_val: 13413.7266	loss_test: 13413.6504	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 46285.6484	loss_val: 46285.9648	loss_test: 46286.7109	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 70691.7812	loss_val: 70691.7812	loss_test: 70691.9453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7354.9243	loss_val: 7356.9961	loss_test: 7355.3042	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4925.7114	loss_val: 4925.7544	loss_test: 4925.7437	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9406.2705	loss_val: 9406.3340	loss_test: 9406.6895	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6198.9517	loss_val: 6199.4917	loss_test: 6199.4009	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10669.2139	loss_val: 10670.4170	loss_test: 10670.0088	accuracy_train: 1.0000	accuracy_val: 0.1667	accuracy_test: 0.5714
[client 9]	loss_train: 12138.1348	loss_val: 12138.1709	loss_test: 12138.1094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6867.6519	loss_val: 6867.6758	loss_test: 6867.6875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4598.3813	loss_val: 4599.1162	loss_test: 4599.7236	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6701.8169	loss_val: 6702.3267	loss_test: 6703.4702	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11836.4561	loss_val: 11836.5449	loss_test: 11837.0996	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6279.0859	loss_val: 6279.0552	loss_test: 6281.4399	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5038.2656	loss_val: 5038.5718	loss_test: 5039.5840	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 5078.2402	loss_val: 5078.2573	loss_test: 5078.2476	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7407.3774	loss_val: 7408.5913	loss_test: 7407.8442	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67714.3203	loss_val: 67714.2812	loss_test: 67714.4141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7081.0552	loss_val: 7081.2300	loss_test: 7081.5444	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 69	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7743
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6466.1367	loss_val: 6467.2568	loss_test: 6466.6938	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13448.8398	loss_val: 13449.1279	loss_test: 13449.0605	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 46250.2852	loss_val: 46250.5898	loss_test: 46251.3555	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 70823.0547	loss_val: 70823.0547	loss_test: 70823.2266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7393.2183	loss_val: 7395.3457	loss_test: 7393.5850	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4943.8936	loss_val: 4943.9355	loss_test: 4943.9253	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9409.0088	loss_val: 9409.0723	loss_test: 9409.4307	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6182.5449	loss_val: 6183.0864	loss_test: 6182.9893	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10745.8174	loss_val: 10747.0381	loss_test: 10746.5977	accuracy_train: 1.0000	accuracy_val: 0.1667	accuracy_test: 0.5714
[client 9]	loss_train: 12098.0508	loss_val: 12098.0879	loss_test: 12098.0254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6870.5186	loss_val: 6870.5430	loss_test: 6870.5532	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4714.1997	loss_val: 4714.9448	loss_test: 4715.6074	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6709.4673	loss_val: 6709.9634	loss_test: 6711.2134	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11830.7480	loss_val: 11830.8379	loss_test: 11831.3975	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6329.4214	loss_val: 6329.3916	loss_test: 6331.7856	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5048.6924	loss_val: 5048.9878	loss_test: 5050.0278	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 5097.3477	loss_val: 5097.3638	loss_test: 5097.3540	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7401.4990	loss_val: 7402.7441	loss_test: 7401.9629	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67462.3750	loss_val: 67462.3359	loss_test: 67462.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7072.4072	loss_val: 7072.5820	loss_test: 7072.9053	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 70	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7823
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6495.0605	loss_val: 6496.1982	loss_test: 6495.6162	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13520.2637	loss_val: 13520.5303	loss_test: 13520.4834	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 46167.1289	loss_val: 46167.4258	loss_test: 46168.2109	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71293.2734	loss_val: 71293.2734	loss_test: 71293.4453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7475.6265	loss_val: 7477.8076	loss_test: 7475.9805	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4967.9414	loss_val: 4967.9814	loss_test: 4967.9722	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9437.2246	loss_val: 9437.2891	loss_test: 9437.6494	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6186.7407	loss_val: 6187.2783	loss_test: 6187.1763	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10840.1152	loss_val: 10841.3604	loss_test: 10840.8848	accuracy_train: 0.9792	accuracy_val: 0.1667	accuracy_test: 0.5714
[client 9]	loss_train: 12024.5908	loss_val: 12024.6289	loss_test: 12024.5674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6858.4565	loss_val: 6858.4810	loss_test: 6858.4907	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4859.2031	loss_val: 4859.9619	loss_test: 4860.6831	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6732.6831	loss_val: 6733.1685	loss_test: 6734.5068	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11802.7725	loss_val: 11802.8604	loss_test: 11803.4316	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6382.6978	loss_val: 6382.6685	loss_test: 6385.0435	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5066.6133	loss_val: 5066.9038	loss_test: 5067.9668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 5117.3960	loss_val: 5117.4116	loss_test: 5117.4014	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7410.0537	loss_val: 7411.3276	loss_test: 7410.5176	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67351.6719	loss_val: 67351.6406	loss_test: 67351.7656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7117.0688	loss_val: 7117.2471	loss_test: 7117.5654	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 71	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7823
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6497.8813	loss_val: 6499.0308	loss_test: 6498.4312	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13560.3535	loss_val: 13560.6025	loss_test: 13560.5723	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 46040.8828	loss_val: 46041.1602	loss_test: 46041.9648	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71440.4688	loss_val: 71440.4766	loss_test: 71440.6562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7548.0601	loss_val: 7550.2832	loss_test: 7548.4058	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4985.5195	loss_val: 4985.5581	loss_test: 4985.5493	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9488.7910	loss_val: 9488.8545	loss_test: 9489.2158	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6153.0015	loss_val: 6153.5352	loss_test: 6153.4268	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10897.2012	loss_val: 10898.4814	loss_test: 10897.9629	accuracy_train: 0.9792	accuracy_val: 0.1667	accuracy_test: 0.4286
[client 9]	loss_train: 11998.9209	loss_val: 11998.9619	loss_test: 11998.8994	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6858.1807	loss_val: 6858.2056	loss_test: 6858.2148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4932.1548	loss_val: 4932.9321	loss_test: 4933.6777	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6765.4858	loss_val: 6765.9580	loss_test: 6767.4141	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11788.0342	loss_val: 11788.1230	loss_test: 11788.7012	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6426.6445	loss_val: 6426.6162	loss_test: 6428.9858	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5082.2373	loss_val: 5082.5239	loss_test: 5083.5986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5136.1611	loss_val: 5136.1768	loss_test: 5136.1670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7429.0527	loss_val: 7430.3545	loss_test: 7429.5249	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67231.0156	loss_val: 67230.9844	loss_test: 67231.1094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7134.5615	loss_val: 7134.7524	loss_test: 7135.0601	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 72	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7690
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6452.0352	loss_val: 6453.2075	loss_test: 6452.5786	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13574.0391	loss_val: 13574.2773	loss_test: 13574.2568	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 45896.1250	loss_val: 45896.3711	loss_test: 45897.2070	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71616.2812	loss_val: 71616.2812	loss_test: 71616.4766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7576.1113	loss_val: 7578.3643	loss_test: 7576.4561	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5010.6353	loss_val: 5010.6733	loss_test: 5010.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9526.3477	loss_val: 9526.4111	loss_test: 9526.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6137.7739	loss_val: 6138.3003	loss_test: 6138.1909	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10890.3799	loss_val: 10891.6885	loss_test: 10891.1348	accuracy_train: 0.9792	accuracy_val: 0.1667	accuracy_test: 0.4286
[client 9]	loss_train: 11955.1436	loss_val: 11955.1875	loss_test: 11955.1230	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6861.7593	loss_val: 6861.7842	loss_test: 6861.7944	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4964.0757	loss_val: 4964.8716	loss_test: 4965.6157	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6802.2134	loss_val: 6802.6782	loss_test: 6804.2329	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11840.8242	loss_val: 11840.9150	loss_test: 11841.4951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6467.6768	loss_val: 6467.6494	loss_test: 6470.0288	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5107.0596	loss_val: 5107.3472	loss_test: 5108.4243	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 5154.8716	loss_val: 5154.8872	loss_test: 5154.8770	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7448.9932	loss_val: 7450.3169	loss_test: 7449.4707	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67051.8984	loss_val: 67051.8672	loss_test: 67051.9922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7235.0854	loss_val: 7235.2920	loss_test: 7235.5742	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 73	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7669
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6418.9624	loss_val: 6420.1646	loss_test: 6419.5195	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13598.5664	loss_val: 13598.7969	loss_test: 13598.7842	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 45557.3711	loss_val: 45557.6094	loss_test: 45558.4570	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 72106.6562	loss_val: 72106.6562	loss_test: 72106.8594	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7550.0830	loss_val: 7552.3721	loss_test: 7550.4375	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5016.9268	loss_val: 5016.9644	loss_test: 5016.9546	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9501.3359	loss_val: 9501.3975	loss_test: 9501.7832	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6143.8721	loss_val: 6144.3945	loss_test: 6144.2861	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10867.6592	loss_val: 10868.9863	loss_test: 10868.4102	accuracy_train: 0.9792	accuracy_val: 0.1667	accuracy_test: 0.4286
[client 9]	loss_train: 11906.7139	loss_val: 11906.7598	loss_test: 11906.6934	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6855.1367	loss_val: 6855.1616	loss_test: 6855.1724	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4903.9448	loss_val: 4904.7656	loss_test: 4905.4678	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6827.0801	loss_val: 6827.5381	loss_test: 6829.1660	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11948.2188	loss_val: 11948.3135	loss_test: 11948.8926	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6480.2070	loss_val: 6480.1802	loss_test: 6482.5454	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5112.5215	loss_val: 5112.8057	loss_test: 5113.8887	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 5168.5850	loss_val: 5168.6001	loss_test: 5168.5894	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7449.4917	loss_val: 7450.8379	loss_test: 7449.9790	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66825.5078	loss_val: 66825.4766	loss_test: 66825.5938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7300.9365	loss_val: 7301.1592	loss_test: 7301.4209	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 74	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7734
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6394.1191	loss_val: 6395.3472	loss_test: 6394.7026	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13594.2461	loss_val: 13594.4775	loss_test: 13594.4658	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 45032.8242	loss_val: 45033.0820	loss_test: 45033.9180	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71723.8594	loss_val: 71723.8594	loss_test: 71724.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7533.9775	loss_val: 7536.2832	loss_test: 7534.3457	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5014.2573	loss_val: 5014.2944	loss_test: 5014.2847	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9431.7617	loss_val: 9431.8174	loss_test: 9432.2275	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6186.3032	loss_val: 6186.8247	loss_test: 6186.7178	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10833.2637	loss_val: 10834.5889	loss_test: 10834.0195	accuracy_train: 0.9792	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 11853.3232	loss_val: 11853.3711	loss_test: 11853.3057	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6852.1045	loss_val: 6852.1294	loss_test: 6852.1401	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4808.3208	loss_val: 4809.1855	loss_test: 4809.8076	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6842.6172	loss_val: 6843.0771	loss_test: 6844.7231	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12051.4404	loss_val: 12051.5400	loss_test: 12052.1182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6465.4854	loss_val: 6465.4590	loss_test: 6467.7979	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5110.6504	loss_val: 5110.9365	loss_test: 5112.0186	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 5177.3252	loss_val: 5177.3389	loss_test: 5177.3291	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7442.0693	loss_val: 7443.4351	loss_test: 7442.5664	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66659.2969	loss_val: 66659.2656	loss_test: 66659.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7389.7666	loss_val: 7390.0146	loss_test: 7390.2383	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 75	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7660
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6385.9814	loss_val: 6387.2275	loss_test: 6386.5952	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13555.2861	loss_val: 13555.5264	loss_test: 13555.5059	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 44573.9062	loss_val: 44574.1797	loss_test: 44575.0117	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71406.5859	loss_val: 71406.5859	loss_test: 71406.7969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7377.2280	loss_val: 7379.5459	loss_test: 7377.5977	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5005.8247	loss_val: 5005.8623	loss_test: 5005.8521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9366.5107	loss_val: 9366.5625	loss_test: 9366.9873	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6231.4790	loss_val: 6232.0000	loss_test: 6231.8984	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10786.0391	loss_val: 10787.3574	loss_test: 10786.7891	accuracy_train: 0.9792	accuracy_val: 0.1667	accuracy_test: 0.4286
[client 9]	loss_train: 11802.4502	loss_val: 11802.4990	loss_test: 11802.4346	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6857.8037	loss_val: 6857.8281	loss_test: 6857.8389	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4697.4883	loss_val: 4698.4053	loss_test: 4698.9346	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6828.9985	loss_val: 6829.4575	loss_test: 6831.1211	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12147.3447	loss_val: 12147.4531	loss_test: 12148.0225	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6434.7427	loss_val: 6434.7168	loss_test: 6436.9951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5111.5171	loss_val: 5111.8105	loss_test: 5112.8896	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 5183.0107	loss_val: 5183.0234	loss_test: 5183.0142	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7447.4883	loss_val: 7448.8408	loss_test: 7447.9897	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66709.2500	loss_val: 66709.2188	loss_test: 66709.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7455.8730	loss_val: 7456.1475	loss_test: 7456.3354	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 76	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7734
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6375.6436	loss_val: 6376.9092	loss_test: 6376.2832	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13532.9746	loss_val: 13533.2246	loss_test: 13533.1953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 44272.5039	loss_val: 44272.7969	loss_test: 44273.6250	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71678.7656	loss_val: 71678.7656	loss_test: 71678.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7201.9121	loss_val: 7204.2451	loss_test: 7202.2847	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5000.8994	loss_val: 5000.9375	loss_test: 5000.9272	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9302.2500	loss_val: 9302.2988	loss_test: 9302.7363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6246.2827	loss_val: 6246.7988	loss_test: 6246.7051	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8571
[client 8]	loss_train: 10711.0498	loss_val: 10712.3545	loss_test: 10711.7949	accuracy_train: 0.9792	accuracy_val: 0.1667	accuracy_test: 0.4286
[client 9]	loss_train: 11749.8516	loss_val: 11749.9004	loss_test: 11749.8379	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6848.3833	loss_val: 6848.4072	loss_test: 6848.4194	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4612.0034	loss_val: 4612.9707	loss_test: 4613.4092	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6812.8940	loss_val: 6813.3540	loss_test: 6814.9980	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12336.5703	loss_val: 12336.6895	loss_test: 12337.2520	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6397.2490	loss_val: 6397.2231	loss_test: 6399.4785	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5099.5195	loss_val: 5099.8159	loss_test: 5100.8887	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 5186.1997	loss_val: 5186.2129	loss_test: 5186.2036	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7447.7397	loss_val: 7449.0767	loss_test: 7448.2490	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66458.9531	loss_val: 66458.9297	loss_test: 66459.0469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7516.2559	loss_val: 7516.5610	loss_test: 7516.7041	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 77	curr_val_accuracy: 0.7978	curr_test_accuracy: 0.7800
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6417.7827	loss_val: 6419.0869	loss_test: 6418.4722	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13502.8145	loss_val: 13503.0674	loss_test: 13503.0352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 43962.9062	loss_val: 43963.2188	loss_test: 43964.0430	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71626.5547	loss_val: 71626.5547	loss_test: 71626.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7078.5522	loss_val: 7080.9136	loss_test: 7078.9458	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4992.3511	loss_val: 4992.3892	loss_test: 4992.3789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9267.0889	loss_val: 9267.1357	loss_test: 9267.5801	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6222.3340	loss_val: 6222.8418	loss_test: 6222.7578	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8571
[client 8]	loss_train: 10557.0439	loss_val: 10558.3350	loss_test: 10557.7744	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 11702.0166	loss_val: 11702.0654	loss_test: 11702.0039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6832.6943	loss_val: 6832.7178	loss_test: 6832.7310	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4538.5103	loss_val: 4539.5171	loss_test: 4539.8818	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6798.0723	loss_val: 6798.5352	loss_test: 6800.1411	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12413.5420	loss_val: 12413.6641	loss_test: 12414.2275	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6372.8164	loss_val: 6372.7910	loss_test: 6375.0356	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5097.5459	loss_val: 5097.8413	loss_test: 5098.9087	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5181.1284	loss_val: 5181.1416	loss_test: 5181.1323	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7441.9468	loss_val: 7443.2334	loss_test: 7442.4648	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66535.4453	loss_val: 66535.4219	loss_test: 66535.5312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7521.1221	loss_val: 7521.4443	loss_test: 7521.5669	accuracy_train: 0.9694	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 78	curr_val_accuracy: 0.7980	curr_test_accuracy: 0.7895
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6481.6016	loss_val: 6482.9619	loss_test: 6482.3481	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13506.6064	loss_val: 13506.8672	loss_test: 13506.8320	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 43719.5000	loss_val: 43719.8281	loss_test: 43720.6602	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71378.0547	loss_val: 71378.0625	loss_test: 71378.2812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6987.7036	loss_val: 6990.0776	loss_test: 6988.1147	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4969.1040	loss_val: 4969.1411	loss_test: 4969.1318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9221.4590	loss_val: 9221.5049	loss_test: 9221.9541	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6208.5269	loss_val: 6209.0303	loss_test: 6208.9536	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8571
[client 8]	loss_train: 10417.6123	loss_val: 10418.8994	loss_test: 10418.3379	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 11650.7480	loss_val: 11650.7969	loss_test: 11650.7363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6823.9214	loss_val: 6823.9443	loss_test: 6823.9590	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4475.9429	loss_val: 4477.0098	loss_test: 4477.2769	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6754.5088	loss_val: 6754.9673	loss_test: 6756.5234	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12459.1260	loss_val: 12459.2529	loss_test: 12459.8154	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6325.2983	loss_val: 6325.2734	loss_test: 6327.4775	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5084.4370	loss_val: 5084.7300	loss_test: 5085.7778	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5173.2734	loss_val: 5173.2871	loss_test: 5173.2778	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7450.0508	loss_val: 7451.2964	loss_test: 7450.5767	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66592.9688	loss_val: 66592.9453	loss_test: 66593.0547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7452.2607	loss_val: 7452.5781	loss_test: 7452.7134	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 79	curr_val_accuracy: 0.7980	curr_test_accuracy: 0.7895
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6561.7505	loss_val: 6563.1768	loss_test: 6562.5732	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 13501.5791	loss_val: 13501.8496	loss_test: 13501.8086	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 43410.9961	loss_val: 43411.3438	loss_test: 43412.1836	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 70796.4531	loss_val: 70796.4609	loss_test: 70796.6875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6929.5801	loss_val: 6931.9678	loss_test: 6930.0142	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4942.8569	loss_val: 4942.8931	loss_test: 4942.8848	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9209.8584	loss_val: 9209.9023	loss_test: 9210.3555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6203.4180	loss_val: 6203.9194	loss_test: 6203.8506	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10319.8711	loss_val: 10321.1416	loss_test: 10320.5898	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 11570.3389	loss_val: 11570.3877	loss_test: 11570.3281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6811.2095	loss_val: 6811.2324	loss_test: 6811.2480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4457.3032	loss_val: 4458.4224	loss_test: 4458.6235	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 6730.9556	loss_val: 6731.4121	loss_test: 6732.9224	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12539.4854	loss_val: 12539.6191	loss_test: 12540.1768	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6301.2417	loss_val: 6301.2173	loss_test: 6303.4072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5085.6226	loss_val: 5085.9121	loss_test: 5086.9487	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5166.1406	loss_val: 5166.1558	loss_test: 5166.1460	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7439.4146	loss_val: 7440.6382	loss_test: 7439.9512	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66678.7969	loss_val: 66678.7734	loss_test: 66678.8828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7451.2056	loss_val: 7451.5308	loss_test: 7451.6562	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 80	curr_val_accuracy: 0.7980	curr_test_accuracy: 0.7584
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6697.6460	loss_val: 6699.1528	loss_test: 6698.5693	accuracy_train: 0.9467	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 1]	loss_train: 13489.1328	loss_val: 13489.4131	loss_test: 13489.3672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 43117.0742	loss_val: 43117.4414	loss_test: 43118.2852	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 70227.7891	loss_val: 70227.7969	loss_test: 70228.0156	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6872.7622	loss_val: 6875.1533	loss_test: 6873.2100	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4923.2749	loss_val: 4923.3096	loss_test: 4923.3018	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9177.2744	loss_val: 9177.3174	loss_test: 9177.7773	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6206.6021	loss_val: 6207.1079	loss_test: 6207.0410	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10260.5029	loss_val: 10261.7432	loss_test: 10261.2305	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 11513.0732	loss_val: 11513.1240	loss_test: 11513.0635	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6798.2515	loss_val: 6798.2744	loss_test: 6798.2920	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4459.8315	loss_val: 4460.9702	loss_test: 4461.1665	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6699.5005	loss_val: 6699.9600	loss_test: 6701.4116	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12610.8535	loss_val: 12610.9951	loss_test: 12611.5488	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6276.6782	loss_val: 6276.6543	loss_test: 6278.8354	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5064.2690	loss_val: 5064.5557	loss_test: 5065.5752	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5159.6855	loss_val: 5159.7026	loss_test: 5159.6919	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7430.7100	loss_val: 7431.9111	loss_test: 7431.2559	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66788.8359	loss_val: 66788.8125	loss_test: 66788.9297	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7458.6289	loss_val: 7458.9478	loss_test: 7459.0820	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 81	curr_val_accuracy: 0.7900	curr_test_accuracy: 0.7612
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6846.4688	loss_val: 6848.0562	loss_test: 6847.4961	accuracy_train: 0.9200	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 1]	loss_train: 13473.0049	loss_val: 13473.2969	loss_test: 13473.2432	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 42856.4062	loss_val: 42856.7891	loss_test: 42857.6406	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 69609.5000	loss_val: 69609.5078	loss_test: 69609.7266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6821.9258	loss_val: 6824.3325	loss_test: 6822.3877	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4906.6099	loss_val: 4906.6431	loss_test: 4906.6357	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9145.3311	loss_val: 9145.3740	loss_test: 9145.8408	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6228.1387	loss_val: 6228.6538	loss_test: 6228.5791	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10151.6445	loss_val: 10152.8613	loss_test: 10152.3779	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 11464.9932	loss_val: 11465.0439	loss_test: 11464.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6775.6045	loss_val: 6775.6270	loss_test: 6775.6460	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4459.4502	loss_val: 4460.5928	loss_test: 4460.8013	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6684.9189	loss_val: 6685.3926	loss_test: 6686.7500	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12679.4609	loss_val: 12679.6104	loss_test: 12680.1592	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6255.0635	loss_val: 6255.0400	loss_test: 6257.2407	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5046.8115	loss_val: 5047.0879	loss_test: 5048.0903	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5151.8623	loss_val: 5151.8809	loss_test: 5151.8691	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7418.8286	loss_val: 7419.9995	loss_test: 7419.3843	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66921.9766	loss_val: 66921.9531	loss_test: 66922.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7434.8052	loss_val: 7435.1064	loss_test: 7435.2637	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 82	curr_val_accuracy: 0.7900	curr_test_accuracy: 0.7535
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6951.5083	loss_val: 6953.1592	loss_test: 6952.5986	accuracy_train: 0.9200	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 1]	loss_train: 13513.6973	loss_val: 13514.0068	loss_test: 13513.9424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 42569.7109	loss_val: 42570.1016	loss_test: 42570.9570	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 69011.4688	loss_val: 69011.4844	loss_test: 69011.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6818.5786	loss_val: 6820.9473	loss_test: 6819.0361	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4896.6948	loss_val: 4896.7266	loss_test: 4896.7202	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9143.0781	loss_val: 9143.1211	loss_test: 9143.5889	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6246.2520	loss_val: 6246.7778	loss_test: 6246.6924	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 10107.6934	loss_val: 10108.8848	loss_test: 10108.4385	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 11418.8525	loss_val: 11418.9043	loss_test: 11418.8447	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6753.3403	loss_val: 6753.3628	loss_test: 6753.3818	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4469.0693	loss_val: 4470.1855	loss_test: 4470.4487	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6676.2896	loss_val: 6676.7769	loss_test: 6678.0537	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12757.1631	loss_val: 12757.3213	loss_test: 12757.8662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6241.9116	loss_val: 6241.8887	loss_test: 6244.0732	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5033.8628	loss_val: 5034.1211	loss_test: 5035.1069	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5150.6196	loss_val: 5150.6401	loss_test: 5150.6270	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7407.3604	loss_val: 7408.5098	loss_test: 7407.9302	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67072.2031	loss_val: 67072.1797	loss_test: 67072.2969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7390.3374	loss_val: 7390.6162	loss_test: 7390.8042	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 83	curr_val_accuracy: 0.7808	curr_test_accuracy: 0.7529
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7003.2944	loss_val: 7004.9971	loss_test: 7004.4087	accuracy_train: 0.8933	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 1]	loss_train: 13466.0684	loss_val: 13466.3896	loss_test: 13466.3154	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 42275.7578	loss_val: 42276.1562	loss_test: 42277.0156	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 68622.8438	loss_val: 68622.8594	loss_test: 68623.0781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6838.9805	loss_val: 6841.3032	loss_test: 6839.4258	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4894.1538	loss_val: 4894.1846	loss_test: 4894.1782	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9183.1230	loss_val: 9183.1670	loss_test: 9183.6279	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6272.6309	loss_val: 6273.1714	loss_test: 6273.0732	accuracy_train: 0.9762	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 9996.8916	loss_val: 9998.0547	loss_test: 9997.6787	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 11372.1523	loss_val: 11372.2041	loss_test: 11372.1445	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6731.3374	loss_val: 6731.3584	loss_test: 6731.3765	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4485.7485	loss_val: 4486.8325	loss_test: 4487.1519	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6684.4570	loss_val: 6684.9580	loss_test: 6686.1406	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12685.9248	loss_val: 12686.0801	loss_test: 12686.6318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6240.8193	loss_val: 6240.7969	loss_test: 6242.9834	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5037.0977	loss_val: 5037.3486	loss_test: 5038.3110	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5150.3872	loss_val: 5150.4087	loss_test: 5150.3945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7403.1948	loss_val: 7404.3086	loss_test: 7403.7739	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67207.4688	loss_val: 67207.4453	loss_test: 67207.5625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7381.2549	loss_val: 7381.5146	loss_test: 7381.7310	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 84	curr_val_accuracy: 0.7981	curr_test_accuracy: 0.7529
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6955.1011	loss_val: 6956.8032	loss_test: 6956.1738	accuracy_train: 0.9333	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 1]	loss_train: 13455.0908	loss_val: 13455.4209	loss_test: 13455.3398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 42064.1055	loss_val: 42064.5273	loss_test: 42065.3828	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 68246.9375	loss_val: 68246.9531	loss_test: 68247.1797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6930.7134	loss_val: 6932.9580	loss_test: 6931.1304	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4898.3643	loss_val: 4898.3950	loss_test: 4898.3887	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9224.5850	loss_val: 9224.6299	loss_test: 9225.0859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6264.2417	loss_val: 6264.8037	loss_test: 6264.6787	accuracy_train: 0.9762	accuracy_val: 0.4000	accuracy_test: 0.7143
[client 8]	loss_train: 9813.7129	loss_val: 9814.8750	loss_test: 9814.5654	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.4286
[client 9]	loss_train: 11411.7461	loss_val: 11411.7979	loss_test: 11411.7393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6723.4634	loss_val: 6723.4829	loss_test: 6723.5000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4513.9980	loss_val: 4515.0371	loss_test: 4515.4282	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6693.9077	loss_val: 6694.4165	loss_test: 6695.5757	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12581.3145	loss_val: 12581.4600	loss_test: 12582.0205	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6259.0811	loss_val: 6259.0596	loss_test: 6261.2549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5042.5249	loss_val: 5042.7778	loss_test: 5043.7134	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5159.9390	loss_val: 5159.9619	loss_test: 5159.9473	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7402.0806	loss_val: 7403.2061	loss_test: 7402.6699	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67547.6484	loss_val: 67547.6250	loss_test: 67547.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7401.0962	loss_val: 7401.3398	loss_test: 7401.5762	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 85	curr_val_accuracy: 0.8067	curr_test_accuracy: 0.7455
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6857.6572	loss_val: 6859.3267	loss_test: 6858.6445	accuracy_train: 0.9467	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 1]	loss_train: 13420.4697	loss_val: 13420.7969	loss_test: 13420.7139	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 41893.9727	loss_val: 41894.4023	loss_test: 41895.2656	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 68366.1406	loss_val: 68366.1562	loss_test: 68366.3750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7064.5439	loss_val: 7066.7402	loss_test: 7064.9424	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4905.8521	loss_val: 4905.8823	loss_test: 4905.8750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9265.4199	loss_val: 9265.4658	loss_test: 9265.9199	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6276.8936	loss_val: 6277.4775	loss_test: 6277.3228	accuracy_train: 0.9762	accuracy_val: 0.4000	accuracy_test: 0.8571
[client 8]	loss_train: 9684.3203	loss_val: 9685.4951	loss_test: 9685.2393	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 11445.9590	loss_val: 11446.0107	loss_test: 11445.9521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6711.9473	loss_val: 6711.9639	loss_test: 6711.9795	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4564.1792	loss_val: 4565.1636	loss_test: 4565.6367	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 6671.5337	loss_val: 6672.0356	loss_test: 6673.2734	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12447.9648	loss_val: 12448.0967	loss_test: 12448.6729	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6281.1709	loss_val: 6281.1494	loss_test: 6283.3203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5065.5391	loss_val: 5065.7837	loss_test: 5066.6982	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5162.3032	loss_val: 5162.3257	loss_test: 5162.3110	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7426.6089	loss_val: 7427.7368	loss_test: 7427.2041	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67753.8594	loss_val: 67753.8359	loss_test: 67753.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7449.4297	loss_val: 7449.6528	loss_test: 7449.9116	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.6923
curr_round: 86	curr_val_accuracy: 0.8241	curr_test_accuracy: 0.7675
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6761.0942	loss_val: 6762.7144	loss_test: 6761.9907	accuracy_train: 0.9600	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 1]	loss_train: 13387.0029	loss_val: 13387.3271	loss_test: 13387.2402	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 41610.8438	loss_val: 41611.2773	loss_test: 41612.1484	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 68061.7109	loss_val: 68061.7266	loss_test: 68061.9453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7266.0098	loss_val: 7268.2036	loss_test: 7266.4092	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4908.0312	loss_val: 4908.0620	loss_test: 4908.0542	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9317.1328	loss_val: 9317.1797	loss_test: 9317.6289	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6232.4756	loss_val: 6233.0781	loss_test: 6232.9058	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8571
[client 8]	loss_train: 9639.5264	loss_val: 9640.7012	loss_test: 9640.4941	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11497.0479	loss_val: 11497.0996	loss_test: 11497.0400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6720.5522	loss_val: 6720.5674	loss_test: 6720.5825	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4595.3257	loss_val: 4596.2720	loss_test: 4596.8008	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6646.6060	loss_val: 6647.1016	loss_test: 6648.4395	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12378.3291	loss_val: 12378.4512	loss_test: 12379.0400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6306.9155	loss_val: 6306.8945	loss_test: 6309.0513	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5095.9219	loss_val: 5096.1562	loss_test: 5097.0571	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5163.9795	loss_val: 5164.0029	loss_test: 5163.9883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7448.8525	loss_val: 7449.9673	loss_test: 7449.4487	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67952.3672	loss_val: 67952.3438	loss_test: 67952.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7442.1924	loss_val: 7442.3892	loss_test: 7442.6836	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.6923
curr_round: 87	curr_val_accuracy: 0.8325	curr_test_accuracy: 0.7675
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6644.8750	loss_val: 6646.4331	loss_test: 6645.6606	accuracy_train: 0.9600	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 1]	loss_train: 13350.8750	loss_val: 13351.1943	loss_test: 13351.1035	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 41370.9727	loss_val: 41371.5273	loss_test: 41372.3867	accuracy_train: 0.9714	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 68142.2422	loss_val: 68142.2578	loss_test: 68142.4766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7487.8013	loss_val: 7489.9980	loss_test: 7488.2173	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4910.4678	loss_val: 4910.4980	loss_test: 4910.4907	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9356.6641	loss_val: 9356.7119	loss_test: 9357.1572	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6181.5908	loss_val: 6182.1968	loss_test: 6182.0225	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8571
[client 8]	loss_train: 9630.5967	loss_val: 9631.7803	loss_test: 9631.5996	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11525.0488	loss_val: 11525.0996	loss_test: 11525.0400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6726.5088	loss_val: 6726.5234	loss_test: 6726.5376	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4604.6328	loss_val: 4605.5635	loss_test: 4606.1201	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6636.3687	loss_val: 6636.8647	loss_test: 6638.2817	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12293.4658	loss_val: 12293.5723	loss_test: 12294.1816	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6326.3052	loss_val: 6326.2842	loss_test: 6328.4810	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5113.1099	loss_val: 5113.3403	loss_test: 5114.2212	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5164.5898	loss_val: 5164.6138	loss_test: 5164.5996	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7478.2896	loss_val: 7479.3936	loss_test: 7478.8901	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 68051.7656	loss_val: 68051.7422	loss_test: 68051.8594	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7411.1182	loss_val: 7411.2866	loss_test: 7411.6162	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.6923
curr_round: 88	curr_val_accuracy: 0.8248	curr_test_accuracy: 0.7598
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6550.5215	loss_val: 6552.0308	loss_test: 6551.2173	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13373.7197	loss_val: 13374.0293	loss_test: 13373.9414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 41307.4609	loss_val: 41308.1094	loss_test: 41308.9688	accuracy_train: 0.9714	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 68278.8359	loss_val: 68278.8594	loss_test: 68279.0781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7694.9648	loss_val: 7697.1997	loss_test: 7695.4209	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4907.2173	loss_val: 4907.2476	loss_test: 4907.2402	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9420.0039	loss_val: 9420.0527	loss_test: 9420.4912	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6126.5864	loss_val: 6127.1904	loss_test: 6127.0176	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8571
[client 8]	loss_train: 9630.0996	loss_val: 9631.2930	loss_test: 9631.1318	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11524.2549	loss_val: 11524.3057	loss_test: 11524.2461	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6725.9629	loss_val: 6725.9766	loss_test: 6725.9902	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4569.5342	loss_val: 4570.4663	loss_test: 4571.0205	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6617.8345	loss_val: 6618.3276	loss_test: 6619.8447	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12234.9434	loss_val: 12235.0420	loss_test: 12235.6602	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6320.0225	loss_val: 6320.0020	loss_test: 6322.2349	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5121.6982	loss_val: 5121.9282	loss_test: 5122.7954	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5153.4351	loss_val: 5153.4590	loss_test: 5153.4453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7482.3105	loss_val: 7483.3965	loss_test: 7482.9160	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67842.6562	loss_val: 67842.6328	loss_test: 67842.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7112.5093	loss_val: 7112.6792	loss_test: 7113.0610	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 89	curr_val_accuracy: 0.8329	curr_test_accuracy: 0.7818
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6469.2778	loss_val: 6470.7490	loss_test: 6469.9150	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13361.8447	loss_val: 13362.1406	loss_test: 13362.0557	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 41253.8125	loss_val: 41254.5234	loss_test: 41255.3828	accuracy_train: 0.9714	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 68404.6797	loss_val: 68404.7031	loss_test: 68404.9219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7727.0029	loss_val: 7729.2695	loss_test: 7727.4956	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4896.8369	loss_val: 4896.8672	loss_test: 4896.8599	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9467.3838	loss_val: 9467.4336	loss_test: 9467.8652	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6140.7715	loss_val: 6141.3853	loss_test: 6141.2056	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8571
[client 8]	loss_train: 9650.1875	loss_val: 9651.3672	loss_test: 9651.2324	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11536.0654	loss_val: 11536.1172	loss_test: 11536.0566	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6725.9263	loss_val: 6725.9395	loss_test: 6725.9517	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4540.4990	loss_val: 4541.4272	loss_test: 4541.9839	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6592.0928	loss_val: 6592.5859	loss_test: 6594.1777	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12252.6143	loss_val: 12252.7109	loss_test: 12253.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6304.4907	loss_val: 6304.4702	loss_test: 6306.7173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5125.2373	loss_val: 5125.4668	loss_test: 5126.3252	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5137.4487	loss_val: 5137.4722	loss_test: 5137.4595	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7491.2256	loss_val: 7492.3018	loss_test: 7491.8340	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67952.5547	loss_val: 67952.5312	loss_test: 67952.6406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6910.2744	loss_val: 6910.5068	loss_test: 6910.8657	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 90	curr_val_accuracy: 0.8155	curr_test_accuracy: 0.7818
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6424.0752	loss_val: 6425.5303	loss_test: 6424.6836	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13365.6123	loss_val: 13365.8965	loss_test: 13365.8164	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 41043.7148	loss_val: 41044.4375	loss_test: 41045.2812	accuracy_train: 0.9714	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 68613.7031	loss_val: 68613.7266	loss_test: 68613.9375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7615.0181	loss_val: 7617.3232	loss_test: 7615.5327	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4889.5215	loss_val: 4889.5518	loss_test: 4889.5454	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9529.8613	loss_val: 9529.9131	loss_test: 9530.3340	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6095.4297	loss_val: 6096.0430	loss_test: 6095.8677	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8571
[client 8]	loss_train: 9691.3320	loss_val: 9692.5010	loss_test: 9692.3760	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11533.3506	loss_val: 11533.4014	loss_test: 11533.3408	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6717.1904	loss_val: 6717.2031	loss_test: 6717.2144	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4566.0352	loss_val: 4566.9224	loss_test: 4567.5229	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6574.5791	loss_val: 6575.0776	loss_test: 6576.7041	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12279.7988	loss_val: 12279.8916	loss_test: 12280.5273	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6305.2812	loss_val: 6305.2607	loss_test: 6307.5254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5138.2852	loss_val: 5138.5127	loss_test: 5139.3706	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5123.1392	loss_val: 5123.1621	loss_test: 5123.1494	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7493.0835	loss_val: 7494.1401	loss_test: 7493.6919	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67681.2266	loss_val: 67681.2031	loss_test: 67681.3125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6764.9209	loss_val: 6765.2612	loss_test: 6765.5474	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 91	curr_val_accuracy: 0.8242	curr_test_accuracy: 0.7818
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6403.1362	loss_val: 6404.5757	loss_test: 6403.7319	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13374.9922	loss_val: 13375.2686	loss_test: 13375.1914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 40868.8086	loss_val: 40869.4883	loss_test: 40870.3242	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 68598.1953	loss_val: 68598.2188	loss_test: 68598.4297	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7470.7075	loss_val: 7473.0625	loss_test: 7471.2222	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4884.3584	loss_val: 4884.3882	loss_test: 4884.3823	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9607.2871	loss_val: 9607.3418	loss_test: 9607.7529	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6073.7930	loss_val: 6074.4053	loss_test: 6074.2363	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 9737.7012	loss_val: 9738.8438	loss_test: 9738.7275	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11577.2412	loss_val: 11577.2910	loss_test: 11577.2305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6690.8936	loss_val: 6690.9058	loss_test: 6690.9165	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4626.1069	loss_val: 4626.9512	loss_test: 4627.6108	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6557.1465	loss_val: 6557.6572	loss_test: 6559.2793	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12305.4658	loss_val: 12305.5566	loss_test: 12306.1973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6308.9253	loss_val: 6308.9053	loss_test: 6311.1831	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5159.1313	loss_val: 5159.3545	loss_test: 5160.2061	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5113.1318	loss_val: 5113.1538	loss_test: 5113.1421	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7495.0132	loss_val: 7496.0640	loss_test: 7495.6201	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67266.6484	loss_val: 67266.6250	loss_test: 67266.7344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6702.6382	loss_val: 6703.0454	loss_test: 6703.2832	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 92	curr_val_accuracy: 0.8247	curr_test_accuracy: 0.7829
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6363.0752	loss_val: 6364.5020	loss_test: 6363.6729	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13341.3281	loss_val: 13341.5977	loss_test: 13341.5234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 40875.4336	loss_val: 40876.0195	loss_test: 40876.8594	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 68449.2734	loss_val: 68449.2969	loss_test: 68449.5000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7327.7148	loss_val: 7330.1230	loss_test: 7328.2295	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4874.9048	loss_val: 4874.9346	loss_test: 4874.9287	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9684.8379	loss_val: 9684.8945	loss_test: 9685.2939	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6028.6836	loss_val: 6029.2905	loss_test: 6029.1343	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 9753.4863	loss_val: 9754.6045	loss_test: 9754.5156	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11587.4248	loss_val: 11587.4717	loss_test: 11587.4131	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6673.8237	loss_val: 6673.8364	loss_test: 6673.8457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4660.1445	loss_val: 4660.9604	loss_test: 4661.6597	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6541.1875	loss_val: 6541.7104	loss_test: 6543.3154	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12341.2832	loss_val: 12341.3701	loss_test: 12342.0166	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6312.2720	loss_val: 6312.2520	loss_test: 6314.5664	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5163.1665	loss_val: 5163.3901	loss_test: 5164.2373	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5091.8013	loss_val: 5091.8228	loss_test: 5091.8115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7504.0684	loss_val: 7505.1128	loss_test: 7504.6782	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67144.7422	loss_val: 67144.7188	loss_test: 67144.8281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6658.7207	loss_val: 6659.1636	loss_test: 6659.3755	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 93	curr_val_accuracy: 0.8323	curr_test_accuracy: 0.7829
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6335.9224	loss_val: 6337.3301	loss_test: 6336.5410	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13344.1748	loss_val: 13344.4385	loss_test: 13344.3652	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 40908.7617	loss_val: 40909.2695	loss_test: 40910.1367	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 68396.6406	loss_val: 68396.6641	loss_test: 68396.8672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7168.9434	loss_val: 7171.4062	loss_test: 7169.4365	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4863.9009	loss_val: 4863.9307	loss_test: 4863.9253	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9750.2402	loss_val: 9750.2988	loss_test: 9750.6904	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5960.0137	loss_val: 5960.6099	loss_test: 5960.4678	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9778.2598	loss_val: 9779.3506	loss_test: 9779.2861	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11618.1514	loss_val: 11618.1953	loss_test: 11618.1387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6650.4482	loss_val: 6650.4604	loss_test: 6650.4697	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4644.1255	loss_val: 4644.9346	loss_test: 4645.6343	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6531.2021	loss_val: 6531.7266	loss_test: 6533.3643	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12338.7871	loss_val: 12338.8691	loss_test: 12339.5244	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6303.4702	loss_val: 6303.4512	loss_test: 6305.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5168.3145	loss_val: 5168.5376	loss_test: 5169.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5072.5640	loss_val: 5072.5854	loss_test: 5072.5747	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7522.9614	loss_val: 7523.9873	loss_test: 7523.5781	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67152.6094	loss_val: 67152.5859	loss_test: 67152.6953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6648.4619	loss_val: 6648.8979	loss_test: 6649.1123	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 94	curr_val_accuracy: 0.8237	curr_test_accuracy: 0.7842
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6345.5444	loss_val: 6346.9526	loss_test: 6346.1997	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13308.6143	loss_val: 13308.8848	loss_test: 13308.8076	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 41128.2617	loss_val: 41128.6875	loss_test: 41129.5938	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 68621.6875	loss_val: 68621.7031	loss_test: 68621.9062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7046.6919	loss_val: 7049.2129	loss_test: 7047.1577	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4857.5322	loss_val: 4857.5620	loss_test: 4857.5566	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9820.3281	loss_val: 9820.3867	loss_test: 9820.7705	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5903.3745	loss_val: 5903.9590	loss_test: 5903.8374	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9809.7197	loss_val: 9810.7695	loss_test: 9810.7373	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11639.7920	loss_val: 11639.8340	loss_test: 11639.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6635.8462	loss_val: 6635.8584	loss_test: 6635.8677	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4613.4253	loss_val: 4614.2373	loss_test: 4614.9204	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6525.5083	loss_val: 6526.0400	loss_test: 6527.6660	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12343.7256	loss_val: 12343.8057	loss_test: 12344.4648	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6316.3911	loss_val: 6316.3726	loss_test: 6318.8149	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5170.7178	loss_val: 5170.9375	loss_test: 5171.7900	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5062.4326	loss_val: 5062.4536	loss_test: 5062.4434	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7512.4731	loss_val: 7513.4971	loss_test: 7513.0967	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67216.9766	loss_val: 67216.9531	loss_test: 67217.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6656.9302	loss_val: 6657.3550	loss_test: 6657.5737	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 95	curr_val_accuracy: 0.8323	curr_test_accuracy: 0.7842
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6354.0625	loss_val: 6355.4624	loss_test: 6354.7456	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13265.0547	loss_val: 13265.3262	loss_test: 13265.2451	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 41377.6758	loss_val: 41378.0273	loss_test: 41378.9766	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 69165.4375	loss_val: 69165.4531	loss_test: 69165.6562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6967.6108	loss_val: 6970.1973	loss_test: 6968.0488	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4855.5293	loss_val: 4855.5596	loss_test: 4855.5542	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9922.1455	loss_val: 9922.2061	loss_test: 9922.5811	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5867.3320	loss_val: 5867.9062	loss_test: 5867.8096	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9882.3125	loss_val: 9883.3008	loss_test: 9883.3242	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 11669.5234	loss_val: 11669.5635	loss_test: 11669.5137	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6618.4355	loss_val: 6618.4478	loss_test: 6618.4561	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4569.1836	loss_val: 4570.0254	loss_test: 4570.6689	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6517.1421	loss_val: 6517.6768	loss_test: 6519.3022	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12347.6406	loss_val: 12347.7207	loss_test: 12348.3838	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6333.4238	loss_val: 6333.4053	loss_test: 6335.8755	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5178.7871	loss_val: 5179.0117	loss_test: 5179.8633	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5053.0962	loss_val: 5053.1177	loss_test: 5053.1074	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7511.3594	loss_val: 7512.3872	loss_test: 7511.9829	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67241.7266	loss_val: 67241.7031	loss_test: 67241.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6696.9546	loss_val: 6697.3477	loss_test: 6697.5850	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 96	curr_val_accuracy: 0.8323	curr_test_accuracy: 0.7918
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6361.2202	loss_val: 6362.6235	loss_test: 6361.9399	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13208.4590	loss_val: 13208.7500	loss_test: 13208.6572	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 41707.5156	loss_val: 41707.7930	loss_test: 41708.8008	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 69580.7812	loss_val: 69580.7969	loss_test: 69580.9922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6889.3916	loss_val: 6892.0488	loss_test: 6889.8091	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4851.8618	loss_val: 4851.8921	loss_test: 4851.8872	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10040.9512	loss_val: 10041.0127	loss_test: 10041.3799	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5837.6040	loss_val: 5838.1733	loss_test: 5838.0947	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9947.6670	loss_val: 9948.6123	loss_test: 9948.6797	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.4286
[client 9]	loss_train: 11698.5078	loss_val: 11698.5459	loss_test: 11698.4990	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6594.1904	loss_val: 6594.2026	loss_test: 6594.2104	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4544.7729	loss_val: 4545.6421	loss_test: 4546.2588	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6509.9546	loss_val: 6510.4883	loss_test: 6512.1157	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12366.6758	loss_val: 12366.7549	loss_test: 12367.4238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6355.8130	loss_val: 6355.7949	loss_test: 6358.2817	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5176.7070	loss_val: 5176.9355	loss_test: 5177.7925	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5043.1147	loss_val: 5043.1362	loss_test: 5043.1270	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7512.6670	loss_val: 7513.7124	loss_test: 7513.2871	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67173.1172	loss_val: 67173.0938	loss_test: 67173.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6763.5039	loss_val: 6763.8560	loss_test: 6764.1201	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 97	curr_val_accuracy: 0.8150	curr_test_accuracy: 0.7770
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6384.0249	loss_val: 6385.4429	loss_test: 6384.7891	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13150.8115	loss_val: 13151.1328	loss_test: 13151.0225	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 41980.4961	loss_val: 41980.7148	loss_test: 41981.7812	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 70298.2422	loss_val: 70298.2656	loss_test: 70298.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6809.3130	loss_val: 6812.0820	loss_test: 6809.7344	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4858.4346	loss_val: 4858.4648	loss_test: 4858.4604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10128.7930	loss_val: 10128.8564	loss_test: 10129.2168	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5889.6963	loss_val: 5890.2661	loss_test: 5890.1929	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10022.3984	loss_val: 10023.3096	loss_test: 10023.4053	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.4286
[client 9]	loss_train: 11727.3965	loss_val: 11727.4326	loss_test: 11727.3887	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6567.3760	loss_val: 6567.3882	loss_test: 6567.3955	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4532.1924	loss_val: 4533.0918	loss_test: 4533.6816	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6497.4580	loss_val: 6497.9912	loss_test: 6499.6064	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12356.2334	loss_val: 12356.3154	loss_test: 12356.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6368.4087	loss_val: 6368.3906	loss_test: 6370.8857	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5179.7129	loss_val: 5179.9448	loss_test: 5180.8008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5032.4316	loss_val: 5032.4541	loss_test: 5032.4448	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7495.7305	loss_val: 7496.7861	loss_test: 7496.3472	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67005.9375	loss_val: 67005.9141	loss_test: 67006.0312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6852.2773	loss_val: 6852.5889	loss_test: 6852.8779	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 98	curr_val_accuracy: 0.8237	curr_test_accuracy: 0.7770
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6417.8315	loss_val: 6419.2651	loss_test: 6418.6328	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13116.1865	loss_val: 13116.5391	loss_test: 13116.4082	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 42281.4766	loss_val: 42281.6445	loss_test: 42282.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 70949.9922	loss_val: 70950.0156	loss_test: 70950.2031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6804.5322	loss_val: 6807.3755	loss_test: 6804.9629	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.9091
[client 5]	loss_train: 4866.7969	loss_val: 4866.8276	loss_test: 4866.8232	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10216.8574	loss_val: 10216.9209	loss_test: 10217.2812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5933.8589	loss_val: 5934.4297	loss_test: 5934.3647	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10129.7178	loss_val: 10130.6094	loss_test: 10130.7246	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.4286
[client 9]	loss_train: 11748.0029	loss_val: 11748.0371	loss_test: 11747.9951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6552.8315	loss_val: 6552.8442	loss_test: 6552.8511	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4508.2422	loss_val: 4509.1929	loss_test: 4509.7358	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 6487.3652	loss_val: 6487.8984	loss_test: 6489.4795	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12405.0303	loss_val: 12405.1182	loss_test: 12405.7871	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6378.8062	loss_val: 6378.7881	loss_test: 6381.2778	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5177.6265	loss_val: 5177.8711	loss_test: 5178.7148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5028.6602	loss_val: 5028.6831	loss_test: 5028.6738	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7509.3442	loss_val: 7510.3906	loss_test: 7509.9526	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66710.9688	loss_val: 66710.9453	loss_test: 66711.0625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6991.7407	loss_val: 6992.0195	loss_test: 6992.3208	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 99	curr_val_accuracy: 0.8313	curr_test_accuracy: 0.7849
best_round: 42	best_val_accuracy: 0.8577	best_test_accuracy: 0.7742
--------------------------------------------------
