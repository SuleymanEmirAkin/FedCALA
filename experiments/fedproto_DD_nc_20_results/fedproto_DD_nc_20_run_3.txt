GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 0.8479	loss_val: 0.8405	loss_test: 0.8179	accuracy_train: 0.4133	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 1]	loss_train: 0.8071	loss_val: 0.7121	loss_test: 1.0561	accuracy_train: 0.2667	accuracy_val: 0.5000	accuracy_test: 0.0000
[client 2]	loss_train: 0.6481	loss_val: 0.6242	loss_test: 0.6552	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 0.7375	loss_val: 0.7880	loss_test: 0.7306	accuracy_train: 0.2167	accuracy_val: 0.0000	accuracy_test: 0.2222
[client 4]	loss_train: 0.6642	loss_val: 0.6609	loss_test: 0.6602	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 0.5459	loss_val: 0.5506	loss_test: 0.5475	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 0.7182	loss_val: 0.6999	loss_test: 0.7433	accuracy_train: 0.2683	accuracy_val: 0.4000	accuracy_test: 0.1429
[client 7]	loss_train: 0.7240	loss_val: 0.7484	loss_test: 0.7166	accuracy_train: 0.3333	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 0.7239	loss_val: 0.6641	loss_test: 0.7080	accuracy_train: 0.3750	accuracy_val: 0.5000	accuracy_test: 0.4286
[client 9]	loss_train: 0.3869	loss_val: 0.4398	loss_test: 0.3286	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 0.9384	loss_val: 0.9348	loss_test: 0.8370	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.2857
[client 11]	loss_train: 0.7006	loss_val: 0.7409	loss_test: 0.6854	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 0.6618	loss_val: 0.6658	loss_test: 0.6575	accuracy_train: 0.6765	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 0.5890	loss_val: 0.5777	loss_test: 0.6215	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 0.7398	loss_val: 0.0000	loss_test: 0.8667	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 0.6606	loss_val: 0.5994	loss_test: 0.6750	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 0.5158	loss_val: 0.5336	loss_test: 0.5209	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 0.6724	loss_val: 0.6493	loss_test: 0.6754	accuracy_train: 0.7037	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 0.5270	loss_val: 0.0544	loss_test: 0.6609	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 0.6984	loss_val: 0.6324	loss_test: 0.6644	accuracy_train: 0.5612	accuracy_val: 0.7500	accuracy_test: 0.6154
curr_round: 0	curr_val_accuracy: 0.5932	curr_test_accuracy: 0.5656
best_round: 0	best_val_accuracy: 0.5932	best_test_accuracy: 0.5656
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 284.1653	loss_val: 284.1528	loss_test: 284.1421	accuracy_train: 0.4133	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 1]	loss_train: 522.2848	loss_val: 522.2535	loss_test: 522.5637	accuracy_train: 0.2667	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 2]	loss_train: 2462.4648	loss_val: 2462.4797	loss_test: 2462.4951	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 610.9112	loss_val: 610.9389	loss_test: 610.9260	accuracy_train: 0.2833	accuracy_val: 0.1429	accuracy_test: 0.2222
[client 4]	loss_train: 365.2540	loss_val: 365.2563	loss_test: 365.2516	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 228.7231	loss_val: 228.7222	loss_test: 228.7202	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 181.0919	loss_val: 181.0908	loss_test: 181.1069	accuracy_train: 0.1220	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 7]	loss_train: 192.6322	loss_val: 192.6483	loss_test: 192.6403	accuracy_train: 0.3810	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 394.2020	loss_val: 394.1582	loss_test: 394.2116	accuracy_train: 0.6250	accuracy_val: 1.0000	accuracy_test: 0.5714
[client 9]	loss_train: 225.3349	loss_val: 225.3608	loss_test: 225.2614	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 171.5157	loss_val: 171.4959	loss_test: 171.4088	accuracy_train: 0.0000	accuracy_val: 0.1429	accuracy_test: 0.1429
[client 11]	loss_train: 212.9408	loss_val: 213.0025	loss_test: 212.9223	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 285.2993	loss_val: 285.3025	loss_test: 285.3162	accuracy_train: 0.7647	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 212.5641	loss_val: 212.5786	loss_test: 212.6258	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 137.1363	loss_val: 136.4128	loss_test: 137.2282	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 220.5678	loss_val: 220.5639	loss_test: 220.5900	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 204.4555	loss_val: 204.4678	loss_test: 204.4705	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 399.2264	loss_val: 399.1080	loss_test: 399.2786	accuracy_train: 0.6667	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 1168.6082	loss_val: 1167.9725	loss_test: 1168.6591	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 186.1703	loss_val: 186.0878	loss_test: 186.1376	accuracy_train: 0.6939	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 1	curr_val_accuracy: 0.6356	curr_test_accuracy: 0.5856
best_round: 1	best_val_accuracy: 0.6356	best_test_accuracy: 0.5856
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 450.8583	loss_val: 450.8496	loss_test: 450.8530	accuracy_train: 0.4133	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 1]	loss_train: 698.4277	loss_val: 698.4284	loss_test: 698.6959	accuracy_train: 0.2667	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 2]	loss_train: 3274.9121	loss_val: 3274.9480	loss_test: 3274.9351	accuracy_train: 0.4571	accuracy_val: 0.2000	accuracy_test: 0.2000
[client 3]	loss_train: 836.0777	loss_val: 836.0979	loss_test: 836.0941	accuracy_train: 0.3000	accuracy_val: 0.1429	accuracy_test: 0.2222
[client 4]	loss_train: 725.0784	loss_val: 725.0799	loss_test: 725.0711	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 300.1206	loss_val: 300.1153	loss_test: 300.1187	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 276.6117	loss_val: 276.6189	loss_test: 276.6380	accuracy_train: 0.4390	accuracy_val: 0.2000	accuracy_test: 0.1429
[client 7]	loss_train: 305.7146	loss_val: 305.7235	loss_test: 305.7215	accuracy_train: 0.5714	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 443.0370	loss_val: 443.0250	loss_test: 443.0409	accuracy_train: 0.7708	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 369.9765	loss_val: 370.0049	loss_test: 369.9092	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 278.5323	loss_val: 278.5135	loss_test: 278.4886	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 11]	loss_train: 375.5657	loss_val: 375.6352	loss_test: 375.5542	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 420.7125	loss_val: 420.7161	loss_test: 420.7235	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 382.2917	loss_val: 382.3125	loss_test: 382.3554	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 291.0633	loss_val: 290.3478	loss_test: 291.0974	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 352.0559	loss_val: 352.0741	loss_test: 352.0706	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 308.3543	loss_val: 308.3655	loss_test: 308.3665	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 670.3619	loss_val: 670.2976	loss_test: 670.3978	accuracy_train: 0.7778	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 1653.0315	loss_val: 1652.3107	loss_test: 1653.0116	accuracy_train: 0.2000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 336.6068	loss_val: 336.5119	loss_test: 336.5544	accuracy_train: 0.6837	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 2	curr_val_accuracy: 0.6214	curr_test_accuracy: 0.5732
best_round: 1	best_val_accuracy: 0.6356	best_test_accuracy: 0.5856
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 711.1914	loss_val: 711.2025	loss_test: 711.2046	accuracy_train: 0.4133	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 1]	loss_train: 994.0107	loss_val: 994.0201	loss_test: 994.2842	accuracy_train: 0.3333	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 2]	loss_train: 4708.4507	loss_val: 4708.4976	loss_test: 4708.4678	accuracy_train: 0.2857	accuracy_val: 0.2000	accuracy_test: 0.0000
[client 3]	loss_train: 1120.4357	loss_val: 1120.4497	loss_test: 1120.4463	accuracy_train: 0.3667	accuracy_val: 0.2857	accuracy_test: 0.5556
[client 4]	loss_train: 1156.6090	loss_val: 1156.6095	loss_test: 1156.5995	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 406.9178	loss_val: 406.9112	loss_test: 406.9173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 434.7095	loss_val: 434.7156	loss_test: 434.7498	accuracy_train: 0.9512	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 506.6352	loss_val: 506.6322	loss_test: 506.6369	accuracy_train: 0.6429	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 515.1794	loss_val: 515.1987	loss_test: 515.1807	accuracy_train: 0.8333	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 613.9105	loss_val: 613.9351	loss_test: 613.8511	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 422.4223	loss_val: 422.3988	loss_test: 422.4081	accuracy_train: 0.0000	accuracy_val: 0.1429	accuracy_test: 0.0000
[client 11]	loss_train: 598.7861	loss_val: 598.8264	loss_test: 598.7953	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 625.9426	loss_val: 625.9573	loss_test: 625.9431	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 741.0656	loss_val: 741.0881	loss_test: 741.1346	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 518.8002	loss_val: 518.1008	loss_test: 518.7876	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 527.6481	loss_val: 527.6665	loss_test: 527.6529	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 436.3137	loss_val: 436.3223	loss_test: 436.3184	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 1033.4646	loss_val: 1033.4760	loss_test: 1033.5049	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 2712.9868	loss_val: 2712.2373	loss_test: 2712.9429	accuracy_train: 0.2000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 575.3627	loss_val: 575.2583	loss_test: 575.3152	accuracy_train: 0.6939	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 3	curr_val_accuracy: 0.6682	curr_test_accuracy: 0.6113
best_round: 3	best_val_accuracy: 0.6682	best_test_accuracy: 0.6113
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1013.6120	loss_val: 1013.6436	loss_test: 1013.6469	accuracy_train: 0.6000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 1]	loss_train: 1395.5446	loss_val: 1395.5697	loss_test: 1395.8156	accuracy_train: 0.5333	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 2]	loss_train: 6413.8892	loss_val: 6413.9424	loss_test: 6413.9019	accuracy_train: 0.3714	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 1414.5420	loss_val: 1414.5588	loss_test: 1414.5575	accuracy_train: 0.7000	accuracy_val: 0.2857	accuracy_test: 0.7778
[client 4]	loss_train: 1598.1294	loss_val: 1598.1343	loss_test: 1598.1204	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 549.0148	loss_val: 549.0118	loss_test: 549.0111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 631.4890	loss_val: 631.4953	loss_test: 631.5359	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 765.9225	loss_val: 765.9135	loss_test: 765.9219	accuracy_train: 0.6429	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 610.2655	loss_val: 610.2796	loss_test: 610.2636	accuracy_train: 0.7500	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 906.2557	loss_val: 906.2758	loss_test: 906.2025	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 594.3633	loss_val: 594.3422	loss_test: 594.3279	accuracy_train: 0.0357	accuracy_val: 0.1429	accuracy_test: 0.1429
[client 11]	loss_train: 860.7473	loss_val: 860.7642	loss_test: 860.7730	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 869.4171	loss_val: 869.4375	loss_test: 869.4100	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 1299.3319	loss_val: 1299.3517	loss_test: 1299.4104	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 789.4538	loss_val: 788.7737	loss_test: 789.3936	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 726.5626	loss_val: 726.5822	loss_test: 726.5705	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 588.9207	loss_val: 588.9273	loss_test: 588.9243	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 1458.5719	loss_val: 1458.6348	loss_test: 1458.6211	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 4070.6509	loss_val: 4069.9177	loss_test: 4070.6221	accuracy_train: 0.2000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 873.1713	loss_val: 873.0609	loss_test: 873.1357	accuracy_train: 0.7143	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 4	curr_val_accuracy: 0.6833	curr_test_accuracy: 0.6691
best_round: 4	best_val_accuracy: 0.6833	best_test_accuracy: 0.6691
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1354.6459	loss_val: 1354.6892	loss_test: 1354.6908	accuracy_train: 0.6267	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 1903.0812	loss_val: 1903.1047	loss_test: 1903.3331	accuracy_train: 0.4667	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 2]	loss_train: 8316.3721	loss_val: 8316.4297	loss_test: 8316.3848	accuracy_train: 0.3714	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 1687.7917	loss_val: 1687.8068	loss_test: 1687.8147	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2045.9327	loss_val: 2045.9421	loss_test: 2045.9260	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 724.9048	loss_val: 724.9068	loss_test: 724.8973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 865.1550	loss_val: 865.1602	loss_test: 865.2070	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1054.5162	loss_val: 1054.5066	loss_test: 1054.5138	accuracy_train: 0.5476	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 737.8836	loss_val: 737.8824	loss_test: 737.8815	accuracy_train: 0.7083	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 1241.5769	loss_val: 1241.5946	loss_test: 1241.5286	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 792.4703	loss_val: 792.4503	loss_test: 792.4313	accuracy_train: 0.0536	accuracy_val: 0.2857	accuracy_test: 0.1429
[client 11]	loss_train: 1149.1088	loss_val: 1149.1057	loss_test: 1149.1521	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 1126.6869	loss_val: 1126.7123	loss_test: 1126.6779	accuracy_train: 0.7353	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 2001.6475	loss_val: 2001.6653	loss_test: 2001.7333	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1099.9860	loss_val: 1099.3231	loss_test: 1099.9003	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 952.4235	loss_val: 952.4398	loss_test: 952.4335	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 764.6074	loss_val: 764.6113	loss_test: 764.6099	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 1909.4824	loss_val: 1909.5885	loss_test: 1909.5413	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 5680.1934	loss_val: 5679.4722	loss_test: 5680.1802	accuracy_train: 0.2000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 1211.5344	loss_val: 1211.4207	loss_test: 1211.5083	accuracy_train: 0.7551	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 5	curr_val_accuracy: 0.7552	curr_test_accuracy: 0.6907
best_round: 5	best_val_accuracy: 0.7552	best_test_accuracy: 0.6907
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1732.3048	loss_val: 1732.3563	loss_test: 1732.3514	accuracy_train: 0.6667	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 2481.9470	loss_val: 2481.9805	loss_test: 2482.1648	accuracy_train: 0.5333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 10454.2051	loss_val: 10454.2529	loss_test: 10454.2188	accuracy_train: 0.3714	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 1942.4340	loss_val: 1942.4459	loss_test: 1942.4633	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2491.7083	loss_val: 2491.7219	loss_test: 2491.7051	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 929.6548	loss_val: 929.6586	loss_test: 929.6413	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1131.5212	loss_val: 1131.5266	loss_test: 1131.5736	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1373.1881	loss_val: 1373.1805	loss_test: 1373.1848	accuracy_train: 0.2619	accuracy_val: 0.4000	accuracy_test: 0.4286
[client 8]	loss_train: 900.4733	loss_val: 900.4528	loss_test: 900.4727	accuracy_train: 0.7292	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 1611.1002	loss_val: 1611.1156	loss_test: 1611.0536	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 1025.4990	loss_val: 1025.4802	loss_test: 1025.4561	accuracy_train: 0.0714	accuracy_val: 0.2857	accuracy_test: 0.1429
[client 11]	loss_train: 1454.9106	loss_val: 1454.8931	loss_test: 1454.9729	accuracy_train: 0.6203	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 1400.0421	loss_val: 1400.0709	loss_test: 1400.0311	accuracy_train: 0.7353	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 2864.3245	loss_val: 2864.3435	loss_test: 2864.4219	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1453.6819	loss_val: 1453.0364	loss_test: 1453.5660	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 1200.9049	loss_val: 1200.9188	loss_test: 1200.9148	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 968.5404	loss_val: 968.5420	loss_test: 968.5413	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 2348.3350	loss_val: 2348.4690	loss_test: 2348.4038	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 7517.1758	loss_val: 7516.4785	loss_test: 7517.1821	accuracy_train: 0.3000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 1572.0353	loss_val: 1571.9205	loss_test: 1572.0177	accuracy_train: 0.7857	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 6	curr_val_accuracy: 0.7705	curr_test_accuracy: 0.6915
best_round: 6	best_val_accuracy: 0.7705	best_test_accuracy: 0.6915
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2159.0591	loss_val: 2159.1187	loss_test: 2159.1028	accuracy_train: 0.6933	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 3129.9944	loss_val: 3130.0396	loss_test: 3130.1973	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 12824.4629	loss_val: 12824.4971	loss_test: 12824.4766	accuracy_train: 0.4000	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 2190.4248	loss_val: 2190.4358	loss_test: 2190.4602	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2947.5112	loss_val: 2947.5293	loss_test: 2947.5117	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1171.9531	loss_val: 1171.9579	loss_test: 1171.9347	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1429.0361	loss_val: 1429.0427	loss_test: 1429.0898	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1712.1678	loss_val: 1712.1630	loss_test: 1712.1616	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1096.5760	loss_val: 1096.5397	loss_test: 1096.5786	accuracy_train: 0.7083	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 9]	loss_train: 1993.5093	loss_val: 1993.5223	loss_test: 1993.4626	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 1293.9156	loss_val: 1293.8998	loss_test: 1293.8611	accuracy_train: 0.4107	accuracy_val: 0.4286	accuracy_test: 0.1429
[client 11]	loss_train: 1788.1793	loss_val: 1788.1519	loss_test: 1788.2607	accuracy_train: 0.6203	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 12]	loss_train: 1680.4635	loss_val: 1680.4951	loss_test: 1680.4503	accuracy_train: 0.6765	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 3855.6992	loss_val: 3855.7168	loss_test: 3855.8088	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 1838.5195	loss_val: 1837.8859	loss_test: 1838.3917	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1458.0184	loss_val: 1458.0352	loss_test: 1458.0319	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1199.3497	loss_val: 1199.3491	loss_test: 1199.3486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 2800.4719	loss_val: 2800.6160	loss_test: 2800.5483	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 9464.2617	loss_val: 9463.5967	loss_test: 9464.2920	accuracy_train: 0.7000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 19]	loss_train: 1967.5170	loss_val: 1967.4055	loss_test: 1967.5098	accuracy_train: 0.7755	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 7	curr_val_accuracy: 0.7784	curr_test_accuracy: 0.6891
best_round: 7	best_val_accuracy: 0.7784	best_test_accuracy: 0.6891
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2638.5510	loss_val: 2638.6160	loss_test: 2638.5920	accuracy_train: 0.7333	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 3840.6946	loss_val: 3840.7510	loss_test: 3840.8948	accuracy_train: 0.5333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 15345.1621	loss_val: 15345.1865	loss_test: 15345.1807	accuracy_train: 0.4286	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 2445.5894	loss_val: 2445.5991	loss_test: 2445.6301	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 3397.1973	loss_val: 3397.2197	loss_test: 3397.2014	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1440.4716	loss_val: 1440.4755	loss_test: 1440.4480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1756.1135	loss_val: 1756.1230	loss_test: 1756.1685	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2078.0723	loss_val: 2078.0706	loss_test: 2078.0623	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1329.4303	loss_val: 1329.3827	loss_test: 1329.4388	accuracy_train: 0.6875	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 9]	loss_train: 2389.5669	loss_val: 2389.5793	loss_test: 2389.5200	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 1590.2972	loss_val: 1590.2841	loss_test: 1590.2371	accuracy_train: 0.8571	accuracy_val: 0.8571	accuracy_test: 0.7143
[client 11]	loss_train: 2128.6592	loss_val: 2128.6240	loss_test: 2128.7598	accuracy_train: 0.6709	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 12]	loss_train: 1965.7627	loss_val: 1965.7944	loss_test: 1965.7533	accuracy_train: 0.7059	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 4956.1274	loss_val: 4956.1426	loss_test: 4956.2417	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2260.5281	loss_val: 2259.9050	loss_test: 2260.3892	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1734.8152	loss_val: 1734.8304	loss_test: 1734.8335	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1452.1139	loss_val: 1452.1116	loss_test: 1452.1102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 3225.7693	loss_val: 3225.9194	loss_test: 3225.8545	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 11556.1143	loss_val: 11555.4785	loss_test: 11556.1680	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 2380.2004	loss_val: 2380.0918	loss_test: 2380.2019	accuracy_train: 0.8061	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 8	curr_val_accuracy: 0.8039	curr_test_accuracy: 0.7351
best_round: 8	best_val_accuracy: 0.8039	best_test_accuracy: 0.7351
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3167.9312	loss_val: 3168.0015	loss_test: 3167.9695	accuracy_train: 0.7467	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 4607.6646	loss_val: 4607.7383	loss_test: 4607.8599	accuracy_train: 0.5333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 18113.9473	loss_val: 18113.9609	loss_test: 18113.9727	accuracy_train: 0.4286	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 2729.4026	loss_val: 2729.4133	loss_test: 2729.4478	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 3841.3057	loss_val: 3841.3323	loss_test: 3841.3145	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1729.2321	loss_val: 1729.2354	loss_test: 1729.2052	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2117.3176	loss_val: 2117.3269	loss_test: 2117.3750	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2465.5115	loss_val: 2465.5120	loss_test: 2465.5007	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1597.1094	loss_val: 1597.0521	loss_test: 1597.1217	accuracy_train: 0.7500	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 9]	loss_train: 2803.6030	loss_val: 2803.6177	loss_test: 2803.5564	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 1927.5835	loss_val: 1927.5730	loss_test: 1927.5214	accuracy_train: 0.9464	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 11]	loss_train: 2483.1230	loss_val: 2483.0815	loss_test: 2483.2432	accuracy_train: 0.7342	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 2249.7544	loss_val: 2249.7844	loss_test: 2249.7495	accuracy_train: 0.7353	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 6123.9976	loss_val: 6124.0078	loss_test: 6124.1191	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2679.1909	loss_val: 2678.5784	loss_test: 2679.0476	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2037.2502	loss_val: 2037.2651	loss_test: 2037.2725	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1726.4409	loss_val: 1726.4375	loss_test: 1726.4351	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 3663.5540	loss_val: 3663.7070	loss_test: 3663.6467	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 13714.7637	loss_val: 13714.1592	loss_test: 13714.8418	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 2816.4814	loss_val: 2816.3752	loss_test: 2816.4912	accuracy_train: 0.7755	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 9	curr_val_accuracy: 0.8129	curr_test_accuracy: 0.7602
best_round: 9	best_val_accuracy: 0.8129	best_test_accuracy: 0.7602
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3729.0808	loss_val: 3729.1577	loss_test: 3729.1169	accuracy_train: 0.7600	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 5356.6001	loss_val: 5356.6963	loss_test: 5356.7832	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 21056.9785	loss_val: 21056.9785	loss_test: 21057.0098	accuracy_train: 0.4286	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 3081.7109	loss_val: 3081.7175	loss_test: 3081.7600	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 4298.0566	loss_val: 4298.0889	loss_test: 4298.0684	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2039.1250	loss_val: 2039.1261	loss_test: 2039.0951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2489.4644	loss_val: 2489.4722	loss_test: 2489.5247	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2852.1011	loss_val: 2852.1025	loss_test: 2852.0862	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1900.7368	loss_val: 1900.6759	loss_test: 1900.7526	accuracy_train: 0.7292	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 9]	loss_train: 3217.0776	loss_val: 3217.0947	loss_test: 3217.0334	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 2290.1721	loss_val: 2290.1638	loss_test: 2290.1123	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 11]	loss_train: 2867.8254	loss_val: 2867.7791	loss_test: 2867.9663	accuracy_train: 0.7722	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 2536.3469	loss_val: 2536.3735	loss_test: 2536.3496	accuracy_train: 0.7647	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 7424.0669	loss_val: 7424.0747	loss_test: 7424.1948	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3128.9541	loss_val: 3128.3503	loss_test: 3128.8069	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2364.3977	loss_val: 2364.4124	loss_test: 2364.4231	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2004.6025	loss_val: 2004.5980	loss_test: 2004.5953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 4072.2502	loss_val: 4072.4053	loss_test: 4072.3489	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 15924.4873	loss_val: 15923.9072	loss_test: 15924.5840	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 3256.2705	loss_val: 3256.1687	loss_test: 3256.2905	accuracy_train: 0.8265	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 10	curr_val_accuracy: 0.8129	curr_test_accuracy: 0.7602
best_round: 9	best_val_accuracy: 0.8129	best_test_accuracy: 0.7602
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 4338.8774	loss_val: 4338.9619	loss_test: 4338.9126	accuracy_train: 0.7733	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 6100.3506	loss_val: 6100.4634	loss_test: 6100.5283	accuracy_train: 0.6000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 24212.4414	loss_val: 24212.4316	loss_test: 24212.4766	accuracy_train: 0.4286	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 3498.2173	loss_val: 3498.2195	loss_test: 3498.2715	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 4749.6240	loss_val: 4749.6626	loss_test: 4749.6372	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2353.8333	loss_val: 2353.8335	loss_test: 2353.8010	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2879.1819	loss_val: 2879.1890	loss_test: 2879.2446	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3237.0061	loss_val: 3237.0071	loss_test: 3236.9871	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2232.3877	loss_val: 2232.3242	loss_test: 2232.4072	accuracy_train: 0.8125	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 9]	loss_train: 3624.5688	loss_val: 3624.5891	loss_test: 3624.5281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 2674.0854	loss_val: 2674.0808	loss_test: 2674.0332	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3265.8889	loss_val: 3265.8396	loss_test: 3266.0505	accuracy_train: 0.7468	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 2834.9468	loss_val: 2834.9680	loss_test: 2834.9609	accuracy_train: 0.7647	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 8835.9541	loss_val: 8835.9590	loss_test: 8836.0879	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3596.8425	loss_val: 3596.2520	loss_test: 3596.6978	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2711.9395	loss_val: 2711.9514	loss_test: 2711.9697	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2283.3206	loss_val: 2283.3152	loss_test: 2283.3123	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 4481.7793	loss_val: 4481.9351	loss_test: 4481.8813	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 18116.0215	loss_val: 18115.4688	loss_test: 18116.1387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 3705.4788	loss_val: 3705.3794	loss_test: 3705.5083	accuracy_train: 0.8265	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 11	curr_val_accuracy: 0.8208	curr_test_accuracy: 0.7517
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 4969.4048	loss_val: 4969.4985	loss_test: 4969.4414	accuracy_train: 0.7733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 6805.0957	loss_val: 6805.2305	loss_test: 6805.2642	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 27622.7559	loss_val: 27622.7383	loss_test: 27622.7969	accuracy_train: 0.4857	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 3985.4028	loss_val: 3985.4016	loss_test: 3985.4580	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 5215.2700	loss_val: 5215.3120	loss_test: 5215.2803	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2667.1335	loss_val: 2667.1323	loss_test: 2667.0999	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3288.9915	loss_val: 3288.9971	loss_test: 3289.0576	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3625.3948	loss_val: 3625.3936	loss_test: 3625.3706	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2586.5635	loss_val: 2586.5029	loss_test: 2586.5879	accuracy_train: 0.7917	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 9]	loss_train: 4035.9836	loss_val: 4036.0059	loss_test: 4035.9463	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 3076.1179	loss_val: 3076.1177	loss_test: 3076.0735	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3667.4517	loss_val: 3667.3994	loss_test: 3667.6350	accuracy_train: 0.7722	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 3149.3650	loss_val: 3149.3784	loss_test: 3149.3962	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10310.0801	loss_val: 10310.0859	loss_test: 10310.2207	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4060.4429	loss_val: 4059.8647	loss_test: 4060.3027	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3071.1187	loss_val: 3071.1296	loss_test: 3071.1550	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2573.9602	loss_val: 2573.9524	loss_test: 2573.9502	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 4877.1172	loss_val: 4877.2715	loss_test: 4877.2236	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 20329.1914	loss_val: 20328.6543	loss_test: 20329.3184	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 4156.7266	loss_val: 4156.6328	loss_test: 4156.7661	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 12	curr_val_accuracy: 0.8197	curr_test_accuracy: 0.7598
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5623.8364	loss_val: 5623.9390	loss_test: 5623.8745	accuracy_train: 0.7733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 7470.2358	loss_val: 7470.3931	loss_test: 7470.4004	accuracy_train: 0.6667	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 2]	loss_train: 31253.5195	loss_val: 31253.4961	loss_test: 31253.5664	accuracy_train: 0.5143	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 4547.0562	loss_val: 4547.0527	loss_test: 4547.1128	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 5664.1172	loss_val: 5664.1616	loss_test: 5664.1226	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2971.7656	loss_val: 2971.7622	loss_test: 2971.7322	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3702.6770	loss_val: 3702.6821	loss_test: 3702.7468	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4020.6938	loss_val: 4020.6902	loss_test: 4020.6633	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2959.2183	loss_val: 2959.1599	loss_test: 2959.2461	accuracy_train: 0.7917	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 9]	loss_train: 4441.6484	loss_val: 4441.6719	loss_test: 4441.6143	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 3484.4609	loss_val: 3484.4648	loss_test: 3484.4236	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4084.7356	loss_val: 4084.6809	loss_test: 4084.9414	accuracy_train: 0.7848	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 3460.7778	loss_val: 3460.7815	loss_test: 3460.8315	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11778.4395	loss_val: 11778.4453	loss_test: 11778.5840	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4498.3877	loss_val: 4497.8203	loss_test: 4498.2524	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3437.3169	loss_val: 3437.3291	loss_test: 3437.3572	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2862.5762	loss_val: 2862.5662	loss_test: 2862.5652	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5249.4912	loss_val: 5249.6455	loss_test: 5249.6016	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 22549.5176	loss_val: 22549.0000	loss_test: 22549.6582	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 4597.4214	loss_val: 4597.3408	loss_test: 4597.4741	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 13	curr_val_accuracy: 0.8032	curr_test_accuracy: 0.7655
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6286.2881	loss_val: 6286.4004	loss_test: 6286.3286	accuracy_train: 0.7867	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 8097.0625	loss_val: 8097.2471	loss_test: 8097.2095	accuracy_train: 0.7333	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 2]	loss_train: 35044.1133	loss_val: 35044.0859	loss_test: 35044.1680	accuracy_train: 0.5143	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 5201.1006	loss_val: 5201.0967	loss_test: 5201.1577	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 6096.3940	loss_val: 6096.4414	loss_test: 6096.3960	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3278.6162	loss_val: 3278.6118	loss_test: 3278.5828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4118.3340	loss_val: 4118.3384	loss_test: 4118.4062	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4407.0269	loss_val: 4407.0166	loss_test: 4406.9888	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 3341.3706	loss_val: 3341.3193	loss_test: 3341.4014	accuracy_train: 0.8125	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 9]	loss_train: 4830.3154	loss_val: 4830.3398	loss_test: 4830.2837	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 3897.6118	loss_val: 3897.6194	loss_test: 3897.5820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4503.4072	loss_val: 4503.3511	loss_test: 4503.6377	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 3773.0354	loss_val: 3773.0303	loss_test: 3773.1123	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 13303.9346	loss_val: 13303.9346	loss_test: 13304.0850	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4899.8120	loss_val: 4899.2593	loss_test: 4899.6821	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3824.7886	loss_val: 3824.8010	loss_test: 3824.8328	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3125.4849	loss_val: 3125.4727	loss_test: 3125.4741	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5588.3018	loss_val: 5588.4517	loss_test: 5588.4160	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 24718.4746	loss_val: 24717.9766	loss_test: 24718.6289	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5010.1138	loss_val: 5010.0571	loss_test: 5010.1787	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 14	curr_val_accuracy: 0.7940	curr_test_accuracy: 0.7739
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6945.4849	loss_val: 6945.6074	loss_test: 6945.5283	accuracy_train: 0.8000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 8691.7676	loss_val: 8691.9805	loss_test: 8691.8984	accuracy_train: 0.8667	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 2]	loss_train: 38783.2109	loss_val: 38783.1758	loss_test: 38783.2734	accuracy_train: 0.5143	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 5901.6616	loss_val: 5901.6572	loss_test: 5901.7197	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 6524.6860	loss_val: 6524.7358	loss_test: 6524.6846	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3595.2244	loss_val: 3595.2180	loss_test: 3595.1919	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4530.0493	loss_val: 4530.0537	loss_test: 4530.1255	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4772.5552	loss_val: 4772.5356	loss_test: 4772.5103	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 3715.4744	loss_val: 3715.4297	loss_test: 3715.5076	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 5199.6289	loss_val: 5199.6548	loss_test: 5199.5991	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 4306.5601	loss_val: 4306.5708	loss_test: 4306.5361	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4930.3193	loss_val: 4930.2622	loss_test: 4930.5747	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 4074.5884	loss_val: 4074.5750	loss_test: 4074.6899	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 14868.8672	loss_val: 14868.8613	loss_test: 14869.0205	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5278.9004	loss_val: 5278.3569	loss_test: 5278.7817	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4206.2314	loss_val: 4206.2427	loss_test: 4206.2812	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3375.8320	loss_val: 3375.8179	loss_test: 3375.8215	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5918.9512	loss_val: 5919.0869	loss_test: 5919.0654	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 26740.1992	loss_val: 26739.7207	loss_test: 26740.3672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5423.8213	loss_val: 5423.7886	loss_test: 5423.8989	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 15	curr_val_accuracy: 0.7853	curr_test_accuracy: 0.7815
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7605.2065	loss_val: 7605.3389	loss_test: 7605.2534	accuracy_train: 0.8133	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 9243.7188	loss_val: 9243.9551	loss_test: 9243.8291	accuracy_train: 0.9333	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 2]	loss_train: 42386.6289	loss_val: 42386.5938	loss_test: 42386.6992	accuracy_train: 0.5429	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 6649.1133	loss_val: 6649.1094	loss_test: 6649.1724	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 6914.1162	loss_val: 6914.1714	loss_test: 6914.1133	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3904.0000	loss_val: 3903.9924	loss_test: 3903.9688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4940.1318	loss_val: 4940.1343	loss_test: 4940.2119	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5130.4951	loss_val: 5130.4644	loss_test: 5130.4434	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 4063.7659	loss_val: 4063.7285	loss_test: 4063.8030	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 5543.1533	loss_val: 5543.1812	loss_test: 5543.1250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 4702.5820	loss_val: 4702.5962	loss_test: 4702.5635	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5330.4209	loss_val: 5330.3628	loss_test: 5330.7021	accuracy_train: 0.8228	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 4383.7256	loss_val: 4383.7026	loss_test: 4383.8608	accuracy_train: 0.8529	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 16402.2422	loss_val: 16402.2305	loss_test: 16402.4004	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5641.3921	loss_val: 5640.8589	loss_test: 5641.2842	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4580.8271	loss_val: 4580.8394	loss_test: 4580.8799	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3598.4058	loss_val: 3598.3906	loss_test: 3598.3950	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6222.7656	loss_val: 6222.8887	loss_test: 6222.8804	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 28661.4824	loss_val: 28661.0254	loss_test: 28661.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5804.8926	loss_val: 5804.8862	loss_test: 5804.9829	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 16	curr_val_accuracy: 0.7853	curr_test_accuracy: 0.7815
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8229.5928	loss_val: 8229.7344	loss_test: 8229.6436	accuracy_train: 0.8400	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 9720.5039	loss_val: 9720.7666	loss_test: 9720.5898	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 2]	loss_train: 45924.7812	loss_val: 45924.7422	loss_test: 45924.8594	accuracy_train: 0.5714	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 7427.0513	loss_val: 7427.0493	loss_test: 7427.1128	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 7296.3535	loss_val: 7296.4165	loss_test: 7296.3491	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4193.8540	loss_val: 4193.8457	loss_test: 4193.8247	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5325.0420	loss_val: 5325.0439	loss_test: 5325.1274	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5470.8115	loss_val: 5470.7686	loss_test: 5470.7549	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 4412.9253	loss_val: 4412.8970	loss_test: 4412.9644	accuracy_train: 0.8333	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 5831.4883	loss_val: 5831.5171	loss_test: 5831.4614	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5076.8242	loss_val: 5076.8408	loss_test: 5076.8096	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5701.3960	loss_val: 5701.3394	loss_test: 5701.7026	accuracy_train: 0.8228	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 4671.6450	loss_val: 4671.6138	loss_test: 4671.8135	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 17855.8457	loss_val: 17855.8281	loss_test: 17856.0078	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5964.2983	loss_val: 5963.7793	loss_test: 5964.2056	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4938.6118	loss_val: 4938.6240	loss_test: 4938.6675	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3810.8337	loss_val: 3810.8176	loss_test: 3810.8228	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6520.0850	loss_val: 6520.1958	loss_test: 6520.2021	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 30422.4707	loss_val: 30422.0352	loss_test: 30422.6660	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6156.9009	loss_val: 6156.9194	loss_test: 6157.0034	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 17	curr_val_accuracy: 0.7853	curr_test_accuracy: 0.7731
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8824.6016	loss_val: 8824.7510	loss_test: 8824.6553	accuracy_train: 0.8400	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 10165.8350	loss_val: 10166.1230	loss_test: 10165.9014	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 49164.5469	loss_val: 49164.5039	loss_test: 49164.6367	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 8234.1660	loss_val: 8234.1641	loss_test: 8234.2305	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 7637.7202	loss_val: 7637.7935	loss_test: 7637.7139	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4462.2910	loss_val: 4462.2822	loss_test: 4462.2627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5698.1782	loss_val: 5698.1792	loss_test: 5698.2690	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5779.7256	loss_val: 5779.6694	loss_test: 5779.6670	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 4752.8955	loss_val: 4752.8784	loss_test: 4752.9351	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6085.8340	loss_val: 6085.8633	loss_test: 6085.8081	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5419.2622	loss_val: 5419.2827	loss_test: 5419.2515	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6051.2104	loss_val: 6051.1577	loss_test: 6051.5410	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 4945.0308	loss_val: 4944.9932	loss_test: 4945.2378	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 19255.3867	loss_val: 19255.3633	loss_test: 19255.5566	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6223.6450	loss_val: 6223.1484	loss_test: 6223.5698	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5277.6304	loss_val: 5277.6421	loss_test: 5277.6919	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3987.1177	loss_val: 3987.1013	loss_test: 3987.1067	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6797.7065	loss_val: 6797.8091	loss_test: 6797.8276	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 32048.0684	loss_val: 32047.6543	loss_test: 32048.2773	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6482.5869	loss_val: 6482.6343	loss_test: 6482.7017	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 18	curr_val_accuracy: 0.7938	curr_test_accuracy: 0.7788
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9375.9541	loss_val: 9376.1113	loss_test: 9376.0117	accuracy_train: 0.8533	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 10520.2217	loss_val: 10520.5361	loss_test: 10520.2646	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 52264.3789	loss_val: 52264.3359	loss_test: 52264.4805	accuracy_train: 0.6571	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 9044.2188	loss_val: 9044.2178	loss_test: 9044.2871	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 7949.2651	loss_val: 7949.3506	loss_test: 7949.2563	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4696.5366	loss_val: 4696.5273	loss_test: 4696.5093	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6055.0713	loss_val: 6055.0713	loss_test: 6055.1694	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6042.0894	loss_val: 6042.0205	loss_test: 6042.0273	accuracy_train: 0.2619	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 5088.8423	loss_val: 5088.8384	loss_test: 5088.8823	accuracy_train: 0.8333	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6300.3481	loss_val: 6300.3784	loss_test: 6300.3232	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5729.9531	loss_val: 5729.9766	loss_test: 5729.9453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6361.3770	loss_val: 6361.3291	loss_test: 6361.7314	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5213.0049	loss_val: 5212.9619	loss_test: 5213.2520	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 20521.0098	loss_val: 20520.9824	loss_test: 20521.1855	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6468.6440	loss_val: 6468.1655	loss_test: 6468.5854	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5577.0366	loss_val: 5577.0508	loss_test: 5577.1006	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4131.8354	loss_val: 4131.8193	loss_test: 4131.8242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7054.6431	loss_val: 7054.7271	loss_test: 7054.7656	accuracy_train: 0.8889	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 33607.9844	loss_val: 33607.5938	loss_test: 33608.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6780.4062	loss_val: 6780.4824	loss_test: 6780.5332	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 19	curr_val_accuracy: 0.7938	curr_test_accuracy: 0.7704
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9846.3184	loss_val: 9846.4824	loss_test: 9846.3799	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 10761.1768	loss_val: 10761.5156	loss_test: 10761.2002	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 55061.4297	loss_val: 55061.3906	loss_test: 55061.5469	accuracy_train: 0.6571	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 9876.4238	loss_val: 9876.4219	loss_test: 9876.4941	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 8221.7842	loss_val: 8221.8848	loss_test: 8221.7725	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4911.9590	loss_val: 4911.9492	loss_test: 4911.9326	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6395.2583	loss_val: 6395.2568	loss_test: 6395.3643	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6271.1182	loss_val: 6271.0391	loss_test: 6271.0513	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 5418.7739	loss_val: 5418.7847	loss_test: 5418.8145	accuracy_train: 0.8750	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6486.5718	loss_val: 6486.6021	loss_test: 6486.5469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6001.5381	loss_val: 6001.5649	loss_test: 6001.5327	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6624.5747	loss_val: 6624.5327	loss_test: 6624.9531	accuracy_train: 0.8481	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5463.7104	loss_val: 5463.6670	loss_test: 5463.9990	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 21610.5469	loss_val: 21610.5156	loss_test: 21610.7324	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6600.3638	loss_val: 6599.9033	loss_test: 6600.3281	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5848.5283	loss_val: 5848.5464	loss_test: 5848.5938	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4243.9194	loss_val: 4243.9038	loss_test: 4243.9072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7296.9272	loss_val: 7296.9888	loss_test: 7297.0586	accuracy_train: 0.9259	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 35093.2148	loss_val: 35092.8438	loss_test: 35093.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7061.9438	loss_val: 7062.0420	loss_test: 7062.0815	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 20	curr_val_accuracy: 0.7938	curr_test_accuracy: 0.7547
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10291.3516	loss_val: 10291.5234	loss_test: 10291.4180	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 10983.8438	loss_val: 10984.2031	loss_test: 10983.8506	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 57590.7500	loss_val: 57590.7148	loss_test: 57590.8789	accuracy_train: 0.6571	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 10716.9619	loss_val: 10716.9590	loss_test: 10717.0342	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8467.0957	loss_val: 8467.2178	loss_test: 8467.0820	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5085.1997	loss_val: 5085.1904	loss_test: 5085.1758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6686.2803	loss_val: 6686.2783	loss_test: 6686.3940	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6456.9414	loss_val: 6456.8530	loss_test: 6456.8672	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 5734.4155	loss_val: 5734.4365	loss_test: 5734.4565	accuracy_train: 0.8333	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6637.9946	loss_val: 6638.0244	loss_test: 6637.9702	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6247.1816	loss_val: 6247.2114	loss_test: 6247.1792	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6868.7310	loss_val: 6868.6934	loss_test: 6869.1343	accuracy_train: 0.8481	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5656.1313	loss_val: 5656.0903	loss_test: 5656.4595	accuracy_train: 0.8529	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 22529.2422	loss_val: 22529.2051	loss_test: 22529.4355	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6720.7065	loss_val: 6720.2690	loss_test: 6720.6934	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6085.9531	loss_val: 6085.9722	loss_test: 6086.0200	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4337.2705	loss_val: 4337.2549	loss_test: 4337.2573	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7510.5376	loss_val: 7510.5664	loss_test: 7510.6802	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 36531.3008	loss_val: 36530.9531	loss_test: 36531.5547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7288.2354	loss_val: 7288.3569	loss_test: 7288.3843	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 21	curr_val_accuracy: 0.8030	curr_test_accuracy: 0.7547
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10637.3857	loss_val: 10637.5654	loss_test: 10637.4561	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11122.7715	loss_val: 11123.1523	loss_test: 11122.7646	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 59878.9844	loss_val: 59878.9531	loss_test: 59879.1211	accuracy_train: 0.6857	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 11528.0439	loss_val: 11528.0410	loss_test: 11528.1182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8649.8916	loss_val: 8650.0381	loss_test: 8649.8770	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5212.9810	loss_val: 5212.9712	loss_test: 5212.9575	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6933.4648	loss_val: 6933.4619	loss_test: 6933.5864	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6593.9238	loss_val: 6593.8247	loss_test: 6593.8477	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 6067.6597	loss_val: 6067.6870	loss_test: 6067.7041	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 6794.1353	loss_val: 6794.1646	loss_test: 6794.1123	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6451.1221	loss_val: 6451.1548	loss_test: 6451.1226	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7092.9863	loss_val: 7092.9546	loss_test: 7093.4170	accuracy_train: 0.8354	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5823.2412	loss_val: 5823.2051	loss_test: 5823.6055	accuracy_train: 0.8529	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 23222.9453	loss_val: 23222.9062	loss_test: 23223.1504	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6726.4736	loss_val: 6726.0630	loss_test: 6726.4849	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6274.9121	loss_val: 6274.9370	loss_test: 6274.9819	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4419.7031	loss_val: 4419.6880	loss_test: 4419.6899	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7674.9146	loss_val: 7674.9170	loss_test: 7675.0708	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 37788.7852	loss_val: 37788.4570	loss_test: 37789.0508	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7456.7026	loss_val: 7456.8389	loss_test: 7456.8628	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 22	curr_val_accuracy: 0.8030	curr_test_accuracy: 0.7398
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10920.7852	loss_val: 10920.9736	loss_test: 10920.8623	accuracy_train: 0.8667	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11207.5000	loss_val: 11207.9111	loss_test: 11207.4844	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 61853.6406	loss_val: 61853.6211	loss_test: 61853.7852	accuracy_train: 0.7429	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 12369.8428	loss_val: 12369.8379	loss_test: 12369.9170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8800.0107	loss_val: 8800.1875	loss_test: 8799.9961	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5336.5439	loss_val: 5336.5342	loss_test: 5336.5220	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7149.8169	loss_val: 7149.8140	loss_test: 7149.9478	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6701.3364	loss_val: 6701.2266	loss_test: 6701.2573	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 6387.1484	loss_val: 6387.1802	loss_test: 6387.1958	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 6890.1865	loss_val: 6890.2148	loss_test: 6890.1646	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6626.0977	loss_val: 6626.1323	loss_test: 6626.0996	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7287.5781	loss_val: 7287.5522	loss_test: 7288.0376	accuracy_train: 0.8354	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5953.6074	loss_val: 5953.5791	loss_test: 5954.0073	accuracy_train: 0.8529	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 23676.4570	loss_val: 23676.4121	loss_test: 23676.6738	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6707.5498	loss_val: 6707.1646	loss_test: 6707.5850	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6403.9849	loss_val: 6404.0127	loss_test: 6404.0591	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4463.8848	loss_val: 4463.8696	loss_test: 4463.8711	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7823.8945	loss_val: 7823.8706	loss_test: 7824.0693	accuracy_train: 0.9630	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 38971.0703	loss_val: 38970.7617	loss_test: 38971.3477	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7580.4370	loss_val: 7580.5864	loss_test: 7580.6074	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 23	curr_val_accuracy: 0.7956	curr_test_accuracy: 0.7473
best_round: 11	best_val_accuracy: 0.8208	best_test_accuracy: 0.7517
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11112.2373	loss_val: 11112.4316	loss_test: 11112.3184	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11268.8906	loss_val: 11269.3301	loss_test: 11268.8779	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 63502.6797	loss_val: 63502.6641	loss_test: 63502.8398	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 13253.3965	loss_val: 13253.3906	loss_test: 13253.4707	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8927.9287	loss_val: 8928.1396	loss_test: 8927.9150	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5419.4717	loss_val: 5419.4619	loss_test: 5419.4502	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7322.0186	loss_val: 7322.0146	loss_test: 7322.1626	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6772.3496	loss_val: 6772.2295	loss_test: 6772.2734	accuracy_train: 0.2381	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 6692.9326	loss_val: 6692.9712	loss_test: 6692.9839	accuracy_train: 0.7708	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 6965.9321	loss_val: 6965.9590	loss_test: 6965.9102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6757.4453	loss_val: 6757.4795	loss_test: 6757.4478	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7458.9570	loss_val: 7458.9370	loss_test: 7459.4478	accuracy_train: 0.8354	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6026.4214	loss_val: 6026.4043	loss_test: 6026.8540	accuracy_train: 0.8529	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 23907.8379	loss_val: 23907.7910	loss_test: 23908.0664	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6652.0132	loss_val: 6651.6533	loss_test: 6652.0713	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6512.6167	loss_val: 6512.6523	loss_test: 6512.6987	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4498.4609	loss_val: 4498.4458	loss_test: 4498.4468	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7918.8989	loss_val: 7918.8496	loss_test: 7919.0947	accuracy_train: 0.9259	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 39941.6680	loss_val: 39941.3750	loss_test: 39941.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7655.8799	loss_val: 7656.0366	loss_test: 7656.0620	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 24	curr_val_accuracy: 0.8213	curr_test_accuracy: 0.7538
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11261.5068	loss_val: 11261.7090	loss_test: 11261.5938	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11307.2832	loss_val: 11307.7461	loss_test: 11307.2744	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 64992.4766	loss_val: 64992.4727	loss_test: 64992.6484	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 14095.9268	loss_val: 14095.9199	loss_test: 14096.0020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8994.9746	loss_val: 8995.2246	loss_test: 8994.9609	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5445.4287	loss_val: 5445.4194	loss_test: 5445.4082	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7469.0200	loss_val: 7469.0137	loss_test: 7469.1787	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6793.3521	loss_val: 6793.2246	loss_test: 6793.2798	accuracy_train: 0.2381	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 7000.2134	loss_val: 7000.2607	loss_test: 7000.2690	accuracy_train: 0.7292	accuracy_val: 0.6667	accuracy_test: 0.4286
[client 9]	loss_train: 7012.3481	loss_val: 7012.3745	loss_test: 7012.3267	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6877.0420	loss_val: 6877.0762	loss_test: 6877.0454	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7521.3198	loss_val: 7521.3125	loss_test: 7521.8359	accuracy_train: 0.8354	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6078.2910	loss_val: 6078.2900	loss_test: 6078.7500	accuracy_train: 0.8529	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 23892.3457	loss_val: 23892.2969	loss_test: 23892.5859	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6536.7129	loss_val: 6536.3818	loss_test: 6536.7954	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6560.9761	loss_val: 6561.0229	loss_test: 6561.0679	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4514.0132	loss_val: 4513.9976	loss_test: 4513.9985	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7971.5737	loss_val: 7971.5083	loss_test: 7971.7910	accuracy_train: 0.9259	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 40717.0508	loss_val: 40716.7773	loss_test: 40717.3438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7678.6699	loss_val: 7678.8267	loss_test: 7678.8628	accuracy_train: 0.8367	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 25	curr_val_accuracy: 0.8127	curr_test_accuracy: 0.7464
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11305.4131	loss_val: 11305.6240	loss_test: 11305.5059	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11326.6494	loss_val: 11327.1289	loss_test: 11326.6494	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66172.4609	loss_val: 66172.4609	loss_test: 66172.6406	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 14956.0889	loss_val: 14956.0811	loss_test: 14956.1641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9028.3154	loss_val: 9028.6064	loss_test: 9028.3037	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5453.2827	loss_val: 5453.2734	loss_test: 5453.2627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7567.6328	loss_val: 7567.6265	loss_test: 7567.8057	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6771.9146	loss_val: 6771.7769	loss_test: 6771.8462	accuracy_train: 0.2619	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 7277.8994	loss_val: 7277.9561	loss_test: 7277.9590	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 7010.3853	loss_val: 7010.4111	loss_test: 7010.3638	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6966.8833	loss_val: 6966.9180	loss_test: 6966.8877	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7533.6699	loss_val: 7533.6777	loss_test: 7534.2085	accuracy_train: 0.8354	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6086.0098	loss_val: 6086.0269	loss_test: 6086.4966	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 23727.6621	loss_val: 23727.6113	loss_test: 23727.9180	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6403.5381	loss_val: 6403.2354	loss_test: 6403.6431	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6587.8643	loss_val: 6587.9238	loss_test: 6587.9692	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4506.0415	loss_val: 4506.0254	loss_test: 4506.0269	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8042.3667	loss_val: 8042.2798	loss_test: 8042.6113	accuracy_train: 0.9259	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 41663.6094	loss_val: 41663.3516	loss_test: 41663.9102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7689.8984	loss_val: 7690.0552	loss_test: 7690.1006	accuracy_train: 0.8367	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 26	curr_val_accuracy: 0.8041	curr_test_accuracy: 0.7604
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11269.0566	loss_val: 11269.2773	loss_test: 11269.1533	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11357.3740	loss_val: 11357.8643	loss_test: 11357.3818	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 67284.3672	loss_val: 67284.3828	loss_test: 67284.5625	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 15878.2627	loss_val: 15878.2549	loss_test: 15878.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8997.0830	loss_val: 8997.4160	loss_test: 8997.0742	accuracy_train: 0.6296	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5436.6440	loss_val: 5436.6343	loss_test: 5436.6240	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7640.6255	loss_val: 7640.6201	loss_test: 7640.8115	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6736.4570	loss_val: 6736.3125	loss_test: 6736.3945	accuracy_train: 0.2857	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 7504.7695	loss_val: 7504.8428	loss_test: 7504.8350	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6975.2002	loss_val: 6975.2256	loss_test: 6975.1777	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7035.2964	loss_val: 7035.3296	loss_test: 7035.3013	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7522.3110	loss_val: 7522.3364	loss_test: 7522.8745	accuracy_train: 0.8481	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6089.0708	loss_val: 6089.1074	loss_test: 6089.5801	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 23379.3105	loss_val: 23379.2598	loss_test: 23379.5820	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6238.3950	loss_val: 6238.1216	loss_test: 6238.5215	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6586.4351	loss_val: 6586.5098	loss_test: 6586.5566	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4499.4922	loss_val: 4499.4756	loss_test: 4499.4766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8073.9390	loss_val: 8073.8364	loss_test: 8074.2168	accuracy_train: 0.9259	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 42386.2930	loss_val: 42386.0547	loss_test: 42386.6055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7634.4717	loss_val: 7634.6289	loss_test: 7634.6816	accuracy_train: 0.8367	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 27	curr_val_accuracy: 0.8041	curr_test_accuracy: 0.7529
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11227.3037	loss_val: 11227.5381	loss_test: 11227.4072	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11358.5625	loss_val: 11359.0605	loss_test: 11358.5781	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 67887.5000	loss_val: 67887.5391	loss_test: 67887.7188	accuracy_train: 0.8000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 16829.6113	loss_val: 16829.6035	loss_test: 16829.6816	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8907.9082	loss_val: 8908.2920	loss_test: 8907.9033	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 5]	loss_train: 5411.7656	loss_val: 5411.7559	loss_test: 5411.7466	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7685.4399	loss_val: 7685.4346	loss_test: 7685.6377	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6657.9521	loss_val: 6657.8032	loss_test: 6657.8989	accuracy_train: 0.3095	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 7706.1040	loss_val: 7706.1973	loss_test: 7706.1724	accuracy_train: 0.6875	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6934.6699	loss_val: 6934.6948	loss_test: 6934.6475	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7086.9365	loss_val: 7086.9692	loss_test: 7086.9429	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7469.9038	loss_val: 7469.9463	loss_test: 7470.4937	accuracy_train: 0.8481	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6050.6865	loss_val: 6050.7446	loss_test: 6051.2227	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 22883.1191	loss_val: 22883.0664	loss_test: 22883.4043	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6086.3452	loss_val: 6086.0996	loss_test: 6086.4907	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6549.2017	loss_val: 6549.2920	loss_test: 6549.3418	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4477.9663	loss_val: 4477.9487	loss_test: 4477.9502	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8078.2988	loss_val: 8078.1875	loss_test: 8078.6079	accuracy_train: 0.9259	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 43117.1406	loss_val: 43116.9180	loss_test: 43117.4570	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7549.8535	loss_val: 7550.0127	loss_test: 7550.0732	accuracy_train: 0.8367	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 28	curr_val_accuracy: 0.7954	curr_test_accuracy: 0.7572
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 11106.6934	loss_val: 11106.9443	loss_test: 11106.8047	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11354.7871	loss_val: 11355.2871	loss_test: 11354.8115	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68467.5078	loss_val: 68467.5703	loss_test: 68467.7578	accuracy_train: 0.8000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 17847.7031	loss_val: 17847.6953	loss_test: 17847.7715	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8798.3887	loss_val: 8798.8320	loss_test: 8798.3896	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 5]	loss_train: 5345.0044	loss_val: 5344.9946	loss_test: 5344.9863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7730.9175	loss_val: 7730.9106	loss_test: 7731.1279	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6545.7510	loss_val: 6545.5977	loss_test: 6545.7095	accuracy_train: 0.3333	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 7870.2651	loss_val: 7870.3784	loss_test: 7870.3369	accuracy_train: 0.7083	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6895.8521	loss_val: 6895.8770	loss_test: 6895.8291	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7119.0005	loss_val: 7119.0347	loss_test: 7119.0063	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7425.1094	loss_val: 7425.1675	loss_test: 7425.7236	accuracy_train: 0.8608	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6004.8281	loss_val: 6004.9111	loss_test: 6005.3970	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 22365.1465	loss_val: 22365.0938	loss_test: 22365.4453	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5902.6079	loss_val: 5902.3853	loss_test: 5902.7676	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6471.2427	loss_val: 6471.3491	loss_test: 6471.4023	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4455.4097	loss_val: 4455.3916	loss_test: 4455.3931	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8072.6177	loss_val: 8072.4932	loss_test: 8072.9668	accuracy_train: 0.9259	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 43616.1016	loss_val: 43615.8906	loss_test: 43616.4219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7449.4785	loss_val: 7449.6440	loss_test: 7449.7080	accuracy_train: 0.8469	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 29	curr_val_accuracy: 0.7954	curr_test_accuracy: 0.7572
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10918.8086	loss_val: 10919.0762	loss_test: 10918.9287	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11339.3594	loss_val: 11339.8613	loss_test: 11339.3926	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68825.7500	loss_val: 68825.8359	loss_test: 68826.0312	accuracy_train: 0.8571	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 18924.0527	loss_val: 18924.0449	loss_test: 18924.1172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8665.8418	loss_val: 8666.3535	loss_test: 8665.8496	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 5]	loss_train: 5273.7202	loss_val: 5273.7109	loss_test: 5273.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7740.1733	loss_val: 7740.1665	loss_test: 7740.3955	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6420.1758	loss_val: 6420.0249	loss_test: 6420.1519	accuracy_train: 0.3333	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 8024.8599	loss_val: 8024.9971	loss_test: 8024.9365	accuracy_train: 0.7292	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6833.6367	loss_val: 6833.6621	loss_test: 6833.6138	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7152.6777	loss_val: 7152.7144	loss_test: 7152.6826	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7396.9038	loss_val: 7396.9756	loss_test: 7397.5449	accuracy_train: 0.8734	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5940.9014	loss_val: 5941.0117	loss_test: 5941.4966	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 21753.3633	loss_val: 21753.3105	loss_test: 21753.6758	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5740.0200	loss_val: 5739.8193	loss_test: 5740.1919	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6396.3232	loss_val: 6396.4409	loss_test: 6396.5049	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4421.9238	loss_val: 4421.9048	loss_test: 4421.9067	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8044.4658	loss_val: 8044.3335	loss_test: 8044.8545	accuracy_train: 0.9259	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 44182.5000	loss_val: 44182.3047	loss_test: 44182.8242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7332.0420	loss_val: 7332.2188	loss_test: 7332.2808	accuracy_train: 0.8469	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 30	curr_val_accuracy: 0.7954	curr_test_accuracy: 0.7572
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10702.8682	loss_val: 10703.1602	loss_test: 10703.0020	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11318.9668	loss_val: 11319.4717	loss_test: 11319.0098	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69144.8984	loss_val: 69145.0078	loss_test: 69145.2031	accuracy_train: 0.8571	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 20035.2344	loss_val: 20035.2266	loss_test: 20035.2969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8483.8076	loss_val: 8484.4014	loss_test: 8483.8252	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 5]	loss_train: 5191.7383	loss_val: 5191.7295	loss_test: 5191.7217	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7750.0127	loss_val: 7750.0059	loss_test: 7750.2466	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6294.5566	loss_val: 6294.4087	loss_test: 6294.5518	accuracy_train: 0.3571	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 8164.4800	loss_val: 8164.6455	loss_test: 8164.5664	accuracy_train: 0.7708	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6779.1982	loss_val: 6779.2236	loss_test: 6779.1753	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7185.6846	loss_val: 7185.7256	loss_test: 7185.6880	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7381.7124	loss_val: 7381.7949	loss_test: 7382.3828	accuracy_train: 0.8987	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 5886.3813	loss_val: 5886.5200	loss_test: 5887.0029	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 21133.8496	loss_val: 21133.7969	loss_test: 21134.1758	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5533.9053	loss_val: 5533.7271	loss_test: 5534.0864	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6308.8418	loss_val: 6308.9697	loss_test: 6309.0542	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 16]	loss_train: 4383.2544	loss_val: 4383.2334	loss_test: 4383.2363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8009.8506	loss_val: 8009.7148	loss_test: 8010.2842	accuracy_train: 0.9259	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 44865.6406	loss_val: 44865.4570	loss_test: 44865.9648	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7190.0327	loss_val: 7190.2241	loss_test: 7190.2803	accuracy_train: 0.8469	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 31	curr_val_accuracy: 0.8038	curr_test_accuracy: 0.7428
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10456.7119	loss_val: 10457.0303	loss_test: 10456.8564	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11250.9150	loss_val: 11251.4199	loss_test: 11250.9678	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69354.7266	loss_val: 69354.8594	loss_test: 69355.0703	accuracy_train: 0.8857	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 21199.7754	loss_val: 21199.7656	loss_test: 21199.8340	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8286.8145	loss_val: 8287.4971	loss_test: 8286.8477	accuracy_train: 0.6296	accuracy_val: 0.5000	accuracy_test: 0.6364
[client 5]	loss_train: 5094.1450	loss_val: 5094.1362	loss_test: 5094.1284	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7758.6895	loss_val: 7758.6831	loss_test: 7758.9331	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6173.6421	loss_val: 6173.5024	loss_test: 6173.6582	accuracy_train: 0.3571	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 8252.1445	loss_val: 8252.3408	loss_test: 8252.2432	accuracy_train: 0.8542	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6722.1812	loss_val: 6722.2065	loss_test: 6722.1597	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7276.3550	loss_val: 7276.3979	loss_test: 7276.3584	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7313.9326	loss_val: 7314.0264	loss_test: 7314.6323	accuracy_train: 0.8987	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5831.1499	loss_val: 5831.3149	loss_test: 5831.8013	accuracy_train: 0.9118	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 20478.5840	loss_val: 20478.5293	loss_test: 20478.9238	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5354.3267	loss_val: 5354.1665	loss_test: 5354.5210	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6168.4937	loss_val: 6168.6348	loss_test: 6168.7446	accuracy_train: 0.6364	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 16]	loss_train: 4335.7930	loss_val: 4335.7705	loss_test: 4335.7739	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7975.7666	loss_val: 7975.6289	loss_test: 7976.2480	accuracy_train: 0.8519	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 45599.2461	loss_val: 45599.0781	loss_test: 45599.5820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7049.0615	loss_val: 7049.2651	loss_test: 7049.3169	accuracy_train: 0.8469	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 32	curr_val_accuracy: 0.7954	curr_test_accuracy: 0.7428
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 10227.0615	loss_val: 10227.4053	loss_test: 10227.2178	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11207.2559	loss_val: 11207.7598	loss_test: 11207.3135	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69472.8516	loss_val: 69473.0156	loss_test: 69473.2266	accuracy_train: 0.8571	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 22352.1270	loss_val: 22352.1191	loss_test: 22352.1836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8071.1914	loss_val: 8071.9717	loss_test: 8071.2417	accuracy_train: 0.6420	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5006.5723	loss_val: 5006.5635	loss_test: 5006.5562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7780.6724	loss_val: 7780.6665	loss_test: 7780.9277	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6041.4814	loss_val: 6041.3618	loss_test: 6041.5259	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 8350.7998	loss_val: 8351.0186	loss_test: 8350.9102	accuracy_train: 0.8542	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6670.4580	loss_val: 6670.4829	loss_test: 6670.4370	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7396.9941	loss_val: 7397.0391	loss_test: 7396.9961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7167.4795	loss_val: 7167.5898	loss_test: 7168.1987	accuracy_train: 0.8861	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5775.0410	loss_val: 5775.2314	loss_test: 5775.7188	accuracy_train: 0.9412	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 19768.6172	loss_val: 19768.5645	loss_test: 19768.9707	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5150.8750	loss_val: 5150.7344	loss_test: 5151.0830	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 6040.7939	loss_val: 6040.9473	loss_test: 6041.0830	accuracy_train: 0.7273	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4307.6802	loss_val: 4307.6558	loss_test: 4307.6597	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7934.3535	loss_val: 7934.2217	loss_test: 7934.8779	accuracy_train: 0.8889	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 46440.2344	loss_val: 46440.0781	loss_test: 46440.5742	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6903.1230	loss_val: 6903.3574	loss_test: 6903.3882	accuracy_train: 0.8469	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 33	curr_val_accuracy: 0.7954	curr_test_accuracy: 0.7490
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9967.1455	loss_val: 9967.5156	loss_test: 9967.3115	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11198.8740	loss_val: 11199.3838	loss_test: 11198.9424	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69319.6328	loss_val: 69319.8281	loss_test: 69320.0469	accuracy_train: 0.8571	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 23558.2852	loss_val: 23558.2773	loss_test: 23558.3379	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7901.7710	loss_val: 7902.6504	loss_test: 7901.8467	accuracy_train: 0.6790	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4923.2559	loss_val: 4923.2476	loss_test: 4923.2407	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7816.6489	loss_val: 7816.6431	loss_test: 7816.9146	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5942.8765	loss_val: 5942.7773	loss_test: 5942.9507	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 8446.5957	loss_val: 8446.8340	loss_test: 8446.7178	accuracy_train: 0.8542	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6626.7051	loss_val: 6626.7300	loss_test: 6626.6846	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7486.5254	loss_val: 7486.5713	loss_test: 7486.5249	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7012.1538	loss_val: 7012.2842	loss_test: 7012.8882	accuracy_train: 0.8987	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5725.4111	loss_val: 5725.6294	loss_test: 5726.1157	accuracy_train: 0.9412	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 19049.6719	loss_val: 19049.6230	loss_test: 19050.0449	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4978.1045	loss_val: 4977.9790	loss_test: 4978.3296	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5903.0366	loss_val: 5903.2002	loss_test: 5903.3682	accuracy_train: 0.7727	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4274.4141	loss_val: 4274.3887	loss_test: 4274.3931	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7884.3379	loss_val: 7884.2153	loss_test: 7884.8916	accuracy_train: 0.9630	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 47317.6992	loss_val: 47317.5547	loss_test: 47318.0469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6761.6230	loss_val: 6761.8872	loss_test: 6761.8975	accuracy_train: 0.8469	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 34	curr_val_accuracy: 0.7954	curr_test_accuracy: 0.7556
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9707.1406	loss_val: 9707.5420	loss_test: 9707.3193	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11223.4902	loss_val: 11224.0088	loss_test: 11223.5684	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69203.8125	loss_val: 69204.0391	loss_test: 69204.2578	accuracy_train: 0.9143	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 24742.2207	loss_val: 24742.2109	loss_test: 24742.2695	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7721.9849	loss_val: 7722.9648	loss_test: 7722.0864	accuracy_train: 0.7160	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4841.0840	loss_val: 4841.0762	loss_test: 4841.0688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7860.9385	loss_val: 7860.9312	loss_test: 7861.2139	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5842.9849	loss_val: 5842.9067	loss_test: 5843.0947	accuracy_train: 0.5238	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 8540.3809	loss_val: 8540.6289	loss_test: 8540.5107	accuracy_train: 0.8542	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6633.9683	loss_val: 6633.9927	loss_test: 6633.9478	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7563.5425	loss_val: 7563.5908	loss_test: 7563.5400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6805.9673	loss_val: 6806.1230	loss_test: 6806.7119	accuracy_train: 0.9241	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5666.6826	loss_val: 5666.9263	loss_test: 5667.4126	accuracy_train: 0.9412	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 18310.5352	loss_val: 18310.4922	loss_test: 18310.9238	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4812.5718	loss_val: 4812.4609	loss_test: 4812.8105	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5780.0254	loss_val: 5780.2017	loss_test: 5780.4009	accuracy_train: 0.9091	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4241.2505	loss_val: 4241.2241	loss_test: 4241.2295	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7880.5869	loss_val: 7880.4678	loss_test: 7881.1841	accuracy_train: 0.9630	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 48106.6836	loss_val: 48106.5508	loss_test: 48107.0352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6680.6899	loss_val: 6680.9844	loss_test: 6680.9761	accuracy_train: 0.8673	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 35	curr_val_accuracy: 0.8073	curr_test_accuracy: 0.7566
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9504.7578	loss_val: 9505.1885	loss_test: 9504.9512	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11255.0205	loss_val: 11255.5400	loss_test: 11255.1064	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69006.7500	loss_val: 69007.0000	loss_test: 69007.2188	accuracy_train: 0.9429	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 25978.1777	loss_val: 25978.1699	loss_test: 25978.2246	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7523.3101	loss_val: 7524.3838	loss_test: 7523.4443	accuracy_train: 0.7407	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4768.3701	loss_val: 4768.3628	loss_test: 4768.3545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7921.1646	loss_val: 7921.1553	loss_test: 7921.4468	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5768.4097	loss_val: 5768.3555	loss_test: 5768.5576	accuracy_train: 0.5952	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 8642.4922	loss_val: 8642.7451	loss_test: 8642.6279	accuracy_train: 0.8542	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 6661.2754	loss_val: 6661.2983	loss_test: 6661.2549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7638.6230	loss_val: 7638.6733	loss_test: 7638.6182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6658.1509	loss_val: 6658.3330	loss_test: 6658.9116	accuracy_train: 0.9367	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5604.0439	loss_val: 5604.3125	loss_test: 5604.7949	accuracy_train: 0.9412	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 17538.2754	loss_val: 17538.2402	loss_test: 17538.6816	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4677.9277	loss_val: 4677.8276	loss_test: 4678.1787	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5673.8262	loss_val: 5674.0200	loss_test: 5674.2480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4211.2422	loss_val: 4211.2148	loss_test: 4211.2207	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7857.6353	loss_val: 7857.5229	loss_test: 7858.2676	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 48823.5859	loss_val: 48823.4609	loss_test: 48823.9375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6605.5972	loss_val: 6605.9131	loss_test: 6605.8936	accuracy_train: 0.8776	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 36	curr_val_accuracy: 0.8073	curr_test_accuracy: 0.7640
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9326.3877	loss_val: 9326.8457	loss_test: 9326.5947	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11336.9990	loss_val: 11337.5254	loss_test: 11337.0947	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68964.3984	loss_val: 68964.6641	loss_test: 68964.8906	accuracy_train: 0.9714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 27301.6211	loss_val: 27301.6133	loss_test: 27301.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7346.0107	loss_val: 7347.1782	loss_test: 7346.1729	accuracy_train: 0.7654	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4700.8276	loss_val: 4700.8208	loss_test: 4700.8120	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8006.5625	loss_val: 8006.5508	loss_test: 8006.8501	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5680.4922	loss_val: 5680.4629	loss_test: 5680.6855	accuracy_train: 0.6667	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 8752.3965	loss_val: 8752.6592	loss_test: 8752.5342	accuracy_train: 0.8750	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 6675.0049	loss_val: 6675.0278	loss_test: 6674.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7724.9028	loss_val: 7724.9556	loss_test: 7724.8960	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6487.7217	loss_val: 6487.9365	loss_test: 6488.4941	accuracy_train: 0.9367	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5555.9590	loss_val: 5556.2534	loss_test: 5556.7236	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 16819.7754	loss_val: 16819.7539	loss_test: 16820.2012	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4550.2036	loss_val: 4550.1123	loss_test: 4550.4653	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5589.6089	loss_val: 5589.8247	loss_test: 5590.0728	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4189.0049	loss_val: 4188.9766	loss_test: 4188.9829	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7862.0220	loss_val: 7861.9136	loss_test: 7862.6821	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 49417.4297	loss_val: 49417.3125	loss_test: 49417.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6557.9229	loss_val: 6558.2466	loss_test: 6558.2290	accuracy_train: 0.8878	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 37	curr_val_accuracy: 0.8165	curr_test_accuracy: 0.7700
best_round: 24	best_val_accuracy: 0.8213	best_test_accuracy: 0.7538
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9083.5244	loss_val: 9084.0068	loss_test: 9083.7393	accuracy_train: 0.9333	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11442.1191	loss_val: 11442.6543	loss_test: 11442.2266	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68858.7109	loss_val: 68858.9766	loss_test: 68859.2109	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 28593.1445	loss_val: 28593.1348	loss_test: 28593.1855	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7199.2822	loss_val: 7200.5420	loss_test: 7199.4692	accuracy_train: 0.7901	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4636.0479	loss_val: 4636.0410	loss_test: 4636.0317	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8098.0024	loss_val: 8097.9893	loss_test: 8098.2915	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5640.8042	loss_val: 5640.7954	loss_test: 5641.0435	accuracy_train: 0.6905	accuracy_val: 0.8000	accuracy_test: 0.4286
[client 8]	loss_train: 8878.2900	loss_val: 8878.5742	loss_test: 8878.4365	accuracy_train: 0.8750	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 6736.6812	loss_val: 6736.7041	loss_test: 6736.6611	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7773.5776	loss_val: 7773.6338	loss_test: 7773.5708	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6342.7070	loss_val: 6342.9521	loss_test: 6343.4966	accuracy_train: 0.9367	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5506.9307	loss_val: 5507.2485	loss_test: 5507.7114	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 16168.3047	loss_val: 16168.2939	loss_test: 16168.7549	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4449.3589	loss_val: 4449.2764	loss_test: 4449.6333	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5497.4966	loss_val: 5497.7363	loss_test: 5497.9995	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4174.7012	loss_val: 4174.6729	loss_test: 4174.6797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7892.2197	loss_val: 7892.1147	loss_test: 7892.9062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 49957.2266	loss_val: 49957.1172	loss_test: 49957.5703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6531.9434	loss_val: 6532.2642	loss_test: 6532.2563	accuracy_train: 0.9286	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 38	curr_val_accuracy: 0.8241	curr_test_accuracy: 0.7869
best_round: 38	best_val_accuracy: 0.8241	best_test_accuracy: 0.7869
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8854.2793	loss_val: 8854.7852	loss_test: 8854.4990	accuracy_train: 0.9333	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11540.7314	loss_val: 11541.2822	loss_test: 11540.8545	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68759.2734	loss_val: 68759.5312	loss_test: 68759.7891	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 29873.4199	loss_val: 29873.4121	loss_test: 29873.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7080.3896	loss_val: 7081.7534	loss_test: 7080.6001	accuracy_train: 0.8519	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4595.5264	loss_val: 4595.5195	loss_test: 4595.5107	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8205.6025	loss_val: 8205.5859	loss_test: 8205.8975	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5584.3218	loss_val: 5584.3452	loss_test: 5584.6201	accuracy_train: 0.7381	accuracy_val: 0.8000	accuracy_test: 0.4286
[client 8]	loss_train: 8992.5996	loss_val: 8992.9111	loss_test: 8992.7568	accuracy_train: 0.8958	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 6792.0537	loss_val: 6792.0762	loss_test: 6792.0337	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7816.0869	loss_val: 7816.1470	loss_test: 7816.0786	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6232.6772	loss_val: 6232.9482	loss_test: 6233.4873	accuracy_train: 0.9494	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5482.4253	loss_val: 5482.7617	loss_test: 5483.2319	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 15567.8770	loss_val: 15567.8779	loss_test: 15568.3525	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4363.9951	loss_val: 4363.9199	loss_test: 4364.2783	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5433.3936	loss_val: 5433.6602	loss_test: 5433.9351	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4157.7373	loss_val: 4157.7080	loss_test: 4157.7153	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7934.2573	loss_val: 7934.1562	loss_test: 7934.9614	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 50488.8242	loss_val: 50488.7188	loss_test: 50489.1562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6501.3862	loss_val: 6501.6958	loss_test: 6501.7012	accuracy_train: 0.9286	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 39	curr_val_accuracy: 0.8241	curr_test_accuracy: 0.7869
best_round: 38	best_val_accuracy: 0.8241	best_test_accuracy: 0.7869
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8600.1172	loss_val: 8600.6289	loss_test: 8600.3291	accuracy_train: 0.9467	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11636.3223	loss_val: 11636.9141	loss_test: 11636.4678	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68685.4922	loss_val: 68685.7422	loss_test: 68686.0156	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 31063.8535	loss_val: 31063.8457	loss_test: 31063.8945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6992.3965	loss_val: 6993.8564	loss_test: 6992.6265	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4553.4072	loss_val: 4553.4004	loss_test: 4553.3916	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8312.1787	loss_val: 8312.1602	loss_test: 8312.4814	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5537.6191	loss_val: 5537.6753	loss_test: 5537.9810	accuracy_train: 0.8333	accuracy_val: 0.8000	accuracy_test: 0.4286
[client 8]	loss_train: 9117.2441	loss_val: 9117.5762	loss_test: 9117.4092	accuracy_train: 0.8958	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 6841.2837	loss_val: 6841.3066	loss_test: 6841.2637	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7832.3755	loss_val: 7832.4395	loss_test: 7832.3677	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6059.9546	loss_val: 6060.2617	loss_test: 6060.7754	accuracy_train: 0.9747	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5460.7041	loss_val: 5461.0596	loss_test: 5461.5244	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 15038.4609	loss_val: 15038.4766	loss_test: 15038.9619	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4300.2432	loss_val: 4300.1743	loss_test: 4300.5381	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5373.8145	loss_val: 5374.1025	loss_test: 5374.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4148.8403	loss_val: 4148.8101	loss_test: 4148.8184	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7940.9375	loss_val: 7940.8398	loss_test: 7941.6514	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 51213.6914	loss_val: 51213.5898	loss_test: 51214.0117	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6488.8213	loss_val: 6489.1201	loss_test: 6489.1382	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 40	curr_val_accuracy: 0.8157	curr_test_accuracy: 0.7945
best_round: 38	best_val_accuracy: 0.8241	best_test_accuracy: 0.7869
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8342.4863	loss_val: 8342.9980	loss_test: 8342.6885	accuracy_train: 0.9600	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 11721.1670	loss_val: 11721.8018	loss_test: 11721.3320	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68822.6719	loss_val: 68822.9219	loss_test: 68823.2188	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 32447.6641	loss_val: 32447.6582	loss_test: 32447.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6917.6387	loss_val: 6919.1968	loss_test: 6917.8862	accuracy_train: 0.9630	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4524.8447	loss_val: 4524.8379	loss_test: 4524.8291	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8448.1797	loss_val: 8448.1611	loss_test: 8448.4883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5477.5049	loss_val: 5477.5947	loss_test: 5477.9282	accuracy_train: 0.9286	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 9228.9561	loss_val: 9229.3105	loss_test: 9229.1279	accuracy_train: 0.8958	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 6897.9287	loss_val: 6897.9517	loss_test: 6897.9087	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7931.5894	loss_val: 7931.6567	loss_test: 7931.5845	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5883.4111	loss_val: 5883.7505	loss_test: 5884.2373	accuracy_train: 0.9747	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5445.1587	loss_val: 5445.5361	loss_test: 5445.9829	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 14557.5195	loss_val: 14557.5508	loss_test: 14558.0459	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4269.3125	loss_val: 4269.2485	loss_test: 4269.6138	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5310.4531	loss_val: 5310.7642	loss_test: 5311.0488	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4140.3608	loss_val: 4140.3296	loss_test: 4140.3389	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7935.1494	loss_val: 7935.0571	loss_test: 7935.8672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 51759.7148	loss_val: 51759.6172	loss_test: 51760.0156	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6515.6675	loss_val: 6515.9331	loss_test: 6515.9814	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 41	curr_val_accuracy: 0.8065	curr_test_accuracy: 0.7945
best_round: 38	best_val_accuracy: 0.8241	best_test_accuracy: 0.7869
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8121.8789	loss_val: 8122.3867	loss_test: 8122.0713	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 11806.1064	loss_val: 11806.7773	loss_test: 11806.2900	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 68828.0859	loss_val: 68828.3438	loss_test: 68828.6484	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 33917.7773	loss_val: 33917.7734	loss_test: 33917.8164	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6866.7954	loss_val: 6868.4517	loss_test: 6867.0605	accuracy_train: 0.9753	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4492.6982	loss_val: 4492.6914	loss_test: 4492.6831	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8583.8818	loss_val: 8583.8643	loss_test: 8584.1953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5446.6187	loss_val: 5446.7368	loss_test: 5447.0962	accuracy_train: 0.9762	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 9338.3340	loss_val: 9338.7070	loss_test: 9338.5137	accuracy_train: 0.8958	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 6994.6865	loss_val: 6994.7095	loss_test: 6994.6675	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8032.5000	loss_val: 8032.5708	loss_test: 8032.4976	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5702.6260	loss_val: 5703.0015	loss_test: 5703.4536	accuracy_train: 0.9873	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5438.2988	loss_val: 5438.6934	loss_test: 5439.1270	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 14187.1074	loss_val: 14187.1523	loss_test: 14187.6543	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4226.8711	loss_val: 4226.8120	loss_test: 4227.1782	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5270.1680	loss_val: 5270.5005	loss_test: 5270.7876	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4133.3760	loss_val: 4133.3442	loss_test: 4133.3545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7955.3687	loss_val: 7955.2812	loss_test: 7956.0938	accuracy_train: 0.9630	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 52272.6133	loss_val: 52272.5195	loss_test: 52272.8984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6559.6709	loss_val: 6559.9014	loss_test: 6559.9790	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 42	curr_val_accuracy: 0.8146	curr_test_accuracy: 0.7889
best_round: 38	best_val_accuracy: 0.8241	best_test_accuracy: 0.7869
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7906.9009	loss_val: 7907.3970	loss_test: 7907.0845	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 11913.4150	loss_val: 11914.1182	loss_test: 11913.6133	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 68996.2188	loss_val: 68996.4922	loss_test: 68996.8047	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 35264.9414	loss_val: 35264.9375	loss_test: 35264.9805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6816.2803	loss_val: 6818.0332	loss_test: 6816.5640	accuracy_train: 0.9877	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4469.3862	loss_val: 4469.3799	loss_test: 4469.3716	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8714.2451	loss_val: 8714.2285	loss_test: 8714.5635	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5422.4780	loss_val: 5422.6211	loss_test: 5423.0073	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 9422.2559	loss_val: 9422.6436	loss_test: 9422.4473	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 7070.5073	loss_val: 7070.5303	loss_test: 7070.4888	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8093.8320	loss_val: 8093.9072	loss_test: 8093.8320	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5588.7837	loss_val: 5589.1865	loss_test: 5589.6191	accuracy_train: 0.9873	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5435.4487	loss_val: 5435.8589	loss_test: 5436.2871	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13858.6396	loss_val: 13858.7021	loss_test: 13859.2129	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4218.8018	loss_val: 4218.7480	loss_test: 4219.1143	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5240.8560	loss_val: 5241.2085	loss_test: 5241.4941	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4139.1123	loss_val: 4139.0796	loss_test: 4139.0918	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8008.7539	loss_val: 8008.6685	loss_test: 8009.4893	accuracy_train: 0.9630	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 52833.5312	loss_val: 52833.4375	loss_test: 52833.7969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6592.4712	loss_val: 6592.6880	loss_test: 6592.7759	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 43	curr_val_accuracy: 0.8146	curr_test_accuracy: 0.7928
best_round: 38	best_val_accuracy: 0.8241	best_test_accuracy: 0.7869
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7717.3940	loss_val: 7717.8848	loss_test: 7717.5771	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 1.0000
[client 1]	loss_train: 12056.3662	loss_val: 12057.0869	loss_test: 12056.5703	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 69418.0312	loss_val: 69418.3359	loss_test: 69418.6250	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 36650.1445	loss_val: 36650.1406	loss_test: 36650.1875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6751.8867	loss_val: 6753.7236	loss_test: 6752.1875	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4444.2114	loss_val: 4444.2056	loss_test: 4444.1968	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8811.0596	loss_val: 8811.0449	loss_test: 8811.3809	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5378.6958	loss_val: 5378.8711	loss_test: 5379.2783	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 9508.8877	loss_val: 9509.2812	loss_test: 9509.0850	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.8571
[client 9]	loss_train: 7177.6216	loss_val: 7177.6450	loss_test: 7177.6040	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8124.9858	loss_val: 8125.0649	loss_test: 8124.9878	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5491.9331	loss_val: 5492.3584	loss_test: 5492.7773	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5425.6177	loss_val: 5426.0405	loss_test: 5426.4619	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13536.8262	loss_val: 13536.9053	loss_test: 13537.4238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4202.4170	loss_val: 4202.3672	loss_test: 4202.7402	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5235.5410	loss_val: 5235.9160	loss_test: 5236.1963	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4149.0166	loss_val: 4148.9839	loss_test: 4148.9976	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8054.8872	loss_val: 8054.8081	loss_test: 8055.6265	accuracy_train: 0.9259	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 53513.1953	loss_val: 53513.1055	loss_test: 53513.4453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6662.4932	loss_val: 6662.6943	loss_test: 6662.7910	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 44	curr_val_accuracy: 0.8146	curr_test_accuracy: 0.8087
best_round: 38	best_val_accuracy: 0.8241	best_test_accuracy: 0.7869
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7574.0156	loss_val: 7574.5083	loss_test: 7574.2085	accuracy_train: 0.9867	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 1]	loss_train: 12199.7832	loss_val: 12200.5186	loss_test: 12199.9951	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 70149.4531	loss_val: 70149.7969	loss_test: 70150.0703	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 38325.4102	loss_val: 38325.4062	loss_test: 38325.4570	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6705.0161	loss_val: 6706.9170	loss_test: 6705.3340	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4443.0337	loss_val: 4443.0288	loss_test: 4443.0186	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8895.8174	loss_val: 8895.8047	loss_test: 8896.1387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5373.6558	loss_val: 5373.8564	loss_test: 5374.2876	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 9576.9893	loss_val: 9577.3955	loss_test: 9577.1943	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 7302.4331	loss_val: 7302.4575	loss_test: 7302.4175	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8158.4448	loss_val: 8158.5269	loss_test: 8158.4497	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5419.2622	loss_val: 5419.7124	loss_test: 5420.1147	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5426.1553	loss_val: 5426.5913	loss_test: 5427.0054	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13234.0791	loss_val: 13234.1729	loss_test: 13234.6973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4202.6787	loss_val: 4202.6323	loss_test: 4203.0112	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5234.7241	loss_val: 5235.1216	loss_test: 5235.3940	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4164.4277	loss_val: 4164.3950	loss_test: 4164.4111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8082.0054	loss_val: 8081.9414	loss_test: 8082.7534	accuracy_train: 0.9630	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 54295.3008	loss_val: 54295.2109	loss_test: 54295.5352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6710.7959	loss_val: 6710.9912	loss_test: 6711.0894	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 45	curr_val_accuracy: 0.8108	curr_test_accuracy: 0.8013
best_round: 38	best_val_accuracy: 0.8241	best_test_accuracy: 0.7869
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7503.4658	loss_val: 7503.9663	loss_test: 7503.6777	accuracy_train: 0.9867	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 1]	loss_train: 12323.4922	loss_val: 12324.2490	loss_test: 12323.7109	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 70927.1484	loss_val: 70927.5156	loss_test: 70927.7891	accuracy_train: 0.9429	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 39770.8906	loss_val: 39770.8828	loss_test: 39770.9375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6675.1157	loss_val: 6677.0859	loss_test: 6675.4463	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4435.5044	loss_val: 4435.5010	loss_test: 4435.4902	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8986.2285	loss_val: 8986.2188	loss_test: 8986.5459	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5353.9868	loss_val: 5354.2095	loss_test: 5354.6621	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 9556.9805	loss_val: 9557.4199	loss_test: 9557.2227	accuracy_train: 0.9583	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 7447.2925	loss_val: 7447.3174	loss_test: 7447.2788	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8162.2993	loss_val: 8162.3833	loss_test: 8162.3066	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5359.6089	loss_val: 5360.0854	loss_test: 5360.4746	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5422.2021	loss_val: 5422.6523	loss_test: 5423.0503	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13004.2998	loss_val: 13004.4033	loss_test: 13004.9355	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4208.8232	loss_val: 4208.7783	loss_test: 4209.1689	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5247.7607	loss_val: 5248.1758	loss_test: 5248.4482	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4180.2139	loss_val: 4180.1812	loss_test: 4180.1987	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8080.3149	loss_val: 8080.2744	loss_test: 8081.0566	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 55340.4570	loss_val: 55340.3711	loss_test: 55340.6836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6732.8711	loss_val: 6733.0635	loss_test: 6733.1611	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 46	curr_val_accuracy: 0.8281	curr_test_accuracy: 0.8013
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7427.0576	loss_val: 7427.5884	loss_test: 7427.2983	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 1]	loss_train: 12500.6396	loss_val: 12501.3994	loss_test: 12500.8574	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 71442.8125	loss_val: 71443.2031	loss_test: 71443.4609	accuracy_train: 0.9429	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 41077.9609	loss_val: 41077.9531	loss_test: 41078.0117	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6666.6309	loss_val: 6668.6460	loss_test: 6666.9678	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4446.5615	loss_val: 4446.5596	loss_test: 4446.5479	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9074.3984	loss_val: 9074.3916	loss_test: 9074.7080	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5353.3374	loss_val: 5353.5806	loss_test: 5354.0479	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 9555.8057	loss_val: 9556.2744	loss_test: 9556.0820	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 7584.3149	loss_val: 7584.3408	loss_test: 7584.3032	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8152.3354	loss_val: 8152.4209	loss_test: 8152.3442	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5357.5210	loss_val: 5358.0112	loss_test: 5358.4141	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5427.3608	loss_val: 5427.8257	loss_test: 5428.2070	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12844.6533	loss_val: 12844.7646	loss_test: 12845.3057	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4210.2017	loss_val: 4210.1582	loss_test: 4210.5576	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5260.0972	loss_val: 5260.5332	loss_test: 5260.8008	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4197.5317	loss_val: 4197.5005	loss_test: 4197.5190	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8044.2124	loss_val: 8044.2017	loss_test: 8044.9360	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 56361.7734	loss_val: 56361.6875	loss_test: 56361.9922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6707.8867	loss_val: 6708.0908	loss_test: 6708.1758	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 47	curr_val_accuracy: 0.8197	curr_test_accuracy: 0.8013
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7366.8999	loss_val: 7367.4751	loss_test: 7367.1729	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 1.0000
[client 1]	loss_train: 12632.1328	loss_val: 12632.8926	loss_test: 12632.3477	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 71477.8047	loss_val: 71478.1953	loss_test: 71478.4531	accuracy_train: 0.9429	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 42201.9180	loss_val: 42201.9102	loss_test: 42201.9727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6677.1504	loss_val: 6679.2251	loss_test: 6677.4932	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4460.6924	loss_val: 4460.6914	loss_test: 4460.6792	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9150.4141	loss_val: 9150.4111	loss_test: 9150.7158	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5362.4170	loss_val: 5362.6797	loss_test: 5363.1523	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 9595.2617	loss_val: 9595.7568	loss_test: 9595.5723	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 7703.9263	loss_val: 7703.9526	loss_test: 7703.9160	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8147.9453	loss_val: 8148.0322	loss_test: 8147.9541	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5433.3730	loss_val: 5433.8691	loss_test: 5434.3164	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5450.9243	loss_val: 5451.4058	loss_test: 5451.7700	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12684.8867	loss_val: 12685.0049	loss_test: 12685.5566	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4216.5776	loss_val: 4216.5366	loss_test: 4216.9468	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5269.8096	loss_val: 5270.2715	loss_test: 5270.5312	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4213.9004	loss_val: 4213.8711	loss_test: 4213.8901	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8031.3428	loss_val: 8031.3525	loss_test: 8032.0537	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 57279.0938	loss_val: 57279.0078	loss_test: 57279.3047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6641.2095	loss_val: 6641.4424	loss_test: 6641.5054	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 48	curr_val_accuracy: 0.7949	curr_test_accuracy: 0.7939
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7336.6353	loss_val: 7337.2573	loss_test: 7336.9395	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 12793.9883	loss_val: 12794.7334	loss_test: 12794.1953	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 71265.0312	loss_val: 71265.4141	loss_test: 71265.6797	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 43636.5938	loss_val: 43636.5859	loss_test: 43636.6484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6702.1055	loss_val: 6704.2480	loss_test: 6702.4473	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4488.6606	loss_val: 4488.6616	loss_test: 4488.6489	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9250.3330	loss_val: 9250.3340	loss_test: 9250.6270	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5377.2407	loss_val: 5377.5186	loss_test: 5378.0015	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 9658.0977	loss_val: 9658.6162	loss_test: 9658.4365	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7825.7490	loss_val: 7825.7764	loss_test: 7825.7397	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8158.1055	loss_val: 8158.1929	loss_test: 8158.1143	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5546.2041	loss_val: 5546.6978	loss_test: 5547.2104	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5469.7778	loss_val: 5470.2715	loss_test: 5470.6270	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12616.8584	loss_val: 12616.9785	loss_test: 12617.5420	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4231.3740	loss_val: 4231.3350	loss_test: 4231.7612	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5278.2837	loss_val: 5278.7686	loss_test: 5279.0220	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4235.7422	loss_val: 4235.7144	loss_test: 4235.7344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7985.6694	loss_val: 7985.7119	loss_test: 7986.3657	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 58298.6406	loss_val: 58298.5586	loss_test: 58298.8477	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6573.7729	loss_val: 6574.0342	loss_test: 6574.0781	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 49	curr_val_accuracy: 0.8035	curr_test_accuracy: 0.7697
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7299.1836	loss_val: 7299.8535	loss_test: 7299.5107	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 12961.0479	loss_val: 12961.7822	loss_test: 12961.2500	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 70505.6797	loss_val: 70506.0312	loss_test: 70506.3359	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 44708.1562	loss_val: 44708.1484	loss_test: 44708.2148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6739.9487	loss_val: 6742.1621	loss_test: 6740.2871	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4519.7939	loss_val: 4519.7964	loss_test: 4519.7832	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9365.0469	loss_val: 9365.0518	loss_test: 9365.3350	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5386.4463	loss_val: 5386.7383	loss_test: 5387.2251	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9702.4668	loss_val: 9703.0088	loss_test: 9702.8330	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7959.8491	loss_val: 7959.8760	loss_test: 7959.8403	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8172.1211	loss_val: 8172.2070	loss_test: 8172.1279	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5632.0513	loss_val: 5632.5439	loss_test: 5633.1123	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5490.4990	loss_val: 5491.0034	loss_test: 5491.3687	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12547.5137	loss_val: 12547.6348	loss_test: 12548.2129	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4255.8135	loss_val: 4255.7764	loss_test: 4256.2148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5300.0571	loss_val: 5300.5674	loss_test: 5300.8110	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4264.1465	loss_val: 4264.1201	loss_test: 4264.1406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7953.6758	loss_val: 7953.7485	loss_test: 7954.3560	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 59264.7148	loss_val: 59264.6328	loss_test: 59264.9141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6515.7773	loss_val: 6516.0703	loss_test: 6516.0928	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 50	curr_val_accuracy: 0.8035	curr_test_accuracy: 0.7839
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7270.9907	loss_val: 7271.6870	loss_test: 7271.3208	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13082.6201	loss_val: 13083.3320	loss_test: 13082.8154	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 70138.0156	loss_val: 70138.3359	loss_test: 70138.6953	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 45918.1289	loss_val: 45918.1211	loss_test: 45918.1914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6792.5967	loss_val: 6794.8770	loss_test: 6792.9351	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4551.7622	loss_val: 4551.7651	loss_test: 4551.7524	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9472.3174	loss_val: 9472.3262	loss_test: 9472.6006	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5401.1182	loss_val: 5401.4185	loss_test: 5401.9092	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9762.1885	loss_val: 9762.7490	loss_test: 9762.5684	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8055.8135	loss_val: 8055.8418	loss_test: 8055.8062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8216.4688	loss_val: 8216.5508	loss_test: 8216.4736	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5659.6367	loss_val: 5660.1309	loss_test: 5660.7383	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5509.9102	loss_val: 5510.4233	loss_test: 5510.8081	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12496.3594	loss_val: 12496.4766	loss_test: 12497.0752	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4274.9355	loss_val: 4274.8994	loss_test: 4275.3530	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5332.4209	loss_val: 5332.9590	loss_test: 5333.1938	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4287.8101	loss_val: 4287.7856	loss_test: 4287.8062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7905.0845	loss_val: 7905.1812	loss_test: 7905.7466	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 60128.0117	loss_val: 60127.9336	loss_test: 60128.2070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6367.4604	loss_val: 6367.8677	loss_test: 6367.8101	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 51	curr_val_accuracy: 0.8122	curr_test_accuracy: 0.7839
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7240.0542	loss_val: 7240.7480	loss_test: 7240.3672	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13172.1523	loss_val: 13172.8418	loss_test: 13172.3398	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 70067.7188	loss_val: 70068.0156	loss_test: 70068.4375	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 47295.7500	loss_val: 47295.7383	loss_test: 47295.8125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6912.9268	loss_val: 6915.2705	loss_test: 6913.2666	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4589.2822	loss_val: 4589.2856	loss_test: 4589.2729	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9571.9043	loss_val: 9571.9160	loss_test: 9572.1836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5426.1016	loss_val: 5426.4067	loss_test: 5426.8984	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9841.8066	loss_val: 9842.3877	loss_test: 9842.1895	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8162.1377	loss_val: 8162.1660	loss_test: 8162.1313	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8282.8496	loss_val: 8282.9287	loss_test: 8282.8535	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5849.8418	loss_val: 5850.3198	loss_test: 5851.0181	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5539.0957	loss_val: 5539.6191	loss_test: 5540.0054	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12431.8389	loss_val: 12431.9531	loss_test: 12432.5684	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4292.9072	loss_val: 4292.8721	loss_test: 4293.3354	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5368.6411	loss_val: 5369.2070	loss_test: 5369.4341	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4322.0962	loss_val: 4322.0737	loss_test: 4322.0938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7837.1602	loss_val: 7837.2910	loss_test: 7837.7861	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 61014.5273	loss_val: 61014.4492	loss_test: 61014.7148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6291.6064	loss_val: 6292.1196	loss_test: 6291.9897	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 52	curr_val_accuracy: 0.8208	curr_test_accuracy: 0.7976
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7212.2363	loss_val: 7212.9214	loss_test: 7212.5361	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13247.3379	loss_val: 13247.9912	loss_test: 13247.5156	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 70161.3281	loss_val: 70161.6484	loss_test: 70162.0703	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 48793.5273	loss_val: 48793.5156	loss_test: 48793.5938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6989.5938	loss_val: 6992.0210	loss_test: 6989.9424	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4617.3379	loss_val: 4617.3423	loss_test: 4617.3291	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9662.7324	loss_val: 9662.7471	loss_test: 9663.0098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5447.1655	loss_val: 5447.4746	loss_test: 5447.9634	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9945.9678	loss_val: 9946.5537	loss_test: 9946.3418	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8264.4023	loss_val: 8264.4307	loss_test: 8264.3965	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8390.3721	loss_val: 8390.4492	loss_test: 8390.3760	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5860.8013	loss_val: 5861.3071	loss_test: 5862.0156	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5549.2222	loss_val: 5549.7534	loss_test: 5550.1733	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12396.4902	loss_val: 12396.5986	loss_test: 12397.2324	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4313.8071	loss_val: 4313.7725	loss_test: 4314.2456	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5388.1958	loss_val: 5388.7954	loss_test: 5389.0195	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4355.2559	loss_val: 4355.2354	loss_test: 4355.2549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7820.2842	loss_val: 7820.4458	loss_test: 7820.8794	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 61692.7734	loss_val: 61692.6992	loss_test: 61692.9570	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6230.4883	loss_val: 6231.1064	loss_test: 6230.9072	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 53	curr_val_accuracy: 0.8132	curr_test_accuracy: 0.8053
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7193.2935	loss_val: 7193.9619	loss_test: 7193.5767	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13313.1729	loss_val: 13313.8115	loss_test: 13313.3486	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 70566.3047	loss_val: 70566.6484	loss_test: 70567.0625	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 50431.6523	loss_val: 50431.6406	loss_test: 50431.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7127.6040	loss_val: 7130.1143	loss_test: 7127.9668	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4643.5620	loss_val: 4643.5664	loss_test: 4643.5537	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9761.6162	loss_val: 9761.6338	loss_test: 9761.8906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5484.4722	loss_val: 5484.7817	loss_test: 5485.2632	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10106.0635	loss_val: 10106.6494	loss_test: 10106.4209	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8369.5459	loss_val: 8369.5742	loss_test: 8369.5430	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8518.4824	loss_val: 8518.5547	loss_test: 8518.4863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5863.6772	loss_val: 5864.2202	loss_test: 5864.9194	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5571.4878	loss_val: 5572.0312	loss_test: 5572.4766	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12306.7676	loss_val: 12306.8730	loss_test: 12307.5244	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4345.6777	loss_val: 4345.6445	loss_test: 4346.1318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5416.0366	loss_val: 5416.6538	loss_test: 5416.8857	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4395.1626	loss_val: 4395.1440	loss_test: 4395.1626	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7820.9272	loss_val: 7821.1143	loss_test: 7821.4946	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62158.1250	loss_val: 62158.0547	loss_test: 62158.3047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6215.3262	loss_val: 6216.0312	loss_test: 6215.7754	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 54	curr_val_accuracy: 0.8040	curr_test_accuracy: 0.8208
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7187.7466	loss_val: 7188.4023	loss_test: 7188.0205	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 1.0000
[client 1]	loss_train: 13324.6191	loss_val: 13325.2480	loss_test: 13324.7910	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 70998.9688	loss_val: 70999.3359	loss_test: 70999.7422	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 52162.2656	loss_val: 52162.2578	loss_test: 52162.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7237.2676	loss_val: 7239.8242	loss_test: 7237.6538	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4669.2397	loss_val: 4669.2441	loss_test: 4669.2314	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9878.0449	loss_val: 9878.0654	loss_test: 9878.3154	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5524.1831	loss_val: 5524.4941	loss_test: 5524.9644	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10302.2119	loss_val: 10302.8057	loss_test: 10302.5479	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 8475.8018	loss_val: 8475.8301	loss_test: 8475.8008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8693.2881	loss_val: 8693.3574	loss_test: 8693.2930	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5817.9072	loss_val: 5818.4976	loss_test: 5819.1558	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5594.0474	loss_val: 5594.6045	loss_test: 5595.0552	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12277.8809	loss_val: 12277.9854	loss_test: 12278.6484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4385.9609	loss_val: 4385.9287	loss_test: 4386.4238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5432.1621	loss_val: 5432.7939	loss_test: 5433.0439	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4434.4014	loss_val: 4434.3843	loss_test: 4434.4023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7866.5293	loss_val: 7866.7319	loss_test: 7867.0796	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62468.3867	loss_val: 62468.3164	loss_test: 62468.5586	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6229.0874	loss_val: 6229.8457	loss_test: 6229.5649	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 55	curr_val_accuracy: 0.8040	curr_test_accuracy: 0.8320
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7187.1294	loss_val: 7187.7710	loss_test: 7187.4053	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 1]	loss_train: 13336.9961	loss_val: 13337.6504	loss_test: 13337.1768	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 71449.7422	loss_val: 71450.1250	loss_test: 71450.5234	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 53702.7773	loss_val: 53702.7695	loss_test: 53702.8477	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7287.6577	loss_val: 7290.2886	loss_test: 7288.0513	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4690.0107	loss_val: 4690.0156	loss_test: 4690.0024	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9963.1904	loss_val: 9963.2119	loss_test: 9963.4570	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5567.1250	loss_val: 5567.4385	loss_test: 5567.9009	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10497.5479	loss_val: 10498.1367	loss_test: 10497.8555	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 8588.6289	loss_val: 8588.6582	loss_test: 8588.6299	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8888.0859	loss_val: 8888.1523	loss_test: 8888.0928	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5722.0205	loss_val: 5722.6470	loss_test: 5723.2642	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5614.4365	loss_val: 5615.0132	loss_test: 5615.4619	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12222.9248	loss_val: 12223.0293	loss_test: 12223.7070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4400.1685	loss_val: 4400.1362	loss_test: 4400.6411	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5458.3882	loss_val: 5459.0352	loss_test: 5459.3052	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4466.6182	loss_val: 4466.6021	loss_test: 4466.6196	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7901.9082	loss_val: 7902.1299	loss_test: 7902.4648	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63013.6133	loss_val: 63013.5469	loss_test: 63013.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6228.5908	loss_val: 6229.4028	loss_test: 6229.0991	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 56	curr_val_accuracy: 0.8034	curr_test_accuracy: 0.8246
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7200.3013	loss_val: 7200.9307	loss_test: 7200.5815	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.9000
[client 1]	loss_train: 13333.4023	loss_val: 13334.0732	loss_test: 13333.5859	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 71680.2031	loss_val: 71680.6094	loss_test: 71680.9688	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 55350.3516	loss_val: 55350.3438	loss_test: 55350.4258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7427.0337	loss_val: 7429.7212	loss_test: 7427.4385	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4714.1157	loss_val: 4714.1206	loss_test: 4714.1069	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10044.5176	loss_val: 10044.5400	loss_test: 10044.7793	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5605.6855	loss_val: 5606.0005	loss_test: 5606.4448	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10727.5488	loss_val: 10728.1367	loss_test: 10727.8291	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 8713.7734	loss_val: 8713.8027	loss_test: 8713.7754	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9076.0352	loss_val: 9076.0986	loss_test: 9076.0420	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5664.9751	loss_val: 5665.6250	loss_test: 5666.2144	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5633.0161	loss_val: 5633.6094	loss_test: 5634.0664	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12201.6904	loss_val: 12201.7959	loss_test: 12202.4805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4431.9229	loss_val: 4431.8916	loss_test: 4432.4092	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5476.5562	loss_val: 5477.2090	loss_test: 5477.5068	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4496.9834	loss_val: 4496.9678	loss_test: 4496.9854	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7909.5439	loss_val: 7909.7886	loss_test: 7910.1064	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63348.2344	loss_val: 63348.1719	loss_test: 63348.3984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6245.1680	loss_val: 6245.9849	loss_test: 6245.6914	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 57	curr_val_accuracy: 0.7948	curr_test_accuracy: 0.8165
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7294.0679	loss_val: 7294.6831	loss_test: 7294.3486	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13291.9229	loss_val: 13292.6045	loss_test: 13292.1094	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 71790.5078	loss_val: 71790.9141	loss_test: 71791.2812	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 57147.5547	loss_val: 57147.5469	loss_test: 57147.6289	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7451.5908	loss_val: 7454.3052	loss_test: 7451.9985	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4730.9141	loss_val: 4730.9180	loss_test: 4730.9048	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10137.9248	loss_val: 10137.9482	loss_test: 10138.1836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5638.6836	loss_val: 5639.0024	loss_test: 5639.4307	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10944.9531	loss_val: 10945.5400	loss_test: 10945.2129	accuracy_train: 0.9583	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 8810.2617	loss_val: 8810.2900	loss_test: 8810.2656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9251.4873	loss_val: 9251.5498	loss_test: 9251.4961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5602.0913	loss_val: 5602.7622	loss_test: 5603.3276	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5663.9136	loss_val: 5664.5234	loss_test: 5665.0142	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12114.4092	loss_val: 12114.5127	loss_test: 12115.2119	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4471.7632	loss_val: 4471.7324	loss_test: 4472.2715	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5499.8218	loss_val: 5500.4888	loss_test: 5500.8145	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4533.3540	loss_val: 4533.3389	loss_test: 4533.3564	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7935.0850	loss_val: 7935.3423	loss_test: 7935.6621	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64007.9023	loss_val: 64007.8438	loss_test: 64008.0625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6268.9971	loss_val: 6269.8071	loss_test: 6269.5312	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 58	curr_val_accuracy: 0.7793	curr_test_accuracy: 0.8165
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7388.3364	loss_val: 7388.9653	loss_test: 7388.6270	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13294.5742	loss_val: 13295.2715	loss_test: 13294.7646	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 71929.8516	loss_val: 71930.2500	loss_test: 71930.6328	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 58949.7070	loss_val: 58949.6992	loss_test: 58949.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7404.8379	loss_val: 7407.5708	loss_test: 7405.2451	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4740.0020	loss_val: 4740.0054	loss_test: 4739.9927	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10219.6455	loss_val: 10219.6689	loss_test: 10219.9023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5666.6147	loss_val: 5666.9375	loss_test: 5667.3550	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11144.5537	loss_val: 11145.1221	loss_test: 11144.7939	accuracy_train: 0.8958	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 8873.9883	loss_val: 8874.0146	loss_test: 8873.9922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9360.1719	loss_val: 9360.2344	loss_test: 9360.1816	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5562.6787	loss_val: 5563.3687	loss_test: 5563.9141	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5691.6182	loss_val: 5692.2446	loss_test: 5692.7729	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12098.6211	loss_val: 12098.7227	loss_test: 12099.4316	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4512.7446	loss_val: 4512.7144	loss_test: 4513.2651	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5514.3184	loss_val: 5514.9946	loss_test: 5515.3477	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4561.8364	loss_val: 4561.8213	loss_test: 4561.8394	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8011.3408	loss_val: 8011.6006	loss_test: 8011.9321	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64330.7305	loss_val: 64330.6719	loss_test: 64330.8828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6298.2231	loss_val: 6298.9858	loss_test: 6298.7505	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 59	curr_val_accuracy: 0.7793	curr_test_accuracy: 0.8165
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7448.8540	loss_val: 7449.4985	loss_test: 7449.1553	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13271.8662	loss_val: 13272.5898	loss_test: 13272.0625	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 71835.5312	loss_val: 71835.9141	loss_test: 71836.3203	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 60586.3047	loss_val: 60586.2969	loss_test: 60586.3750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7223.3955	loss_val: 7226.1846	loss_test: 7223.8018	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4746.9263	loss_val: 4746.9297	loss_test: 4746.9170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10285.4639	loss_val: 10285.4863	loss_test: 10285.7217	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5672.3188	loss_val: 5672.6479	loss_test: 5673.0596	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11282.0312	loss_val: 11282.6074	loss_test: 11282.2676	accuracy_train: 0.8958	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 8918.2529	loss_val: 8918.2783	loss_test: 8918.2578	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9453.7090	loss_val: 9453.7725	loss_test: 9453.7197	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5457.0005	loss_val: 5457.7134	loss_test: 5458.2061	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5708.1499	loss_val: 5708.7915	loss_test: 5709.3579	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12022.3594	loss_val: 12022.4580	loss_test: 12023.1787	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4536.2251	loss_val: 4536.1953	loss_test: 4536.7598	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5536.3457	loss_val: 5537.0337	loss_test: 5537.4146	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4576.8174	loss_val: 4576.8027	loss_test: 4576.8213	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8067.3579	loss_val: 8067.6201	loss_test: 8067.9644	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64567.6406	loss_val: 64567.5859	loss_test: 64567.7930	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6352.6470	loss_val: 6353.3276	loss_test: 6353.1567	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 60	curr_val_accuracy: 0.7628	curr_test_accuracy: 0.8086
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7465.9526	loss_val: 7466.6133	loss_test: 7466.2588	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13228.3545	loss_val: 13229.1084	loss_test: 13228.5547	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 71627.1328	loss_val: 71627.4922	loss_test: 71627.9297	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 3]	loss_train: 61569.0078	loss_val: 61569.0000	loss_test: 61569.0820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7020.4453	loss_val: 7023.3193	loss_test: 7020.8667	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4751.9097	loss_val: 4751.9126	loss_test: 4751.8999	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10343.4355	loss_val: 10343.4570	loss_test: 10343.6943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5677.7007	loss_val: 5678.0332	loss_test: 5678.4438	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11382.0830	loss_val: 11382.6729	loss_test: 11382.3242	accuracy_train: 0.8542	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 8933.0693	loss_val: 8933.0938	loss_test: 8933.0742	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9518.1504	loss_val: 9518.2139	loss_test: 9518.1611	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5347.1943	loss_val: 5347.9448	loss_test: 5348.3701	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5711.6899	loss_val: 5712.3530	loss_test: 5712.9497	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11994.7588	loss_val: 11994.8545	loss_test: 11995.5830	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4542.6699	loss_val: 4542.6416	loss_test: 4543.2148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5541.2939	loss_val: 5541.9897	loss_test: 5542.3887	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4580.9233	loss_val: 4580.9087	loss_test: 4580.9277	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8180.6328	loss_val: 8180.8853	loss_test: 8181.2549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 64800.6133	loss_val: 64800.5586	loss_test: 64800.7578	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6383.1479	loss_val: 6383.7676	loss_test: 6383.6406	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 61	curr_val_accuracy: 0.7702	curr_test_accuracy: 0.8086
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7439.4722	loss_val: 7440.1475	loss_test: 7439.7817	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13227.2041	loss_val: 13227.9893	loss_test: 13227.4111	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 71150.7500	loss_val: 71151.0859	loss_test: 71151.5547	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 62766.7148	loss_val: 62766.7031	loss_test: 62766.7852	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6886.1987	loss_val: 6889.1631	loss_test: 6886.6548	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4755.2373	loss_val: 4755.2407	loss_test: 4755.2285	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10397.8555	loss_val: 10397.8760	loss_test: 10398.1162	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5682.7832	loss_val: 5683.1182	loss_test: 5683.5347	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11456.4482	loss_val: 11457.0479	loss_test: 11456.7021	accuracy_train: 0.8958	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 8911.0293	loss_val: 8911.0547	loss_test: 8911.0352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9548.9980	loss_val: 9549.0625	loss_test: 9549.0088	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5255.6538	loss_val: 5256.4399	loss_test: 5256.8037	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5720.1372	loss_val: 5720.8184	loss_test: 5721.4355	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11968.5879	loss_val: 11968.6826	loss_test: 11969.4209	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4546.7524	loss_val: 4546.7246	loss_test: 4547.3071	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5543.7393	loss_val: 5544.4419	loss_test: 5544.8560	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4585.1396	loss_val: 4585.1250	loss_test: 4585.1445	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8278.1855	loss_val: 8278.4238	loss_test: 8278.8193	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 64593.2070	loss_val: 64593.1562	loss_test: 64593.3516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6402.4272	loss_val: 6402.9863	loss_test: 6402.9004	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 62	curr_val_accuracy: 0.7954	curr_test_accuracy: 0.7953
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7391.7896	loss_val: 7392.4912	loss_test: 7392.1025	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13220.9326	loss_val: 13221.7490	loss_test: 13221.1455	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 70857.3125	loss_val: 70857.6328	loss_test: 70858.1328	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63331.9102	loss_val: 63331.8984	loss_test: 63331.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6822.1035	loss_val: 6825.1855	loss_test: 6822.5874	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4758.1460	loss_val: 4758.1494	loss_test: 4758.1377	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10453.6553	loss_val: 10453.6748	loss_test: 10453.9219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5682.3691	loss_val: 5682.7036	loss_test: 5683.1416	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11460.7549	loss_val: 11461.3662	loss_test: 11461.0312	accuracy_train: 0.9167	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 8917.2754	loss_val: 8917.2998	loss_test: 8917.2812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9551.1816	loss_val: 9551.2490	loss_test: 9551.1934	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5214.2437	loss_val: 5215.0532	loss_test: 5215.3882	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5731.2080	loss_val: 5731.9126	loss_test: 5732.5566	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11970.0010	loss_val: 11970.0967	loss_test: 11970.8457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4546.6616	loss_val: 4546.6343	loss_test: 4547.2324	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5539.7793	loss_val: 5540.4946	loss_test: 5540.9067	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4586.7363	loss_val: 4586.7217	loss_test: 4586.7417	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8438.2070	loss_val: 8438.4287	loss_test: 8438.8467	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 64829.8867	loss_val: 64829.8359	loss_test: 64830.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6409.3657	loss_val: 6409.8916	loss_test: 6409.8271	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 63	curr_val_accuracy: 0.8114	curr_test_accuracy: 0.8032
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7354.8994	loss_val: 7355.6279	loss_test: 7355.2124	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13229.5527	loss_val: 13230.3867	loss_test: 13229.7676	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 70335.2109	loss_val: 70335.5156	loss_test: 70336.0703	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63756.0078	loss_val: 63755.9961	loss_test: 63756.0859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6834.7114	loss_val: 6837.9272	loss_test: 6835.1929	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4771.5303	loss_val: 4771.5342	loss_test: 4771.5229	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10529.1611	loss_val: 10529.1816	loss_test: 10529.4355	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5650.0723	loss_val: 5650.4062	loss_test: 5650.8682	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11498.6523	loss_val: 11499.2666	loss_test: 11498.9258	accuracy_train: 0.8958	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 8907.0674	loss_val: 8907.0918	loss_test: 8907.0742	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9509.6631	loss_val: 9509.7324	loss_test: 9509.6748	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5202.2510	loss_val: 5203.0649	loss_test: 5203.4160	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5739.6943	loss_val: 5740.4175	loss_test: 5741.0591	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11984.6143	loss_val: 11984.7129	loss_test: 11985.4668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4559.6294	loss_val: 4559.6030	loss_test: 4560.2168	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5552.5435	loss_val: 5553.2842	loss_test: 5553.6787	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4597.7090	loss_val: 4597.6948	loss_test: 4597.7148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8577.6201	loss_val: 8577.8252	loss_test: 8578.2656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 64751.8320	loss_val: 64751.7812	loss_test: 64751.9648	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6421.6479	loss_val: 6422.1440	loss_test: 6422.0996	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 64	curr_val_accuracy: 0.7860	curr_test_accuracy: 0.7951
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7335.6172	loss_val: 7336.3662	loss_test: 7335.9277	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13215.9297	loss_val: 13216.7666	loss_test: 13216.1465	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 69820.4922	loss_val: 69820.7969	loss_test: 69821.3828	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 64248.9883	loss_val: 64248.9766	loss_test: 64249.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6866.6836	loss_val: 6869.9907	loss_test: 6867.1587	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4777.3008	loss_val: 4777.3042	loss_test: 4777.2939	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10612.8428	loss_val: 10612.8633	loss_test: 10613.1270	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5665.6963	loss_val: 5666.0312	loss_test: 5666.5308	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11383.3516	loss_val: 11383.9844	loss_test: 11383.6465	accuracy_train: 0.9375	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 8873.8984	loss_val: 8873.9238	loss_test: 8873.9053	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9543.5869	loss_val: 9543.6572	loss_test: 9543.5986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5200.5947	loss_val: 5201.4048	loss_test: 5201.7822	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5761.5601	loss_val: 5762.2935	loss_test: 5762.9546	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11956.9443	loss_val: 11957.0449	loss_test: 11957.8076	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4566.4019	loss_val: 4566.3760	loss_test: 4567.0122	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5549.8892	loss_val: 5550.6445	loss_test: 5551.0220	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4612.0024	loss_val: 4611.9878	loss_test: 4612.0078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8765.9375	loss_val: 8766.1279	loss_test: 8766.5986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 64595.3398	loss_val: 64595.2930	loss_test: 64595.4727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6393.8047	loss_val: 6394.2993	loss_test: 6394.2603	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 65	curr_val_accuracy: 0.7776	curr_test_accuracy: 0.8032
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7326.6909	loss_val: 7327.4624	loss_test: 7327.0020	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13210.2432	loss_val: 13211.0820	loss_test: 13210.4590	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 69333.8047	loss_val: 69334.1250	loss_test: 69334.7109	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63907.2852	loss_val: 63907.2773	loss_test: 63907.3711	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6970.0010	loss_val: 6973.3477	loss_test: 6970.4404	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4784.0410	loss_val: 4784.0444	loss_test: 4784.0347	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10697.4229	loss_val: 10697.4443	loss_test: 10697.7158	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5671.8594	loss_val: 5672.1934	loss_test: 5672.7246	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11223.9365	loss_val: 11224.6016	loss_test: 11224.2725	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 8833.7881	loss_val: 8833.8145	loss_test: 8833.7959	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9554.9053	loss_val: 9554.9785	loss_test: 9554.9180	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5220.7334	loss_val: 5221.5176	loss_test: 5221.9634	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5774.7559	loss_val: 5775.4878	loss_test: 5776.2227	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11812.1318	loss_val: 11812.2363	loss_test: 11813.0068	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4581.9771	loss_val: 4581.9512	loss_test: 4582.6011	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5560.1587	loss_val: 5560.9204	loss_test: 5561.2886	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4624.4414	loss_val: 4624.4268	loss_test: 4624.4463	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8892.6846	loss_val: 8892.8623	loss_test: 8893.3662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63975.8320	loss_val: 63975.7891	loss_test: 63975.9648	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6378.8008	loss_val: 6379.3022	loss_test: 6379.2578	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 66	curr_val_accuracy: 0.8030	curr_test_accuracy: 0.8106
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7336.4995	loss_val: 7337.2915	loss_test: 7336.8149	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13237.2012	loss_val: 13238.0264	loss_test: 13237.4111	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 68799.1641	loss_val: 68799.5000	loss_test: 68800.1016	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63847.6406	loss_val: 63847.6328	loss_test: 63847.7305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7128.2036	loss_val: 7131.5562	loss_test: 7128.6138	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4800.9067	loss_val: 4800.9097	loss_test: 4800.9004	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10779.8877	loss_val: 10779.9092	loss_test: 10780.1904	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5680.1597	loss_val: 5680.4937	loss_test: 5681.0596	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11061.6143	loss_val: 11062.2959	loss_test: 11061.9912	accuracy_train: 0.9792	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 8785.1777	loss_val: 8785.2051	loss_test: 8785.1865	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9537.5127	loss_val: 9537.5879	loss_test: 9537.5254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5272.4521	loss_val: 5273.1919	loss_test: 5273.7544	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5783.5986	loss_val: 5784.3267	loss_test: 5785.1230	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11716.0586	loss_val: 11716.1641	loss_test: 11716.9404	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4600.8936	loss_val: 4600.8687	loss_test: 4601.5229	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5577.9448	loss_val: 5578.7222	loss_test: 5579.0811	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4640.2310	loss_val: 4640.2158	loss_test: 4640.2344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9003.5537	loss_val: 9003.7256	loss_test: 9004.2520	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63692.8555	loss_val: 63692.8164	loss_test: 63692.9922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6317.8252	loss_val: 6318.4155	loss_test: 6318.3115	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 67	curr_val_accuracy: 0.8030	curr_test_accuracy: 0.8032
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7345.9844	loss_val: 7346.7964	loss_test: 7346.3096	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13274.3984	loss_val: 13275.1895	loss_test: 13274.5996	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68369.9375	loss_val: 68370.2969	loss_test: 68370.9141	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63636.4297	loss_val: 63636.4258	loss_test: 63636.5234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7263.5142	loss_val: 7266.8877	loss_test: 7263.9092	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4817.7490	loss_val: 4817.7520	loss_test: 4817.7432	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10860.2891	loss_val: 10860.3115	loss_test: 10860.5967	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5705.7300	loss_val: 5706.0640	loss_test: 5706.6592	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10871.3945	loss_val: 10872.1006	loss_test: 10871.8232	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 8739.0811	loss_val: 8739.1094	loss_test: 8739.0908	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9575.0078	loss_val: 9575.0859	loss_test: 9575.0215	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5332.8608	loss_val: 5333.5640	loss_test: 5334.2480	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5790.4517	loss_val: 5791.1729	loss_test: 5792.0137	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11686.2803	loss_val: 11686.3936	loss_test: 11687.1680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4615.7544	loss_val: 4615.7300	loss_test: 4616.3794	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5580.4355	loss_val: 5581.2231	loss_test: 5581.5752	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4654.2871	loss_val: 4654.2720	loss_test: 4654.2896	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9024.6553	loss_val: 9024.8311	loss_test: 9025.3418	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63330.8320	loss_val: 63330.7930	loss_test: 63330.9688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6255.8276	loss_val: 6256.5371	loss_test: 6256.3535	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 68	curr_val_accuracy: 0.8030	curr_test_accuracy: 0.8089
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7369.8706	loss_val: 7370.6885	loss_test: 7370.1909	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13350.3945	loss_val: 13351.1602	loss_test: 13350.5879	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 67860.5938	loss_val: 67860.9766	loss_test: 67861.6094	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63319.2305	loss_val: 63319.2227	loss_test: 63319.3242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7396.0757	loss_val: 7399.4731	loss_test: 7396.4692	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4832.3208	loss_val: 4832.3237	loss_test: 4832.3149	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10914.7129	loss_val: 10914.7363	loss_test: 10915.0244	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5715.2871	loss_val: 5715.6221	loss_test: 5716.2402	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10666.0889	loss_val: 10666.8115	loss_test: 10666.5752	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 8671.6113	loss_val: 8671.6406	loss_test: 8671.6221	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9569.6748	loss_val: 9569.7539	loss_test: 9569.6875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5314.8452	loss_val: 5315.5801	loss_test: 5316.2505	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5772.3472	loss_val: 5773.0669	loss_test: 5773.8853	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11696.5586	loss_val: 11696.6807	loss_test: 11697.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4620.0996	loss_val: 4620.0762	loss_test: 4620.7300	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5572.6304	loss_val: 5573.4253	loss_test: 5573.7681	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4659.3799	loss_val: 4659.3652	loss_test: 4659.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9035.4336	loss_val: 9035.6133	loss_test: 9036.1035	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63247.1875	loss_val: 63247.1523	loss_test: 63247.3320	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6267.8359	loss_val: 6268.5552	loss_test: 6268.3730	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 69	curr_val_accuracy: 0.8116	curr_test_accuracy: 0.8017
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7383.9355	loss_val: 7384.7554	loss_test: 7384.2568	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13414.3906	loss_val: 13415.1113	loss_test: 13414.5723	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 67341.9922	loss_val: 67342.3828	loss_test: 67343.0469	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63051.6250	loss_val: 63051.6211	loss_test: 63051.7227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7557.6157	loss_val: 7561.0205	loss_test: 7558.0205	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4844.3584	loss_val: 4844.3608	loss_test: 4844.3525	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10988.7363	loss_val: 10988.7617	loss_test: 10989.0518	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5724.0679	loss_val: 5724.4038	loss_test: 5725.0493	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10507.6826	loss_val: 10508.4258	loss_test: 10508.2178	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8603.7842	loss_val: 8603.8145	loss_test: 8603.7969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9580.7070	loss_val: 9580.7881	loss_test: 9580.7197	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5252.8188	loss_val: 5253.6162	loss_test: 5254.2075	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5745.3276	loss_val: 5746.0430	loss_test: 5746.8511	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11722.4512	loss_val: 11722.5811	loss_test: 11723.3506	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4618.0225	loss_val: 4617.9990	loss_test: 4618.6636	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5561.9653	loss_val: 5562.7676	loss_test: 5563.1162	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4661.4678	loss_val: 4661.4536	loss_test: 4661.4712	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9028.8564	loss_val: 9029.0391	loss_test: 9029.5078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62834.2227	loss_val: 62834.1875	loss_test: 62834.3672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6310.1738	loss_val: 6310.8848	loss_test: 6310.7144	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 70	curr_val_accuracy: 0.8116	curr_test_accuracy: 0.7862
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7403.1182	loss_val: 7403.9458	loss_test: 7403.4531	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 13449.5557	loss_val: 13450.2432	loss_test: 13449.7266	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66322.7188	loss_val: 66323.0859	loss_test: 66323.7812	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 62990.6094	loss_val: 62990.6055	loss_test: 62990.7070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7558.5103	loss_val: 7561.9390	loss_test: 7558.9126	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4854.3389	loss_val: 4854.3413	loss_test: 4854.3335	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11068.9014	loss_val: 11068.9277	loss_test: 11069.2207	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5737.1235	loss_val: 5737.4600	loss_test: 5738.1211	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10411.5820	loss_val: 10412.3350	loss_test: 10412.1611	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8530.6494	loss_val: 8530.6807	loss_test: 8530.6631	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9567.9580	loss_val: 9568.0400	loss_test: 9567.9697	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5224.1743	loss_val: 5225.0312	loss_test: 5225.5591	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5734.0693	loss_val: 5734.7852	loss_test: 5735.5488	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11811.8447	loss_val: 11811.9844	loss_test: 11812.7549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4626.5161	loss_val: 4626.4937	loss_test: 4627.1572	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5545.6118	loss_val: 5546.4097	loss_test: 5546.7612	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4674.6162	loss_val: 4674.6030	loss_test: 4674.6201	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8977.2031	loss_val: 8977.3896	loss_test: 8977.8350	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62550.6250	loss_val: 62550.5898	loss_test: 62550.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6414.0220	loss_val: 6414.6509	loss_test: 6414.5469	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 71	curr_val_accuracy: 0.7951	curr_test_accuracy: 0.7862
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7411.4810	loss_val: 7412.3154	loss_test: 7411.8379	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13506.5586	loss_val: 13507.2070	loss_test: 13506.7207	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 65666.2500	loss_val: 65666.5781	loss_test: 65667.3203	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 62742.0273	loss_val: 62742.0234	loss_test: 62742.1328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7484.8037	loss_val: 7488.1729	loss_test: 7485.2197	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4858.7974	loss_val: 4858.7998	loss_test: 4858.7920	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11145.1064	loss_val: 11145.1348	loss_test: 11145.4258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5737.3447	loss_val: 5737.6816	loss_test: 5738.3486	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10324.2295	loss_val: 10324.9795	loss_test: 10324.8535	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8477.2217	loss_val: 8477.2520	loss_test: 8477.2344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9547.0977	loss_val: 9547.1807	loss_test: 9547.1094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5199.1504	loss_val: 5200.0532	loss_test: 5200.5371	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5712.9990	loss_val: 5713.7119	loss_test: 5714.4209	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 11980.1133	loss_val: 11980.2656	loss_test: 11981.0371	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4628.4580	loss_val: 4628.4365	loss_test: 4629.0986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5557.2793	loss_val: 5558.0869	loss_test: 5558.4438	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4684.5117	loss_val: 4684.4990	loss_test: 4684.5161	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8923.3711	loss_val: 8923.5557	loss_test: 8923.9834	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62288.3516	loss_val: 62288.3203	loss_test: 62288.5078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6521.4556	loss_val: 6522.0190	loss_test: 6521.9673	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 72	curr_val_accuracy: 0.8035	curr_test_accuracy: 0.7858
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7396.9478	loss_val: 7397.8057	loss_test: 7397.3481	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13522.0742	loss_val: 13522.7012	loss_test: 13522.2295	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 65291.0352	loss_val: 65291.3203	loss_test: 65292.1055	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 62750.1211	loss_val: 62750.1172	loss_test: 62750.2266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7393.5781	loss_val: 7396.8843	loss_test: 7394.0039	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4872.7051	loss_val: 4872.7080	loss_test: 4872.7002	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11235.8750	loss_val: 11235.9043	loss_test: 11236.1943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5741.0264	loss_val: 5741.3643	loss_test: 5742.0293	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10264.8408	loss_val: 10265.5986	loss_test: 10265.4990	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8428.7354	loss_val: 8428.7666	loss_test: 8428.7490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9513.0146	loss_val: 9513.0967	loss_test: 9513.0254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5190.5762	loss_val: 5191.4976	loss_test: 5191.9712	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5707.9287	loss_val: 5708.6416	loss_test: 5709.3037	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12111.4707	loss_val: 12111.6348	loss_test: 12112.4033	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4632.2158	loss_val: 4632.1943	loss_test: 4632.8530	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5548.0713	loss_val: 5548.8799	loss_test: 5549.2549	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4700.1030	loss_val: 4700.0913	loss_test: 4700.1084	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8887.1113	loss_val: 8887.2979	loss_test: 8887.7041	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62155.7383	loss_val: 62155.7070	loss_test: 62155.8945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6614.1260	loss_val: 6614.6489	loss_test: 6614.6304	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 73	curr_val_accuracy: 0.8209	curr_test_accuracy: 0.7858
best_round: 46	best_val_accuracy: 0.8281	best_test_accuracy: 0.8013
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7393.3940	loss_val: 7394.2896	loss_test: 7393.8403	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13542.0811	loss_val: 13542.6816	loss_test: 13542.2275	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 64955.0898	loss_val: 64955.3477	loss_test: 64956.1680	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 62681.4258	loss_val: 62681.4219	loss_test: 62681.5312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7237.0630	loss_val: 7240.3066	loss_test: 7237.4976	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4871.8447	loss_val: 4871.8477	loss_test: 4871.8398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11277.2646	loss_val: 11277.2949	loss_test: 11277.5859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5751.8892	loss_val: 5752.2280	loss_test: 5752.8906	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10219.4541	loss_val: 10220.2061	loss_test: 10220.1367	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8374.9199	loss_val: 8374.9521	loss_test: 8374.9336	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9480.8896	loss_val: 9480.9707	loss_test: 9480.9004	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5172.7256	loss_val: 5173.6484	loss_test: 5174.1392	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5703.8242	loss_val: 5704.5425	loss_test: 5705.1421	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12252.1572	loss_val: 12252.3320	loss_test: 12253.0986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4618.4600	loss_val: 4618.4390	loss_test: 4619.0864	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5533.2852	loss_val: 5534.0806	loss_test: 5534.4668	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4710.4326	loss_val: 4710.4219	loss_test: 4710.4385	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8837.0020	loss_val: 8837.1924	loss_test: 8837.5742	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62173.8672	loss_val: 62173.8359	loss_test: 62174.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6600.1680	loss_val: 6600.7393	loss_test: 6600.6978	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 74	curr_val_accuracy: 0.8283	curr_test_accuracy: 0.7858
best_round: 74	best_val_accuracy: 0.8283	best_test_accuracy: 0.7858
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7393.1841	loss_val: 7394.1211	loss_test: 7393.6753	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13538.5781	loss_val: 13539.1777	loss_test: 13538.7236	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 64921.5781	loss_val: 64921.8281	loss_test: 64922.6602	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 62413.9531	loss_val: 62413.9492	loss_test: 62414.0625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6973.3062	loss_val: 6976.4868	loss_test: 6973.7412	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4866.7847	loss_val: 4866.7871	loss_test: 4866.7798	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11319.9482	loss_val: 11319.9805	loss_test: 11320.2695	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5769.9014	loss_val: 5770.2461	loss_test: 5770.9009	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10206.8701	loss_val: 10207.6162	loss_test: 10207.5693	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8318.2568	loss_val: 8318.2900	loss_test: 8318.2715	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9481.0908	loss_val: 9481.1699	loss_test: 9481.1016	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5164.4961	loss_val: 5165.3955	loss_test: 5165.9551	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5701.0977	loss_val: 5701.8257	loss_test: 5702.3296	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12329.2734	loss_val: 12329.4531	loss_test: 12330.2236	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4602.4297	loss_val: 4602.4092	loss_test: 4603.0522	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5515.5332	loss_val: 5516.3120	loss_test: 5516.7017	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4715.5708	loss_val: 4715.5610	loss_test: 4715.5776	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8776.8076	loss_val: 8776.9961	loss_test: 8777.3701	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62124.7461	loss_val: 62124.7148	loss_test: 62124.9062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6567.0371	loss_val: 6567.6523	loss_test: 6567.5933	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 75	curr_val_accuracy: 0.8364	curr_test_accuracy: 0.7858
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7391.7603	loss_val: 7392.7002	loss_test: 7392.2529	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13482.8398	loss_val: 13483.4453	loss_test: 13482.9854	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 65014.0430	loss_val: 65014.2852	loss_test: 65015.1250	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 62254.3438	loss_val: 62254.3398	loss_test: 62254.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6767.8081	loss_val: 6770.9595	loss_test: 6768.2588	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4864.9326	loss_val: 4864.9355	loss_test: 4864.9277	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11398.2354	loss_val: 11398.2686	loss_test: 11398.5547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5786.9678	loss_val: 5787.3218	loss_test: 5787.9727	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10174.3105	loss_val: 10175.0654	loss_test: 10175.0273	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8315.0781	loss_val: 8315.1084	loss_test: 8315.0938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9477.8662	loss_val: 9477.9434	loss_test: 9477.8779	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5160.2559	loss_val: 5161.1270	loss_test: 5161.7598	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5694.9111	loss_val: 5695.6436	loss_test: 5696.0957	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12445.5850	loss_val: 12445.7705	loss_test: 12446.5400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4600.9814	loss_val: 4600.9609	loss_test: 4601.6147	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5503.8667	loss_val: 5504.6406	loss_test: 5505.0337	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4726.0635	loss_val: 4726.0547	loss_test: 4726.0713	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8704.6729	loss_val: 8704.8662	loss_test: 8705.2119	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62152.7422	loss_val: 62152.7109	loss_test: 62152.9023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6544.8550	loss_val: 6545.5200	loss_test: 6545.4351	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 76	curr_val_accuracy: 0.8196	curr_test_accuracy: 0.7936
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7375.4365	loss_val: 7376.3989	loss_test: 7375.9463	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13432.7529	loss_val: 13433.3604	loss_test: 13432.8984	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 65384.9141	loss_val: 65385.1602	loss_test: 65386.0000	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 62741.2734	loss_val: 62741.2734	loss_test: 62741.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6624.4155	loss_val: 6627.5527	loss_test: 6624.8872	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4863.6802	loss_val: 4863.6831	loss_test: 4863.6758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11415.5205	loss_val: 11415.5537	loss_test: 11415.8398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5805.6631	loss_val: 5806.0254	loss_test: 5806.6665	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10182.8721	loss_val: 10183.6172	loss_test: 10183.5859	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8339.7207	loss_val: 8339.7500	loss_test: 8339.7373	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9475.4434	loss_val: 9475.5176	loss_test: 9475.4551	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5166.8179	loss_val: 5167.6572	loss_test: 5168.3638	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5700.1216	loss_val: 5700.8677	loss_test: 5701.2490	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12532.5596	loss_val: 12532.7520	loss_test: 12533.5264	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4594.0674	loss_val: 4594.0474	loss_test: 4594.7065	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5483.1631	loss_val: 5483.9302	loss_test: 5484.3096	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4735.8369	loss_val: 4735.8286	loss_test: 4735.8447	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8615.2393	loss_val: 8615.4404	loss_test: 8615.7510	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62375.6914	loss_val: 62375.6602	loss_test: 62375.8555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6471.9370	loss_val: 6472.6719	loss_test: 6472.5518	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 77	curr_val_accuracy: 0.8277	curr_test_accuracy: 0.7858
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7367.4414	loss_val: 7368.4404	loss_test: 7367.9712	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13392.3350	loss_val: 13392.9619	loss_test: 13392.4844	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 65519.7539	loss_val: 65520.0078	loss_test: 65520.8438	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 62964.9648	loss_val: 62964.9648	loss_test: 62965.0742	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6492.4980	loss_val: 6495.6343	loss_test: 6492.9961	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4857.9868	loss_val: 4857.9897	loss_test: 4857.9824	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11412.5127	loss_val: 11412.5469	loss_test: 11412.8330	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5850.7368	loss_val: 5851.1084	loss_test: 5851.7549	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10252.6963	loss_val: 10253.4326	loss_test: 10253.3975	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8377.3467	loss_val: 8377.3750	loss_test: 8377.3643	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9461.4854	loss_val: 9461.5586	loss_test: 9461.4980	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5152.8550	loss_val: 5153.6831	loss_test: 5154.4268	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5704.4902	loss_val: 5705.2578	loss_test: 5705.5464	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12606.5371	loss_val: 12606.7324	loss_test: 12607.5098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4577.4238	loss_val: 4577.4043	loss_test: 4578.0654	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5463.3301	loss_val: 5464.0942	loss_test: 5464.4575	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4739.5020	loss_val: 4739.4946	loss_test: 4739.5107	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8542.8037	loss_val: 8543.0137	loss_test: 8543.2969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 62615.1250	loss_val: 62615.0938	loss_test: 62615.2891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6404.8979	loss_val: 6405.6553	loss_test: 6405.5278	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 78	curr_val_accuracy: 0.8190	curr_test_accuracy: 0.7783
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7374.0571	loss_val: 7375.0903	loss_test: 7374.6025	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13310.5088	loss_val: 13311.1846	loss_test: 13310.6709	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 65849.6094	loss_val: 65849.8984	loss_test: 65850.7109	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63311.0234	loss_val: 63311.0234	loss_test: 63311.1367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6420.0288	loss_val: 6423.1704	loss_test: 6420.5586	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4864.0459	loss_val: 4864.0498	loss_test: 4864.0420	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11408.6689	loss_val: 11408.7031	loss_test: 11408.9912	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5908.4165	loss_val: 5908.7988	loss_test: 5909.4556	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10346.3682	loss_val: 10347.0967	loss_test: 10347.0586	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8443.0566	loss_val: 8443.0830	loss_test: 8443.0742	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9468.6289	loss_val: 9468.7012	loss_test: 9468.6426	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5149.4766	loss_val: 5150.2876	loss_test: 5151.0781	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5719.6763	loss_val: 5720.4639	loss_test: 5720.7056	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12699.7393	loss_val: 12699.9395	loss_test: 12700.7178	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4573.5015	loss_val: 4573.4824	loss_test: 4574.1479	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5438.1606	loss_val: 5438.9189	loss_test: 5439.2651	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4741.2158	loss_val: 4741.2095	loss_test: 4741.2256	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8524.9150	loss_val: 8525.1289	loss_test: 8525.3848	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 62695.9336	loss_val: 62695.9062	loss_test: 62696.1016	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6333.6938	loss_val: 6334.4653	loss_test: 6334.3354	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 79	curr_val_accuracy: 0.8191	curr_test_accuracy: 0.7783
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7369.8555	loss_val: 7370.9131	loss_test: 7370.4082	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13246.5732	loss_val: 13247.2988	loss_test: 13246.7490	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66212.5000	loss_val: 66212.8203	loss_test: 66213.6172	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63202.3125	loss_val: 63202.3086	loss_test: 63202.4258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6379.3872	loss_val: 6382.5308	loss_test: 6379.9458	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4868.3247	loss_val: 4868.3291	loss_test: 4868.3208	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11416.9414	loss_val: 11416.9756	loss_test: 11417.2646	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5961.7261	loss_val: 5962.1167	loss_test: 5962.7930	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10387.2588	loss_val: 10387.9746	loss_test: 10387.9453	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8491.7471	loss_val: 8491.7734	loss_test: 8491.7646	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9480.2480	loss_val: 9480.3193	loss_test: 9480.2637	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5171.7798	loss_val: 5172.5522	loss_test: 5173.4316	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5721.9604	loss_val: 5722.7690	loss_test: 5722.9575	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12750.4834	loss_val: 12750.6865	loss_test: 12751.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4571.0381	loss_val: 4571.0195	loss_test: 4571.7002	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5425.5142	loss_val: 5426.2744	loss_test: 5426.5996	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4740.7827	loss_val: 4740.7764	loss_test: 4740.7925	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8519.1230	loss_val: 8519.3330	loss_test: 8519.5732	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63002.9688	loss_val: 63002.9414	loss_test: 63003.1367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6280.2729	loss_val: 6281.0361	loss_test: 6280.9141	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 80	curr_val_accuracy: 0.8107	curr_test_accuracy: 0.7718
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7375.8008	loss_val: 7376.8804	loss_test: 7376.3633	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13198.1445	loss_val: 13198.8975	loss_test: 13198.3242	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66582.9297	loss_val: 66583.2812	loss_test: 66584.0859	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63292.8984	loss_val: 63292.8945	loss_test: 63293.0117	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6376.0674	loss_val: 6379.2290	loss_test: 6376.6440	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4885.7207	loss_val: 4885.7261	loss_test: 4885.7178	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11443.6533	loss_val: 11443.6865	loss_test: 11443.9795	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5987.5776	loss_val: 5987.9780	loss_test: 5988.6655	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10483.3242	loss_val: 10484.0371	loss_test: 10483.9990	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8487.5664	loss_val: 8487.5928	loss_test: 8487.5840	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9469.6191	loss_val: 9469.6895	loss_test: 9469.6357	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5216.4980	loss_val: 5217.2417	loss_test: 5218.2070	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5741.7739	loss_val: 5742.6040	loss_test: 5742.7383	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12753.4707	loss_val: 12753.6768	loss_test: 12754.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4580.2056	loss_val: 4580.1865	loss_test: 4580.8760	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5423.6880	loss_val: 5424.4512	loss_test: 5424.7568	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4759.5474	loss_val: 4759.5415	loss_test: 4759.5566	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8519.7461	loss_val: 8519.9570	loss_test: 8520.1807	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63106.7500	loss_val: 63106.7188	loss_test: 63106.9180	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6270.7812	loss_val: 6271.4785	loss_test: 6271.4043	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 81	curr_val_accuracy: 0.8107	curr_test_accuracy: 0.7718
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7389.7046	loss_val: 7390.8179	loss_test: 7390.2788	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13171.4014	loss_val: 13172.1895	loss_test: 13171.5869	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66662.5000	loss_val: 66662.8828	loss_test: 66663.6875	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63528.8281	loss_val: 63528.8242	loss_test: 63528.9414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6386.2612	loss_val: 6389.4395	loss_test: 6386.8521	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4907.8340	loss_val: 4907.8394	loss_test: 4907.8315	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11433.7061	loss_val: 11433.7383	loss_test: 11434.0361	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5986.4600	loss_val: 5986.8677	loss_test: 5987.5664	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10596.0811	loss_val: 10596.8027	loss_test: 10596.7373	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8448.6035	loss_val: 8448.6318	loss_test: 8448.6221	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9457.3418	loss_val: 9457.4111	loss_test: 9457.3604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5350.1748	loss_val: 5350.8789	loss_test: 5351.9741	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5770.6519	loss_val: 5771.4985	loss_test: 5771.5967	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12775.1250	loss_val: 12775.3281	loss_test: 12776.1074	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4589.4624	loss_val: 4589.4434	loss_test: 4590.1445	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5433.0991	loss_val: 5433.8677	loss_test: 5434.1631	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4777.5703	loss_val: 4777.5649	loss_test: 4777.5796	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8506.8076	loss_val: 8507.0225	loss_test: 8507.2305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63294.5312	loss_val: 63294.5039	loss_test: 63294.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6314.4370	loss_val: 6314.9766	loss_test: 6315.0146	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 82	curr_val_accuracy: 0.8107	curr_test_accuracy: 0.7716
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7395.5020	loss_val: 7396.6406	loss_test: 7396.0854	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13129.8564	loss_val: 13130.6641	loss_test: 13130.0410	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66601.0781	loss_val: 66601.4844	loss_test: 66602.3047	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63857.0742	loss_val: 63857.0703	loss_test: 63857.1875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6372.6533	loss_val: 6375.8545	loss_test: 6373.2666	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4929.9272	loss_val: 4929.9336	loss_test: 4929.9263	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11435.5146	loss_val: 11435.5449	loss_test: 11435.8535	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5991.1377	loss_val: 5991.5542	loss_test: 5992.2656	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10686.8555	loss_val: 10687.5791	loss_test: 10687.4961	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8414.7656	loss_val: 8414.7959	loss_test: 8414.7842	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9494.6455	loss_val: 9494.7158	loss_test: 9494.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5492.0601	loss_val: 5492.7695	loss_test: 5493.9194	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5786.3604	loss_val: 5787.2222	loss_test: 5787.3066	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12749.9893	loss_val: 12750.1885	loss_test: 12750.9707	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4590.3335	loss_val: 4590.3145	loss_test: 4591.0112	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5430.4360	loss_val: 5431.1865	loss_test: 5431.4780	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4789.2070	loss_val: 4789.2021	loss_test: 4789.2168	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8500.3916	loss_val: 8500.6055	loss_test: 8500.8076	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63244.3984	loss_val: 63244.3672	loss_test: 63244.5664	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6378.3423	loss_val: 6378.7446	loss_test: 6378.8721	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 83	curr_val_accuracy: 0.8278	curr_test_accuracy: 0.7716
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7385.1938	loss_val: 7386.3618	loss_test: 7385.7920	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13219.6299	loss_val: 13220.4160	loss_test: 13219.8057	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66722.6562	loss_val: 66723.0703	loss_test: 66723.9219	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 64389.7188	loss_val: 64389.7148	loss_test: 64389.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6361.2935	loss_val: 6364.5166	loss_test: 6361.9238	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4944.0288	loss_val: 4944.0356	loss_test: 4944.0283	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11429.1611	loss_val: 11429.1885	loss_test: 11429.5088	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5956.9917	loss_val: 5957.4150	loss_test: 5958.1343	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10761.4668	loss_val: 10762.1943	loss_test: 10762.0889	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8360.4092	loss_val: 8360.4424	loss_test: 8360.4268	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9540.1641	loss_val: 9540.2344	loss_test: 9540.1826	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5485.5996	loss_val: 5486.3491	loss_test: 5487.4551	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5794.6328	loss_val: 5795.4941	loss_test: 5795.6147	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12686.4150	loss_val: 12686.6104	loss_test: 12687.3994	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4589.6650	loss_val: 4589.6465	loss_test: 4590.3354	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5414.4839	loss_val: 5415.2222	loss_test: 5415.5098	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4789.5957	loss_val: 4789.5908	loss_test: 4789.6050	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8492.0605	loss_val: 8492.2715	loss_test: 8492.4717	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63202.4492	loss_val: 63202.4219	loss_test: 63202.6172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6471.4907	loss_val: 6471.7812	loss_test: 6471.9692	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 84	curr_val_accuracy: 0.8278	curr_test_accuracy: 0.7716
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7379.0820	loss_val: 7380.3169	loss_test: 7379.7114	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13316.6436	loss_val: 13317.3965	loss_test: 13316.8076	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66840.2031	loss_val: 66840.6172	loss_test: 66841.4922	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 64947.9297	loss_val: 64947.9258	loss_test: 64948.0430	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6324.5732	loss_val: 6327.8369	loss_test: 6325.2329	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4953.0625	loss_val: 4953.0693	loss_test: 4953.0620	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11399.5684	loss_val: 11399.5938	loss_test: 11399.9238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5919.3052	loss_val: 5919.7349	loss_test: 5920.4507	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10821.8076	loss_val: 10822.5381	loss_test: 10822.4160	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8299.8994	loss_val: 8299.9346	loss_test: 8299.9160	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9596.0391	loss_val: 9596.1094	loss_test: 9596.0576	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5410.7100	loss_val: 5411.4976	loss_test: 5412.5410	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5782.6826	loss_val: 5783.5371	loss_test: 5783.7324	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12653.0840	loss_val: 12653.2725	loss_test: 12654.0674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4568.8716	loss_val: 4568.8535	loss_test: 4569.5415	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5395.9468	loss_val: 5396.6885	loss_test: 5396.9624	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4780.1504	loss_val: 4780.1455	loss_test: 4780.1602	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8475.0391	loss_val: 8475.2393	loss_test: 8475.4521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63343.3828	loss_val: 63343.3555	loss_test: 63343.5469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6532.0532	loss_val: 6532.2852	loss_test: 6532.4961	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 85	curr_val_accuracy: 0.8110	curr_test_accuracy: 0.7795
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7378.4863	loss_val: 7379.8193	loss_test: 7379.1621	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13435.6221	loss_val: 13436.3330	loss_test: 13435.7764	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66979.4688	loss_val: 66979.8750	loss_test: 66980.7656	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 64917.7500	loss_val: 64917.7461	loss_test: 64917.8633	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6301.4185	loss_val: 6304.7109	loss_test: 6302.1001	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4956.9175	loss_val: 4956.9248	loss_test: 4956.9180	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11333.1514	loss_val: 11333.1738	loss_test: 11333.5146	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5857.6729	loss_val: 5858.1050	loss_test: 5858.8232	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10882.3682	loss_val: 10883.0947	loss_test: 10882.9561	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 8235.3066	loss_val: 8235.3457	loss_test: 8235.3213	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9599.3594	loss_val: 9599.4307	loss_test: 9599.3789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5323.0063	loss_val: 5323.8267	loss_test: 5324.8013	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5773.5269	loss_val: 5774.3794	loss_test: 5774.6260	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12590.1113	loss_val: 12590.2891	loss_test: 12591.1035	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4551.4199	loss_val: 4551.4023	loss_test: 4552.0967	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5377.4800	loss_val: 5378.2231	loss_test: 5378.4814	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4770.0562	loss_val: 4770.0518	loss_test: 4770.0669	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8474.7432	loss_val: 8474.9336	loss_test: 8475.1523	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63258.9492	loss_val: 63258.9219	loss_test: 63259.1133	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6526.3374	loss_val: 6526.5547	loss_test: 6526.7651	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 86	curr_val_accuracy: 0.8110	curr_test_accuracy: 0.7790
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7275.7349	loss_val: 7277.0312	loss_test: 7276.3940	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13588.2295	loss_val: 13588.8984	loss_test: 13588.3711	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68122.5156	loss_val: 68122.9766	loss_test: 68123.8438	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 64871.6680	loss_val: 64871.6641	loss_test: 64871.7773	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6291.5449	loss_val: 6294.8662	loss_test: 6292.2446	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4966.1738	loss_val: 4966.1812	loss_test: 4966.1748	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11281.6123	loss_val: 11281.6328	loss_test: 11281.9805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5800.6743	loss_val: 5801.1094	loss_test: 5801.8232	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10866.4912	loss_val: 10867.2109	loss_test: 10867.0713	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 8176.4121	loss_val: 8176.4536	loss_test: 8176.4243	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9618.9912	loss_val: 9619.0635	loss_test: 9619.0107	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5273.4829	loss_val: 5274.3081	loss_test: 5275.2583	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5758.9629	loss_val: 5759.8042	loss_test: 5760.1304	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12560.2871	loss_val: 12560.4561	loss_test: 12561.2852	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4533.5884	loss_val: 4533.5708	loss_test: 4534.2661	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5354.4556	loss_val: 5355.2012	loss_test: 5355.4570	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4773.4312	loss_val: 4773.4272	loss_test: 4773.4424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8464.2178	loss_val: 8464.4033	loss_test: 8464.6240	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63191.1289	loss_val: 63191.1016	loss_test: 63191.2891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6549.2925	loss_val: 6549.4937	loss_test: 6549.6987	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 87	curr_val_accuracy: 0.8197	curr_test_accuracy: 0.7709
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7208.3008	loss_val: 7209.5664	loss_test: 7208.9434	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13709.5000	loss_val: 13710.1230	loss_test: 13709.6279	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69276.9766	loss_val: 69277.4766	loss_test: 69278.3359	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 64918.5234	loss_val: 64918.5195	loss_test: 64918.6367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6289.3794	loss_val: 6292.7148	loss_test: 6290.0791	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4970.8027	loss_val: 4970.8101	loss_test: 4970.8042	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11248.1543	loss_val: 11248.1738	loss_test: 11248.5273	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5745.2124	loss_val: 5745.6499	loss_test: 5746.3535	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10768.7480	loss_val: 10769.4668	loss_test: 10769.3389	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8144.8931	loss_val: 8144.9355	loss_test: 8144.9028	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9621.0889	loss_val: 9621.1611	loss_test: 9621.1074	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5224.9590	loss_val: 5225.7725	loss_test: 5226.7144	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5737.3330	loss_val: 5738.1636	loss_test: 5738.5820	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12504.9941	loss_val: 12505.1543	loss_test: 12505.9971	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4525.5396	loss_val: 4525.5220	loss_test: 4526.2148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5342.8506	loss_val: 5343.5942	loss_test: 5343.8428	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4774.9443	loss_val: 4774.9404	loss_test: 4774.9561	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8450.4590	loss_val: 8450.6416	loss_test: 8450.8682	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63116.6133	loss_val: 63116.5898	loss_test: 63116.7695	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6512.2871	loss_val: 6512.5205	loss_test: 6512.7007	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 88	curr_val_accuracy: 0.8026	curr_test_accuracy: 0.7561
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7154.5947	loss_val: 7155.8257	loss_test: 7155.2148	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13809.3906	loss_val: 13809.9873	loss_test: 13809.5117	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69825.3984	loss_val: 69825.9297	loss_test: 69826.7656	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 65000.2500	loss_val: 65000.2461	loss_test: 65000.3633	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6292.6104	loss_val: 6296.0122	loss_test: 6293.3052	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4977.8882	loss_val: 4977.8960	loss_test: 4977.8906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11216.6572	loss_val: 11216.6748	loss_test: 11217.0332	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5700.5889	loss_val: 5701.0269	loss_test: 5701.7100	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10681.9102	loss_val: 10682.6211	loss_test: 10682.5107	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8122.3198	loss_val: 8122.3613	loss_test: 8122.3267	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9610.1855	loss_val: 9610.2568	loss_test: 9610.2031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5195.6128	loss_val: 5196.3999	loss_test: 5197.3667	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5721.3569	loss_val: 5722.1719	loss_test: 5722.6870	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12453.4961	loss_val: 12453.6494	loss_test: 12454.5010	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4513.7188	loss_val: 4513.7012	loss_test: 4514.3848	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5333.0098	loss_val: 5333.7505	loss_test: 5333.9941	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4770.9209	loss_val: 4770.9170	loss_test: 4770.9326	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8426.4941	loss_val: 8426.6719	loss_test: 8426.9131	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63475.8086	loss_val: 63475.7852	loss_test: 63475.9648	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6481.3765	loss_val: 6481.6514	loss_test: 6481.8027	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 89	curr_val_accuracy: 0.8026	curr_test_accuracy: 0.7626
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7113.9946	loss_val: 7115.1875	loss_test: 7114.5884	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13924.1191	loss_val: 13924.6846	loss_test: 13924.2324	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 70050.1406	loss_val: 70050.6797	loss_test: 70051.5078	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 64650.2188	loss_val: 64650.2148	loss_test: 64650.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6329.0054	loss_val: 6332.4048	loss_test: 6329.6191	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4972.9795	loss_val: 4972.9873	loss_test: 4972.9829	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11223.5996	loss_val: 11223.6172	loss_test: 11223.9756	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5654.3608	loss_val: 5654.7979	loss_test: 5655.4614	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10618.9072	loss_val: 10619.6182	loss_test: 10619.5156	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8095.1230	loss_val: 8095.1646	loss_test: 8095.1274	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9597.1797	loss_val: 9597.2490	loss_test: 9597.1953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5146.9004	loss_val: 5147.6733	loss_test: 5148.6338	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5717.4414	loss_val: 5718.2451	loss_test: 5718.8491	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12421.6582	loss_val: 12421.8096	loss_test: 12422.6680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4506.6733	loss_val: 4506.6562	loss_test: 4507.3379	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5326.2681	loss_val: 5327.0029	loss_test: 5327.2505	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4763.2798	loss_val: 4763.2754	loss_test: 4763.2915	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8421.6406	loss_val: 8421.8135	loss_test: 8422.0684	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63692.6094	loss_val: 63692.5859	loss_test: 63692.7617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6384.7573	loss_val: 6385.1279	loss_test: 6385.2227	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 90	curr_val_accuracy: 0.8113	curr_test_accuracy: 0.7705
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7077.0620	loss_val: 7078.1997	loss_test: 7077.6191	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 14036.5801	loss_val: 14037.1172	loss_test: 14036.6855	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69961.5703	loss_val: 69962.1094	loss_test: 69962.9219	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 64320.2344	loss_val: 64320.2266	loss_test: 64320.3516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6408.3262	loss_val: 6411.7095	loss_test: 6408.8755	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4975.9346	loss_val: 4975.9424	loss_test: 4975.9385	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11271.0566	loss_val: 11271.0752	loss_test: 11271.4336	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5632.8794	loss_val: 5633.3115	loss_test: 5633.9639	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10557.3438	loss_val: 10558.0488	loss_test: 10557.9658	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8069.7705	loss_val: 8069.8120	loss_test: 8069.7720	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9602.7480	loss_val: 9602.8174	loss_test: 9602.7637	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5167.5781	loss_val: 5168.3135	loss_test: 5169.3247	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5714.4888	loss_val: 5715.2793	loss_test: 5715.9736	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12374.2900	loss_val: 12374.4414	loss_test: 12375.3096	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4497.9512	loss_val: 4497.9346	loss_test: 4498.6104	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5317.2959	loss_val: 5318.0298	loss_test: 5318.2852	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4758.5425	loss_val: 4758.5386	loss_test: 4758.5547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8435.7939	loss_val: 8435.9629	loss_test: 8436.2354	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 63450.9414	loss_val: 63450.9180	loss_test: 63451.0938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6309.2002	loss_val: 6309.6606	loss_test: 6309.6963	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 91	curr_val_accuracy: 0.8113	curr_test_accuracy: 0.7626
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7061.2988	loss_val: 7062.3823	loss_test: 7061.8164	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8000
[client 1]	loss_train: 14119.4814	loss_val: 14120.0029	loss_test: 14119.5811	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69712.5938	loss_val: 69713.1094	loss_test: 69713.9062	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 64056.9492	loss_val: 64056.9453	loss_test: 64057.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6521.9902	loss_val: 6525.3926	loss_test: 6522.4990	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4975.7896	loss_val: 4975.7979	loss_test: 4975.7939	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11333.6064	loss_val: 11333.6250	loss_test: 11333.9883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5622.1533	loss_val: 5622.5781	loss_test: 5623.2300	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10490.5273	loss_val: 10491.2246	loss_test: 10491.1729	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8056.0376	loss_val: 8056.0791	loss_test: 8056.0366	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9570.1553	loss_val: 9570.2236	loss_test: 9570.1680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5207.5957	loss_val: 5208.2979	loss_test: 5209.3633	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5721.4092	loss_val: 5722.1943	loss_test: 5722.9438	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12264.9648	loss_val: 12265.1133	loss_test: 12265.9893	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4498.5352	loss_val: 4498.5186	loss_test: 4499.2070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5320.2432	loss_val: 5320.9761	loss_test: 5321.2417	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4754.2871	loss_val: 4754.2837	loss_test: 4754.3003	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8455.7695	loss_val: 8455.9336	loss_test: 8456.2256	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63419.4414	loss_val: 63419.4180	loss_test: 63419.5938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6264.9688	loss_val: 6265.5063	loss_test: 6265.4902	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 92	curr_val_accuracy: 0.8205	curr_test_accuracy: 0.7781
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7046.1108	loss_val: 7047.1816	loss_test: 7046.6079	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 1]	loss_train: 14119.5938	loss_val: 14120.1143	loss_test: 14119.6934	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 70183.2891	loss_val: 70183.8438	loss_test: 70184.6250	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63678.0039	loss_val: 63677.9961	loss_test: 63678.1250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6627.8057	loss_val: 6631.2324	loss_test: 6628.2866	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4973.2573	loss_val: 4973.2656	loss_test: 4973.2617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11364.8662	loss_val: 11364.8848	loss_test: 11365.2520	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5635.0576	loss_val: 5635.4775	loss_test: 5636.1445	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10470.6895	loss_val: 10471.3691	loss_test: 10471.3584	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8029.4126	loss_val: 8029.4536	loss_test: 8029.4097	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9527.1982	loss_val: 9527.2666	loss_test: 9527.2100	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5287.2065	loss_val: 5287.8691	loss_test: 5289.0034	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5717.3052	loss_val: 5718.0869	loss_test: 5718.8442	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12253.8965	loss_val: 12254.0605	loss_test: 12254.9287	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4500.2041	loss_val: 4500.1880	loss_test: 4500.8745	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5320.2207	loss_val: 5320.9556	loss_test: 5321.2275	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4746.4658	loss_val: 4746.4629	loss_test: 4746.4795	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8470.2754	loss_val: 8470.4336	loss_test: 8470.7480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63298.6758	loss_val: 63298.6523	loss_test: 63298.8281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6249.7427	loss_val: 6250.3423	loss_test: 6250.2856	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 93	curr_val_accuracy: 0.7951	curr_test_accuracy: 0.7860
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7035.4751	loss_val: 7036.5757	loss_test: 7035.9775	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 1]	loss_train: 14059.2480	loss_val: 14059.7754	loss_test: 14059.3516	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 70297.0078	loss_val: 70297.5859	loss_test: 70298.3594	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63667.2109	loss_val: 63667.2031	loss_test: 63667.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6809.4346	loss_val: 6812.8638	loss_test: 6809.9014	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4958.1074	loss_val: 4958.1157	loss_test: 4958.1118	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11415.8408	loss_val: 11415.8604	loss_test: 11416.2324	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5637.1240	loss_val: 5637.5381	loss_test: 5638.2100	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10472.0791	loss_val: 10472.7461	loss_test: 10472.7695	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8008.9390	loss_val: 8008.9800	loss_test: 8008.9346	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9482.4648	loss_val: 9482.5332	loss_test: 9482.4756	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5378.0874	loss_val: 5378.7217	loss_test: 5379.9146	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5715.4917	loss_val: 5716.2700	loss_test: 5717.0151	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12261.1387	loss_val: 12261.3105	loss_test: 12262.1836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4504.6035	loss_val: 4504.5874	loss_test: 4505.2720	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5311.3252	loss_val: 5312.0464	loss_test: 5312.3403	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4742.8848	loss_val: 4742.8813	loss_test: 4742.8984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8531.1992	loss_val: 8531.3535	loss_test: 8531.6895	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63145.9414	loss_val: 63145.9180	loss_test: 63146.0938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6234.1084	loss_val: 6234.7910	loss_test: 6234.6831	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 94	curr_val_accuracy: 0.7951	curr_test_accuracy: 0.7860
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7015.2017	loss_val: 7016.3442	loss_test: 7015.7280	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8000
[client 1]	loss_train: 14003.6230	loss_val: 14004.1572	loss_test: 14003.7305	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69861.4531	loss_val: 69862.0234	loss_test: 69862.7656	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63615.8672	loss_val: 63615.8633	loss_test: 63615.9961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6961.3613	loss_val: 6964.7759	loss_test: 6961.8311	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4941.2017	loss_val: 4941.2095	loss_test: 4941.2056	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11459.0352	loss_val: 11459.0547	loss_test: 11459.4326	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5645.8623	loss_val: 5646.2729	loss_test: 5646.9492	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10416.4248	loss_val: 10417.0811	loss_test: 10417.1572	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7998.5806	loss_val: 7998.6182	loss_test: 7998.5767	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9461.4854	loss_val: 9461.5537	loss_test: 9461.4941	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5356.6538	loss_val: 5357.3140	loss_test: 5358.4575	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5708.5229	loss_val: 5709.2988	loss_test: 5710.0332	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12250.3584	loss_val: 12250.5361	loss_test: 12251.4131	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4494.1211	loss_val: 4494.1050	loss_test: 4494.7837	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5290.2505	loss_val: 5290.9604	loss_test: 5291.2852	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4731.7144	loss_val: 4731.7114	loss_test: 4731.7280	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8612.5586	loss_val: 8612.7100	loss_test: 8613.0762	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63370.3984	loss_val: 63370.3750	loss_test: 63370.5508	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6212.1089	loss_val: 6212.8999	loss_test: 6212.7236	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 95	curr_val_accuracy: 0.8032	curr_test_accuracy: 0.7860
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6993.9307	loss_val: 6995.1226	loss_test: 6994.4976	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13916.2881	loss_val: 13916.8291	loss_test: 13916.3984	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 69469.9531	loss_val: 69470.4922	loss_test: 69471.2031	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63617.2773	loss_val: 63617.2734	loss_test: 63617.4102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7029.3896	loss_val: 7032.7871	loss_test: 7029.8672	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4913.4829	loss_val: 4913.4902	loss_test: 4913.4863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11469.9551	loss_val: 11469.9736	loss_test: 11470.3574	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5643.5059	loss_val: 5643.9116	loss_test: 5644.5923	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10372.4189	loss_val: 10373.0771	loss_test: 10373.1855	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7976.7993	loss_val: 7976.8345	loss_test: 7976.7959	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9443.5000	loss_val: 9443.5684	loss_test: 9443.5088	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5235.5913	loss_val: 5236.3193	loss_test: 5237.3369	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 12]	loss_train: 5691.1226	loss_val: 5691.9043	loss_test: 5692.5962	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12269.3320	loss_val: 12269.5098	loss_test: 12270.3906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4474.2524	loss_val: 4474.2363	loss_test: 4474.9248	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5267.0674	loss_val: 5267.7617	loss_test: 5268.1230	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4707.2627	loss_val: 4707.2588	loss_test: 4707.2759	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8658.3330	loss_val: 8658.4805	loss_test: 8658.8857	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 63046.9336	loss_val: 63046.9102	loss_test: 63047.0820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6183.9365	loss_val: 6184.8179	loss_test: 6184.5864	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 96	curr_val_accuracy: 0.8112	curr_test_accuracy: 0.7779
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6978.1509	loss_val: 6979.3818	loss_test: 6978.7544	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13920.2715	loss_val: 13920.8232	loss_test: 13920.3877	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 68672.1328	loss_val: 68672.6406	loss_test: 68673.3125	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63573.8125	loss_val: 63573.8086	loss_test: 63573.9492	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7029.6230	loss_val: 7032.9907	loss_test: 7030.1060	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4890.4272	loss_val: 4890.4341	loss_test: 4890.4302	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11485.4170	loss_val: 11485.4365	loss_test: 11485.8223	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5637.2856	loss_val: 5637.6890	loss_test: 5638.3760	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10324.9082	loss_val: 10325.5459	loss_test: 10325.7168	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7950.7148	loss_val: 7950.7485	loss_test: 7950.7124	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9416.3447	loss_val: 9416.4121	loss_test: 9416.3525	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5104.7192	loss_val: 5105.5376	loss_test: 5106.3857	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5674.7485	loss_val: 5675.5347	loss_test: 5676.1714	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12296.7627	loss_val: 12296.9414	loss_test: 12297.8262	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4454.5205	loss_val: 4454.5044	loss_test: 4455.2021	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5248.0122	loss_val: 5248.6909	loss_test: 5249.0806	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4686.2065	loss_val: 4686.2026	loss_test: 4686.2197	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8706.7461	loss_val: 8706.8877	loss_test: 8707.3320	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 62789.9922	loss_val: 62789.9688	loss_test: 62790.1367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6140.8789	loss_val: 6141.8491	loss_test: 6141.5640	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 97	curr_val_accuracy: 0.8196	curr_test_accuracy: 0.7701
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6998.8428	loss_val: 7000.1582	loss_test: 6999.5054	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13837.8818	loss_val: 13838.4473	loss_test: 13838.0029	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 67640.3438	loss_val: 67640.8203	loss_test: 67641.4609	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63716.5586	loss_val: 63716.5547	loss_test: 63716.6992	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7048.2295	loss_val: 7051.5547	loss_test: 7048.7222	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4875.1880	loss_val: 4875.1943	loss_test: 4875.1904	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11532.7129	loss_val: 11532.7324	loss_test: 11533.1191	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5640.5635	loss_val: 5640.9678	loss_test: 5641.6553	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10272.4229	loss_val: 10273.0605	loss_test: 10273.2627	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7972.3267	loss_val: 7972.3589	loss_test: 7972.3262	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9367.2998	loss_val: 9367.3652	loss_test: 9367.3066	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4998.5757	loss_val: 4999.4878	loss_test: 5000.1836	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5671.7393	loss_val: 5672.5327	loss_test: 5673.1064	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12371.4521	loss_val: 12371.6328	loss_test: 12372.5195	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4436.3452	loss_val: 4436.3301	loss_test: 4437.0127	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5230.4800	loss_val: 5231.1514	loss_test: 5231.5474	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4671.2886	loss_val: 4671.2852	loss_test: 4671.3022	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8782.4199	loss_val: 8782.5566	loss_test: 8783.0488	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 62808.0039	loss_val: 62807.9844	loss_test: 62808.1484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6117.9424	loss_val: 6118.9556	loss_test: 6118.6479	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 98	curr_val_accuracy: 0.8196	curr_test_accuracy: 0.7626
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7032.6514	loss_val: 7034.0298	loss_test: 7033.3560	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13783.4121	loss_val: 13784.0020	loss_test: 13783.5420	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 66555.2500	loss_val: 66555.6953	loss_test: 66556.3359	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 63949.1289	loss_val: 63949.1250	loss_test: 63949.2695	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7019.8545	loss_val: 7023.1338	loss_test: 7020.3501	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4856.2349	loss_val: 4856.2407	loss_test: 4856.2368	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 11543.5518	loss_val: 11543.5732	loss_test: 11543.9629	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5630.9941	loss_val: 5631.3989	loss_test: 5632.0889	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10242.2969	loss_val: 10242.9443	loss_test: 10243.1514	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7996.2271	loss_val: 7996.2568	loss_test: 7996.2275	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 9311.7920	loss_val: 9311.8564	loss_test: 9311.7988	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4925.2285	loss_val: 4926.2319	loss_test: 4926.7856	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5657.2188	loss_val: 5658.0059	loss_test: 5658.5801	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12420.0703	loss_val: 12420.2539	loss_test: 12421.1436	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4409.2061	loss_val: 4409.1914	loss_test: 4409.8638	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5218.2271	loss_val: 5218.8945	loss_test: 5219.2964	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4656.1528	loss_val: 4656.1489	loss_test: 4656.1660	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8832.3008	loss_val: 8832.4297	loss_test: 8832.9746	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 18]	loss_train: 62684.4531	loss_val: 62684.4336	loss_test: 62684.5938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6084.7021	loss_val: 6085.7671	loss_test: 6085.4287	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 99	curr_val_accuracy: 0.8280	curr_test_accuracy: 0.7626
best_round: 75	best_val_accuracy: 0.8364	best_test_accuracy: 0.7858
--------------------------------------------------
