GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 0.6521	loss_val: 0.6588	loss_test: 0.6663	accuracy_train: 0.6533	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 0.7509	loss_val: 0.6794	loss_test: 0.8596	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 0.6556	loss_val: 0.6173	loss_test: 0.6783	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 0.6036	loss_val: 0.6029	loss_test: 0.6570	accuracy_train: 0.8167	accuracy_val: 0.7143	accuracy_test: 0.7778
[client 4]	loss_train: 0.6802	loss_val: 0.6922	loss_test: 0.6932	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1.1406	loss_val: 1.2056	loss_test: 1.1589	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 6]	loss_train: 0.8024	loss_val: 0.8043	loss_test: 0.7848	accuracy_train: 0.0732	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 7]	loss_train: 0.5250	loss_val: 0.4476	loss_test: 0.5363	accuracy_train: 0.7619	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 0.6440	loss_val: 0.6874	loss_test: 0.6511	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 0.5124	loss_val: 0.5478	loss_test: 0.4724	accuracy_train: 0.9701	accuracy_val: 0.8750	accuracy_test: 1.0000
[client 10]	loss_train: 0.7082	loss_val: 0.8253	loss_test: 1.2954	accuracy_train: 0.4821	accuracy_val: 0.2857	accuracy_test: 0.4286
[client 11]	loss_train: 0.6592	loss_val: 0.6512	loss_test: 0.6712	accuracy_train: 0.7215	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 12]	loss_train: 0.6344	loss_val: 0.6398	loss_test: 0.6321	accuracy_train: 0.6176	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 0.6072	loss_val: 0.6466	loss_test: 0.6297	accuracy_train: 0.8889	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 14]	loss_train: 0.6886	loss_val: 6.5154	loss_test: 0.6452	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 1.0000
[client 15]	loss_train: 0.7297	loss_val: 0.7839	loss_test: 0.7254	accuracy_train: 0.3182	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 16]	loss_train: 0.6775	loss_val: 0.6819	loss_test: 0.6956	accuracy_train: 0.8065	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 17]	loss_train: 0.6664	loss_val: 0.6661	loss_test: 0.6700	accuracy_train: 0.8148	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 0.6420	loss_val: 0.0000	loss_test: 0.6764	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 0.8279	loss_val: 0.7832	loss_test: 0.7984	accuracy_train: 0.1837	accuracy_val: 0.1667	accuracy_test: 0.2308
curr_round: 0	curr_val_accuracy: 0.5545	curr_test_accuracy: 0.5906
best_round: 0	best_val_accuracy: 0.5545	best_test_accuracy: 0.5906
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 252.7037	loss_val: 252.7031	loss_test: 252.7192	accuracy_train: 0.6133	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 423.8259	loss_val: 423.8239	loss_test: 423.8457	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 2585.9458	loss_val: 2585.9495	loss_test: 2585.9373	accuracy_train: 0.3714	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 617.2012	loss_val: 617.1972	loss_test: 617.2294	accuracy_train: 0.7167	accuracy_val: 0.5714	accuracy_test: 0.6667
[client 4]	loss_train: 358.2000	loss_val: 358.2002	loss_test: 358.2092	accuracy_train: 0.6543	accuracy_val: 0.7000	accuracy_test: 0.6364
[client 5]	loss_train: 227.6445	loss_val: 227.6796	loss_test: 227.6491	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 6]	loss_train: 214.9362	loss_val: 214.9516	loss_test: 214.8922	accuracy_train: 0.0488	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 7]	loss_train: 270.7101	loss_val: 270.6499	loss_test: 270.7121	accuracy_train: 0.7381	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 325.9553	loss_val: 326.0005	loss_test: 325.9821	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 214.2181	loss_val: 214.2440	loss_test: 214.1580	accuracy_train: 0.8209	accuracy_val: 0.7500	accuracy_test: 0.6667
[client 10]	loss_train: 308.7134	loss_val: 308.7560	loss_test: 308.7847	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 11]	loss_train: 199.0432	loss_val: 199.0532	loss_test: 199.0570	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 167.7936	loss_val: 167.7961	loss_test: 167.7850	accuracy_train: 0.6176	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 364.8203	loss_val: 364.8531	loss_test: 364.8156	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 14]	loss_train: 248.3007	loss_val: 258.9701	loss_test: 248.2361	accuracy_train: 0.4286	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 205.9212	loss_val: 205.9379	loss_test: 205.9234	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 207.4907	loss_val: 207.4974	loss_test: 207.4978	accuracy_train: 0.5968	accuracy_val: 0.6250	accuracy_test: 0.7500
[client 17]	loss_train: 307.7327	loss_val: 307.7174	loss_test: 307.7401	accuracy_train: 0.8148	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 18]	loss_train: 1228.5746	loss_val: 1227.8773	loss_test: 1228.5649	accuracy_train: 0.7000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 250.6750	loss_val: 250.6101	loss_test: 250.6232	accuracy_train: 0.1837	accuracy_val: 0.1667	accuracy_test: 0.2308
curr_round: 1	curr_val_accuracy: 0.5496	curr_test_accuracy: 0.5705
best_round: 0	best_val_accuracy: 0.5545	best_test_accuracy: 0.5906
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 349.8951	loss_val: 349.9027	loss_test: 349.9105	accuracy_train: 0.6533	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 772.6922	loss_val: 772.7346	loss_test: 772.7175	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 3767.2107	loss_val: 3767.2029	loss_test: 3767.2021	accuracy_train: 0.3714	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 3]	loss_train: 1218.6926	loss_val: 1218.6724	loss_test: 1218.7052	accuracy_train: 0.6500	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 492.7336	loss_val: 492.7242	loss_test: 492.7394	accuracy_train: 0.7654	accuracy_val: 1.0000	accuracy_test: 0.7273
[client 5]	loss_train: 331.0129	loss_val: 331.0425	loss_test: 331.0029	accuracy_train: 0.0800	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 6]	loss_train: 306.8983	loss_val: 306.9154	loss_test: 306.8564	accuracy_train: 0.0732	accuracy_val: 0.0000	accuracy_test: 0.1429
[client 7]	loss_train: 426.7447	loss_val: 426.6849	loss_test: 426.7528	accuracy_train: 0.7857	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 337.8531	loss_val: 337.8819	loss_test: 337.8902	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 336.7388	loss_val: 336.7548	loss_test: 336.6702	accuracy_train: 0.3433	accuracy_val: 0.2500	accuracy_test: 0.4444
[client 10]	loss_train: 451.8556	loss_val: 451.8735	loss_test: 451.8079	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 322.1483	loss_val: 322.1416	loss_test: 322.1918	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 310.8646	loss_val: 310.8651	loss_test: 310.8723	accuracy_train: 0.6176	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 471.4752	loss_val: 471.5009	loss_test: 471.4564	accuracy_train: 0.0556	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 14]	loss_train: 363.5537	loss_val: 384.9473	loss_test: 363.4774	accuracy_train: 0.4286	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 270.5269	loss_val: 270.5518	loss_test: 270.5416	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 353.9282	loss_val: 353.9172	loss_test: 353.9242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 571.4317	loss_val: 571.4282	loss_test: 571.4456	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 2122.1555	loss_val: 2121.4165	loss_test: 2122.1060	accuracy_train: 0.6000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 432.3568	loss_val: 432.2738	loss_test: 432.2850	accuracy_train: 0.1837	accuracy_val: 0.1667	accuracy_test: 0.2308
curr_round: 2	curr_val_accuracy: 0.5828	curr_test_accuracy: 0.5896
best_round: 2	best_val_accuracy: 0.5828	best_test_accuracy: 0.5896
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 459.5258	loss_val: 459.5398	loss_test: 459.5458	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 1286.6835	loss_val: 1286.7366	loss_test: 1286.7349	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 5277.7617	loss_val: 5277.7271	loss_test: 5277.7603	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 1979.5624	loss_val: 1979.5352	loss_test: 1979.5724	accuracy_train: 0.9500	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 674.4215	loss_val: 674.4084	loss_test: 674.4299	accuracy_train: 0.7778	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 451.7178	loss_val: 451.7331	loss_test: 451.6981	accuracy_train: 0.1000	accuracy_val: 0.0000	accuracy_test: 0.2857
[client 6]	loss_train: 424.1862	loss_val: 424.2018	loss_test: 424.1588	accuracy_train: 0.1220	accuracy_val: 0.2000	accuracy_test: 0.1429
[client 7]	loss_train: 626.9149	loss_val: 626.8577	loss_test: 626.9231	accuracy_train: 0.7619	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 412.2118	loss_val: 412.2406	loss_test: 412.2513	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 492.6386	loss_val: 492.6368	loss_test: 492.5699	accuracy_train: 0.0746	accuracy_val: 0.0000	accuracy_test: 0.4444
[client 10]	loss_train: 664.4816	loss_val: 664.4862	loss_test: 664.4334	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 492.4451	loss_val: 492.4265	loss_test: 492.5037	accuracy_train: 0.6203	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 521.5715	loss_val: 521.5663	loss_test: 521.5937	accuracy_train: 0.6176	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 687.1987	loss_val: 687.2328	loss_test: 687.1771	accuracy_train: 0.0556	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 14]	loss_train: 498.1985	loss_val: 528.9173	loss_test: 498.1490	accuracy_train: 0.4286	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 384.2030	loss_val: 384.2557	loss_test: 384.2090	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 504.0962	loss_val: 504.0866	loss_test: 504.0917	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 954.7905	loss_val: 954.8145	loss_test: 954.8047	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 3534.8464	loss_val: 3539.5603	loss_test: 3534.8533	accuracy_train: 0.7000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 664.5372	loss_val: 664.4392	loss_test: 664.4617	accuracy_train: 0.1939	accuracy_val: 0.2500	accuracy_test: 0.2308
curr_round: 3	curr_val_accuracy: 0.5611	curr_test_accuracy: 0.6127
best_round: 2	best_val_accuracy: 0.5828	best_test_accuracy: 0.5896
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 584.6487	loss_val: 584.6684	loss_test: 584.6747	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 1959.0521	loss_val: 1959.1129	loss_test: 1959.1060	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 7089.1992	loss_val: 7089.1572	loss_test: 7089.2036	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 2790.1521	loss_val: 2790.1194	loss_test: 2790.1631	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 906.1655	loss_val: 906.1517	loss_test: 906.1796	accuracy_train: 0.8272	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 582.9637	loss_val: 582.9712	loss_test: 582.9419	accuracy_train: 0.1400	accuracy_val: 0.0000	accuracy_test: 0.4286
[client 6]	loss_train: 564.2159	loss_val: 564.2236	loss_test: 564.2105	accuracy_train: 0.3659	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 7]	loss_train: 851.7805	loss_val: 851.7213	loss_test: 851.7852	accuracy_train: 0.7143	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 561.2867	loss_val: 561.3378	loss_test: 561.3199	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 675.8857	loss_val: 675.8731	loss_test: 675.8236	accuracy_train: 0.1194	accuracy_val: 0.1250	accuracy_test: 0.3333
[client 10]	loss_train: 893.8617	loss_val: 893.8586	loss_test: 893.8170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 691.7916	loss_val: 691.7617	loss_test: 691.8623	accuracy_train: 0.6076	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 767.2707	loss_val: 767.2644	loss_test: 767.2979	accuracy_train: 0.7353	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 975.0195	loss_val: 975.0496	loss_test: 974.9902	accuracy_train: 0.0556	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 14]	loss_train: 647.0432	loss_val: 684.8194	loss_test: 646.9966	accuracy_train: 0.4286	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 553.8628	loss_val: 553.9428	loss_test: 553.8680	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 637.7043	loss_val: 637.6990	loss_test: 637.6986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 1409.4330	loss_val: 1409.4923	loss_test: 1409.4490	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 5405.9131	loss_val: 5421.2607	loss_test: 5405.9805	accuracy_train: 0.8000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 921.8901	loss_val: 921.7814	loss_test: 921.8211	accuracy_train: 0.4592	accuracy_val: 0.6667	accuracy_test: 0.6923
curr_round: 4	curr_val_accuracy: 0.6214	curr_test_accuracy: 0.6727
best_round: 4	best_val_accuracy: 0.6214	best_test_accuracy: 0.6727
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 734.8148	loss_val: 734.8421	loss_test: 734.8458	accuracy_train: 0.6667	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 2767.9895	loss_val: 2768.0591	loss_test: 2768.0291	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 9163.6846	loss_val: 9163.6416	loss_test: 9163.6904	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 3670.3474	loss_val: 3670.3127	loss_test: 3670.3621	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 1193.0811	loss_val: 1193.0698	loss_test: 1193.1011	accuracy_train: 0.7778	accuracy_val: 0.6000	accuracy_test: 0.5455
[client 5]	loss_train: 726.2241	loss_val: 726.2223	loss_test: 726.1976	accuracy_train: 0.2800	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 6]	loss_train: 731.7864	loss_val: 731.7854	loss_test: 731.8062	accuracy_train: 0.8293	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 1096.9362	loss_val: 1096.8717	loss_test: 1096.9421	accuracy_train: 0.7619	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 777.7402	loss_val: 777.8160	loss_test: 777.7664	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 867.7734	loss_val: 867.7573	loss_test: 867.7134	accuracy_train: 0.1642	accuracy_val: 0.1250	accuracy_test: 0.3333
[client 10]	loss_train: 1128.2678	loss_val: 1128.2627	loss_test: 1128.2256	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 926.4233	loss_val: 926.3834	loss_test: 926.5042	accuracy_train: 0.6203	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 1046.9094	loss_val: 1046.8998	loss_test: 1046.9458	accuracy_train: 0.7353	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 1337.2950	loss_val: 1337.3284	loss_test: 1337.2701	accuracy_train: 0.1111	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 14]	loss_train: 812.4310	loss_val: 856.3828	loss_test: 812.3787	accuracy_train: 0.4286	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 779.9943	loss_val: 780.0824	loss_test: 780.0091	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 761.7567	loss_val: 761.7562	loss_test: 761.7509	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 1922.7412	loss_val: 1922.8387	loss_test: 1922.7584	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 7800.0371	loss_val: 7823.9229	loss_test: 7800.1411	accuracy_train: 0.8000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 1202.1483	loss_val: 1202.0341	loss_test: 1202.0917	accuracy_train: 0.6531	accuracy_val: 0.7500	accuracy_test: 0.6154
curr_round: 5	curr_val_accuracy: 0.6827	curr_test_accuracy: 0.6630
best_round: 5	best_val_accuracy: 0.6827	best_test_accuracy: 0.6630
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 917.5679	loss_val: 917.6027	loss_test: 917.6038	accuracy_train: 0.6667	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 3670.0652	loss_val: 3670.1418	loss_test: 3670.0984	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 11508.9707	loss_val: 11508.9170	loss_test: 11508.9766	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 4582.6021	loss_val: 4582.5728	loss_test: 4582.6216	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 1535.4434	loss_val: 1535.4371	loss_test: 1535.4661	accuracy_train: 0.7284	accuracy_val: 0.6000	accuracy_test: 0.5455
[client 5]	loss_train: 877.2816	loss_val: 877.2750	loss_test: 877.2528	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 6]	loss_train: 925.5080	loss_val: 925.4982	loss_test: 925.5497	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1373.1473	loss_val: 1373.0787	loss_test: 1373.1530	accuracy_train: 0.7619	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 1070.5464	loss_val: 1070.6333	loss_test: 1070.5702	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 1075.0939	loss_val: 1075.0757	loss_test: 1075.0341	accuracy_train: 0.1940	accuracy_val: 0.1250	accuracy_test: 0.3333
[client 10]	loss_train: 1373.4541	loss_val: 1373.4497	loss_test: 1373.4148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1190.5618	loss_val: 1190.5122	loss_test: 1190.6526	accuracy_train: 0.6456	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 12]	loss_train: 1354.8181	loss_val: 1354.8097	loss_test: 1354.8596	accuracy_train: 0.7353	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 1799.2013	loss_val: 1799.2319	loss_test: 1799.1831	accuracy_train: 0.1667	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 14]	loss_train: 987.6071	loss_val: 1036.0620	loss_test: 987.5436	accuracy_train: 0.4286	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1041.4550	loss_val: 1041.5538	loss_test: 1041.4813	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 879.0495	loss_val: 879.0516	loss_test: 879.0436	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 2483.4729	loss_val: 2483.6067	loss_test: 2483.4929	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 10608.6094	loss_val: 10639.5498	loss_test: 10608.7393	accuracy_train: 0.9000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 1510.8743	loss_val: 1510.7533	loss_test: 1510.8271	accuracy_train: 0.7143	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 6	curr_val_accuracy: 0.7003	curr_test_accuracy: 0.7015
best_round: 6	best_val_accuracy: 0.7003	best_test_accuracy: 0.7015
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1137.6851	loss_val: 1137.7278	loss_test: 1137.7242	accuracy_train: 0.6667	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 4681.8604	loss_val: 4681.9487	loss_test: 4681.8735	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 14010.5322	loss_val: 14010.4678	loss_test: 14010.5391	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 5510.0000	loss_val: 5509.9756	loss_test: 5510.0254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 1935.1393	loss_val: 1935.1432	loss_test: 1935.1646	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1035.3302	loss_val: 1035.3219	loss_test: 1035.2992	accuracy_train: 0.9200	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1140.2097	loss_val: 1140.1932	loss_test: 1140.2733	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1684.6559	loss_val: 1684.5820	loss_test: 1684.6608	accuracy_train: 0.7381	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 1436.5693	loss_val: 1436.6675	loss_test: 1436.5947	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 1291.4290	loss_val: 1291.4092	loss_test: 1291.3635	accuracy_train: 0.2239	accuracy_val: 0.2500	accuracy_test: 0.3333
[client 10]	loss_train: 1630.1559	loss_val: 1630.1528	loss_test: 1630.1176	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1478.6031	loss_val: 1478.5459	loss_test: 1478.7064	accuracy_train: 0.6835	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 12]	loss_train: 1682.9249	loss_val: 1682.9219	loss_test: 1682.9675	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 2341.0378	loss_val: 2341.0632	loss_test: 2341.0264	accuracy_train: 0.2222	accuracy_val: 0.0000	accuracy_test: 0.2500
[client 14]	loss_train: 1183.7812	loss_val: 1238.0367	loss_test: 1183.6984	accuracy_train: 0.4286	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1330.1989	loss_val: 1330.3102	loss_test: 1330.2363	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 987.0784	loss_val: 987.0862	loss_test: 987.0707	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 3083.1567	loss_val: 3083.3264	loss_test: 3083.1794	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 13849.4414	loss_val: 13886.3535	loss_test: 13849.5928	accuracy_train: 0.9000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 1837.5615	loss_val: 1837.4343	loss_test: 1837.5242	accuracy_train: 0.7653	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 7	curr_val_accuracy: 0.7360	curr_test_accuracy: 0.7323
best_round: 7	best_val_accuracy: 0.7360	best_test_accuracy: 0.7323
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1394.0361	loss_val: 1394.0876	loss_test: 1394.0786	accuracy_train: 0.6667	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 5744.4863	loss_val: 5744.5840	loss_test: 5744.4800	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 16813.1211	loss_val: 16813.0469	loss_test: 16813.1289	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 6459.5962	loss_val: 6459.5728	loss_test: 6459.6240	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2388.3442	loss_val: 2388.3604	loss_test: 2388.3760	accuracy_train: 0.6543	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1194.1461	loss_val: 1194.1367	loss_test: 1194.1138	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1368.3510	loss_val: 1368.3335	loss_test: 1368.4305	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2018.9880	loss_val: 2018.9072	loss_test: 2018.9910	accuracy_train: 0.7619	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 1860.5826	loss_val: 1860.6891	loss_test: 1860.6057	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 1510.1396	loss_val: 1510.1198	loss_test: 1510.0680	accuracy_train: 0.2537	accuracy_val: 0.2500	accuracy_test: 0.5556
[client 10]	loss_train: 1891.5590	loss_val: 1891.5562	loss_test: 1891.5216	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1800.1606	loss_val: 1800.0979	loss_test: 1800.2810	accuracy_train: 0.7215	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 12]	loss_train: 2028.9800	loss_val: 2028.9835	loss_test: 2029.0216	accuracy_train: 0.7647	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 2987.6455	loss_val: 2987.6692	loss_test: 2987.6426	accuracy_train: 0.2778	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 14]	loss_train: 1392.5253	loss_val: 1451.0034	loss_test: 1392.4304	accuracy_train: 0.4286	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1660.0438	loss_val: 1660.1661	loss_test: 1660.0941	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1100.1941	loss_val: 1100.2081	loss_test: 1100.1843	accuracy_train: 0.9839	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 3710.7122	loss_val: 3710.9216	loss_test: 3710.7371	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 17419.3457	loss_val: 17460.4648	loss_test: 17419.5137	accuracy_train: 0.9000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 2181.4321	loss_val: 2181.2986	loss_test: 2181.4014	accuracy_train: 0.7755	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 8	curr_val_accuracy: 0.7360	curr_test_accuracy: 0.7533
best_round: 7	best_val_accuracy: 0.7360	best_test_accuracy: 0.7323
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1689.0837	loss_val: 1689.1420	loss_test: 1689.1276	accuracy_train: 0.6667	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 6841.9019	loss_val: 6842.0093	loss_test: 6841.8770	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 19875.6836	loss_val: 19875.6016	loss_test: 19875.6914	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 7385.9971	loss_val: 7385.9736	loss_test: 7386.0303	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2863.2012	loss_val: 2863.2273	loss_test: 2863.2390	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1363.8688	loss_val: 1363.8602	loss_test: 1363.8372	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1617.1860	loss_val: 1617.1685	loss_test: 1617.2819	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2378.5881	loss_val: 2378.5042	loss_test: 2378.5896	accuracy_train: 0.7381	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 2337.3308	loss_val: 2337.4458	loss_test: 2337.3503	accuracy_train: 0.8125	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 1732.3831	loss_val: 1732.3618	loss_test: 1732.3042	accuracy_train: 0.3433	accuracy_val: 0.5000	accuracy_test: 0.5556
[client 10]	loss_train: 2168.3250	loss_val: 2168.3220	loss_test: 2168.2893	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2150.6614	loss_val: 2150.5969	loss_test: 2150.8008	accuracy_train: 0.7595	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 2394.5105	loss_val: 2394.5229	loss_test: 2394.5496	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 3729.6104	loss_val: 3729.6355	loss_test: 3729.6208	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 14]	loss_train: 1625.8894	loss_val: 1688.1820	loss_test: 1625.7886	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2001.6633	loss_val: 2001.7926	loss_test: 2001.7272	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1220.6910	loss_val: 1220.7072	loss_test: 1220.6781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 4358.5864	loss_val: 4358.8320	loss_test: 4358.6113	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 21299.7500	loss_val: 21344.7012	loss_test: 21299.9336	accuracy_train: 0.9000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 2526.2424	loss_val: 2526.1045	loss_test: 2526.2192	accuracy_train: 0.7551	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 9	curr_val_accuracy: 0.7725	curr_test_accuracy: 0.7459
best_round: 9	best_val_accuracy: 0.7725	best_test_accuracy: 0.7459
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2007.3794	loss_val: 2007.4452	loss_test: 2007.4243	accuracy_train: 0.6667	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 8023.4688	loss_val: 8023.5850	loss_test: 8023.4072	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 23167.1074	loss_val: 23167.0176	loss_test: 23167.1113	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 8335.3887	loss_val: 8335.3643	loss_test: 8335.4277	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 3369.7266	loss_val: 3369.7654	loss_test: 3369.7705	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1547.4637	loss_val: 1547.4576	loss_test: 1547.4347	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1880.1656	loss_val: 1880.1473	loss_test: 1880.2758	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2760.9211	loss_val: 2760.8350	loss_test: 2760.9233	accuracy_train: 0.7381	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 2875.2864	loss_val: 2875.4128	loss_test: 2875.3025	accuracy_train: 0.8333	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 1942.1089	loss_val: 1942.0868	loss_test: 1942.0253	accuracy_train: 0.4328	accuracy_val: 0.5000	accuracy_test: 0.5556
[client 10]	loss_train: 2460.4856	loss_val: 2460.4827	loss_test: 2460.4521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2519.9014	loss_val: 2519.8379	loss_test: 2520.0632	accuracy_train: 0.7468	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 2765.1125	loss_val: 2765.1360	loss_test: 2765.1477	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 4551.2095	loss_val: 4551.2358	loss_test: 4551.2256	accuracy_train: 0.3889	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 14]	loss_train: 1874.9227	loss_val: 1940.0536	loss_test: 1874.8176	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2358.8982	loss_val: 2359.0259	loss_test: 2358.9741	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1350.2988	loss_val: 1350.3185	loss_test: 1350.2806	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5013.9502	loss_val: 5014.2339	loss_test: 5013.9766	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 25556.3125	loss_val: 25604.2285	loss_test: 25556.5117	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 2880.0728	loss_val: 2879.9316	loss_test: 2880.0557	accuracy_train: 0.7755	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 10	curr_val_accuracy: 0.7725	curr_test_accuracy: 0.7375
best_round: 9	best_val_accuracy: 0.7725	best_test_accuracy: 0.7459
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2351.7310	loss_val: 2351.8035	loss_test: 2351.7747	accuracy_train: 0.6667	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 9192.7754	loss_val: 9192.8994	loss_test: 9192.6807	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 26740.7480	loss_val: 26740.6543	loss_test: 26740.7500	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 9304.7900	loss_val: 9304.7646	loss_test: 9304.8340	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 3903.0588	loss_val: 3903.1116	loss_test: 3903.1089	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1734.3408	loss_val: 1734.3374	loss_test: 1734.3159	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2148.6633	loss_val: 2148.6455	loss_test: 2148.7854	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3173.6150	loss_val: 3173.5278	loss_test: 3173.6196	accuracy_train: 0.7857	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 3444.6748	loss_val: 3444.8093	loss_test: 3444.6882	accuracy_train: 0.8333	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 2143.4001	loss_val: 2143.3772	loss_test: 2143.3127	accuracy_train: 0.4925	accuracy_val: 0.7500	accuracy_test: 0.6667
[client 10]	loss_train: 2779.4109	loss_val: 2779.4082	loss_test: 2779.3784	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2910.3901	loss_val: 2910.3298	loss_test: 2910.5771	accuracy_train: 0.7848	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 3124.6572	loss_val: 3124.6907	loss_test: 3124.6897	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 5410.7871	loss_val: 5410.8018	loss_test: 5410.8062	accuracy_train: 0.5556	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 14]	loss_train: 2135.0701	loss_val: 2202.5039	loss_test: 2134.9673	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2701.2061	loss_val: 2701.3333	loss_test: 2701.2927	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1491.4269	loss_val: 1491.4464	loss_test: 1491.4050	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5656.5859	loss_val: 5656.9126	loss_test: 5656.6157	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 30123.8164	loss_val: 30174.0234	loss_test: 30124.0254	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 3243.5085	loss_val: 3243.3660	loss_test: 3243.4968	accuracy_train: 0.7755	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 11	curr_val_accuracy: 0.8005	curr_test_accuracy: 0.7454
best_round: 11	best_val_accuracy: 0.8005	best_test_accuracy: 0.7454
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2711.2104	loss_val: 2711.2896	loss_test: 2711.2517	accuracy_train: 0.6800	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 10363.6572	loss_val: 10363.7891	loss_test: 10363.5352	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 30262.8516	loss_val: 30262.7578	loss_test: 30262.8516	accuracy_train: 0.4000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 10236.2520	loss_val: 10236.2266	loss_test: 10236.3008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 4428.8018	loss_val: 4428.8696	loss_test: 4428.8569	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1919.6835	loss_val: 1919.6833	loss_test: 1919.6625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2430.6187	loss_val: 2430.6013	loss_test: 2430.7483	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3577.2163	loss_val: 3577.1289	loss_test: 3577.2246	accuracy_train: 0.8333	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 4038.1885	loss_val: 4038.3345	loss_test: 4038.1990	accuracy_train: 0.8333	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 2330.5486	loss_val: 2330.5256	loss_test: 2330.4578	accuracy_train: 0.6567	accuracy_val: 0.7500	accuracy_test: 0.7778
[client 10]	loss_train: 3124.9507	loss_val: 3124.9480	loss_test: 3124.9182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3321.4890	loss_val: 3321.4329	loss_test: 3321.7031	accuracy_train: 0.7848	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 3497.3872	loss_val: 3497.4348	loss_test: 3497.4124	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 6355.5024	loss_val: 6355.5029	loss_test: 6355.5278	accuracy_train: 0.8333	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2417.2092	loss_val: 2484.9431	loss_test: 2417.1079	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3042.5293	loss_val: 3042.6580	loss_test: 3042.6233	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1643.9143	loss_val: 1643.9332	loss_test: 1643.8882	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6292.7002	loss_val: 6293.0693	loss_test: 6292.7344	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 34894.5781	loss_val: 34944.1992	loss_test: 34894.8047	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 3620.0210	loss_val: 3619.8765	loss_test: 3620.0129	accuracy_train: 0.7755	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 12	curr_val_accuracy: 0.8005	curr_test_accuracy: 0.7584
best_round: 11	best_val_accuracy: 0.8005	best_test_accuracy: 0.7454
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3089.9707	loss_val: 3090.0562	loss_test: 3090.0093	accuracy_train: 0.6933	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 11494.5137	loss_val: 11494.6553	loss_test: 11494.3809	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 33858.3633	loss_val: 33858.2656	loss_test: 33858.3633	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 11118.8105	loss_val: 11118.7861	loss_test: 11118.8633	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 4948.6382	loss_val: 4948.7236	loss_test: 4948.6987	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2119.6316	loss_val: 2119.6333	loss_test: 2119.6138	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2725.7000	loss_val: 2725.6831	loss_test: 2725.8369	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3949.1934	loss_val: 3949.1040	loss_test: 3949.2063	accuracy_train: 0.8333	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 4659.5293	loss_val: 4659.6846	loss_test: 4659.5410	accuracy_train: 0.8333	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 2504.5962	loss_val: 2504.5737	loss_test: 2504.5012	accuracy_train: 0.7612	accuracy_val: 0.8750	accuracy_test: 1.0000
[client 10]	loss_train: 3484.0037	loss_val: 3484.0007	loss_test: 3483.9714	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3734.5132	loss_val: 3734.4607	loss_test: 3734.7551	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 3863.9680	loss_val: 3864.0295	loss_test: 3863.9844	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 7331.4048	loss_val: 7331.3901	loss_test: 7331.4385	accuracy_train: 0.8889	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2701.9128	loss_val: 2770.2695	loss_test: 2701.8228	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3359.7314	loss_val: 3359.8672	loss_test: 3359.8347	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1808.7219	loss_val: 1808.7393	loss_test: 1808.6927	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6914.5596	loss_val: 6914.9683	loss_test: 6914.5972	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 39802.5352	loss_val: 39851.6523	loss_test: 39802.7734	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 3998.3574	loss_val: 3998.2136	loss_test: 3998.3542	accuracy_train: 0.7755	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 13	curr_val_accuracy: 0.8094	curr_test_accuracy: 0.7901
best_round: 13	best_val_accuracy: 0.8094	best_test_accuracy: 0.7901
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3492.8855	loss_val: 3492.9792	loss_test: 3492.9214	accuracy_train: 0.7067	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 12625.8848	loss_val: 12626.0410	loss_test: 12625.7490	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 37220.7734	loss_val: 37220.6719	loss_test: 37220.7695	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 11915.2881	loss_val: 11915.2637	loss_test: 11915.3457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 5436.9917	loss_val: 5437.0952	loss_test: 5437.0557	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2320.1924	loss_val: 2320.1956	loss_test: 2320.1768	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3029.7507	loss_val: 3029.7344	loss_test: 3029.8926	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4278.8618	loss_val: 4278.7720	loss_test: 4278.8755	accuracy_train: 0.8333	accuracy_val: 0.8000	accuracy_test: 1.0000
[client 8]	loss_train: 5279.6611	loss_val: 5279.8311	loss_test: 5279.6772	accuracy_train: 0.8542	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 2663.8918	loss_val: 2663.8687	loss_test: 2663.7932	accuracy_train: 0.8806	accuracy_val: 0.8750	accuracy_test: 1.0000
[client 10]	loss_train: 3852.6846	loss_val: 3852.6819	loss_test: 3852.6523	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4152.9346	loss_val: 4152.8853	loss_test: 4153.2061	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 4224.7690	loss_val: 4224.8477	loss_test: 4224.7759	accuracy_train: 0.7353	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 8302.0566	loss_val: 8302.0283	loss_test: 8302.0977	accuracy_train: 0.8889	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2979.6892	loss_val: 3046.6992	loss_test: 2979.6113	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3651.7903	loss_val: 3651.9351	loss_test: 3651.9053	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1979.6964	loss_val: 1979.7112	loss_test: 1979.6637	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7494.8145	loss_val: 7495.2554	loss_test: 7494.8530	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 44735.6484	loss_val: 44782.5234	loss_test: 44735.8945	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 4359.8442	loss_val: 4359.7026	loss_test: 4359.8447	accuracy_train: 0.7653	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 14	curr_val_accuracy: 0.8013	curr_test_accuracy: 0.7981
best_round: 13	best_val_accuracy: 0.8094	best_test_accuracy: 0.7901
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3908.4480	loss_val: 3908.5518	loss_test: 3908.4817	accuracy_train: 0.7200	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13619.2998	loss_val: 13619.4658	loss_test: 13619.1582	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 40548.7383	loss_val: 40548.6289	loss_test: 40548.7344	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 12659.5850	loss_val: 12659.5605	loss_test: 12659.6465	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 5892.5967	loss_val: 5892.7217	loss_test: 5892.6641	accuracy_train: 0.6914	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2521.4302	loss_val: 2521.4351	loss_test: 2521.4153	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3328.8767	loss_val: 3328.8606	loss_test: 3329.0227	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4601.0298	loss_val: 4600.9419	loss_test: 4601.0439	accuracy_train: 0.8333	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 5928.7822	loss_val: 5928.9678	loss_test: 5928.8032	accuracy_train: 0.8125	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 2810.5330	loss_val: 2810.5085	loss_test: 2810.4302	accuracy_train: 0.9552	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 4210.7529	loss_val: 4210.7505	loss_test: 4210.7212	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4577.0254	loss_val: 4576.9795	loss_test: 4577.3267	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 4573.1504	loss_val: 4573.2456	loss_test: 4573.1475	accuracy_train: 0.7059	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 9271.1895	loss_val: 9271.1475	loss_test: 9271.2432	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3253.1421	loss_val: 3319.5425	loss_test: 3253.0818	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3940.5603	loss_val: 3940.7144	loss_test: 3940.6875	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2158.5081	loss_val: 2158.5210	loss_test: 2158.4734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8050.8584	loss_val: 8051.3276	loss_test: 8050.8960	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 49287.1328	loss_val: 49330.2031	loss_test: 49287.3984	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 4706.7451	loss_val: 4706.6064	loss_test: 4706.7500	accuracy_train: 0.7755	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 15	curr_val_accuracy: 0.8183	curr_test_accuracy: 0.7916
best_round: 15	best_val_accuracy: 0.8183	best_test_accuracy: 0.7916
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 4331.6890	loss_val: 4331.8047	loss_test: 4331.7222	accuracy_train: 0.7467	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14565.2773	loss_val: 14565.4551	loss_test: 14565.1436	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 43665.0156	loss_val: 43664.9062	loss_test: 43665.0156	accuracy_train: 0.5143	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 13390.8047	loss_val: 13390.7803	loss_test: 13390.8691	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6312.2646	loss_val: 6312.4116	loss_test: 6312.3345	accuracy_train: 0.6914	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2720.1121	loss_val: 2720.1184	loss_test: 2720.0986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3634.5925	loss_val: 3634.5752	loss_test: 3634.7449	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4889.5596	loss_val: 4889.4751	loss_test: 4889.5718	accuracy_train: 0.8571	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 6536.7437	loss_val: 6536.9458	loss_test: 6536.7700	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 2956.8169	loss_val: 2956.7915	loss_test: 2956.7129	accuracy_train: 0.9851	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 4571.5615	loss_val: 4571.5586	loss_test: 4571.5303	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4993.9541	loss_val: 4993.9116	loss_test: 4994.2856	accuracy_train: 0.7975	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 4909.7427	loss_val: 4909.8564	loss_test: 4909.7329	accuracy_train: 0.6765	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 10184.2861	loss_val: 10184.2295	loss_test: 10184.3516	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3528.2051	loss_val: 3593.0330	loss_test: 3528.1667	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4196.4741	loss_val: 4196.6318	loss_test: 4196.6133	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2343.7153	loss_val: 2343.7273	loss_test: 2343.6790	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8538.7178	loss_val: 8539.2109	loss_test: 8538.7539	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 53522.3242	loss_val: 53559.5586	loss_test: 53522.6055	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5051.5601	loss_val: 5051.4258	loss_test: 5051.5703	accuracy_train: 0.7857	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 16	curr_val_accuracy: 0.8189	curr_test_accuracy: 0.8071
best_round: 16	best_val_accuracy: 0.8189	best_test_accuracy: 0.8071
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 4755.0947	loss_val: 4755.2251	loss_test: 4755.1289	accuracy_train: 0.7733	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15435.8486	loss_val: 15436.0391	loss_test: 15435.7285	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 46405.2461	loss_val: 46405.1328	loss_test: 46405.2539	accuracy_train: 0.5143	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 14133.5312	loss_val: 14133.5059	loss_test: 14133.5967	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6693.1875	loss_val: 6693.3574	loss_test: 6693.2588	accuracy_train: 0.7037	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2919.6736	loss_val: 2919.6812	loss_test: 2919.6611	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3950.1885	loss_val: 3950.1709	loss_test: 3950.3474	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5124.6196	loss_val: 5124.5381	loss_test: 5124.6299	accuracy_train: 0.8571	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 7128.2363	loss_val: 7128.4541	loss_test: 7128.2671	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3090.9802	loss_val: 3090.9541	loss_test: 3090.8752	accuracy_train: 0.9851	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 4899.3081	loss_val: 4899.3047	loss_test: 4899.2778	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5401.9268	loss_val: 5401.8882	loss_test: 5402.2910	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 12]	loss_train: 5224.7695	loss_val: 5224.9023	loss_test: 5224.7534	accuracy_train: 0.7059	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 11032.9893	loss_val: 11032.9219	loss_test: 11033.0654	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3791.8418	loss_val: 3852.4512	loss_test: 3791.8286	accuracy_train: 0.5714	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4420.3325	loss_val: 4420.5010	loss_test: 4420.4878	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2540.8672	loss_val: 2540.8770	loss_test: 2540.8298	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8941.2188	loss_val: 8941.7295	loss_test: 8941.2520	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 57346.9180	loss_val: 57378.2305	loss_test: 57347.2148	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5380.9414	loss_val: 5380.8135	loss_test: 5380.9570	accuracy_train: 0.8061	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 17	curr_val_accuracy: 0.8114	curr_test_accuracy: 0.8071
best_round: 16	best_val_accuracy: 0.8189	best_test_accuracy: 0.8071
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5202.0020	loss_val: 5202.1484	loss_test: 5202.0396	accuracy_train: 0.7733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 16202.8486	loss_val: 16203.0557	loss_test: 16202.7480	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 48878.0000	loss_val: 48877.8867	loss_test: 48878.0195	accuracy_train: 0.5429	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 14790.1182	loss_val: 14790.0908	loss_test: 14790.1855	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7012.5391	loss_val: 7012.7314	loss_test: 7012.6108	accuracy_train: 0.7160	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3109.3513	loss_val: 3109.3599	loss_test: 3109.3396	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4241.0239	loss_val: 4241.0054	loss_test: 4241.1899	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5308.4673	loss_val: 5308.3911	loss_test: 5308.4785	accuracy_train: 0.8571	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 7688.1372	loss_val: 7688.3735	loss_test: 7688.1733	accuracy_train: 0.8125	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3245.1689	loss_val: 3245.1438	loss_test: 3245.0637	accuracy_train: 0.9851	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5208.0132	loss_val: 5208.0093	loss_test: 5207.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5787.1821	loss_val: 5787.1460	loss_test: 5787.5796	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 12]	loss_train: 5509.6182	loss_val: 5509.7759	loss_test: 5509.5957	accuracy_train: 0.6765	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 11796.9102	loss_val: 11796.8350	loss_test: 11796.9990	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4049.3970	loss_val: 4104.4990	loss_test: 4049.4187	accuracy_train: 0.7143	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4621.5815	loss_val: 4621.7607	loss_test: 4621.7515	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2740.2493	loss_val: 2740.2571	loss_test: 2740.2112	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9301.1455	loss_val: 9301.6709	loss_test: 9301.1748	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 60423.2617	loss_val: 60447.8359	loss_test: 60423.5703	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5664.6606	loss_val: 5664.5396	loss_test: 5664.6831	accuracy_train: 0.8163	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 18	curr_val_accuracy: 0.8195	curr_test_accuracy: 0.8068
best_round: 18	best_val_accuracy: 0.8195	best_test_accuracy: 0.8068
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5693.0400	loss_val: 5693.2051	loss_test: 5693.0835	accuracy_train: 0.7733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 16897.7363	loss_val: 16897.9609	loss_test: 16897.6602	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 51004.5820	loss_val: 51004.4648	loss_test: 51004.6055	accuracy_train: 0.5714	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 15338.4414	loss_val: 15338.4131	loss_test: 15338.5107	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7299.9956	loss_val: 7300.2119	loss_test: 7300.0674	accuracy_train: 0.6914	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3298.0791	loss_val: 3298.0879	loss_test: 3298.0681	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4522.6216	loss_val: 4522.6025	loss_test: 4522.7949	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5486.4395	loss_val: 5486.3716	loss_test: 5486.4526	accuracy_train: 0.8571	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 8172.5161	loss_val: 8172.7690	loss_test: 8172.5586	accuracy_train: 0.8333	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3402.5769	loss_val: 3402.5542	loss_test: 3402.4697	accuracy_train: 0.9851	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5491.5562	loss_val: 5491.5522	loss_test: 5491.5288	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6149.4565	loss_val: 6149.4229	loss_test: 6149.8867	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5759.4917	loss_val: 5759.6724	loss_test: 5759.4673	accuracy_train: 0.6765	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 12479.9248	loss_val: 12479.8428	loss_test: 12480.0225	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4299.2280	loss_val: 4351.0850	loss_test: 4299.2778	accuracy_train: 0.7143	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4774.4614	loss_val: 4774.6562	loss_test: 4774.6489	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2942.0833	loss_val: 2942.0876	loss_test: 2942.0442	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9617.4883	loss_val: 9618.0244	loss_test: 9617.5156	accuracy_train: 0.8519	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 63108.2070	loss_val: 63124.8555	loss_test: 63108.5273	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5925.6035	loss_val: 5925.4902	loss_test: 5925.6328	accuracy_train: 0.8163	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 19	curr_val_accuracy: 0.8120	curr_test_accuracy: 0.7984
best_round: 18	best_val_accuracy: 0.8195	best_test_accuracy: 0.8068
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6191.8647	loss_val: 6192.0527	loss_test: 6191.9141	accuracy_train: 0.8000	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 17465.5371	loss_val: 17465.7734	loss_test: 17465.4824	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 53006.0781	loss_val: 53005.9648	loss_test: 53006.1172	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 15831.5068	loss_val: 15831.4775	loss_test: 15831.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7534.3730	loss_val: 7534.6152	loss_test: 7534.4443	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3495.2688	loss_val: 3495.2766	loss_test: 3495.2588	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4796.5317	loss_val: 4796.5117	loss_test: 4796.7129	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5614.1587	loss_val: 5614.1016	loss_test: 5614.1758	accuracy_train: 0.8571	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 8605.4023	loss_val: 8605.6699	loss_test: 8605.4482	accuracy_train: 0.8333	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3552.9224	loss_val: 3552.9031	loss_test: 3552.8135	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5746.8301	loss_val: 5746.8267	loss_test: 5746.8052	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6466.8550	loss_val: 6466.8257	loss_test: 6467.3174	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5958.5796	loss_val: 5958.7808	loss_test: 5958.5576	accuracy_train: 0.6765	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 13114.8398	loss_val: 13114.7549	loss_test: 13114.9473	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4516.8281	loss_val: 4565.3569	loss_test: 4516.9062	accuracy_train: 0.7143	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4911.0835	loss_val: 4911.2920	loss_test: 4911.2861	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3131.8799	loss_val: 3131.8796	loss_test: 3131.8391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9842.9443	loss_val: 9843.4834	loss_test: 9842.9746	accuracy_train: 0.8519	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 65441.2734	loss_val: 65449.1484	loss_test: 65441.6094	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6132.0884	loss_val: 6131.9819	loss_test: 6132.1245	accuracy_train: 0.8265	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 20	curr_val_accuracy: 0.8126	curr_test_accuracy: 0.7984
best_round: 18	best_val_accuracy: 0.8195	best_test_accuracy: 0.8068
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6676.8345	loss_val: 6677.0449	loss_test: 6676.8911	accuracy_train: 0.8133	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18082.0938	loss_val: 18082.3418	loss_test: 18082.0684	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 54726.0977	loss_val: 54725.9844	loss_test: 54726.1523	accuracy_train: 0.6571	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 16289.4072	loss_val: 16289.3760	loss_test: 16289.4795	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7718.9883	loss_val: 7719.2583	loss_test: 7719.0615	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3691.5876	loss_val: 3691.5947	loss_test: 3691.5784	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5068.1147	loss_val: 5068.0952	loss_test: 5068.3032	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5701.9585	loss_val: 5701.9121	loss_test: 5701.9814	accuracy_train: 0.8810	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 8977.4072	loss_val: 8977.7031	loss_test: 8977.4619	accuracy_train: 0.8333	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3728.8186	loss_val: 3728.8047	loss_test: 3728.7083	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5963.6860	loss_val: 5963.6831	loss_test: 5963.6636	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6744.8047	loss_val: 6744.7812	loss_test: 6745.2998	accuracy_train: 0.8101	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6124.8394	loss_val: 6125.0601	loss_test: 6124.8213	accuracy_train: 0.6765	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 13621.5742	loss_val: 13621.4854	loss_test: 13621.6895	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4653.2412	loss_val: 4694.7485	loss_test: 4653.3555	accuracy_train: 0.7143	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5008.1050	loss_val: 5008.3281	loss_test: 5008.3262	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3298.6980	loss_val: 3298.6934	loss_test: 3298.6560	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9953.6826	loss_val: 9954.2168	loss_test: 9953.7197	accuracy_train: 0.8519	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 67581.7812	loss_val: 67581.5781	loss_test: 67582.1328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6342.8218	loss_val: 6342.7246	loss_test: 6342.8657	accuracy_train: 0.8673	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 21	curr_val_accuracy: 0.8245	curr_test_accuracy: 0.7984
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7130.1147	loss_val: 7130.3452	loss_test: 7130.1787	accuracy_train: 0.8533	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18484.2539	loss_val: 18484.5098	loss_test: 18484.2578	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56229.9141	loss_val: 56229.8086	loss_test: 56229.9883	accuracy_train: 0.6571	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 16711.3809	loss_val: 16711.3477	loss_test: 16711.4551	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7837.6201	loss_val: 7837.9185	loss_test: 7837.6958	accuracy_train: 0.6914	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3870.4805	loss_val: 3870.4871	loss_test: 3870.4717	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5324.4907	loss_val: 5324.4712	loss_test: 5324.6865	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5759.7070	loss_val: 5759.6763	loss_test: 5759.7388	accuracy_train: 0.8810	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 9222.3516	loss_val: 9222.6748	loss_test: 9222.4170	accuracy_train: 0.8333	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 3920.1716	loss_val: 3920.1631	loss_test: 3920.0598	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6155.2573	loss_val: 6155.2554	loss_test: 6155.2363	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6984.9180	loss_val: 6984.9009	loss_test: 6985.4478	accuracy_train: 0.8228	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6248.1074	loss_val: 6248.3501	loss_test: 6248.0967	accuracy_train: 0.6765	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 14091.4033	loss_val: 14091.3125	loss_test: 14091.5264	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4800.6333	loss_val: 4838.2793	loss_test: 4800.7827	accuracy_train: 0.7143	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5095.2158	loss_val: 5095.4487	loss_test: 5095.4551	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3465.7756	loss_val: 3465.7671	loss_test: 3465.7327	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 10024.9766	loss_val: 10025.5088	loss_test: 10025.0215	accuracy_train: 0.8889	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 69214.1172	loss_val: 69213.8125	loss_test: 69214.4922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6496.6895	loss_val: 6496.6011	loss_test: 6496.7417	accuracy_train: 0.8776	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 22	curr_val_accuracy: 0.8245	curr_test_accuracy: 0.7907
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7485.0220	loss_val: 7485.2720	loss_test: 7485.0942	accuracy_train: 0.8533	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18828.3984	loss_val: 18828.6602	loss_test: 18828.4258	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 57567.5547	loss_val: 57567.4570	loss_test: 57567.6523	accuracy_train: 0.6571	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 17153.1992	loss_val: 17153.1641	loss_test: 17153.2754	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7903.6631	loss_val: 7903.9907	loss_test: 7903.7461	accuracy_train: 0.7284	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4020.4939	loss_val: 4020.5007	loss_test: 4020.4856	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5562.1621	loss_val: 5562.1421	loss_test: 5562.3643	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5772.2749	loss_val: 5772.2612	loss_test: 5772.3188	accuracy_train: 0.9048	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 9456.4404	loss_val: 9456.8018	loss_test: 9456.5215	accuracy_train: 0.8333	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4066.4282	loss_val: 4066.4238	loss_test: 4066.3181	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6311.0698	loss_val: 6311.0688	loss_test: 6311.0518	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7190.2612	loss_val: 7190.2515	loss_test: 7190.8257	accuracy_train: 0.8354	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6338.3379	loss_val: 6338.6025	loss_test: 6338.3398	accuracy_train: 0.6765	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 14453.5615	loss_val: 14453.4707	loss_test: 14453.6953	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4898.0366	loss_val: 4929.1377	loss_test: 4898.2227	accuracy_train: 0.7143	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5150.4287	loss_val: 5150.6724	loss_test: 5150.6875	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3614.6028	loss_val: 3614.5896	loss_test: 3614.5588	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 10024.8613	loss_val: 10025.3926	loss_test: 10024.9111	accuracy_train: 0.9259	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 70580.9531	loss_val: 70580.6562	loss_test: 70581.3438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6620.1421	loss_val: 6620.0596	loss_test: 6620.2026	accuracy_train: 0.8673	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 23	curr_val_accuracy: 0.8245	curr_test_accuracy: 0.7907
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7781.0278	loss_val: 7781.2959	loss_test: 7781.1084	accuracy_train: 0.8800	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18976.7070	loss_val: 18976.9727	loss_test: 18976.7539	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 58817.4766	loss_val: 58817.3945	loss_test: 58817.5977	accuracy_train: 0.6857	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 17617.8340	loss_val: 17617.7949	loss_test: 17617.9102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7929.7236	loss_val: 7930.0811	loss_test: 7929.8159	accuracy_train: 0.7407	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4141.3140	loss_val: 4141.3208	loss_test: 4141.3052	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5770.3745	loss_val: 5770.3545	loss_test: 5770.5830	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5738.0122	loss_val: 5738.0171	loss_test: 5738.0718	accuracy_train: 0.9048	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 9676.0498	loss_val: 9676.4531	loss_test: 9676.1445	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4235.8276	loss_val: 4235.8267	loss_test: 4235.7197	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6432.0430	loss_val: 6432.0425	loss_test: 6432.0269	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7330.3345	loss_val: 7330.3354	loss_test: 7330.9316	accuracy_train: 0.8354	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6374.7153	loss_val: 6375.0044	loss_test: 6374.7363	accuracy_train: 0.7059	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 14717.7412	loss_val: 14717.6514	loss_test: 14717.8887	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4966.9883	loss_val: 4991.9868	loss_test: 4967.2090	accuracy_train: 0.7143	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5188.6001	loss_val: 5188.8584	loss_test: 5188.8809	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3747.1650	loss_val: 3747.1477	loss_test: 3747.1201	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9954.4717	loss_val: 9955.0020	loss_test: 9954.5283	accuracy_train: 0.9259	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 71222.6172	loss_val: 71222.3359	loss_test: 71223.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6719.4507	loss_val: 6719.3730	loss_test: 6719.5181	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 24	curr_val_accuracy: 0.8245	curr_test_accuracy: 0.7907
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8008.5923	loss_val: 8008.8779	loss_test: 8008.6807	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 19039.0469	loss_val: 19039.3164	loss_test: 19039.1152	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 59897.6562	loss_val: 59897.5781	loss_test: 59897.7969	accuracy_train: 0.7143	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 18072.1328	loss_val: 18072.0918	loss_test: 18072.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7926.1343	loss_val: 7926.5215	loss_test: 7926.2373	accuracy_train: 0.7531	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4224.3691	loss_val: 4224.3760	loss_test: 4224.3599	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5969.3315	loss_val: 5969.3105	loss_test: 5969.5469	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5674.6392	loss_val: 5674.6660	loss_test: 5674.7173	accuracy_train: 0.9286	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 9852.5957	loss_val: 9853.0439	loss_test: 9852.7021	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4447.3633	loss_val: 4447.3633	loss_test: 4447.2554	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6522.0781	loss_val: 6522.0786	loss_test: 6522.0645	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7422.8467	loss_val: 7422.8613	loss_test: 7423.4790	accuracy_train: 0.8608	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6382.9277	loss_val: 6383.2417	loss_test: 6382.9736	accuracy_train: 0.7059	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 14949.5918	loss_val: 14949.5039	loss_test: 14949.7539	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5008.0952	loss_val: 5027.7222	loss_test: 5008.3457	accuracy_train: 0.7143	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5190.3926	loss_val: 5190.6655	loss_test: 5190.6948	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3850.2661	loss_val: 3850.2454	loss_test: 3850.2207	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9825.1436	loss_val: 9825.6699	loss_test: 9825.2051	accuracy_train: 0.9630	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 71229.6719	loss_val: 71229.3984	loss_test: 71230.0859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6806.8252	loss_val: 6806.7505	loss_test: 6806.8989	accuracy_train: 0.8673	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 25	curr_val_accuracy: 0.8245	curr_test_accuracy: 0.8065
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8165.8901	loss_val: 8166.1919	loss_test: 8165.9868	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18951.5859	loss_val: 18951.8594	loss_test: 18951.6816	accuracy_train: 0.8667	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 60806.8867	loss_val: 60806.8203	loss_test: 60807.0547	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 18459.8750	loss_val: 18459.8301	loss_test: 18459.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7912.5889	loss_val: 7913.0044	loss_test: 7912.7031	accuracy_train: 0.7654	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4269.9082	loss_val: 4269.9160	loss_test: 4269.8979	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6122.4795	loss_val: 6122.4575	loss_test: 6122.7007	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5580.6665	loss_val: 5580.7183	loss_test: 5580.7671	accuracy_train: 0.9524	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 10019.0986	loss_val: 10019.5869	loss_test: 10019.2148	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4710.6792	loss_val: 4710.6792	loss_test: 4710.5698	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6562.5674	loss_val: 6562.5684	loss_test: 6562.5552	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7484.1470	loss_val: 7484.1743	loss_test: 7484.8154	accuracy_train: 0.8608	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6360.2173	loss_val: 6360.5552	loss_test: 6360.2949	accuracy_train: 0.7353	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 15035.5186	loss_val: 15035.4346	loss_test: 15035.6924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5030.3818	loss_val: 5043.5850	loss_test: 5030.6592	accuracy_train: 0.7143	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5195.9233	loss_val: 5196.2100	loss_test: 5196.2441	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3934.3452	loss_val: 3934.3206	loss_test: 3934.2993	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9672.2871	loss_val: 9672.8096	loss_test: 9672.3574	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 70863.8125	loss_val: 70863.5469	loss_test: 70864.2344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6872.9434	loss_val: 6872.8711	loss_test: 6873.0225	accuracy_train: 0.8673	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 26	curr_val_accuracy: 0.8245	curr_test_accuracy: 0.8065
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8251.3457	loss_val: 8251.6641	loss_test: 8251.4482	accuracy_train: 0.8933	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18798.3027	loss_val: 18798.5840	loss_test: 18798.4258	accuracy_train: 0.8667	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 61567.9102	loss_val: 61567.8555	loss_test: 61568.1016	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 18838.3184	loss_val: 18838.2715	loss_test: 18838.3984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7889.4932	loss_val: 7889.9390	loss_test: 7889.6211	accuracy_train: 0.8148	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4312.1943	loss_val: 4312.2026	loss_test: 4312.1831	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6254.9683	loss_val: 6254.9443	loss_test: 6255.1968	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5472.4692	loss_val: 5472.5454	loss_test: 5472.5957	accuracy_train: 0.9524	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 10168.9639	loss_val: 10169.4902	loss_test: 10169.0869	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 4987.1016	loss_val: 4987.1016	loss_test: 4986.9912	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6588.8853	loss_val: 6588.8867	loss_test: 6588.8745	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7512.9185	loss_val: 7512.9604	loss_test: 7513.6245	accuracy_train: 0.8608	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6314.2173	loss_val: 6314.5825	loss_test: 6314.3306	accuracy_train: 0.7353	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 15071.7227	loss_val: 15071.6465	loss_test: 15071.9111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5019.8481	loss_val: 5026.1523	loss_test: 5020.1562	accuracy_train: 0.8571	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5205.1694	loss_val: 5205.4668	loss_test: 5205.5083	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3998.0117	loss_val: 3997.9839	loss_test: 3997.9658	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9497.7617	loss_val: 9498.2773	loss_test: 9497.8438	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 70307.9688	loss_val: 70307.7109	loss_test: 70308.3906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6922.9258	loss_val: 6922.8574	loss_test: 6923.0112	accuracy_train: 0.8673	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 27	curr_val_accuracy: 0.8245	curr_test_accuracy: 0.8141
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8241.3936	loss_val: 8241.7256	loss_test: 8241.5010	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18506.6582	loss_val: 18506.9453	loss_test: 18506.8066	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 62379.7539	loss_val: 62379.7148	loss_test: 62379.9688	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 19297.9922	loss_val: 19297.9453	loss_test: 19298.0723	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7866.8877	loss_val: 7867.3594	loss_test: 7867.0283	accuracy_train: 0.8889	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4337.7290	loss_val: 4337.7373	loss_test: 4337.7173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6380.1528	loss_val: 6380.1270	loss_test: 6380.3901	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5356.4780	loss_val: 5356.5786	loss_test: 5356.6328	accuracy_train: 0.9524	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 10283.3682	loss_val: 10283.9424	loss_test: 10283.5020	accuracy_train: 0.8750	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 5257.2563	loss_val: 5257.2539	loss_test: 5257.1465	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6599.6543	loss_val: 6599.6572	loss_test: 6599.6450	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7521.9141	loss_val: 7521.9736	loss_test: 7522.6606	accuracy_train: 0.8608	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6256.2930	loss_val: 6256.6860	loss_test: 6256.4399	accuracy_train: 0.7647	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 15044.9238	loss_val: 15044.8545	loss_test: 15045.1270	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4968.2842	loss_val: 4969.7378	loss_test: 4968.6191	accuracy_train: 1.0000	accuracy_val: 0.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5219.1587	loss_val: 5219.4741	loss_test: 5219.5200	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4033.9326	loss_val: 4033.9016	loss_test: 4033.8862	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9274.9395	loss_val: 9275.4590	loss_test: 9275.0332	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 69244.5938	loss_val: 69244.3438	loss_test: 69245.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6974.7661	loss_val: 6974.7012	loss_test: 6974.8569	accuracy_train: 0.8673	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 28	curr_val_accuracy: 0.8159	curr_test_accuracy: 0.8141
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8152.0791	loss_val: 8152.4243	loss_test: 8152.1904	accuracy_train: 0.9067	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 18210.8848	loss_val: 18211.1758	loss_test: 18211.0664	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 62981.9023	loss_val: 62981.8828	loss_test: 62982.1445	accuracy_train: 0.7714	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 19780.0332	loss_val: 19779.9844	loss_test: 19780.1152	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7859.6060	loss_val: 7860.0977	loss_test: 7859.7563	accuracy_train: 0.9136	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4335.8140	loss_val: 4335.8237	loss_test: 4335.8013	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6468.1372	loss_val: 6468.1099	loss_test: 6468.3779	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5247.0044	loss_val: 5247.1270	loss_test: 5247.1880	accuracy_train: 0.9762	accuracy_val: 0.8000	accuracy_test: 0.8571
[client 8]	loss_train: 10444.0049	loss_val: 10444.6182	loss_test: 10444.1455	accuracy_train: 0.8958	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 5497.0708	loss_val: 5497.0679	loss_test: 5496.9629	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6593.9536	loss_val: 6593.9575	loss_test: 6593.9458	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7488.9897	loss_val: 7489.0688	loss_test: 7489.7764	accuracy_train: 0.8608	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 6172.6948	loss_val: 6173.1157	loss_test: 6172.8706	accuracy_train: 0.7647	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 14944.3672	loss_val: 14944.3096	loss_test: 14944.5879	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4921.8906	loss_val: 4921.6514	loss_test: 4922.2480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5206.9907	loss_val: 5207.3188	loss_test: 5207.3750	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4049.8171	loss_val: 4049.7837	loss_test: 4049.7708	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9025.3408	loss_val: 9025.8555	loss_test: 9025.4463	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 68363.7266	loss_val: 68363.4922	loss_test: 68364.1641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7010.2432	loss_val: 7010.1846	loss_test: 7010.3403	accuracy_train: 0.8776	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 29	curr_val_accuracy: 0.8159	curr_test_accuracy: 0.8141
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7982.3110	loss_val: 7982.6709	loss_test: 7982.4272	accuracy_train: 0.9200	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 17847.8477	loss_val: 17848.1348	loss_test: 17848.0664	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 63621.1133	loss_val: 63621.1094	loss_test: 63621.3867	accuracy_train: 0.8286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 20327.1738	loss_val: 20327.1230	loss_test: 20327.2598	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7876.4570	loss_val: 7876.9580	loss_test: 7876.6147	accuracy_train: 0.9383	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4315.6650	loss_val: 4315.6758	loss_test: 4315.6504	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6547.8032	loss_val: 6547.7764	loss_test: 6548.0498	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5130.9507	loss_val: 5131.0938	loss_test: 5131.1646	accuracy_train: 0.9762	accuracy_val: 0.8000	accuracy_test: 0.7143
[client 8]	loss_train: 10592.1758	loss_val: 10592.8232	loss_test: 10592.3213	accuracy_train: 0.9167	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 5789.8042	loss_val: 5789.8003	loss_test: 5789.6978	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6566.0522	loss_val: 6566.0571	loss_test: 6566.0454	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7420.4199	loss_val: 7420.5181	loss_test: 7421.2456	accuracy_train: 0.8608	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 6097.7930	loss_val: 6098.2417	loss_test: 6097.9980	accuracy_train: 0.7941	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 14785.0215	loss_val: 14784.9756	loss_test: 14785.2627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4884.1699	loss_val: 4883.9487	loss_test: 4884.5410	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5213.2500	loss_val: 5213.5991	loss_test: 5213.6621	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4046.7722	loss_val: 4046.7373	loss_test: 4046.7263	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8766.1924	loss_val: 8766.7061	loss_test: 8766.3086	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 67661.3125	loss_val: 67661.0781	loss_test: 67661.7500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7039.6138	loss_val: 7039.5649	loss_test: 7039.7178	accuracy_train: 0.8980	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 30	curr_val_accuracy: 0.8159	curr_test_accuracy: 0.8118
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7803.9858	loss_val: 7804.3613	loss_test: 7804.1079	accuracy_train: 0.9200	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 17365.7402	loss_val: 17366.0293	loss_test: 17365.9961	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 64493.3945	loss_val: 64493.4102	loss_test: 64493.6953	accuracy_train: 0.8286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 20809.7637	loss_val: 20809.7129	loss_test: 20809.8555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7953.3530	loss_val: 7953.8584	loss_test: 7953.5171	accuracy_train: 0.9506	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 4298.2075	loss_val: 4298.2192	loss_test: 4298.1909	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6617.6777	loss_val: 6617.6519	loss_test: 6617.9282	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5002.9277	loss_val: 5003.0879	loss_test: 5003.1689	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5714
[client 8]	loss_train: 10753.1709	loss_val: 10753.8613	loss_test: 10753.3252	accuracy_train: 0.9167	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6073.9058	loss_val: 6073.9009	loss_test: 6073.8027	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6506.2559	loss_val: 6506.2627	loss_test: 6506.2505	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7333.3809	loss_val: 7333.5024	loss_test: 7334.2432	accuracy_train: 0.8608	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 6003.5952	loss_val: 6004.0713	loss_test: 6003.8364	accuracy_train: 0.8235	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 14579.7686	loss_val: 14579.7354	loss_test: 14580.0303	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4843.1694	loss_val: 4842.9717	loss_test: 4843.5591	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5217.1318	loss_val: 5217.4990	loss_test: 5217.5693	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4036.1523	loss_val: 4036.1162	loss_test: 4036.1069	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8511.9629	loss_val: 8512.4814	loss_test: 8512.0928	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66992.1953	loss_val: 66991.9766	loss_test: 66992.6484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7058.8325	loss_val: 7058.7964	loss_test: 7058.9448	accuracy_train: 0.8980	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 31	curr_val_accuracy: 0.8153	curr_test_accuracy: 0.8053
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7611.3608	loss_val: 7611.7505	loss_test: 7611.4897	accuracy_train: 0.9200	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 16954.0293	loss_val: 16954.3281	loss_test: 16954.3223	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 65109.7891	loss_val: 65109.8242	loss_test: 65110.1211	accuracy_train: 0.8571	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 21427.1621	loss_val: 21427.1113	loss_test: 21427.2617	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8060.8198	loss_val: 8061.3286	loss_test: 8060.9941	accuracy_train: 0.9383	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4274.2412	loss_val: 4274.2539	loss_test: 4274.2236	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6644.1807	loss_val: 6644.1572	loss_test: 6644.4341	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4891.7495	loss_val: 4891.9297	loss_test: 4892.0210	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10941.4912	loss_val: 10942.2100	loss_test: 10941.6533	accuracy_train: 0.9375	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6322.8569	loss_val: 6322.8525	loss_test: 6322.7607	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6460.2290	loss_val: 6460.2373	loss_test: 6460.2251	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7223.8555	loss_val: 7224.0044	loss_test: 7224.7485	accuracy_train: 0.8987	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5907.7949	loss_val: 5908.2969	loss_test: 5908.0728	accuracy_train: 0.8824	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 14377.4766	loss_val: 14377.4561	loss_test: 14377.7607	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4783.3340	loss_val: 4783.1582	loss_test: 4783.7344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5200.7637	loss_val: 5201.1450	loss_test: 5201.2256	accuracy_train: 0.7727	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4020.1355	loss_val: 4020.0974	loss_test: 4020.0908	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8265.2959	loss_val: 8265.8281	loss_test: 8265.4385	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66873.0234	loss_val: 66872.8125	loss_test: 66873.4844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7062.8145	loss_val: 7062.8096	loss_test: 7062.9434	accuracy_train: 0.9388	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 32	curr_val_accuracy: 0.8051	curr_test_accuracy: 0.7974
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7464.3315	loss_val: 7464.7383	loss_test: 7464.4717	accuracy_train: 0.9333	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 16501.7031	loss_val: 16502.0156	loss_test: 16502.0293	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 65589.1562	loss_val: 65589.2031	loss_test: 65589.5234	accuracy_train: 0.9143	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 22000.4414	loss_val: 22000.3867	loss_test: 22000.5469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8192.5479	loss_val: 8193.0635	loss_test: 8192.7373	accuracy_train: 0.9136	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4243.5327	loss_val: 4243.5454	loss_test: 4243.5142	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6660.9609	loss_val: 6660.9404	loss_test: 6661.2163	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4810.6523	loss_val: 4810.8535	loss_test: 4810.9556	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11078.8340	loss_val: 11079.5801	loss_test: 11079.0039	accuracy_train: 0.9375	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6586.5405	loss_val: 6586.5356	loss_test: 6586.4521	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6407.3242	loss_val: 6407.3335	loss_test: 6407.3218	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 7100.1069	loss_val: 7100.2861	loss_test: 7101.0283	accuracy_train: 0.9114	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5811.5317	loss_val: 5812.0601	loss_test: 5811.8442	accuracy_train: 0.8824	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 14165.6631	loss_val: 14165.6602	loss_test: 14165.9717	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4721.8081	loss_val: 4721.6523	loss_test: 4722.2178	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5188.0791	loss_val: 5188.4771	loss_test: 5188.5640	accuracy_train: 0.8182	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3998.9888	loss_val: 3998.9487	loss_test: 3998.9443	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8050.5664	loss_val: 8051.1182	loss_test: 8050.7212	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66552.7812	loss_val: 66552.5781	loss_test: 66553.2500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7068.5815	loss_val: 7068.6084	loss_test: 7068.7266	accuracy_train: 0.9388	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 33	curr_val_accuracy: 0.8224	curr_test_accuracy: 0.7987
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7346.5991	loss_val: 7347.0264	loss_test: 7346.7495	accuracy_train: 0.9333	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 16013.5576	loss_val: 16013.8828	loss_test: 16013.9180	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 65852.8125	loss_val: 65852.8828	loss_test: 65853.2188	accuracy_train: 0.9429	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 22696.6055	loss_val: 22696.5508	loss_test: 22696.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8319.5820	loss_val: 8320.1143	loss_test: 8319.7861	accuracy_train: 0.9136	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4227.1733	loss_val: 4227.1860	loss_test: 4227.1543	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6685.3970	loss_val: 6685.3813	loss_test: 6685.6523	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4749.4722	loss_val: 4749.6914	loss_test: 4749.8032	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11147.9219	loss_val: 11148.7100	loss_test: 11148.1084	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6852.6655	loss_val: 6852.6602	loss_test: 6852.5830	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6341.0840	loss_val: 6341.0942	loss_test: 6341.0835	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6945.4839	loss_val: 6945.6978	loss_test: 6946.4321	accuracy_train: 0.9114	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5718.4272	loss_val: 5718.9805	loss_test: 5718.7739	accuracy_train: 0.9118	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 13968.4229	loss_val: 13968.4346	loss_test: 13968.7559	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4664.5249	loss_val: 4664.3857	loss_test: 4664.9346	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5179.2192	loss_val: 5179.6274	loss_test: 5179.7271	accuracy_train: 0.8182	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3979.9968	loss_val: 3979.9556	loss_test: 3979.9526	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7858.4717	loss_val: 7859.0576	loss_test: 7858.6450	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66313.8125	loss_val: 66313.6172	loss_test: 66314.2891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7092.8931	loss_val: 7092.9541	loss_test: 7093.0522	accuracy_train: 0.9388	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 34	curr_val_accuracy: 0.8224	curr_test_accuracy: 0.7987
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7218.1084	loss_val: 7218.5576	loss_test: 7218.2705	accuracy_train: 0.9467	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 15633.8408	loss_val: 15634.1797	loss_test: 15634.2373	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 65691.4688	loss_val: 65691.5469	loss_test: 65691.9062	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 23548.6855	loss_val: 23548.6328	loss_test: 23548.8066	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8418.4775	loss_val: 8419.0244	loss_test: 8418.6992	accuracy_train: 0.8889	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4214.5903	loss_val: 4214.6030	loss_test: 4214.5713	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6715.4380	loss_val: 6715.4272	loss_test: 6715.6948	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4698.4409	loss_val: 4698.6802	loss_test: 4698.7993	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11206.2295	loss_val: 11207.0645	loss_test: 11206.4316	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 7130.8726	loss_val: 7130.8677	loss_test: 7130.7935	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6277.8315	loss_val: 6277.8428	loss_test: 6277.8330	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6804.4312	loss_val: 6804.6787	loss_test: 6805.4033	accuracy_train: 0.9241	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5623.3281	loss_val: 5623.9092	loss_test: 5623.6997	accuracy_train: 0.9118	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 13783.6338	loss_val: 13783.6562	loss_test: 13783.9922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4612.1099	loss_val: 4611.9829	loss_test: 4612.5200	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5156.7256	loss_val: 5157.1396	loss_test: 5157.2510	accuracy_train: 0.8636	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3958.5186	loss_val: 3958.4763	loss_test: 3958.4746	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7713.4932	loss_val: 7714.1221	loss_test: 7713.6934	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 66044.2266	loss_val: 66044.0391	loss_test: 66044.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7140.1582	loss_val: 7140.2529	loss_test: 7140.3315	accuracy_train: 0.9388	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 35	curr_val_accuracy: 0.8224	curr_test_accuracy: 0.7908
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7148.8101	loss_val: 7149.2861	loss_test: 7148.9810	accuracy_train: 0.9600	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 15295.2451	loss_val: 15295.5977	loss_test: 15295.6729	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 65895.1953	loss_val: 65895.2812	loss_test: 65895.6719	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 24448.3438	loss_val: 24448.2891	loss_test: 24448.4707	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8476.7070	loss_val: 8477.2910	loss_test: 8476.9424	accuracy_train: 0.8889	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4212.8252	loss_val: 4212.8384	loss_test: 4212.8052	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6764.2212	loss_val: 6764.2158	loss_test: 6764.4795	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4668.0894	loss_val: 4668.3486	loss_test: 4668.4771	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11240.6436	loss_val: 11241.5322	loss_test: 11240.8643	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 7371.2061	loss_val: 7371.2026	loss_test: 7371.1304	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6223.7319	loss_val: 6223.7441	loss_test: 6223.7358	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6648.1519	loss_val: 6648.4326	loss_test: 6649.1392	accuracy_train: 0.9367	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5537.2407	loss_val: 5537.8467	loss_test: 5537.6367	accuracy_train: 0.9706	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 13557.3320	loss_val: 13557.3652	loss_test: 13557.7148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4562.9883	loss_val: 4562.8730	loss_test: 4563.3940	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5139.7686	loss_val: 5140.1870	loss_test: 5140.3135	accuracy_train: 0.8636	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3944.7791	loss_val: 3944.7368	loss_test: 3944.7368	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7591.7383	loss_val: 7592.4224	loss_test: 7591.9727	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 65703.3516	loss_val: 65703.1797	loss_test: 65703.8438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7196.5332	loss_val: 7196.6499	loss_test: 7196.7163	accuracy_train: 0.9388	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 36	curr_val_accuracy: 0.8224	curr_test_accuracy: 0.7908
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7161.2871	loss_val: 7161.7905	loss_test: 7161.4653	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14942.2217	loss_val: 14942.5859	loss_test: 14942.6865	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 65974.8047	loss_val: 65974.9062	loss_test: 65975.3281	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 25591.8535	loss_val: 25591.8008	loss_test: 25591.9863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8436.7383	loss_val: 8437.3721	loss_test: 8436.9844	accuracy_train: 0.8889	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4228.8457	loss_val: 4228.8589	loss_test: 4228.8252	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6824.5630	loss_val: 6824.5635	loss_test: 6824.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4643.2104	loss_val: 4643.4873	loss_test: 4643.6260	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11264.0791	loss_val: 11265.0273	loss_test: 11264.3184	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 7607.4604	loss_val: 7607.4600	loss_test: 7607.3887	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6193.7476	loss_val: 6193.7612	loss_test: 6193.7539	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6507.2002	loss_val: 6507.5078	loss_test: 6508.2041	accuracy_train: 0.9367	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5463.5801	loss_val: 5464.2095	loss_test: 5464.0034	accuracy_train: 0.9706	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 13351.6211	loss_val: 13351.6641	loss_test: 13352.0254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4515.8291	loss_val: 4515.7261	loss_test: 4516.2285	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5136.5054	loss_val: 5136.9243	loss_test: 5137.0679	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3942.0010	loss_val: 3941.9597	loss_test: 3941.9604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7482.6284	loss_val: 7483.3623	loss_test: 7482.8955	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 65300.2578	loss_val: 65300.0938	loss_test: 65300.7539	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7252.7754	loss_val: 7252.9048	loss_test: 7252.9648	accuracy_train: 0.9490	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 37	curr_val_accuracy: 0.8224	curr_test_accuracy: 0.7908
best_round: 21	best_val_accuracy: 0.8245	best_test_accuracy: 0.7984
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7218.6553	loss_val: 7219.1904	loss_test: 7218.8389	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14676.8750	loss_val: 14677.2441	loss_test: 14677.3838	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 66343.9297	loss_val: 66344.0312	loss_test: 66344.4922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 26628.7148	loss_val: 26628.6641	loss_test: 26628.8535	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8254.1768	loss_val: 8254.8799	loss_test: 8254.4287	accuracy_train: 0.9383	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4250.2402	loss_val: 4250.2539	loss_test: 4250.2202	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6886.0298	loss_val: 6886.0366	loss_test: 6886.2866	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4636.6191	loss_val: 4636.9160	loss_test: 4637.0615	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11277.3252	loss_val: 11278.3291	loss_test: 11277.5820	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 7804.8423	loss_val: 7804.8462	loss_test: 7804.7764	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6176.0483	loss_val: 6176.0645	loss_test: 6176.0562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6379.8818	loss_val: 6380.2104	loss_test: 6380.9048	accuracy_train: 0.9367	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5401.5542	loss_val: 5402.2012	loss_test: 5402.0127	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 13138.7686	loss_val: 13138.8213	loss_test: 13139.1953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4488.2065	loss_val: 4488.1108	loss_test: 4488.5981	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5125.1787	loss_val: 5125.5942	loss_test: 5125.7563	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 3952.1670	loss_val: 3952.1277	loss_test: 3952.1272	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7403.6934	loss_val: 7404.4697	loss_test: 7403.9927	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 65045.6680	loss_val: 65045.5117	loss_test: 65046.1680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7324.4912	loss_val: 7324.6216	loss_test: 7324.6831	accuracy_train: 0.9592	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 38	curr_val_accuracy: 0.8419	curr_test_accuracy: 0.7982
best_round: 38	best_val_accuracy: 0.8419	best_test_accuracy: 0.7982
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7222.8418	loss_val: 7223.4004	loss_test: 7223.0312	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14468.4336	loss_val: 14468.8096	loss_test: 14468.9854	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 66804.6094	loss_val: 66804.7188	loss_test: 66805.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 27614.6582	loss_val: 27614.6074	loss_test: 27614.8027	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8036.0903	loss_val: 8036.8740	loss_test: 8036.3369	accuracy_train: 0.9383	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4263.1509	loss_val: 4263.1650	loss_test: 4263.1313	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6949.3647	loss_val: 6949.3765	loss_test: 6949.6216	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4648.8716	loss_val: 4649.1904	loss_test: 4649.3325	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11301.8564	loss_val: 11302.9092	loss_test: 11302.1270	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 8023.1768	loss_val: 8023.1846	loss_test: 8023.1182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6177.3877	loss_val: 6177.4053	loss_test: 6177.3970	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6225.1919	loss_val: 6225.5420	loss_test: 6226.2275	accuracy_train: 0.9494	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5333.0649	loss_val: 5333.7251	loss_test: 5333.5513	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 12933.4355	loss_val: 12933.4980	loss_test: 12933.8789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4446.8018	loss_val: 4446.7139	loss_test: 4447.1860	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5119.5396	loss_val: 5119.9507	loss_test: 5120.1362	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 3960.2595	loss_val: 3960.2224	loss_test: 3960.2207	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7336.5713	loss_val: 7337.3828	loss_test: 7336.9023	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 64804.9414	loss_val: 64804.7891	loss_test: 64805.4414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7413.5034	loss_val: 7413.6548	loss_test: 7413.7080	accuracy_train: 0.9592	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 39	curr_val_accuracy: 0.8419	curr_test_accuracy: 0.7982
best_round: 38	best_val_accuracy: 0.8419	best_test_accuracy: 0.7982
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7217.8794	loss_val: 7218.4634	loss_test: 7218.0757	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14304.0938	loss_val: 14304.4688	loss_test: 14304.6895	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 67304.1562	loss_val: 67304.2891	loss_test: 67304.8047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 28726.1211	loss_val: 28726.0723	loss_test: 28726.2676	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7759.2158	loss_val: 7760.0879	loss_test: 7759.4497	accuracy_train: 0.9506	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4271.5181	loss_val: 4271.5342	loss_test: 4271.5005	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7019.9819	loss_val: 7019.9980	loss_test: 7020.2397	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4664.0488	loss_val: 4664.3911	loss_test: 4664.5303	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11266.4209	loss_val: 11267.5195	loss_test: 11266.7041	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 8228.2080	loss_val: 8228.2178	loss_test: 8228.1543	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6186.0078	loss_val: 6186.0264	loss_test: 6186.0176	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6118.5913	loss_val: 6118.9580	loss_test: 6119.6479	accuracy_train: 0.9747	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5282.4951	loss_val: 5283.1631	loss_test: 5283.0156	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12752.0723	loss_val: 12752.1475	loss_test: 12752.5322	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4431.5635	loss_val: 4431.4814	loss_test: 4431.9355	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5110.3262	loss_val: 5110.7334	loss_test: 5110.9438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 3980.2046	loss_val: 3980.1694	loss_test: 3980.1670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7292.9775	loss_val: 7293.8120	loss_test: 7293.3359	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 64557.9492	loss_val: 64557.8047	loss_test: 64558.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7521.2104	loss_val: 7521.3628	loss_test: 7521.4224	accuracy_train: 0.9592	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 40	curr_val_accuracy: 0.8420	curr_test_accuracy: 0.7982
best_round: 40	best_val_accuracy: 0.8420	best_test_accuracy: 0.7982
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7281.2607	loss_val: 7281.8774	loss_test: 7281.4624	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14147.4414	loss_val: 14147.8096	loss_test: 14148.0723	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 67600.5391	loss_val: 67600.6719	loss_test: 67601.2188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 29783.0996	loss_val: 29783.0508	loss_test: 29783.2480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7475.4614	loss_val: 7476.4048	loss_test: 7475.6943	accuracy_train: 0.9753	accuracy_val: 0.7000	accuracy_test: 0.8182
[client 5]	loss_train: 4298.1577	loss_val: 4298.1763	loss_test: 4298.1426	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7103.8428	loss_val: 7103.8643	loss_test: 7104.1001	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4700.5044	loss_val: 4700.8696	loss_test: 4701.0049	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11116.6621	loss_val: 11117.8193	loss_test: 11116.9590	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 8458.9785	loss_val: 8458.9922	loss_test: 8458.9297	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6188.2637	loss_val: 6188.2837	loss_test: 6188.2734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6057.3457	loss_val: 6057.7212	loss_test: 6058.4404	accuracy_train: 0.9747	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5235.6997	loss_val: 5236.3730	loss_test: 5236.2593	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12568.5029	loss_val: 12568.5879	loss_test: 12568.9805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4423.4180	loss_val: 4423.3428	loss_test: 4423.7759	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5107.2407	loss_val: 5107.6416	loss_test: 5107.8745	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4007.5737	loss_val: 4007.5417	loss_test: 4007.5381	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7257.3916	loss_val: 7258.2368	loss_test: 7257.7847	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 64249.0117	loss_val: 64248.8711	loss_test: 64249.5039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7614.5654	loss_val: 7614.7104	loss_test: 7614.7827	accuracy_train: 0.9796	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 41	curr_val_accuracy: 0.8420	curr_test_accuracy: 0.8061
best_round: 40	best_val_accuracy: 0.8420	best_test_accuracy: 0.7982
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7283.3535	loss_val: 7284.0063	loss_test: 7283.5625	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14082.6416	loss_val: 14082.9785	loss_test: 14083.3203	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 67625.1875	loss_val: 67625.3438	loss_test: 67625.9062	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 30943.7734	loss_val: 30943.7285	loss_test: 30943.9258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7226.1841	loss_val: 7227.1943	loss_test: 7226.4302	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4321.1558	loss_val: 4321.1758	loss_test: 4321.1426	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7180.5952	loss_val: 7180.6201	loss_test: 7180.8545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4720.6128	loss_val: 4720.9980	loss_test: 4721.1328	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10946.8848	loss_val: 10948.1006	loss_test: 10947.1963	accuracy_train: 0.9792	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 8655.1680	loss_val: 8655.1855	loss_test: 8655.1240	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6190.7588	loss_val: 6190.7798	loss_test: 6190.7686	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6005.8599	loss_val: 6006.2451	loss_test: 6006.9976	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5189.3188	loss_val: 5189.9902	loss_test: 5189.9253	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12443.9170	loss_val: 12444.0098	loss_test: 12444.4102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4426.9058	loss_val: 4426.8359	loss_test: 4427.2544	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5101.7065	loss_val: 5102.1035	loss_test: 5102.3584	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4035.0295	loss_val: 4035.0005	loss_test: 4034.9934	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7260.7368	loss_val: 7261.5898	loss_test: 7261.1733	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 63922.0508	loss_val: 63921.9180	loss_test: 63922.5312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7701.2603	loss_val: 7701.3853	loss_test: 7701.4805	accuracy_train: 0.9898	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 42	curr_val_accuracy: 0.8341	curr_test_accuracy: 0.8005
best_round: 40	best_val_accuracy: 0.8420	best_test_accuracy: 0.7982
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7348.9224	loss_val: 7349.6255	loss_test: 7349.1387	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14076.6992	loss_val: 14077.0117	loss_test: 14077.4355	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67292.4062	loss_val: 67292.5859	loss_test: 67293.1484	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 32058.9395	loss_val: 32058.8945	loss_test: 32059.0938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6963.7661	loss_val: 6964.8325	loss_test: 6964.0425	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4350.9014	loss_val: 4350.9229	loss_test: 4350.8901	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7246.4775	loss_val: 7246.5049	loss_test: 7246.7388	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4734.0259	loss_val: 4734.4248	loss_test: 4734.5640	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10786.8711	loss_val: 10788.1367	loss_test: 10787.1973	accuracy_train: 0.9792	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 8846.7988	loss_val: 8846.8213	loss_test: 8846.7568	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6209.6953	loss_val: 6209.7173	loss_test: 6209.7051	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5968.4712	loss_val: 5968.8633	loss_test: 5969.6509	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5158.1685	loss_val: 5158.8413	loss_test: 5158.8120	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12309.5967	loss_val: 12309.6924	loss_test: 12310.1045	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4443.1577	loss_val: 4443.0923	loss_test: 4443.4946	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5111.2539	loss_val: 5111.6548	loss_test: 5111.9214	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4074.0762	loss_val: 4074.0510	loss_test: 4074.0410	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7252.5151	loss_val: 7253.3784	loss_test: 7253.0024	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 63857.1445	loss_val: 63857.0195	loss_test: 63857.6172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7825.3418	loss_val: 7825.4224	loss_test: 7825.5566	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 43	curr_val_accuracy: 0.8307	curr_test_accuracy: 0.7926
best_round: 40	best_val_accuracy: 0.8420	best_test_accuracy: 0.7982
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7425.1689	loss_val: 7425.9302	loss_test: 7425.3936	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 14125.4336	loss_val: 14125.7266	loss_test: 14126.2285	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67151.4688	loss_val: 67151.6797	loss_test: 67152.2500	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 33209.6602	loss_val: 33209.6172	loss_test: 33209.8164	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6779.3760	loss_val: 6780.4819	loss_test: 6779.6807	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4392.5278	loss_val: 4392.5513	loss_test: 4392.5200	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7321.9780	loss_val: 7322.0054	loss_test: 7322.2437	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4766.7710	loss_val: 4767.1836	loss_test: 4767.3276	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10652.2471	loss_val: 10653.5547	loss_test: 10652.5898	accuracy_train: 0.9792	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 9068.9160	loss_val: 9068.9414	loss_test: 9068.8750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6228.8755	loss_val: 6228.8975	loss_test: 6228.8843	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5925.9507	loss_val: 5926.3486	loss_test: 5927.1753	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5136.9766	loss_val: 5137.6479	loss_test: 5137.6562	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12252.3838	loss_val: 12252.4814	loss_test: 12252.9072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4474.5132	loss_val: 4474.4521	loss_test: 4474.8364	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5130.9692	loss_val: 5131.3701	loss_test: 5131.6509	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4120.2681	loss_val: 4120.2461	loss_test: 4120.2339	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7271.2959	loss_val: 7272.1743	loss_test: 7271.8301	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 63701.5000	loss_val: 63701.3789	loss_test: 63701.9609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8002.8574	loss_val: 8002.8838	loss_test: 8003.0591	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 44	curr_val_accuracy: 0.8388	curr_test_accuracy: 0.7852
best_round: 40	best_val_accuracy: 0.8420	best_test_accuracy: 0.7982
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7426.3945	loss_val: 7427.2070	loss_test: 7426.6318	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 14201.2695	loss_val: 14201.5352	loss_test: 14202.1172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67210.2109	loss_val: 67210.4453	loss_test: 67211.0234	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 34320.9062	loss_val: 34320.8633	loss_test: 34321.0664	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6659.9897	loss_val: 6661.1133	loss_test: 6660.3174	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4424.6733	loss_val: 4424.6982	loss_test: 4424.6675	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7393.5649	loss_val: 7393.5913	loss_test: 7393.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4800.8896	loss_val: 4801.3140	loss_test: 4801.4619	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10526.6865	loss_val: 10528.0146	loss_test: 10527.0420	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 9258.6016	loss_val: 9258.6309	loss_test: 9258.5635	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6226.5625	loss_val: 6226.5850	loss_test: 6226.5713	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5908.7910	loss_val: 5909.1987	loss_test: 5910.0684	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5134.7842	loss_val: 5135.4663	loss_test: 5135.4595	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12263.9150	loss_val: 12263.9980	loss_test: 12264.4561	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4503.9141	loss_val: 4503.8569	loss_test: 4504.2227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5145.9404	loss_val: 5146.3403	loss_test: 5146.6348	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4165.5142	loss_val: 4165.4951	loss_test: 4165.4805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7294.1689	loss_val: 7295.0522	loss_test: 7294.7407	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 63708.6016	loss_val: 63708.4883	loss_test: 63709.0586	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8184.7266	loss_val: 8184.7256	loss_test: 8184.9209	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 45	curr_val_accuracy: 0.8475	curr_test_accuracy: 0.7852
best_round: 45	best_val_accuracy: 0.8475	best_test_accuracy: 0.7852
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7339.0259	loss_val: 7339.8682	loss_test: 7339.2754	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 14269.8945	loss_val: 14270.1445	loss_test: 14270.7988	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67556.6562	loss_val: 67556.8906	loss_test: 67557.5000	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 35497.2461	loss_val: 35497.2070	loss_test: 35497.4062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6650.5596	loss_val: 6651.6865	loss_test: 6650.8994	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4447.5913	loss_val: 4447.6172	loss_test: 4447.5869	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7485.9312	loss_val: 7485.9565	loss_test: 7486.2070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4850.7729	loss_val: 4851.2129	loss_test: 4851.3623	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10425.5078	loss_val: 10426.8486	loss_test: 10425.8789	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9434.2178	loss_val: 9434.2480	loss_test: 9434.1797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6226.1108	loss_val: 6226.1333	loss_test: 6226.1191	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5930.8320	loss_val: 5931.2524	loss_test: 5932.1675	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5137.0396	loss_val: 5137.7319	loss_test: 5137.7007	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12275.9316	loss_val: 12275.9951	loss_test: 12276.4873	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4527.9146	loss_val: 4527.8608	loss_test: 4528.2124	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5166.9746	loss_val: 5167.3828	loss_test: 5167.6816	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4213.1094	loss_val: 4213.0928	loss_test: 4213.0767	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7300.3887	loss_val: 7301.2974	loss_test: 7301.0044	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 63783.3711	loss_val: 63783.2656	loss_test: 63783.8320	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8325.5098	loss_val: 8325.4961	loss_test: 8325.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 46	curr_val_accuracy: 0.8400	curr_test_accuracy: 0.7778
best_round: 45	best_val_accuracy: 0.8475	best_test_accuracy: 0.7852
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7232.1943	loss_val: 7233.0596	loss_test: 7232.4556	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 14327.6035	loss_val: 14327.8418	loss_test: 14328.5400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 68135.2422	loss_val: 68135.4453	loss_test: 68136.0859	accuracy_train: 0.9429	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 36446.1914	loss_val: 36446.1562	loss_test: 36446.3594	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6733.4619	loss_val: 6734.5835	loss_test: 6733.8047	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4477.6670	loss_val: 4477.6938	loss_test: 4477.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7571.1079	loss_val: 7571.1333	loss_test: 7571.3901	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4922.1812	loss_val: 4922.6387	loss_test: 4922.7856	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10363.4307	loss_val: 10364.7764	loss_test: 10363.8105	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9598.6680	loss_val: 9598.7002	loss_test: 9598.6299	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6221.6475	loss_val: 6221.6694	loss_test: 6221.6562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5914.6323	loss_val: 5915.0713	loss_test: 5916.0117	accuracy_train: 0.9747	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5161.9111	loss_val: 5162.6187	loss_test: 5162.5474	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12324.1904	loss_val: 12324.2363	loss_test: 12324.7598	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4562.4800	loss_val: 4562.4287	loss_test: 4562.7690	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5183.6626	loss_val: 5184.0747	loss_test: 5184.3833	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4256.7158	loss_val: 4256.7017	loss_test: 4256.6851	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7296.3477	loss_val: 7297.2817	loss_test: 7296.9980	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 63910.7109	loss_val: 63910.6094	loss_test: 63911.1680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8407.3281	loss_val: 8407.3086	loss_test: 8407.5234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 47	curr_val_accuracy: 0.8400	curr_test_accuracy: 0.7778
best_round: 45	best_val_accuracy: 0.8475	best_test_accuracy: 0.7852
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7093.5869	loss_val: 7094.4517	loss_test: 7093.8647	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 14368.8027	loss_val: 14369.0254	loss_test: 14369.7832	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 68439.4922	loss_val: 68439.6719	loss_test: 68440.3359	accuracy_train: 0.9429	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 37405.2461	loss_val: 37405.2148	loss_test: 37405.4141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6806.2964	loss_val: 6807.4214	loss_test: 6806.6416	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4506.6938	loss_val: 4506.7217	loss_test: 4506.6924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7664.3721	loss_val: 7664.3975	loss_test: 7664.6587	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4980.7051	loss_val: 4981.1763	loss_test: 4981.3247	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10312.1572	loss_val: 10313.5088	loss_test: 10312.5508	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 9743.9932	loss_val: 9744.0273	loss_test: 9743.9561	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6213.9907	loss_val: 6214.0122	loss_test: 6213.9995	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5866.4487	loss_val: 5866.9033	loss_test: 5867.8584	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5187.4600	loss_val: 5188.1777	loss_test: 5188.0728	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12373.4189	loss_val: 12373.4561	loss_test: 12373.9961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4581.3940	loss_val: 4581.3447	loss_test: 4581.6807	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5200.2759	loss_val: 5200.6909	loss_test: 5201.0044	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4302.8911	loss_val: 4302.8794	loss_test: 4302.8623	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7315.5635	loss_val: 7316.4966	loss_test: 7316.2373	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 64219.8047	loss_val: 64219.7070	loss_test: 64220.2539	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8480.4590	loss_val: 8480.4326	loss_test: 8480.6553	accuracy_train: 0.9898	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 48	curr_val_accuracy: 0.8487	curr_test_accuracy: 0.7701
best_round: 48	best_val_accuracy: 0.8487	best_test_accuracy: 0.7701
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6932.4351	loss_val: 6933.2817	loss_test: 6932.7275	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.9000
[client 1]	loss_train: 14484.4941	loss_val: 14484.7090	loss_test: 14485.5205	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 68141.0078	loss_val: 68141.2109	loss_test: 68141.8906	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 38506.2773	loss_val: 38506.2500	loss_test: 38506.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6900.7471	loss_val: 6901.8896	loss_test: 6901.0859	accuracy_train: 0.9877	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4534.3276	loss_val: 4534.3550	loss_test: 4534.3271	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7767.4907	loss_val: 7767.5156	loss_test: 7767.7842	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5042.3721	loss_val: 5042.8584	loss_test: 5043.0112	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10276.7812	loss_val: 10278.1240	loss_test: 10277.1855	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 9905.4277	loss_val: 9905.4629	loss_test: 9905.3916	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6203.4233	loss_val: 6203.4448	loss_test: 6203.4331	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5819.4009	loss_val: 5819.8833	loss_test: 5820.8418	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5206.0752	loss_val: 5206.7959	loss_test: 5206.6958	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12431.0195	loss_val: 12431.0547	loss_test: 12431.6006	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4616.0181	loss_val: 4615.9717	loss_test: 4616.2969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5225.6943	loss_val: 5226.1157	loss_test: 5226.4355	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4341.6123	loss_val: 4341.6030	loss_test: 4341.5869	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7368.7563	loss_val: 7369.6890	loss_test: 7369.4341	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 64565.0625	loss_val: 64564.9688	loss_test: 64565.5000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8478.2529	loss_val: 8478.2363	loss_test: 8478.4658	accuracy_train: 0.9898	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 49	curr_val_accuracy: 0.8573	curr_test_accuracy: 0.7852
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6965.0820	loss_val: 6965.9497	loss_test: 6965.4092	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14593.0674	loss_val: 14593.2715	loss_test: 14594.1426	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 68117.0234	loss_val: 68117.2578	loss_test: 68117.9766	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 39620.4883	loss_val: 39620.4648	loss_test: 39620.6680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7108.4336	loss_val: 7109.5825	loss_test: 7108.7539	accuracy_train: 0.9753	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4560.9019	loss_val: 4560.9307	loss_test: 4560.9028	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7867.3340	loss_val: 7867.3594	loss_test: 7867.6362	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5103.4761	loss_val: 5103.9775	loss_test: 5104.1333	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10279.0918	loss_val: 10280.4326	loss_test: 10279.5068	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 10059.2158	loss_val: 10059.2529	loss_test: 10059.1816	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6178.5659	loss_val: 6178.5884	loss_test: 6178.5771	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5798.4492	loss_val: 5798.9585	loss_test: 5799.9229	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5215.7080	loss_val: 5216.4268	loss_test: 5216.3618	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12426.3916	loss_val: 12426.4336	loss_test: 12426.9775	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4641.4033	loss_val: 4641.3584	loss_test: 4641.6743	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5243.6592	loss_val: 5244.0859	loss_test: 5244.4102	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4373.1836	loss_val: 4373.1772	loss_test: 4373.1621	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7396.2754	loss_val: 7397.2227	loss_test: 7396.9585	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 64868.7500	loss_val: 64868.6602	loss_test: 64869.1797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8411.9443	loss_val: 8411.9531	loss_test: 8412.1875	accuracy_train: 0.9898	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 50	curr_val_accuracy: 0.8573	curr_test_accuracy: 0.7845
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6978.1733	loss_val: 6979.0469	loss_test: 6978.5317	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14716.0498	loss_val: 14716.2383	loss_test: 14717.1729	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67862.4688	loss_val: 67862.7266	loss_test: 67863.4766	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 40493.5781	loss_val: 40493.5547	loss_test: 40493.7656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7233.6997	loss_val: 7234.8730	loss_test: 7234.0112	accuracy_train: 0.9753	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 4593.7666	loss_val: 4593.7959	loss_test: 4593.7681	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7973.4556	loss_val: 7973.4810	loss_test: 7973.7651	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5172.7417	loss_val: 5173.2559	loss_test: 5173.4126	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10317.7061	loss_val: 10319.0391	loss_test: 10318.1260	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 10224.1172	loss_val: 10224.1553	loss_test: 10224.0850	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6179.4272	loss_val: 6179.4502	loss_test: 6179.4399	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5751.4961	loss_val: 5752.0337	loss_test: 5752.9937	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5224.0791	loss_val: 5224.7983	loss_test: 5224.7632	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12418.4219	loss_val: 12418.4688	loss_test: 12419.0166	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4663.7607	loss_val: 4663.7168	loss_test: 4664.0283	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5254.6445	loss_val: 5255.0742	loss_test: 5255.4038	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4406.3120	loss_val: 4406.3081	loss_test: 4406.2949	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7432.1206	loss_val: 7433.0806	loss_test: 7432.8013	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65232.7070	loss_val: 65232.6172	loss_test: 65233.1172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8307.7832	loss_val: 8307.8438	loss_test: 8308.0674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 51	curr_val_accuracy: 0.8487	curr_test_accuracy: 0.7924
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6993.5200	loss_val: 6994.3931	loss_test: 6993.9102	accuracy_train: 0.9867	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14878.5508	loss_val: 14878.7295	loss_test: 14879.7178	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 68544.1797	loss_val: 68544.4375	loss_test: 68545.2266	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 41307.5117	loss_val: 41307.4883	loss_test: 41307.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7271.6157	loss_val: 7272.8174	loss_test: 7271.9292	accuracy_train: 0.9753	accuracy_val: 0.8000	accuracy_test: 0.8182
[client 5]	loss_train: 4619.4604	loss_val: 4619.4907	loss_test: 4619.4624	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8078.3433	loss_val: 8078.3687	loss_test: 8078.6582	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5255.0586	loss_val: 5255.5825	loss_test: 5255.7407	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10417.4121	loss_val: 10418.7295	loss_test: 10417.8271	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 10499.5391	loss_val: 10499.5771	loss_test: 10499.5127	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6201.5044	loss_val: 6201.5283	loss_test: 6201.5171	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5681.7505	loss_val: 5682.3193	loss_test: 5683.2529	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5229.5908	loss_val: 5230.3076	loss_test: 5230.3032	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12403.6855	loss_val: 12403.7383	loss_test: 12404.2881	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4678.5522	loss_val: 4678.5098	loss_test: 4678.8179	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5277.5869	loss_val: 5278.0161	loss_test: 5278.3516	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4441.3623	loss_val: 4441.3604	loss_test: 4441.3486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7479.6089	loss_val: 7480.5767	loss_test: 7480.2695	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65878.0391	loss_val: 65877.9531	loss_test: 65878.4375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8175.1631	loss_val: 8175.3452	loss_test: 8175.4966	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 52	curr_val_accuracy: 0.8313	curr_test_accuracy: 0.7924
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6898.3184	loss_val: 6899.1611	loss_test: 6898.7266	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14956.8008	loss_val: 14956.9727	loss_test: 14957.9980	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 69398.6328	loss_val: 69398.8828	loss_test: 69399.7109	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 41805.6406	loss_val: 41805.6211	loss_test: 41805.8398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7270.7783	loss_val: 7272.0391	loss_test: 7271.1118	accuracy_train: 0.9753	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4640.8228	loss_val: 4640.8535	loss_test: 4640.8252	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8161.7354	loss_val: 8161.7607	loss_test: 8162.0557	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5295.5586	loss_val: 5296.0835	loss_test: 5296.2520	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10491.4561	loss_val: 10492.7656	loss_test: 10491.8652	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 10759.1543	loss_val: 10759.1904	loss_test: 10759.1318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6212.0498	loss_val: 6212.0747	loss_test: 6212.0630	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5625.0527	loss_val: 5625.6523	loss_test: 5626.5654	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5231.9121	loss_val: 5232.6240	loss_test: 5232.6782	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 12397.8809	loss_val: 12397.9424	loss_test: 12398.4824	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4685.9985	loss_val: 4685.9575	loss_test: 4686.2656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5303.1055	loss_val: 5303.5425	loss_test: 5303.8809	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4478.2583	loss_val: 4478.2583	loss_test: 4478.2485	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7511.5498	loss_val: 7512.5571	loss_test: 7512.2114	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 66377.1641	loss_val: 66377.0859	loss_test: 66377.5625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8149.2368	loss_val: 8149.5522	loss_test: 8149.6089	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 53	curr_val_accuracy: 0.8313	curr_test_accuracy: 0.7845
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6863.3521	loss_val: 6864.1924	loss_test: 6863.7842	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15105.9639	loss_val: 15106.1309	loss_test: 15107.1846	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 69921.6406	loss_val: 69921.8828	loss_test: 69922.7500	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 42429.9062	loss_val: 42429.8867	loss_test: 42430.1133	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7266.6978	loss_val: 7268.0122	loss_test: 7267.0537	accuracy_train: 0.9877	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4650.5181	loss_val: 4650.5488	loss_test: 4650.5200	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8233.6523	loss_val: 8233.6777	loss_test: 8233.9775	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5325.5352	loss_val: 5326.0630	loss_test: 5326.2349	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10590.1426	loss_val: 10591.4443	loss_test: 10590.5312	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11008.9141	loss_val: 11008.9482	loss_test: 11008.8945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6207.9995	loss_val: 6208.0249	loss_test: 6208.0137	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5596.1001	loss_val: 5596.7368	loss_test: 5597.6299	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5228.5498	loss_val: 5229.2515	loss_test: 5229.3760	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12393.7686	loss_val: 12393.8389	loss_test: 12394.3711	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4706.0693	loss_val: 4706.0293	loss_test: 4706.3364	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5334.7417	loss_val: 5335.1924	loss_test: 5335.5371	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4509.1919	loss_val: 4509.1934	loss_test: 4509.1841	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7547.5059	loss_val: 7548.5518	loss_test: 7548.1592	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 66546.4844	loss_val: 66546.4062	loss_test: 66546.8750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8170.8057	loss_val: 8171.2471	loss_test: 8171.2163	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 54	curr_val_accuracy: 0.8388	curr_test_accuracy: 0.7905
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6853.2959	loss_val: 6854.1489	loss_test: 6853.7539	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15222.8145	loss_val: 15222.9766	loss_test: 15224.0547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 69867.0625	loss_val: 69867.2969	loss_test: 69868.1953	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 42901.5312	loss_val: 42901.5156	loss_test: 42901.7500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7223.6875	loss_val: 7225.0479	loss_test: 7224.0698	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4669.6455	loss_val: 4669.6758	loss_test: 4669.6470	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8317.4219	loss_val: 8317.4473	loss_test: 8317.7500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5349.0493	loss_val: 5349.5776	loss_test: 5349.7480	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10663.1426	loss_val: 10664.4648	loss_test: 10663.5234	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11170.9287	loss_val: 11170.9609	loss_test: 11170.9111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6215.8433	loss_val: 6215.8691	loss_test: 6215.8584	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5553.4150	loss_val: 5554.0703	loss_test: 5554.9478	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5238.8052	loss_val: 5239.5010	loss_test: 5239.6787	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12318.0615	loss_val: 12318.1396	loss_test: 12318.6660	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4719.3022	loss_val: 4719.2637	loss_test: 4719.5688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5365.6304	loss_val: 5366.0889	loss_test: 5366.4434	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4541.5723	loss_val: 4541.5752	loss_test: 4541.5674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7586.5835	loss_val: 7587.6655	loss_test: 7587.2329	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 66901.9453	loss_val: 66901.8672	loss_test: 66902.3281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8211.6826	loss_val: 8212.1934	loss_test: 8212.1201	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 55	curr_val_accuracy: 0.8388	curr_test_accuracy: 0.7970
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6771.0371	loss_val: 6771.8828	loss_test: 6771.5015	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15288.1064	loss_val: 15288.2637	loss_test: 15289.3574	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 69534.7656	loss_val: 69534.9922	loss_test: 69535.9141	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 43179.1055	loss_val: 43179.0938	loss_test: 43179.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7230.7070	loss_val: 7232.0957	loss_test: 7231.1108	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4684.2949	loss_val: 4684.3242	loss_test: 4684.2964	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8405.3320	loss_val: 8405.3564	loss_test: 8405.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5381.7271	loss_val: 5382.2627	loss_test: 5382.4224	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10698.5498	loss_val: 10699.9141	loss_test: 10698.9258	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11339.0879	loss_val: 11339.1162	loss_test: 11339.0723	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6220.9888	loss_val: 6221.0146	loss_test: 6221.0054	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5506.9038	loss_val: 5507.5703	loss_test: 5508.4370	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5238.1914	loss_val: 5238.8794	loss_test: 5239.1167	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12264.3662	loss_val: 12264.4580	loss_test: 12264.9727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4742.0952	loss_val: 4742.0576	loss_test: 4742.3584	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5401.7935	loss_val: 5402.2524	loss_test: 5402.6143	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4562.2383	loss_val: 4562.2437	loss_test: 4562.2368	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7632.8188	loss_val: 7633.9233	loss_test: 7633.4531	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67054.7734	loss_val: 67054.7031	loss_test: 67055.1641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8228.5430	loss_val: 8229.0996	loss_test: 8229.0020	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 56	curr_val_accuracy: 0.8468	curr_test_accuracy: 0.7970
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6658.7896	loss_val: 6659.6260	loss_test: 6659.2544	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15308.4170	loss_val: 15308.5723	loss_test: 15309.6670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 68955.9219	loss_val: 68956.1562	loss_test: 68957.0781	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 43533.0859	loss_val: 43533.0781	loss_test: 43533.3281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7219.1587	loss_val: 7220.5708	loss_test: 7219.5806	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4694.9229	loss_val: 4694.9517	loss_test: 4694.9243	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8497.6377	loss_val: 8497.6602	loss_test: 8497.9736	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5378.9756	loss_val: 5379.5181	loss_test: 5379.6680	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10748.2646	loss_val: 10749.6680	loss_test: 10748.6357	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11465.3477	loss_val: 11465.3740	loss_test: 11465.3320	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6218.3906	loss_val: 6218.4165	loss_test: 6218.4087	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5475.9238	loss_val: 5476.5967	loss_test: 5477.4663	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5237.5088	loss_val: 5238.1870	loss_test: 5238.4888	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12197.7100	loss_val: 12197.8174	loss_test: 12198.3174	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4751.2168	loss_val: 4751.1797	loss_test: 4751.4780	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5435.2393	loss_val: 5435.6963	loss_test: 5436.0688	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4589.5044	loss_val: 4589.5112	loss_test: 4589.5049	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7677.6333	loss_val: 7678.7515	loss_test: 7678.2485	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67196.2891	loss_val: 67196.2188	loss_test: 67196.6875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8239.4561	loss_val: 8240.0059	loss_test: 8239.9277	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 57	curr_val_accuracy: 0.8468	curr_test_accuracy: 0.7970
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6560.1460	loss_val: 6560.9717	loss_test: 6560.6079	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15410.4561	loss_val: 15410.5996	loss_test: 15411.7227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 68170.5078	loss_val: 68170.7422	loss_test: 68171.6719	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 43851.5781	loss_val: 43851.5664	loss_test: 43851.8281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7153.5122	loss_val: 7154.9380	loss_test: 7153.9541	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4709.1465	loss_val: 4709.1753	loss_test: 4709.1484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8580.9434	loss_val: 8580.9648	loss_test: 8581.2861	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5373.8892	loss_val: 5374.4375	loss_test: 5374.5718	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10775.8311	loss_val: 10777.2734	loss_test: 10776.2002	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11537.6504	loss_val: 11537.6748	loss_test: 11537.6348	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6207.3071	loss_val: 6207.3335	loss_test: 6207.3267	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5437.0127	loss_val: 5437.6929	loss_test: 5438.5742	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5233.0386	loss_val: 5233.7070	loss_test: 5234.0757	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12120.3623	loss_val: 12120.4805	loss_test: 12120.9717	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4764.1392	loss_val: 4764.1025	loss_test: 4764.3979	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5465.5566	loss_val: 5466.0083	loss_test: 5466.3931	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4611.0835	loss_val: 4611.0918	loss_test: 4611.0854	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7728.6123	loss_val: 7729.7334	loss_test: 7729.2124	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67339.8125	loss_val: 67339.7500	loss_test: 67340.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8230.3838	loss_val: 8230.9082	loss_test: 8230.8652	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 58	curr_val_accuracy: 0.8468	curr_test_accuracy: 0.7970
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6456.6470	loss_val: 6457.4663	loss_test: 6457.1123	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15516.2949	loss_val: 15516.4355	loss_test: 15517.5771	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67690.4297	loss_val: 67690.6719	loss_test: 67691.6172	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 44291.5859	loss_val: 44291.5781	loss_test: 44291.8438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7037.8579	loss_val: 7039.2812	loss_test: 7038.3188	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 4720.7661	loss_val: 4720.7935	loss_test: 4720.7686	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8664.1201	loss_val: 8664.1406	loss_test: 8664.4707	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5357.3154	loss_val: 5357.8682	loss_test: 5357.9878	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10609.6299	loss_val: 10611.1494	loss_test: 10610.0186	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11567.9131	loss_val: 11567.9336	loss_test: 11567.8965	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6203.7881	loss_val: 6203.8154	loss_test: 6203.8096	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5418.7148	loss_val: 5419.3999	loss_test: 5420.3105	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5238.2720	loss_val: 5238.9292	loss_test: 5239.3706	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12054.8604	loss_val: 12054.9844	loss_test: 12055.4736	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4783.1138	loss_val: 4783.0781	loss_test: 4783.3701	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5483.9175	loss_val: 5484.3491	loss_test: 5484.7471	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4635.9009	loss_val: 4635.9116	loss_test: 4635.9048	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7780.5601	loss_val: 7781.6899	loss_test: 7781.1440	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67244.8672	loss_val: 67244.8047	loss_test: 67245.2656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8226.7812	loss_val: 8227.2637	loss_test: 8227.2686	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 59	curr_val_accuracy: 0.8468	curr_test_accuracy: 0.7970
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6387.8086	loss_val: 6388.6230	loss_test: 6388.2832	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15547.9268	loss_val: 15548.0674	loss_test: 15549.2236	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67242.0078	loss_val: 67242.2422	loss_test: 67243.1953	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 44577.0273	loss_val: 44577.0195	loss_test: 44577.2930	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6923.5767	loss_val: 6925.0073	loss_test: 6924.0586	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4736.3105	loss_val: 4736.3374	loss_test: 4736.3145	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8748.6191	loss_val: 8748.6377	loss_test: 8748.9766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5349.6890	loss_val: 5350.2500	loss_test: 5350.3555	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10516.3711	loss_val: 10517.9473	loss_test: 10516.7715	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11587.8721	loss_val: 11587.8916	loss_test: 11587.8555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6229.2847	loss_val: 6229.3125	loss_test: 6229.3062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5385.0234	loss_val: 5385.7075	loss_test: 5386.6343	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5239.3311	loss_val: 5239.9810	loss_test: 5240.4829	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12011.6572	loss_val: 12011.7842	loss_test: 12012.2783	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4781.1924	loss_val: 4781.1567	loss_test: 4781.4458	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5515.5381	loss_val: 5515.9600	loss_test: 5516.3721	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4652.9116	loss_val: 4652.9248	loss_test: 4652.9170	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7838.7310	loss_val: 7839.8701	loss_test: 7839.3096	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67191.7422	loss_val: 67191.6797	loss_test: 67192.1328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8252.2363	loss_val: 8252.6445	loss_test: 8252.7197	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 60	curr_val_accuracy: 0.8382	curr_test_accuracy: 0.7970
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6319.9980	loss_val: 6320.8184	loss_test: 6320.4937	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 15583.2383	loss_val: 15583.3838	loss_test: 15584.5156	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 66877.1406	loss_val: 66877.3750	loss_test: 66878.3359	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 45071.5430	loss_val: 45071.5352	loss_test: 45071.8164	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6864.6538	loss_val: 6866.1074	loss_test: 6865.1426	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4753.4453	loss_val: 4753.4712	loss_test: 4753.4497	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8842.3594	loss_val: 8842.3789	loss_test: 8842.7236	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5347.7749	loss_val: 5348.3394	loss_test: 5348.4390	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10437.8555	loss_val: 10439.4863	loss_test: 10438.2842	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11614.1611	loss_val: 11614.1787	loss_test: 11614.1436	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6251.6328	loss_val: 6251.6611	loss_test: 6251.6543	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5398.3027	loss_val: 5398.9932	loss_test: 5399.9536	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5250.3999	loss_val: 5251.0435	loss_test: 5251.6074	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 11993.8809	loss_val: 11994.0146	loss_test: 11994.5059	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4793.8940	loss_val: 4793.8584	loss_test: 4794.1392	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5548.4575	loss_val: 5548.8716	loss_test: 5549.2920	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4670.1216	loss_val: 4670.1377	loss_test: 4670.1289	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7877.6538	loss_val: 7878.7974	loss_test: 7878.2285	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67071.8828	loss_val: 67071.8203	loss_test: 67072.2656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8295.1953	loss_val: 8295.5166	loss_test: 8295.6689	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 61	curr_val_accuracy: 0.8378	curr_test_accuracy: 0.7970
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6280.9253	loss_val: 6281.7793	loss_test: 6281.4556	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 15562.3379	loss_val: 15562.4883	loss_test: 15563.5986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 66471.5234	loss_val: 66471.7344	loss_test: 66472.7031	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 45737.7188	loss_val: 45737.7148	loss_test: 45738.0000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6842.9253	loss_val: 6844.4121	loss_test: 6843.4141	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4769.5420	loss_val: 4769.5674	loss_test: 4769.5469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8934.7646	loss_val: 8934.7832	loss_test: 8935.1338	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5350.7993	loss_val: 5351.3682	loss_test: 5351.4634	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10434.9902	loss_val: 10436.6826	loss_test: 10435.4414	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11609.3320	loss_val: 11609.3496	loss_test: 11609.3135	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6249.3682	loss_val: 6249.3970	loss_test: 6249.3911	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5399.6401	loss_val: 5400.3467	loss_test: 5401.3164	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5269.0908	loss_val: 5269.7271	loss_test: 5270.3608	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 11942.7275	loss_val: 11942.8672	loss_test: 11943.3633	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4807.3901	loss_val: 4807.3555	loss_test: 4807.6294	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5585.4512	loss_val: 5585.8599	loss_test: 5586.2935	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4688.6475	loss_val: 4688.6660	loss_test: 4688.6572	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7910.6899	loss_val: 7911.8306	loss_test: 7911.2583	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67483.8281	loss_val: 67483.7734	loss_test: 67484.2188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8326.5156	loss_val: 8326.7871	loss_test: 8326.9834	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 62	curr_val_accuracy: 0.8298	curr_test_accuracy: 0.7955
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6270.1724	loss_val: 6271.0718	loss_test: 6270.7515	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15545.7979	loss_val: 15545.9531	loss_test: 15547.0439	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 66378.9375	loss_val: 66379.1172	loss_test: 66380.0938	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 46172.1250	loss_val: 46172.1211	loss_test: 46172.4102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6798.8330	loss_val: 6800.3359	loss_test: 6799.3252	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4782.9746	loss_val: 4782.9990	loss_test: 4782.9795	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9020.1357	loss_val: 9020.1562	loss_test: 9020.5117	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5362.6074	loss_val: 5363.1748	loss_test: 5363.2686	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10475.8525	loss_val: 10477.5947	loss_test: 10476.3145	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11628.9512	loss_val: 11628.9688	loss_test: 11628.9326	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6249.4019	loss_val: 6249.4316	loss_test: 6249.4263	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5433.3486	loss_val: 5434.0791	loss_test: 5435.0640	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5282.1401	loss_val: 5282.7725	loss_test: 5283.4683	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 11970.2920	loss_val: 11970.4385	loss_test: 11970.9355	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4815.3594	loss_val: 4815.3252	loss_test: 4815.5972	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5616.4688	loss_val: 5616.8691	loss_test: 5617.3237	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4705.3271	loss_val: 4705.3477	loss_test: 4705.3384	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7908.3979	loss_val: 7909.5552	loss_test: 7908.9746	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67458.7266	loss_val: 67458.6719	loss_test: 67459.1172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8343.5898	loss_val: 8343.8281	loss_test: 8344.0566	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 63	curr_val_accuracy: 0.8304	curr_test_accuracy: 0.8036
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6292.1313	loss_val: 6293.0845	loss_test: 6292.7617	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15373.5723	loss_val: 15373.7412	loss_test: 15374.7686	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 66155.2891	loss_val: 66155.4453	loss_test: 66156.4297	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 46526.6719	loss_val: 46526.6680	loss_test: 46526.9570	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6740.1367	loss_val: 6741.6807	loss_test: 6740.6318	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4792.7363	loss_val: 4792.7598	loss_test: 4792.7412	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9090.0332	loss_val: 9090.0527	loss_test: 9090.4150	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5367.2119	loss_val: 5367.7803	loss_test: 5367.8745	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7143
[client 8]	loss_train: 10539.6045	loss_val: 10541.3818	loss_test: 10540.0723	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11642.9014	loss_val: 11642.9189	loss_test: 11642.8828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6228.4678	loss_val: 6228.4976	loss_test: 6228.4932	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5446.0859	loss_val: 5446.8433	loss_test: 5447.8237	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5285.4629	loss_val: 5286.0981	loss_test: 5286.8081	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 11979.7227	loss_val: 11979.8750	loss_test: 11980.3721	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4814.1372	loss_val: 4814.1035	loss_test: 4814.3716	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5621.1372	loss_val: 5621.5342	loss_test: 5622.0083	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4721.9092	loss_val: 4721.9331	loss_test: 4721.9229	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7915.5190	loss_val: 7916.6909	loss_test: 7916.0991	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67609.0391	loss_val: 67608.9844	loss_test: 67609.4219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8294.0703	loss_val: 8294.3271	loss_test: 8294.5547	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 64	curr_val_accuracy: 0.8217	curr_test_accuracy: 0.8036
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6307.4971	loss_val: 6308.5239	loss_test: 6308.1870	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 15350.9863	loss_val: 15351.1592	loss_test: 15352.1592	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 66807.8359	loss_val: 66808.0000	loss_test: 66808.9531	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 47556.3750	loss_val: 47556.3750	loss_test: 47556.6680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6678.6533	loss_val: 6680.2031	loss_test: 6679.1650	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4797.5469	loss_val: 4797.5693	loss_test: 4797.5522	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9138.7881	loss_val: 9138.8096	loss_test: 9139.1758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5361.9653	loss_val: 5362.5337	loss_test: 5362.6362	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10594.6641	loss_val: 10596.4688	loss_test: 10595.1377	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11636.8701	loss_val: 11636.8867	loss_test: 11636.8516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6232.8057	loss_val: 6232.8364	loss_test: 6232.8315	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5465.4956	loss_val: 5466.2876	loss_test: 5467.2554	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5279.2954	loss_val: 5279.9375	loss_test: 5280.6436	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12024.0322	loss_val: 12024.1914	loss_test: 12024.6934	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4818.8506	loss_val: 4818.8174	loss_test: 4819.0801	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5628.0874	loss_val: 5628.4800	loss_test: 5628.9741	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 16]	loss_train: 4736.4580	loss_val: 4736.4844	loss_test: 4736.4727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7928.2271	loss_val: 7929.3984	loss_test: 7928.8062	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67778.7891	loss_val: 67778.7344	loss_test: 67779.1641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8151.5493	loss_val: 8151.9043	loss_test: 8152.0742	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 65	curr_val_accuracy: 0.8050	curr_test_accuracy: 0.7889
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6320.2153	loss_val: 6321.2612	loss_test: 6320.9126	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 15373.3438	loss_val: 15373.5137	loss_test: 15374.5020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67622.8906	loss_val: 67623.0781	loss_test: 67624.0156	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 48454.3203	loss_val: 48454.3203	loss_test: 48454.6133	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6662.1816	loss_val: 6663.7397	loss_test: 6662.7090	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4797.1484	loss_val: 4797.1694	loss_test: 4797.1538	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9196.2695	loss_val: 9196.2920	loss_test: 9196.6631	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5373.3340	loss_val: 5373.8989	loss_test: 5374.0078	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10661.1465	loss_val: 10662.9707	loss_test: 10661.6162	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11707.1729	loss_val: 11707.1885	loss_test: 11707.1553	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6228.0322	loss_val: 6228.0635	loss_test: 6228.0586	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5475.8369	loss_val: 5476.6641	loss_test: 5477.6206	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5270.7373	loss_val: 5271.3848	loss_test: 5272.1011	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12061.2012	loss_val: 12061.3604	loss_test: 12061.8779	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4822.7969	loss_val: 4822.7646	loss_test: 4823.0210	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5643.0117	loss_val: 5643.3970	loss_test: 5643.9087	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4755.6294	loss_val: 4755.6577	loss_test: 4755.6450	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7929.8896	loss_val: 7931.0659	loss_test: 7930.4878	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67610.5469	loss_val: 67610.4922	loss_test: 67610.9141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8029.0166	loss_val: 8029.5176	loss_test: 8029.5879	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 66	curr_val_accuracy: 0.8050	curr_test_accuracy: 0.7688
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6324.5376	loss_val: 6325.5894	loss_test: 6325.2231	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 15403.1338	loss_val: 15403.3125	loss_test: 15404.2568	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 67581.0312	loss_val: 67581.2344	loss_test: 67582.1641	accuracy_train: 0.9429	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 49238.8672	loss_val: 49238.8672	loss_test: 49239.1602	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6643.9087	loss_val: 6645.4878	loss_test: 6644.4453	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4809.6611	loss_val: 4809.6807	loss_test: 4809.6670	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9257.6279	loss_val: 9257.6514	loss_test: 9258.0293	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5392.2588	loss_val: 5392.8184	loss_test: 5392.9307	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10733.1416	loss_val: 10734.9736	loss_test: 10733.6035	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11744.3779	loss_val: 11744.3945	loss_test: 11744.3613	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6225.7549	loss_val: 6225.7866	loss_test: 6225.7817	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5477.7739	loss_val: 5478.6255	loss_test: 5479.5581	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5280.6968	loss_val: 5281.3447	loss_test: 5282.0938	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12096.4980	loss_val: 12096.6572	loss_test: 12097.1865	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4840.0513	loss_val: 4840.0190	loss_test: 4840.2686	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5641.0786	loss_val: 5641.4580	loss_test: 5641.9839	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4776.6660	loss_val: 4776.6958	loss_test: 4776.6821	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7918.0405	loss_val: 7919.2314	loss_test: 7918.6660	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67416.7891	loss_val: 67416.7344	loss_test: 67417.1406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7973.0405	loss_val: 7973.6489	loss_test: 7973.6436	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 67	curr_val_accuracy: 0.8050	curr_test_accuracy: 0.7688
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6325.0322	loss_val: 6326.0601	loss_test: 6325.6777	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15380.4570	loss_val: 15380.6357	loss_test: 15381.5469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 66766.5469	loss_val: 66766.7656	loss_test: 66767.7188	accuracy_train: 0.9429	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 50045.6523	loss_val: 50045.6523	loss_test: 50045.9414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6640.8921	loss_val: 6642.5269	loss_test: 6641.4282	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4832.8599	loss_val: 4832.8784	loss_test: 4832.8662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9306.9502	loss_val: 9306.9746	loss_test: 9307.3564	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5420.1875	loss_val: 5420.7441	loss_test: 5420.8574	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10845.7041	loss_val: 10847.5166	loss_test: 10846.1436	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11792.4414	loss_val: 11792.4590	loss_test: 11792.4258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6212.8604	loss_val: 6212.8926	loss_test: 6212.8882	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5478.0503	loss_val: 5478.9214	loss_test: 5479.8428	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5289.2012	loss_val: 5289.8516	loss_test: 5290.6177	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12153.9707	loss_val: 12154.1299	loss_test: 12154.6719	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4854.4961	loss_val: 4854.4639	loss_test: 4854.7134	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5641.4175	loss_val: 5641.7974	loss_test: 5642.3413	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4794.8320	loss_val: 4794.8623	loss_test: 4794.8486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7924.2466	loss_val: 7925.4429	loss_test: 7924.9111	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67349.4609	loss_val: 67349.4062	loss_test: 67349.8047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7968.3540	loss_val: 7969.0269	loss_test: 7968.9800	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 68	curr_val_accuracy: 0.8130	curr_test_accuracy: 0.7769
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6321.6675	loss_val: 6322.6704	loss_test: 6322.2793	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15481.2793	loss_val: 15481.4463	loss_test: 15482.3750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 66740.6875	loss_val: 66741.0078	loss_test: 66741.9688	accuracy_train: 0.9429	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 50517.9961	loss_val: 50517.9961	loss_test: 50518.2812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6595.6206	loss_val: 6597.2969	loss_test: 6596.1641	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4847.7651	loss_val: 4847.7827	loss_test: 4847.7715	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9316.9404	loss_val: 9316.9658	loss_test: 9317.3525	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5468.0913	loss_val: 5468.6460	loss_test: 5468.7603	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10904.4648	loss_val: 10906.2549	loss_test: 10904.8965	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11843.7881	loss_val: 11843.8066	loss_test: 11843.7744	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6202.6333	loss_val: 6202.6660	loss_test: 6202.6621	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5436.9941	loss_val: 5437.8755	loss_test: 5438.7705	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5285.1353	loss_val: 5285.7896	loss_test: 5286.5659	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12218.0996	loss_val: 12218.2549	loss_test: 12218.8115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4854.8428	loss_val: 4854.8105	loss_test: 4855.0576	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5646.5791	loss_val: 5646.9648	loss_test: 5647.5259	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4802.4487	loss_val: 4802.4795	loss_test: 4802.4653	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7937.1157	loss_val: 7938.3115	loss_test: 7937.8076	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67251.8281	loss_val: 67251.7734	loss_test: 67252.1641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7989.3569	loss_val: 7990.0967	loss_test: 7990.0034	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 69	curr_val_accuracy: 0.8130	curr_test_accuracy: 0.7769
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6323.6479	loss_val: 6324.6084	loss_test: 6324.2227	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 15570.2529	loss_val: 15570.4111	loss_test: 15571.3486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 66372.8750	loss_val: 66373.2812	loss_test: 66374.2578	accuracy_train: 0.9714	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 51055.4922	loss_val: 51055.4922	loss_test: 51055.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6561.6509	loss_val: 6563.3569	loss_test: 6562.2051	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4878.4507	loss_val: 4878.4668	loss_test: 4878.4570	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9336.6582	loss_val: 9336.6826	loss_test: 9337.0781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5486.2075	loss_val: 5486.7607	loss_test: 5486.8789	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10946.9229	loss_val: 10948.6885	loss_test: 10947.3564	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11925.5928	loss_val: 11925.6113	loss_test: 11925.5801	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6201.1660	loss_val: 6201.1982	loss_test: 6201.1963	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5430.0259	loss_val: 5430.9170	loss_test: 5431.7944	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5293.0015	loss_val: 5293.6606	loss_test: 5294.4312	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12281.0361	loss_val: 12281.1924	loss_test: 12281.7568	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4896.1968	loss_val: 4896.1650	loss_test: 4896.4087	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5666.0439	loss_val: 5666.4292	loss_test: 5667.0068	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4818.9404	loss_val: 4818.9717	loss_test: 4818.9580	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7959.3823	loss_val: 7960.5835	loss_test: 7960.1045	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67288.3359	loss_val: 67288.2891	loss_test: 67288.6719	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7983.6147	loss_val: 7984.2759	loss_test: 7984.2466	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 70	curr_val_accuracy: 0.8130	curr_test_accuracy: 0.7769
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6306.1450	loss_val: 6307.0938	loss_test: 6306.7100	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 15581.8662	loss_val: 15582.0215	loss_test: 15582.9463	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 65584.8125	loss_val: 65585.2500	loss_test: 65586.2344	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 51196.2266	loss_val: 51196.2266	loss_test: 51196.5078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6492.2700	loss_val: 6494.0132	loss_test: 6492.8330	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4915.2041	loss_val: 4915.2202	loss_test: 4915.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9360.7422	loss_val: 9360.7676	loss_test: 9361.1689	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5496.6714	loss_val: 5497.2256	loss_test: 5497.3428	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10982.1211	loss_val: 10983.8477	loss_test: 10982.5547	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11992.1338	loss_val: 11992.1543	loss_test: 11992.1221	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6199.0034	loss_val: 6199.0356	loss_test: 6199.0352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5376.3042	loss_val: 5377.2007	loss_test: 5378.0435	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5293.6348	loss_val: 5294.3037	loss_test: 5295.0591	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12317.2295	loss_val: 12317.3828	loss_test: 12317.9590	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4916.6646	loss_val: 4916.6338	loss_test: 4916.8774	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5668.1226	loss_val: 5668.5073	loss_test: 5669.1006	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4828.7114	loss_val: 4828.7427	loss_test: 4828.7290	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7993.0752	loss_val: 7994.2788	loss_test: 7993.8154	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67401.3984	loss_val: 67401.3516	loss_test: 67401.7266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7996.4092	loss_val: 7996.9756	loss_test: 7997.0225	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 71	curr_val_accuracy: 0.8130	curr_test_accuracy: 0.7688
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6291.5483	loss_val: 6292.4946	loss_test: 6292.1123	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 15585.2510	loss_val: 15585.4053	loss_test: 15586.3145	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 64572.7148	loss_val: 64573.1172	loss_test: 64574.1055	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 51422.4727	loss_val: 51422.4688	loss_test: 51422.7500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6427.2749	loss_val: 6429.0757	loss_test: 6427.8521	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4955.4951	loss_val: 4955.5103	loss_test: 4955.5024	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9392.3877	loss_val: 9392.4121	loss_test: 9392.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5524.7754	loss_val: 5525.3306	loss_test: 5525.4468	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11108.2676	loss_val: 11109.9600	loss_test: 11108.6943	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12026.7666	loss_val: 12026.7881	loss_test: 12026.7549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6231.4575	loss_val: 6231.4893	loss_test: 6231.4902	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5336.2065	loss_val: 5337.1055	loss_test: 5337.9146	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5298.0210	loss_val: 5298.7051	loss_test: 5299.4272	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12348.5781	loss_val: 12348.7256	loss_test: 12349.3193	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4942.8979	loss_val: 4942.8677	loss_test: 4943.1138	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5667.9219	loss_val: 5668.3159	loss_test: 5668.9214	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4835.6279	loss_val: 4835.6587	loss_test: 4835.6455	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8005.3726	loss_val: 8006.5747	loss_test: 8006.1221	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67422.0312	loss_val: 67421.9844	loss_test: 67422.3516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8067.8267	loss_val: 8068.2529	loss_test: 8068.4097	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 72	curr_val_accuracy: 0.8211	curr_test_accuracy: 0.7765
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6269.8330	loss_val: 6270.7832	loss_test: 6270.3940	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 15557.2344	loss_val: 15557.3936	loss_test: 15558.2822	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 63934.5195	loss_val: 63934.8438	loss_test: 63935.8750	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 51594.2891	loss_val: 51594.2891	loss_test: 51594.5664	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6355.8218	loss_val: 6357.6929	loss_test: 6356.4258	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4994.3770	loss_val: 4994.3921	loss_test: 4994.3853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9413.5361	loss_val: 9413.5615	loss_test: 9413.9727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5519.3867	loss_val: 5519.9429	loss_test: 5520.0605	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11239.0713	loss_val: 11240.7178	loss_test: 11239.4951	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12059.7324	loss_val: 12059.7549	loss_test: 12059.7207	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6246.5044	loss_val: 6246.5356	loss_test: 6246.5386	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5274.0352	loss_val: 5274.9434	loss_test: 5275.7124	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 5315.5977	loss_val: 5316.2964	loss_test: 5316.9912	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12334.3057	loss_val: 12334.4473	loss_test: 12335.0566	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4977.4795	loss_val: 4977.4492	loss_test: 4977.6982	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5677.6782	loss_val: 5678.0864	loss_test: 5678.6948	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4842.8857	loss_val: 4842.9165	loss_test: 4842.9033	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8033.2417	loss_val: 8034.4380	loss_test: 8033.9819	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67340.6875	loss_val: 67340.6406	loss_test: 67341.0078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8223.4990	loss_val: 8223.7705	loss_test: 8224.0410	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 73	curr_val_accuracy: 0.8211	curr_test_accuracy: 0.7680
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6264.3516	loss_val: 6265.2979	loss_test: 6264.9082	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 1]	loss_train: 15480.2383	loss_val: 15480.4102	loss_test: 15481.2588	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 63781.9375	loss_val: 63782.1875	loss_test: 63783.3086	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 51910.0430	loss_val: 51910.0430	loss_test: 51910.3164	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6316.6763	loss_val: 6318.6255	loss_test: 6317.3022	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5028.0293	loss_val: 5028.0439	loss_test: 5028.0381	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9435.8154	loss_val: 9435.8389	loss_test: 9436.2568	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5509.9248	loss_val: 5510.4800	loss_test: 5510.6157	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11400.5791	loss_val: 11402.1963	loss_test: 11400.9883	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12029.1553	loss_val: 12029.1797	loss_test: 12029.1455	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6275.4634	loss_val: 6275.4951	loss_test: 6275.4980	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5228.6899	loss_val: 5229.6108	loss_test: 5230.3350	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5331.3999	loss_val: 5332.1079	loss_test: 5332.7896	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12300.8467	loss_val: 12300.9795	loss_test: 12301.6084	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5019.9370	loss_val: 5019.9072	loss_test: 5020.1587	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5676.5923	loss_val: 5677.0088	loss_test: 5677.6245	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4845.5522	loss_val: 4845.5830	loss_test: 4845.5693	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8054.1929	loss_val: 8055.3950	loss_test: 8054.9204	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67407.9297	loss_val: 67407.8828	loss_test: 67408.2422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8419.8145	loss_val: 8419.9893	loss_test: 8420.3193	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 74	curr_val_accuracy: 0.8376	curr_test_accuracy: 0.7680
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6251.6055	loss_val: 6252.5479	loss_test: 6252.1592	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 1]	loss_train: 15423.6035	loss_val: 15423.7881	loss_test: 15424.5977	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 64012.4141	loss_val: 64012.6016	loss_test: 64013.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 52040.7656	loss_val: 52040.7656	loss_test: 52041.0391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6262.6421	loss_val: 6264.6567	loss_test: 6263.2925	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5047.1411	loss_val: 5047.1553	loss_test: 5047.1499	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9451.5820	loss_val: 9451.6045	loss_test: 9452.0312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5498.1226	loss_val: 5498.6782	loss_test: 5498.8320	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11624.7568	loss_val: 11626.3574	loss_test: 11625.1484	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12003.7842	loss_val: 12003.8105	loss_test: 12003.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6301.2705	loss_val: 6301.3013	loss_test: 6301.3062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5151.1943	loss_val: 5152.1377	loss_test: 5152.7832	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 5343.7881	loss_val: 5344.4995	loss_test: 5345.1680	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12310.0332	loss_val: 12310.1553	loss_test: 12310.8076	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5052.7803	loss_val: 5052.7515	loss_test: 5053.0083	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5673.6455	loss_val: 5674.0747	loss_test: 5674.6924	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4843.6528	loss_val: 4843.6836	loss_test: 4843.6704	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8090.9731	loss_val: 8092.1724	loss_test: 8091.6733	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67497.1016	loss_val: 67497.0625	loss_test: 67497.4219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8621.4131	loss_val: 8621.5283	loss_test: 8621.8867	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 75	curr_val_accuracy: 0.8369	curr_test_accuracy: 0.7680
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6244.1987	loss_val: 6245.1289	loss_test: 6244.7388	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 15350.8408	loss_val: 15351.0488	loss_test: 15351.8135	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 64409.7188	loss_val: 64409.8672	loss_test: 64411.1602	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 52025.2031	loss_val: 52025.2031	loss_test: 52025.4727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6247.7671	loss_val: 6249.8413	loss_test: 6248.4326	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5070.7573	loss_val: 5070.7715	loss_test: 5070.7661	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9488.1826	loss_val: 9488.2041	loss_test: 9488.6309	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5459.7349	loss_val: 5460.2905	loss_test: 5460.4727	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11822.4658	loss_val: 11824.0469	loss_test: 11822.8457	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11977.8008	loss_val: 11977.8291	loss_test: 11977.7910	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6329.6519	loss_val: 6329.6826	loss_test: 6329.6880	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5099.6108	loss_val: 5100.5947	loss_test: 5101.1543	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 12]	loss_train: 5349.3589	loss_val: 5350.0752	loss_test: 5350.7319	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12202.3115	loss_val: 12202.4219	loss_test: 12203.0986	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5072.0967	loss_val: 5072.0684	loss_test: 5072.3296	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5666.8940	loss_val: 5667.3345	loss_test: 5667.9624	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4847.7856	loss_val: 4847.8159	loss_test: 4847.8027	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8123.8604	loss_val: 8125.0654	loss_test: 8124.5312	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67376.2500	loss_val: 67376.2109	loss_test: 67376.5625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8804.5859	loss_val: 8804.6660	loss_test: 8805.0322	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 76	curr_val_accuracy: 0.8372	curr_test_accuracy: 0.7827
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6243.9204	loss_val: 6244.8516	loss_test: 6244.4556	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15339.4434	loss_val: 15339.6680	loss_test: 15340.4111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 64467.9453	loss_val: 64468.0742	loss_test: 64469.3984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 52277.7031	loss_val: 52277.7031	loss_test: 52277.9688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6258.0884	loss_val: 6260.1890	loss_test: 6258.7563	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5096.7476	loss_val: 5096.7622	loss_test: 5096.7563	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9501.5342	loss_val: 9501.5547	loss_test: 9501.9854	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5440.5532	loss_val: 5441.1128	loss_test: 5441.3120	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11970.2744	loss_val: 11971.8486	loss_test: 11970.6426	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12001.6016	loss_val: 12001.6318	loss_test: 12001.5908	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6348.9565	loss_val: 6348.9883	loss_test: 6348.9932	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5085.6279	loss_val: 5086.6416	loss_test: 5087.1548	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 12]	loss_train: 5348.3555	loss_val: 5349.0776	loss_test: 5349.7173	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12129.5986	loss_val: 12129.6982	loss_test: 12130.3994	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5099.5078	loss_val: 5099.4795	loss_test: 5099.7461	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5657.1221	loss_val: 5657.5737	loss_test: 5658.2036	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4852.7251	loss_val: 4852.7554	loss_test: 4852.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8170.7422	loss_val: 8171.9482	loss_test: 8171.3877	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67196.3828	loss_val: 67196.3438	loss_test: 67196.6953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8898.1016	loss_val: 8898.1660	loss_test: 8898.5322	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 77	curr_val_accuracy: 0.8291	curr_test_accuracy: 0.7827
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6266.0317	loss_val: 6266.9844	loss_test: 6266.5620	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15279.7002	loss_val: 15279.9355	loss_test: 15280.6602	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.3333
[client 2]	loss_train: 64252.8125	loss_val: 64252.9336	loss_test: 64254.2695	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 52244.8672	loss_val: 52244.8711	loss_test: 52245.1328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6261.1948	loss_val: 6263.3008	loss_test: 6261.8657	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5108.6094	loss_val: 5108.6240	loss_test: 5108.6182	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9500.7422	loss_val: 9500.7617	loss_test: 9501.1992	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5441.1069	loss_val: 5441.6709	loss_test: 5441.8813	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11967.2949	loss_val: 11968.8828	loss_test: 11967.6641	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11981.2451	loss_val: 11981.2773	loss_test: 11981.2344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6365.0288	loss_val: 6365.0601	loss_test: 6365.0645	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5071.3872	loss_val: 5072.4561	loss_test: 5072.8965	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5353.9565	loss_val: 5354.6797	loss_test: 5355.3271	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12056.9375	loss_val: 12057.0254	loss_test: 12057.7490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5111.1724	loss_val: 5111.1450	loss_test: 5111.4106	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5639.1470	loss_val: 5639.6104	loss_test: 5640.2446	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4852.7261	loss_val: 4852.7563	loss_test: 4852.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8191.6562	loss_val: 8192.8682	loss_test: 8192.2734	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67245.8125	loss_val: 67245.7734	loss_test: 67246.1250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8861.0371	loss_val: 8861.0977	loss_test: 8861.4697	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 78	curr_val_accuracy: 0.8291	curr_test_accuracy: 0.7989
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6295.9009	loss_val: 6296.8921	loss_test: 6296.4268	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15228.8623	loss_val: 15229.1133	loss_test: 15229.8086	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 63647.3750	loss_val: 63647.4961	loss_test: 63648.8203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 52184.7539	loss_val: 52184.7578	loss_test: 52185.0195	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6270.9873	loss_val: 6273.0752	loss_test: 6271.6465	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5108.7183	loss_val: 5108.7334	loss_test: 5108.7266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9499.8154	loss_val: 9499.8350	loss_test: 9500.2764	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5431.6392	loss_val: 5432.2065	loss_test: 5432.4365	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11979.5752	loss_val: 11981.1768	loss_test: 11979.9424	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11986.8135	loss_val: 11986.8457	loss_test: 11986.8018	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6370.8813	loss_val: 6370.9131	loss_test: 6370.9155	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5080.1309	loss_val: 5081.2261	loss_test: 5081.6382	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5356.2520	loss_val: 5356.9858	loss_test: 5357.6060	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12033.0498	loss_val: 12033.1289	loss_test: 12033.8750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5123.5674	loss_val: 5123.5410	loss_test: 5123.8101	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5625.7646	loss_val: 5626.2427	loss_test: 5626.8774	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4848.8862	loss_val: 4848.9155	loss_test: 4848.9023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8202.6963	loss_val: 8203.9199	loss_test: 8203.3018	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 67186.3984	loss_val: 67186.3594	loss_test: 67186.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8799.5166	loss_val: 8799.5781	loss_test: 8799.9551	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 79	curr_val_accuracy: 0.8377	curr_test_accuracy: 0.7967
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6251.0786	loss_val: 6252.0762	loss_test: 6251.6006	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15185.7939	loss_val: 15186.0674	loss_test: 15186.7275	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 62327.6250	loss_val: 62327.7695	loss_test: 62329.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 52073.3438	loss_val: 52073.3477	loss_test: 52073.6094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6307.0513	loss_val: 6309.1006	loss_test: 6307.6802	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5087.7817	loss_val: 5087.7974	loss_test: 5087.7896	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9499.1162	loss_val: 9499.1348	loss_test: 9499.5811	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5418.2695	loss_val: 5418.8447	loss_test: 5419.0898	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11995.9248	loss_val: 11997.5332	loss_test: 11996.2871	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11962.2832	loss_val: 11962.3154	loss_test: 11962.2725	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6369.4424	loss_val: 6369.4741	loss_test: 6369.4736	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5078.1353	loss_val: 5079.2495	loss_test: 5079.6519	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5355.3989	loss_val: 5356.1455	loss_test: 5356.7251	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12050.6758	loss_val: 12050.7500	loss_test: 12051.5098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5116.3823	loss_val: 5116.3569	loss_test: 5116.6294	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5597.5513	loss_val: 5598.0415	loss_test: 5598.6753	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4834.4214	loss_val: 4834.4502	loss_test: 4834.4370	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8198.5547	loss_val: 8199.7910	loss_test: 8199.1475	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 66887.9766	loss_val: 66887.9375	loss_test: 66888.2969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8640.4170	loss_val: 8640.4854	loss_test: 8640.8730	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 80	curr_val_accuracy: 0.8377	curr_test_accuracy: 0.7967
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6179.8320	loss_val: 6180.8271	loss_test: 6180.3423	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15108.0459	loss_val: 15108.3535	loss_test: 15108.9668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 61741.4688	loss_val: 61741.6797	loss_test: 61742.8398	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 51930.5430	loss_val: 51930.5508	loss_test: 51930.8164	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6401.8945	loss_val: 6403.9014	loss_test: 6402.4849	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5073.5947	loss_val: 5073.6108	loss_test: 5073.6025	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9517.9424	loss_val: 9517.9600	loss_test: 9518.4111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5407.8887	loss_val: 5408.4697	loss_test: 5408.7314	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11872.6162	loss_val: 11874.2402	loss_test: 11873.0020	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11907.6699	loss_val: 11907.7021	loss_test: 11907.6592	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6366.3794	loss_val: 6366.4106	loss_test: 6366.4072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5083.7241	loss_val: 5084.8257	loss_test: 5085.2505	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5344.5835	loss_val: 5345.3335	loss_test: 5345.9067	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12077.6328	loss_val: 12077.7012	loss_test: 12078.4717	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5105.1523	loss_val: 5105.1274	loss_test: 5105.4009	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5575.3916	loss_val: 5575.8911	loss_test: 5576.5220	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4820.7661	loss_val: 4820.7949	loss_test: 4820.7817	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8206.9805	loss_val: 8208.2266	loss_test: 8207.5625	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 66677.1562	loss_val: 66677.1172	loss_test: 66677.4766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8431.7441	loss_val: 8431.8242	loss_test: 8432.2188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 81	curr_val_accuracy: 0.8301	curr_test_accuracy: 0.7902
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6113.9985	loss_val: 6115.0049	loss_test: 6114.5034	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15112.2764	loss_val: 15112.5986	loss_test: 15113.1973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 61692.7109	loss_val: 61693.0000	loss_test: 61694.0703	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 51954.7773	loss_val: 51954.7812	loss_test: 51955.0469	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6512.5728	loss_val: 6514.5571	loss_test: 6513.1387	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5049.4492	loss_val: 5049.4663	loss_test: 5049.4565	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9525.2236	loss_val: 9525.2422	loss_test: 9525.6924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5395.0122	loss_val: 5395.6001	loss_test: 5395.8779	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11763.9092	loss_val: 11765.5449	loss_test: 11764.3154	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11876.1572	loss_val: 11876.1885	loss_test: 11876.1465	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6366.6924	loss_val: 6366.7231	loss_test: 6366.7178	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5099.9727	loss_val: 5101.0518	loss_test: 5101.5103	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5340.9814	loss_val: 5341.7324	loss_test: 5342.3066	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12112.3125	loss_val: 12112.3818	loss_test: 12113.1582	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5080.4536	loss_val: 5080.4292	loss_test: 5080.7134	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5554.8247	loss_val: 5555.3398	loss_test: 5555.9668	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4813.9067	loss_val: 4813.9355	loss_test: 4813.9219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8219.3428	loss_val: 8220.6113	loss_test: 8219.9219	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 66283.6797	loss_val: 66283.6406	loss_test: 66284.0078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8209.3096	loss_val: 8209.4102	loss_test: 8209.8125	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 82	curr_val_accuracy: 0.8214	curr_test_accuracy: 0.7902
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6066.7227	loss_val: 6067.7437	loss_test: 6067.2207	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15054.7363	loss_val: 15055.0693	loss_test: 15055.6553	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 61864.8320	loss_val: 61865.1992	loss_test: 61866.2031	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 51965.4492	loss_val: 51965.4570	loss_test: 51965.7227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6635.4053	loss_val: 6637.3804	loss_test: 6635.9570	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5020.7036	loss_val: 5020.7207	loss_test: 5020.7104	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9533.7549	loss_val: 9533.7734	loss_test: 9534.2236	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5384.3149	loss_val: 5384.9106	loss_test: 5385.2021	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11682.3428	loss_val: 11684.0059	loss_test: 11682.7646	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11850.0117	loss_val: 11850.0410	loss_test: 11850.0000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6369.1040	loss_val: 6369.1333	loss_test: 6369.1270	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5120.2896	loss_val: 5121.3345	loss_test: 5121.8389	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5329.9600	loss_val: 5330.7134	loss_test: 5331.2832	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12177.8857	loss_val: 12177.9551	loss_test: 12178.7344	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5054.0142	loss_val: 5053.9902	loss_test: 5054.2925	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5521.3179	loss_val: 5521.8408	loss_test: 5522.4727	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4795.0679	loss_val: 4795.0967	loss_test: 4795.0830	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8228.3857	loss_val: 8229.6748	loss_test: 8228.9707	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65957.5469	loss_val: 65957.5078	loss_test: 65957.8750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7882.8555	loss_val: 7883.0244	loss_test: 7883.4097	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 83	curr_val_accuracy: 0.8214	curr_test_accuracy: 0.7825
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6006.6660	loss_val: 6007.6938	loss_test: 6007.1641	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 15010.9746	loss_val: 15011.3135	loss_test: 15011.8945	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 62169.3125	loss_val: 62169.7422	loss_test: 62170.6992	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 51789.8008	loss_val: 51789.8047	loss_test: 51790.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6740.3306	loss_val: 6742.3125	loss_test: 6740.8706	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4993.0181	loss_val: 4993.0352	loss_test: 4993.0239	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9553.6914	loss_val: 9553.7109	loss_test: 9554.1572	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5386.2539	loss_val: 5386.8525	loss_test: 5387.1538	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11619.3574	loss_val: 11621.0293	loss_test: 11619.7930	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11833.7891	loss_val: 11833.8184	loss_test: 11833.7773	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6372.4478	loss_val: 6372.4766	loss_test: 6372.4692	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5162.6045	loss_val: 5163.6045	loss_test: 5164.1738	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 5325.6670	loss_val: 5326.4233	loss_test: 5326.9854	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12241.9873	loss_val: 12242.0537	loss_test: 12242.8457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5045.7461	loss_val: 5045.7227	loss_test: 5046.0327	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5499.4282	loss_val: 5499.9580	loss_test: 5500.5938	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4784.2876	loss_val: 4784.3164	loss_test: 4784.3022	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8258.2324	loss_val: 8259.5293	loss_test: 8258.8203	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65976.1562	loss_val: 65976.1250	loss_test: 65976.4922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7674.3296	loss_val: 7674.5649	loss_test: 7674.9199	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 84	curr_val_accuracy: 0.8298	curr_test_accuracy: 0.7741
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5931.6821	loss_val: 5932.7056	loss_test: 5932.1782	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 14973.5654	loss_val: 14973.9238	loss_test: 14974.4844	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 62269.2383	loss_val: 62269.6953	loss_test: 62270.6328	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 51601.1094	loss_val: 51601.1133	loss_test: 51601.3789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6822.0000	loss_val: 6823.9995	loss_test: 6822.5332	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4980.6782	loss_val: 4980.6958	loss_test: 4980.6836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9556.3965	loss_val: 9556.4160	loss_test: 9556.8662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5390.0518	loss_val: 5390.6499	loss_test: 5390.9600	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11521.8770	loss_val: 11523.5664	loss_test: 11522.3320	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11773.8613	loss_val: 11773.8906	loss_test: 11773.8496	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6360.3457	loss_val: 6360.3735	loss_test: 6360.3662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5191.0410	loss_val: 5192.0093	loss_test: 5192.6313	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5321.9766	loss_val: 5322.7402	loss_test: 5323.2827	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12316.1699	loss_val: 12316.2354	loss_test: 12317.0371	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5026.5996	loss_val: 5026.5762	loss_test: 5026.8950	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5468.1396	loss_val: 5468.6758	loss_test: 5469.3188	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4771.5303	loss_val: 4771.5586	loss_test: 4771.5449	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8270.7793	loss_val: 8272.0879	loss_test: 8271.3652	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65955.2812	loss_val: 65955.2500	loss_test: 65955.6172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7500.3779	loss_val: 7500.7051	loss_test: 7501.0020	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 85	curr_val_accuracy: 0.8297	curr_test_accuracy: 0.7741
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5864.1577	loss_val: 5865.1792	loss_test: 5864.6689	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14951.2393	loss_val: 14951.6152	loss_test: 14952.1660	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 62054.9570	loss_val: 62055.4219	loss_test: 62056.3398	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 51336.6406	loss_val: 51336.6445	loss_test: 51336.9141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6814.8452	loss_val: 6816.8862	loss_test: 6815.3853	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 4962.7676	loss_val: 4962.7856	loss_test: 4962.7725	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9571.0303	loss_val: 9571.0498	loss_test: 9571.5000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5395.4878	loss_val: 5396.0820	loss_test: 5396.4014	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11440.1387	loss_val: 11441.8350	loss_test: 11440.5957	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11769.5312	loss_val: 11769.5605	loss_test: 11769.5195	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6354.2207	loss_val: 6354.2476	loss_test: 6354.2397	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5183.7607	loss_val: 5184.7041	loss_test: 5185.3740	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5324.1621	loss_val: 5324.9365	loss_test: 5325.4551	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12380.5557	loss_val: 12380.6221	loss_test: 12381.4248	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5009.6929	loss_val: 5009.6699	loss_test: 5009.9824	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5442.1421	loss_val: 5442.6821	loss_test: 5443.3306	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4758.9448	loss_val: 4758.9736	loss_test: 4758.9600	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8243.6455	loss_val: 8245.0078	loss_test: 8244.2510	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65806.5234	loss_val: 65806.4922	loss_test: 65806.8516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7372.4331	loss_val: 7372.8730	loss_test: 7373.0918	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 86	curr_val_accuracy: 0.8297	curr_test_accuracy: 0.7822
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5809.0518	loss_val: 5810.0649	loss_test: 5809.5957	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 14952.0938	loss_val: 14952.4775	loss_test: 14953.0342	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 61639.7969	loss_val: 61640.2500	loss_test: 61641.1523	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 51611.0664	loss_val: 51611.0703	loss_test: 51611.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6684.5767	loss_val: 6686.6626	loss_test: 6685.1401	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4952.1572	loss_val: 4952.1763	loss_test: 4952.1626	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9585.3291	loss_val: 9585.3486	loss_test: 9585.7969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5404.6709	loss_val: 5405.2627	loss_test: 5405.5879	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11419.8086	loss_val: 11421.5098	loss_test: 11420.2539	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11742.4863	loss_val: 11742.5156	loss_test: 11742.4746	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6348.8936	loss_val: 6348.9199	loss_test: 6348.9126	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5158.9189	loss_val: 5159.8433	loss_test: 5160.5444	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5319.3408	loss_val: 5320.1313	loss_test: 5320.6079	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12466.7754	loss_val: 12466.8408	loss_test: 12467.6514	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4982.4146	loss_val: 4982.3921	loss_test: 4982.7012	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5428.2783	loss_val: 5428.8223	loss_test: 5429.4780	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4752.7969	loss_val: 4752.8252	loss_test: 4752.8115	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8203.0928	loss_val: 8204.5049	loss_test: 8203.7207	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65666.8281	loss_val: 65666.7969	loss_test: 65667.1562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7286.8018	loss_val: 7287.3208	loss_test: 7287.4824	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 87	curr_val_accuracy: 0.8291	curr_test_accuracy: 0.7741
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5750.6367	loss_val: 5751.6738	loss_test: 5751.2339	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 14956.1650	loss_val: 14956.5557	loss_test: 14957.1104	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 61106.0977	loss_val: 61106.5234	loss_test: 61107.4219	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 3]	loss_train: 51894.1133	loss_val: 51894.1172	loss_test: 51894.3789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6567.9722	loss_val: 6570.1143	loss_test: 6568.5703	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4940.5205	loss_val: 4940.5396	loss_test: 4940.5254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9610.3359	loss_val: 9610.3574	loss_test: 9610.8027	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5425.0703	loss_val: 5425.6592	loss_test: 5425.9893	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11436.6660	loss_val: 11438.3662	loss_test: 11437.0938	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11734.6426	loss_val: 11734.6719	loss_test: 11734.6299	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6347.1997	loss_val: 6347.2261	loss_test: 6347.2197	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5124.9585	loss_val: 5125.8643	loss_test: 5126.5942	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5312.8423	loss_val: 5313.6465	loss_test: 5314.0933	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12545.5537	loss_val: 12545.6182	loss_test: 12546.4355	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4966.1953	loss_val: 4966.1729	loss_test: 4966.4883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5416.4668	loss_val: 5417.0127	loss_test: 5417.6719	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4743.8804	loss_val: 4743.9082	loss_test: 4743.8950	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8177.5308	loss_val: 8178.9673	loss_test: 8178.1855	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65337.7461	loss_val: 65337.7148	loss_test: 65338.0664	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7238.4141	loss_val: 7238.9629	loss_test: 7239.1060	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 88	curr_val_accuracy: 0.8130	curr_test_accuracy: 0.7741
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5716.3677	loss_val: 5717.4414	loss_test: 5717.0127	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8000
[client 1]	loss_train: 14979.1230	loss_val: 14979.5107	loss_test: 14980.0801	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 60274.4258	loss_val: 60274.8047	loss_test: 60275.7109	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 51906.6172	loss_val: 51906.6172	loss_test: 51906.8828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6464.9673	loss_val: 6467.1685	loss_test: 6465.5942	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4947.2446	loss_val: 4947.2617	loss_test: 4947.2505	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9642.2939	loss_val: 9642.3164	loss_test: 9642.7578	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5446.1216	loss_val: 5446.7061	loss_test: 5447.0356	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11487.5410	loss_val: 11489.2383	loss_test: 11487.9512	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11724.9229	loss_val: 11724.9512	loss_test: 11724.9102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6337.3618	loss_val: 6337.3872	loss_test: 6337.3818	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5104.2612	loss_val: 5105.1484	loss_test: 5105.9131	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5310.3511	loss_val: 5311.1641	loss_test: 5311.5918	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12682.4785	loss_val: 12682.5459	loss_test: 12683.3662	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4952.2744	loss_val: 4952.2520	loss_test: 4952.5669	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5403.5000	loss_val: 5404.0415	loss_test: 5404.7056	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4736.5752	loss_val: 4736.6021	loss_test: 4736.5889	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8157.1475	loss_val: 8158.6113	loss_test: 8157.8105	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65071.5742	loss_val: 65071.5430	loss_test: 65071.8867	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7212.9653	loss_val: 7213.4741	loss_test: 7213.6533	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 89	curr_val_accuracy: 0.8049	curr_test_accuracy: 0.7857
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5698.3521	loss_val: 5699.4790	loss_test: 5699.0513	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 14997.9805	loss_val: 14998.3594	loss_test: 14998.9492	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 59440.0625	loss_val: 59440.3906	loss_test: 59441.3359	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 52259.7539	loss_val: 52259.7578	loss_test: 52260.0195	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6384.9453	loss_val: 6387.1934	loss_test: 6385.6050	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4953.1616	loss_val: 4953.1777	loss_test: 4953.1685	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9686.8896	loss_val: 9686.9121	loss_test: 9687.3535	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5472.3281	loss_val: 5472.9087	loss_test: 5473.2363	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11497.3623	loss_val: 11499.0742	loss_test: 11497.7676	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11729.0840	loss_val: 11729.1123	loss_test: 11729.0713	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6321.0786	loss_val: 6321.1035	loss_test: 6321.0991	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5095.1694	loss_val: 5096.0513	loss_test: 5096.8438	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5312.5659	loss_val: 5313.3921	loss_test: 5313.7759	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12826.1943	loss_val: 12826.2686	loss_test: 12827.0820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4945.8271	loss_val: 4945.8052	loss_test: 4946.1250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5381.1665	loss_val: 5381.7026	loss_test: 5382.3672	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4730.6748	loss_val: 4730.7012	loss_test: 4730.6880	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8141.8853	loss_val: 8143.3589	loss_test: 8142.5498	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 64993.1758	loss_val: 64993.1445	loss_test: 64993.4844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7185.2007	loss_val: 7185.7812	loss_test: 7185.9082	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 90	curr_val_accuracy: 0.8049	curr_test_accuracy: 0.7777
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5668.0146	loss_val: 5669.2026	loss_test: 5668.7681	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 15000.1699	loss_val: 15000.5391	loss_test: 15001.1553	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 58630.3359	loss_val: 58630.6055	loss_test: 58631.5938	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 52503.2422	loss_val: 52503.2422	loss_test: 52503.5078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6339.2549	loss_val: 6341.5327	loss_test: 6339.9448	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 4959.7559	loss_val: 4959.7710	loss_test: 4959.7627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9731.9082	loss_val: 9731.9316	loss_test: 9732.3682	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5502.5029	loss_val: 5503.0737	loss_test: 5503.4082	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11560.0049	loss_val: 11561.7471	loss_test: 11560.3994	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11701.7354	loss_val: 11701.7637	loss_test: 11701.7227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6307.5391	loss_val: 6307.5640	loss_test: 6307.5601	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5094.6323	loss_val: 5095.5103	loss_test: 5096.3330	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5322.1348	loss_val: 5322.9771	loss_test: 5323.3140	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 12911.2178	loss_val: 12911.2998	loss_test: 12912.1055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4951.0264	loss_val: 4951.0044	loss_test: 4951.3247	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5357.4043	loss_val: 5357.9302	loss_test: 5358.5972	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4730.9468	loss_val: 4730.9722	loss_test: 4730.9600	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8097.7759	loss_val: 8099.2983	loss_test: 8098.4653	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65086.1133	loss_val: 65086.0820	loss_test: 65086.4141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7184.7910	loss_val: 7185.3916	loss_test: 7185.5068	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 91	curr_val_accuracy: 0.8049	curr_test_accuracy: 0.7777
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5651.0762	loss_val: 5652.3022	loss_test: 5651.8633	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 15055.2539	loss_val: 15055.6074	loss_test: 15056.2627	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 57860.3789	loss_val: 57860.5898	loss_test: 57861.6445	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 52722.5156	loss_val: 52722.5156	loss_test: 52722.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6288.5200	loss_val: 6290.8115	loss_test: 6289.2422	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4961.6035	loss_val: 4961.6177	loss_test: 4961.6104	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9767.7686	loss_val: 9767.7920	loss_test: 9768.2227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5528.6953	loss_val: 5529.2603	loss_test: 5529.5981	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11583.8623	loss_val: 11585.6260	loss_test: 11584.2529	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11675.9199	loss_val: 11675.9473	loss_test: 11675.9072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6308.8608	loss_val: 6308.8853	loss_test: 6308.8809	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5141.2549	loss_val: 5142.1396	loss_test: 5143.0171	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.4000
[client 12]	loss_train: 5323.6250	loss_val: 5324.4565	loss_test: 5324.8330	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 13036.9541	loss_val: 13037.0479	loss_test: 13037.8447	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4966.1553	loss_val: 4966.1338	loss_test: 4966.4507	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5349.0918	loss_val: 5349.6021	loss_test: 5350.2759	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4729.7676	loss_val: 4729.7930	loss_test: 4729.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8072.7720	loss_val: 8074.3252	loss_test: 8073.5000	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65417.1797	loss_val: 65417.1484	loss_test: 65417.4883	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7199.8911	loss_val: 7200.4556	loss_test: 7200.6025	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 92	curr_val_accuracy: 0.7962	curr_test_accuracy: 0.7777
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5642.3076	loss_val: 5643.5493	loss_test: 5643.1201	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 15071.2441	loss_val: 15071.5947	loss_test: 15072.2676	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 57249.6641	loss_val: 57249.8281	loss_test: 57250.9492	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 53109.3125	loss_val: 53109.3125	loss_test: 53109.5820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6294.0825	loss_val: 6296.3530	loss_test: 6294.8208	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4973.4775	loss_val: 4973.4912	loss_test: 4973.4839	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9786.9795	loss_val: 9787.0029	loss_test: 9787.4307	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5555.5752	loss_val: 5556.1338	loss_test: 5556.4688	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11626.9062	loss_val: 11628.7021	loss_test: 11627.2891	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11628.2666	loss_val: 11628.2939	loss_test: 11628.2549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6291.0264	loss_val: 6291.0508	loss_test: 6291.0459	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5195.6567	loss_val: 5196.5459	loss_test: 5197.4805	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5333.3560	loss_val: 5334.1802	loss_test: 5334.5718	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 13207.0625	loss_val: 13207.1680	loss_test: 13207.9512	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4983.5679	loss_val: 4983.5464	loss_test: 4983.8604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5349.0566	loss_val: 5349.5571	loss_test: 5350.2354	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4732.6782	loss_val: 4732.7026	loss_test: 4732.6914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8052.3491	loss_val: 8053.9204	loss_test: 8053.0801	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65504.2500	loss_val: 65504.2188	loss_test: 65504.5586	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7261.3608	loss_val: 7261.8149	loss_test: 7262.0483	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 93	curr_val_accuracy: 0.7955	curr_test_accuracy: 0.7861
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5635.3374	loss_val: 5636.5874	loss_test: 5636.1582	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 15077.7021	loss_val: 15078.0537	loss_test: 15078.7373	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56733.0508	loss_val: 56733.1758	loss_test: 56734.3711	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 53192.9336	loss_val: 53192.9336	loss_test: 53193.2070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6271.3887	loss_val: 6273.6426	loss_test: 6272.1602	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4988.1445	loss_val: 4988.1577	loss_test: 4988.1509	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9797.0439	loss_val: 9797.0674	loss_test: 9797.4961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5592.2510	loss_val: 5592.8052	loss_test: 5593.1177	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11632.6084	loss_val: 11634.4238	loss_test: 11632.9824	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11569.0742	loss_val: 11569.1006	loss_test: 11569.0615	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6282.0522	loss_val: 6282.0762	loss_test: 6282.0713	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5237.2842	loss_val: 5238.1870	loss_test: 5239.1548	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5336.3267	loss_val: 5337.1328	loss_test: 5337.5649	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 13327.9775	loss_val: 13328.0957	loss_test: 13328.8691	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4993.5957	loss_val: 4993.5742	loss_test: 4993.8931	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5353.1738	loss_val: 5353.6636	loss_test: 5354.3516	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4735.6392	loss_val: 4735.6626	loss_test: 4735.6528	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8033.4165	loss_val: 8035.0195	loss_test: 8034.1807	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65819.4844	loss_val: 65819.4531	loss_test: 65819.7891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7348.1958	loss_val: 7348.5483	loss_test: 7348.8569	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 94	curr_val_accuracy: 0.7955	curr_test_accuracy: 0.7861
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5643.1738	loss_val: 5644.4097	loss_test: 5643.9771	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 15031.2217	loss_val: 15031.5850	loss_test: 15032.2715	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 56440.6289	loss_val: 56440.7344	loss_test: 56441.9805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 53390.0195	loss_val: 53390.0195	loss_test: 53390.2930	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6275.5947	loss_val: 6277.8125	loss_test: 6276.3726	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4997.5786	loss_val: 4997.5918	loss_test: 4997.5850	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9787.0088	loss_val: 9787.0322	loss_test: 9787.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5620.7817	loss_val: 5621.3335	loss_test: 5621.6294	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11631.4297	loss_val: 11633.2539	loss_test: 11631.7998	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11526.9082	loss_val: 11526.9346	loss_test: 11526.8965	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6268.9043	loss_val: 6268.9282	loss_test: 6268.9229	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5258.7734	loss_val: 5259.6909	loss_test: 5260.6753	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5350.4233	loss_val: 5351.2197	loss_test: 5351.6724	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 13413.1201	loss_val: 13413.2510	loss_test: 13414.0156	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5021.3057	loss_val: 5021.2842	loss_test: 5021.6089	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5373.8428	loss_val: 5374.3364	loss_test: 5375.0249	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4746.2246	loss_val: 4746.2476	loss_test: 4746.2383	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7999.0835	loss_val: 8000.7100	loss_test: 7999.8945	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65909.4219	loss_val: 65909.3906	loss_test: 65909.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7478.4717	loss_val: 7478.7163	loss_test: 7479.1025	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 95	curr_val_accuracy: 0.7955	curr_test_accuracy: 0.7804
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5659.2739	loss_val: 5660.4912	loss_test: 5660.0557	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 14905.8008	loss_val: 14906.1807	loss_test: 14906.8564	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 56175.5430	loss_val: 56175.6367	loss_test: 56176.9258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 53529.5000	loss_val: 53529.5000	loss_test: 53529.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6284.9268	loss_val: 6287.1001	loss_test: 6285.6865	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5010.1909	loss_val: 5010.2036	loss_test: 5010.1973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9797.5371	loss_val: 9797.5596	loss_test: 9797.9863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5641.7642	loss_val: 5642.3159	loss_test: 5642.6035	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11619.9365	loss_val: 11621.7549	loss_test: 11620.3105	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11486.1484	loss_val: 11486.1748	loss_test: 11486.1377	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6258.8062	loss_val: 6258.8306	loss_test: 6258.8242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5275.7217	loss_val: 5276.6592	loss_test: 5277.6440	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5360.8149	loss_val: 5361.6016	loss_test: 5362.0767	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 13492.5430	loss_val: 13492.6816	loss_test: 13493.4414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5056.9941	loss_val: 5056.9736	loss_test: 5057.2998	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5392.8643	loss_val: 5393.3555	loss_test: 5394.0488	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4760.6685	loss_val: 4760.6904	loss_test: 4760.6821	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7977.8682	loss_val: 7979.5195	loss_test: 7978.7324	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65875.1719	loss_val: 65875.1406	loss_test: 65875.4688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7651.9199	loss_val: 7652.0723	loss_test: 7652.5171	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 96	curr_val_accuracy: 0.8042	curr_test_accuracy: 0.7804
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5663.8354	loss_val: 5665.0225	loss_test: 5664.5840	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 14790.0439	loss_val: 14790.4404	loss_test: 14791.0957	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56012.8359	loss_val: 56012.9219	loss_test: 56014.2539	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 53435.3320	loss_val: 53435.3281	loss_test: 53435.6133	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6326.1240	loss_val: 6328.2432	loss_test: 6326.8574	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5019.3120	loss_val: 5019.3242	loss_test: 5019.3179	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9823.4111	loss_val: 9823.4336	loss_test: 9823.8535	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5603.5278	loss_val: 5604.0801	loss_test: 5604.3696	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11590.5771	loss_val: 11592.3730	loss_test: 11590.9561	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11412.0010	loss_val: 11412.0264	loss_test: 11411.9922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6252.9136	loss_val: 6252.9390	loss_test: 6252.9321	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5226.4448	loss_val: 5227.4092	loss_test: 5228.3501	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5368.6450	loss_val: 5369.4272	loss_test: 5369.9248	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 13550.3955	loss_val: 13550.5381	loss_test: 13551.2959	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5082.9150	loss_val: 5082.8945	loss_test: 5083.2280	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5405.9033	loss_val: 5406.4014	loss_test: 5407.0952	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4769.5117	loss_val: 4769.5332	loss_test: 4769.5254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7977.2515	loss_val: 7978.9180	loss_test: 7978.1494	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65830.0938	loss_val: 65830.0625	loss_test: 65830.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7806.4727	loss_val: 7806.5723	loss_test: 7807.0400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 97	curr_val_accuracy: 0.8299	curr_test_accuracy: 0.7861
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5666.0151	loss_val: 5667.1680	loss_test: 5666.7275	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 14769.6104	loss_val: 14770.0156	loss_test: 14770.6797	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 55670.0586	loss_val: 55670.1484	loss_test: 55671.5078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 53081.3789	loss_val: 53081.3750	loss_test: 53081.6680	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6358.6353	loss_val: 6360.7407	loss_test: 6359.3379	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5021.7979	loss_val: 5021.8101	loss_test: 5021.8037	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9875.0127	loss_val: 9875.0352	loss_test: 9875.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5556.7695	loss_val: 5557.3223	loss_test: 5557.6152	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11574.1377	loss_val: 11575.9111	loss_test: 11574.5195	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11343.9404	loss_val: 11343.9658	loss_test: 11343.9326	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6248.9546	loss_val: 6248.9800	loss_test: 6248.9727	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5237.3657	loss_val: 5238.3540	loss_test: 5239.2979	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5380.7256	loss_val: 5381.5059	loss_test: 5382.0234	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 13622.6328	loss_val: 13622.7852	loss_test: 13623.5391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5100.2974	loss_val: 5100.2773	loss_test: 5100.6113	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5424.1040	loss_val: 5424.6045	loss_test: 5425.3008	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4779.0962	loss_val: 4779.1177	loss_test: 4779.1104	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7970.2954	loss_val: 7971.9736	loss_test: 7971.2246	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65665.3516	loss_val: 65665.3203	loss_test: 65665.6328	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7992.1094	loss_val: 7992.1797	loss_test: 7992.6479	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 98	curr_val_accuracy: 0.8131	curr_test_accuracy: 0.7804
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5660.3242	loss_val: 5661.4380	loss_test: 5660.9976	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8000
[client 1]	loss_train: 14713.0752	loss_val: 14713.4971	loss_test: 14714.1484	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 55157.4570	loss_val: 55157.5469	loss_test: 55158.9258	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 53100.9336	loss_val: 53100.9336	loss_test: 53101.2266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6296.1294	loss_val: 6298.2744	loss_test: 6296.8345	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5007.1323	loss_val: 5007.1445	loss_test: 5007.1377	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9913.5010	loss_val: 9913.5234	loss_test: 9913.9375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5515.6616	loss_val: 5516.2129	loss_test: 5516.5142	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11663.7246	loss_val: 11665.4658	loss_test: 11664.1055	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 11306.2822	loss_val: 11306.3076	loss_test: 11306.2764	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6244.4209	loss_val: 6244.4463	loss_test: 6244.4385	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5204.7290	loss_val: 5205.7324	loss_test: 5206.6616	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5386.3027	loss_val: 5387.0723	loss_test: 5387.6572	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 13642.5820	loss_val: 13642.7383	loss_test: 13643.4961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5108.3901	loss_val: 5108.3706	loss_test: 5108.7026	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 5430.3828	loss_val: 5430.8857	loss_test: 5431.5786	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4786.1982	loss_val: 4786.2197	loss_test: 4786.2129	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7958.0469	loss_val: 7959.7266	loss_test: 7958.9761	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 65486.3047	loss_val: 65486.2734	loss_test: 65486.5820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 8112.5713	loss_val: 8112.6328	loss_test: 8113.0898	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 99	curr_val_accuracy: 0.8215	curr_test_accuracy: 0.7941
best_round: 49	best_val_accuracy: 0.8573	best_test_accuracy: 0.7852
--------------------------------------------------
