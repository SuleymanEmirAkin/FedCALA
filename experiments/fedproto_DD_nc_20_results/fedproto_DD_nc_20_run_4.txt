GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
GIN(
  (convs): ModuleList(
    (0): GINConv(nn=Sequential(
      (0): Linear(in_features=89, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
    (1): GINConv(nn=Sequential(
      (0): Linear(in_features=64, out_features=128, bias=True)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Linear(in_features=128, out_features=64, bias=True)
    ))
  )
  (batch_norms): ModuleList(
    (0-1): 2 x BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (lin1): Linear(in_features=64, out_features=64, bias=True)
  (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (lin2): Linear(in_features=64, out_features=2, bias=True)
)
round # 0		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 0.6558	loss_val: 0.6595	loss_test: 0.6751	accuracy_train: 0.6533	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 0.7295	loss_val: 0.7277	loss_test: 0.7942	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 0.7174	loss_val: 0.7259	loss_test: 0.7194	accuracy_train: 0.2286	accuracy_val: 0.0000	accuracy_test: 0.2000
[client 3]	loss_train: 0.9271	loss_val: 0.8991	loss_test: 0.7924	accuracy_train: 0.1500	accuracy_val: 0.2857	accuracy_test: 0.2222
[client 4]	loss_train: 0.6629	loss_val: 0.6641	loss_test: 0.6616	accuracy_train: 0.7531	accuracy_val: 0.8000	accuracy_test: 0.7273
[client 5]	loss_train: 0.4543	loss_val: 0.4062	loss_test: 0.4465	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 0.5344	loss_val: 0.5332	loss_test: 0.5828	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 0.8522	loss_val: 0.8118	loss_test: 0.8047	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 0.8116	loss_val: 0.8230	loss_test: 0.7891	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 0.7625	loss_val: 0.7568	loss_test: 0.7518	accuracy_train: 0.0896	accuracy_val: 0.1250	accuracy_test: 0.3333
[client 10]	loss_train: 0.8244	loss_val: 0.9043	loss_test: 1.5967	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 11]	loss_train: 0.6709	loss_val: 0.6303	loss_test: 0.6982	accuracy_train: 0.4557	accuracy_val: 0.5000	accuracy_test: 0.6000
[client 12]	loss_train: 0.7017	loss_val: 0.7123	loss_test: 0.6772	accuracy_train: 0.3824	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 13]	loss_train: 0.5171	loss_val: 0.4981	loss_test: 0.5194	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 14]	loss_train: 0.6744	loss_val: 0.0000	loss_test: 0.6543	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 0.7644	loss_val: 0.8561	loss_test: 0.8010	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 0.6211	loss_val: 0.6205	loss_test: 0.6228	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 0.4376	loss_val: 0.8383	loss_test: 0.5845	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 0.5569	loss_val: 13.8312	loss_test: 0.6601	accuracy_train: 0.8000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 0.6671	loss_val: 0.7818	loss_test: 0.6864	accuracy_train: 0.6531	accuracy_val: 0.5000	accuracy_test: 0.4615
curr_round: 0	curr_val_accuracy: 0.5162	curr_test_accuracy: 0.5292
best_round: 0	best_val_accuracy: 0.5162	best_test_accuracy: 0.5292
--------------------------------------------------
round # 1		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 364.8979	loss_val: 364.9092	loss_test: 364.9015	accuracy_train: 0.4267	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 1]	loss_train: 470.6403	loss_val: 470.5919	loss_test: 470.7425	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 2545.5203	loss_val: 2545.5098	loss_test: 2545.5208	accuracy_train: 0.5714	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 699.3962	loss_val: 699.3804	loss_test: 699.3439	accuracy_train: 0.5833	accuracy_val: 0.7143	accuracy_test: 0.6667
[client 4]	loss_train: 223.9710	loss_val: 223.9732	loss_test: 223.9792	accuracy_train: 0.7778	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 176.4834	loss_val: 176.4508	loss_test: 176.4911	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 318.2835	loss_val: 318.2721	loss_test: 318.3421	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 430.7889	loss_val: 430.7899	loss_test: 430.7416	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 292.2126	loss_val: 292.1775	loss_test: 292.1683	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 238.0532	loss_val: 238.0482	loss_test: 238.1596	accuracy_train: 0.0299	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 10]	loss_train: 285.0804	loss_val: 285.1469	loss_test: 285.5126	accuracy_train: 0.1429	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 11]	loss_train: 256.3857	loss_val: 256.3527	loss_test: 256.4112	accuracy_train: 0.6203	accuracy_val: 0.7000	accuracy_test: 0.4000
[client 12]	loss_train: 225.8644	loss_val: 225.8905	loss_test: 225.8328	accuracy_train: 0.3824	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 13]	loss_train: 265.4466	loss_val: 265.4555	loss_test: 265.4308	accuracy_train: 0.8333	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 14]	loss_train: 141.6466	loss_val: 141.0031	loss_test: 141.6267	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 401.6100	loss_val: 401.7102	loss_test: 401.6205	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 286.0717	loss_val: 286.0730	loss_test: 286.0762	accuracy_train: 0.9677	accuracy_val: 1.0000	accuracy_test: 0.6250
[client 17]	loss_train: 384.9130	loss_val: 385.2913	loss_test: 385.0123	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 1635.3564	loss_val: 1639.9631	loss_test: 1635.4304	accuracy_train: 0.8000	accuracy_val: 0.0000	accuracy_test: 0.6667
[client 19]	loss_train: 242.2316	loss_val: 242.3157	loss_test: 242.2454	accuracy_train: 0.8061	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 1	curr_val_accuracy: 0.5767	curr_test_accuracy: 0.5280
best_round: 1	best_val_accuracy: 0.5767	best_test_accuracy: 0.5280
--------------------------------------------------
round # 2		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 587.6843	loss_val: 587.6959	loss_test: 587.6827	accuracy_train: 0.4133	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 1]	loss_train: 728.8521	loss_val: 728.8075	loss_test: 728.9036	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 4290.7861	loss_val: 4290.7690	loss_test: 4290.7983	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 1226.7545	loss_val: 1226.7283	loss_test: 1226.7153	accuracy_train: 0.7667	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 349.1971	loss_val: 349.1978	loss_test: 349.2071	accuracy_train: 0.7778	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 272.2866	loss_val: 272.2628	loss_test: 272.2992	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 498.8259	loss_val: 498.8096	loss_test: 498.9161	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 726.9897	loss_val: 727.0031	loss_test: 726.9289	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 414.0669	loss_val: 414.0250	loss_test: 414.0044	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 269.2598	loss_val: 269.2456	loss_test: 269.3513	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 10]	loss_train: 440.9469	loss_val: 440.9777	loss_test: 441.0435	accuracy_train: 0.8929	accuracy_val: 0.8571	accuracy_test: 0.8571
[client 11]	loss_train: 427.5258	loss_val: 427.4839	loss_test: 427.5608	accuracy_train: 0.6835	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 344.5599	loss_val: 344.5975	loss_test: 344.5241	accuracy_train: 0.3824	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 13]	loss_train: 459.5182	loss_val: 459.5343	loss_test: 459.5052	accuracy_train: 0.8333	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 14]	loss_train: 227.0089	loss_val: 226.3922	loss_test: 226.9627	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 15]	loss_train: 668.7002	loss_val: 668.7678	loss_test: 668.7150	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 476.3867	loss_val: 476.4042	loss_test: 476.3939	accuracy_train: 0.0161	accuracy_val: 0.1250	accuracy_test: 0.1250
[client 17]	loss_train: 668.6715	loss_val: 669.0230	loss_test: 668.7462	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 2715.3142	loss_val: 2714.7129	loss_test: 2715.3530	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 478.8483	loss_val: 478.8928	loss_test: 478.8566	accuracy_train: 0.8367	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 2	curr_val_accuracy: 0.5989	curr_test_accuracy: 0.5442
best_round: 2	best_val_accuracy: 0.5989	best_test_accuracy: 0.5442
--------------------------------------------------
round # 3		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 944.5282	loss_val: 944.5457	loss_test: 944.5316	accuracy_train: 0.4133	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 1]	loss_train: 1154.9207	loss_val: 1154.8834	loss_test: 1154.9366	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 6385.7690	loss_val: 6385.7432	loss_test: 6385.7832	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 1909.1592	loss_val: 1909.1392	loss_test: 1909.1431	accuracy_train: 0.8667	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 573.6790	loss_val: 573.6793	loss_test: 573.6865	accuracy_train: 0.7284	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 387.9224	loss_val: 387.9029	loss_test: 387.9335	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 775.0182	loss_val: 774.9941	loss_test: 775.1292	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1102.6626	loss_val: 1102.6769	loss_test: 1102.6007	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 580.1328	loss_val: 580.1008	loss_test: 580.0730	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 360.7023	loss_val: 360.7046	loss_test: 360.6965	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 10]	loss_train: 644.4884	loss_val: 644.4939	loss_test: 644.4872	accuracy_train: 1.0000	accuracy_val: 0.8571	accuracy_test: 1.0000
[client 11]	loss_train: 642.3711	loss_val: 642.3196	loss_test: 642.4191	accuracy_train: 0.7089	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 523.5911	loss_val: 523.6313	loss_test: 523.5654	accuracy_train: 0.4118	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 13]	loss_train: 750.4301	loss_val: 750.4522	loss_test: 750.4161	accuracy_train: 0.7222	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 14]	loss_train: 345.7205	loss_val: 345.1074	loss_test: 345.6464	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 979.0149	loss_val: 979.0631	loss_test: 979.0297	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 695.3652	loss_val: 695.3846	loss_test: 695.3788	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.0000
[client 17]	loss_train: 1062.8612	loss_val: 1063.2288	loss_test: 1062.9268	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 4737.3091	loss_val: 4736.6685	loss_test: 4737.3447	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 804.6661	loss_val: 804.6868	loss_test: 804.6768	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 3	curr_val_accuracy: 0.5804	curr_test_accuracy: 0.5482
best_round: 2	best_val_accuracy: 0.5989	best_test_accuracy: 0.5442
--------------------------------------------------
round # 4		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1391.2838	loss_val: 1391.3098	loss_test: 1391.2892	accuracy_train: 0.4667	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 1]	loss_train: 1690.2987	loss_val: 1690.2684	loss_test: 1690.2836	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 8612.2393	loss_val: 8612.2002	loss_test: 8612.2480	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 2649.9927	loss_val: 2649.9780	loss_test: 2649.9946	accuracy_train: 0.9500	accuracy_val: 0.8571	accuracy_test: 0.8889
[client 4]	loss_train: 884.0703	loss_val: 884.0767	loss_test: 884.0841	accuracy_train: 0.7284	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 526.8867	loss_val: 526.8700	loss_test: 526.8961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1119.8014	loss_val: 1119.7753	loss_test: 1119.9188	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 1542.0435	loss_val: 1542.0631	loss_test: 1541.9780	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 786.7915	loss_val: 786.7673	loss_test: 786.7371	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 521.7170	loss_val: 521.7368	loss_test: 521.6377	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.2222
[client 10]	loss_train: 872.7977	loss_val: 872.7938	loss_test: 872.7440	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 887.0187	loss_val: 886.9620	loss_test: 887.0780	accuracy_train: 0.7595	accuracy_val: 0.9000	accuracy_test: 0.4000
[client 12]	loss_train: 748.0557	loss_val: 748.0995	loss_test: 748.0371	accuracy_train: 0.4412	accuracy_val: 0.4000	accuracy_test: 0.4000
[client 13]	loss_train: 1164.1876	loss_val: 1164.2166	loss_test: 1164.1761	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 14]	loss_train: 497.9799	loss_val: 497.3774	loss_test: 497.8956	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1309.1864	loss_val: 1309.2203	loss_test: 1309.2037	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 936.2281	loss_val: 936.2534	loss_test: 936.2449	accuracy_train: 0.0000	accuracy_val: 0.1250	accuracy_test: 0.0000
[client 17]	loss_train: 1481.3975	loss_val: 1481.7820	loss_test: 1481.4626	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 7269.3496	loss_val: 7268.7241	loss_test: 7269.4004	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 1191.9327	loss_val: 1191.9336	loss_test: 1191.9436	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 4	curr_val_accuracy: 0.6133	curr_test_accuracy: 0.5751
best_round: 4	best_val_accuracy: 0.6133	best_test_accuracy: 0.5751
--------------------------------------------------
round # 5		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 1904.1415	loss_val: 1904.1752	loss_test: 1904.1514	accuracy_train: 0.6800	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 2322.3657	loss_val: 2322.3472	loss_test: 2322.3291	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 10952.1055	loss_val: 10952.0557	loss_test: 10952.1074	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 3474.7253	loss_val: 3474.7097	loss_test: 3474.7393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 1252.4622	loss_val: 1252.4700	loss_test: 1252.4800	accuracy_train: 0.7160	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 684.1310	loss_val: 684.1161	loss_test: 684.1391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1521.8811	loss_val: 1521.8562	loss_test: 1521.9983	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2031.9434	loss_val: 2031.9652	loss_test: 2031.8795	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1029.6920	loss_val: 1029.6710	loss_test: 1029.6420	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 751.1548	loss_val: 751.1829	loss_test: 751.0202	accuracy_train: 0.0000	accuracy_val: 0.0000	accuracy_test: 0.2222
[client 10]	loss_train: 1134.0171	loss_val: 1134.0077	loss_test: 1133.9432	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1153.6812	loss_val: 1153.6193	loss_test: 1153.7544	accuracy_train: 0.7975	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 1013.5922	loss_val: 1013.6379	loss_test: 1013.5784	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 1699.9125	loss_val: 1699.9437	loss_test: 1699.8993	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 14]	loss_train: 671.7234	loss_val: 671.1263	loss_test: 671.6318	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1631.2961	loss_val: 1631.3174	loss_test: 1631.3157	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1199.0083	loss_val: 1199.0361	loss_test: 1199.0300	accuracy_train: 0.0161	accuracy_val: 0.2500	accuracy_test: 0.0000
[client 17]	loss_train: 1895.8438	loss_val: 1896.2539	loss_test: 1895.9052	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 10245.5166	loss_val: 10244.9170	loss_test: 10245.5889	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 1624.3990	loss_val: 1624.3802	loss_test: 1624.4066	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 5	curr_val_accuracy: 0.6389	curr_test_accuracy: 0.5910
best_round: 5	best_val_accuracy: 0.6389	best_test_accuracy: 0.5910
--------------------------------------------------
round # 6		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 2471.9600	loss_val: 2472.0020	loss_test: 2471.9746	accuracy_train: 0.6933	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 1]	loss_train: 3075.3760	loss_val: 3075.3723	loss_test: 3075.3206	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.3333
[client 2]	loss_train: 13474.6660	loss_val: 13474.6094	loss_test: 13474.6631	accuracy_train: 0.6286	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 4350.9160	loss_val: 4350.9019	loss_test: 4350.9438	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 1672.5854	loss_val: 1672.5957	loss_test: 1672.6060	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 854.3309	loss_val: 854.3182	loss_test: 854.3384	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 1983.7167	loss_val: 1983.6929	loss_test: 1983.8319	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 2581.2732	loss_val: 2581.2961	loss_test: 2581.2095	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1321.2926	loss_val: 1321.2693	loss_test: 1321.2451	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 1044.6122	loss_val: 1044.6478	loss_test: 1044.4401	accuracy_train: 0.0299	accuracy_val: 0.0000	accuracy_test: 0.3333
[client 10]	loss_train: 1428.9962	loss_val: 1428.9810	loss_test: 1428.9215	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1436.2362	loss_val: 1436.1702	loss_test: 1436.3271	accuracy_train: 0.7975	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 1318.1846	loss_val: 1318.2344	loss_test: 1318.1744	accuracy_train: 0.5294	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 2350.5042	loss_val: 2350.5276	loss_test: 2350.4927	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 14]	loss_train: 867.5328	loss_val: 866.9321	loss_test: 867.4351	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 1943.5756	loss_val: 1943.5817	loss_test: 1943.5962	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1488.8916	loss_val: 1488.9198	loss_test: 1488.9161	accuracy_train: 0.0645	accuracy_val: 0.2500	accuracy_test: 0.0000
[client 17]	loss_train: 2308.6147	loss_val: 2309.0586	loss_test: 2308.6719	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 13662.9033	loss_val: 13662.3340	loss_test: 13663.0000	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 2108.3975	loss_val: 2108.3647	loss_test: 2108.4011	accuracy_train: 0.8265	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 6	curr_val_accuracy: 0.6389	curr_test_accuracy: 0.6064
best_round: 5	best_val_accuracy: 0.6389	best_test_accuracy: 0.5910
--------------------------------------------------
round # 7		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3067.9714	loss_val: 3068.0200	loss_test: 3067.9905	accuracy_train: 0.7333	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 3876.9341	loss_val: 3876.9482	loss_test: 3876.8599	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 16014.7129	loss_val: 16014.6494	loss_test: 16014.7080	accuracy_train: 0.7143	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 5310.2954	loss_val: 5310.2808	loss_test: 5310.3325	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2142.4280	loss_val: 2142.4419	loss_test: 2142.4536	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1032.8606	loss_val: 1032.8496	loss_test: 1032.8672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 2480.9065	loss_val: 2480.8828	loss_test: 2481.0195	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3173.1899	loss_val: 3173.2139	loss_test: 3173.1279	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 1655.3760	loss_val: 1655.3489	loss_test: 1655.3344	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 1390.5491	loss_val: 1390.5920	loss_test: 1390.3623	accuracy_train: 0.0746	accuracy_val: 0.0000	accuracy_test: 0.4444
[client 10]	loss_train: 1758.8181	loss_val: 1758.7996	loss_test: 1758.7479	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 1735.6040	loss_val: 1735.5330	loss_test: 1735.7109	accuracy_train: 0.7722	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 1656.1656	loss_val: 1656.2202	loss_test: 1656.1582	accuracy_train: 0.5882	accuracy_val: 0.4000	accuracy_test: 0.6000
[client 13]	loss_train: 3099.5525	loss_val: 3099.5769	loss_test: 3099.5364	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 14]	loss_train: 1074.9069	loss_val: 1074.3110	loss_test: 1074.8082	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2252.2290	loss_val: 2252.2246	loss_test: 2252.2510	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 1807.4059	loss_val: 1807.4362	loss_test: 1807.4287	accuracy_train: 0.1290	accuracy_val: 0.3750	accuracy_test: 0.2500
[client 17]	loss_train: 2710.9763	loss_val: 2711.4502	loss_test: 2711.0303	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 17310.2246	loss_val: 17309.6797	loss_test: 17310.3418	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 2631.9858	loss_val: 2631.9465	loss_test: 2631.9858	accuracy_train: 0.8367	accuracy_val: 0.7500	accuracy_test: 0.7692
curr_round: 7	curr_val_accuracy: 0.6304	curr_test_accuracy: 0.6452
best_round: 5	best_val_accuracy: 0.6389	best_test_accuracy: 0.5910
--------------------------------------------------
round # 8		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 3694.0884	loss_val: 3694.1416	loss_test: 3694.1113	accuracy_train: 0.7467	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 4717.8696	loss_val: 4717.8955	loss_test: 4717.7754	accuracy_train: 0.3333	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 18743.7207	loss_val: 18743.6504	loss_test: 18743.7168	accuracy_train: 0.7714	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 6309.7627	loss_val: 6309.7480	loss_test: 6309.8105	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 2655.4238	loss_val: 2655.4409	loss_test: 2655.4551	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1217.8975	loss_val: 1217.8884	loss_test: 1217.9031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3023.0686	loss_val: 3023.0483	loss_test: 3023.1714	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 3829.5723	loss_val: 3829.5979	loss_test: 3829.5083	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2040.2749	loss_val: 2040.2458	loss_test: 2040.2375	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 1783.1346	loss_val: 1783.1863	loss_test: 1782.9406	accuracy_train: 0.1940	accuracy_val: 0.0000	accuracy_test: 0.4444
[client 10]	loss_train: 2116.9607	loss_val: 2116.9382	loss_test: 2116.8950	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2047.3225	loss_val: 2047.2465	loss_test: 2047.4458	accuracy_train: 0.7722	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 2026.8988	loss_val: 2026.9575	loss_test: 2026.8939	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 3961.2810	loss_val: 3961.3074	loss_test: 3961.2620	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 14]	loss_train: 1304.2957	loss_val: 1303.6965	loss_test: 1304.1960	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2561.0334	loss_val: 2561.0156	loss_test: 2561.0576	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2147.6519	loss_val: 2147.6787	loss_test: 2147.6709	accuracy_train: 0.2903	accuracy_val: 0.3750	accuracy_test: 0.3750
[client 17]	loss_train: 3100.8311	loss_val: 3101.3301	loss_test: 3100.8821	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 21166.1660	loss_val: 21165.6367	loss_test: 21166.2969	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 3189.1436	loss_val: 3189.0959	loss_test: 3189.1382	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 8	curr_val_accuracy: 0.6383	curr_test_accuracy: 0.6609
best_round: 5	best_val_accuracy: 0.6389	best_test_accuracy: 0.5910
--------------------------------------------------
round # 9		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 4340.8730	loss_val: 4340.9307	loss_test: 4340.8989	accuracy_train: 0.7467	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 5605.0044	loss_val: 5605.0459	loss_test: 5604.8838	accuracy_train: 0.5333	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 21789.0762	loss_val: 21789.0000	loss_test: 21789.0742	accuracy_train: 0.8286	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 7388.7393	loss_val: 7388.7241	loss_test: 7388.7969	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 3229.9976	loss_val: 3230.0146	loss_test: 3230.0322	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1423.9048	loss_val: 1423.8970	loss_test: 1423.9098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 3597.4670	loss_val: 3597.4490	loss_test: 3597.5613	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 4506.4663	loss_val: 4506.4922	loss_test: 4506.4014	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2480.4421	loss_val: 2480.4121	loss_test: 2480.4099	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 2206.1091	loss_val: 2206.1716	loss_test: 2205.9143	accuracy_train: 0.2836	accuracy_val: 0.0000	accuracy_test: 0.4444
[client 10]	loss_train: 2495.7646	loss_val: 2495.7417	loss_test: 2495.7043	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2366.8447	loss_val: 2366.7639	loss_test: 2366.9824	accuracy_train: 0.7722	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 2426.7419	loss_val: 2426.8042	loss_test: 2426.7417	accuracy_train: 0.6176	accuracy_val: 0.4000	accuracy_test: 0.8000
[client 13]	loss_train: 4888.1934	loss_val: 4888.2139	loss_test: 4888.1733	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 14]	loss_train: 1538.3175	loss_val: 1537.7061	loss_test: 1538.2151	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 2868.0515	loss_val: 2868.0195	loss_test: 2868.0762	accuracy_train: 0.5000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2506.9143	loss_val: 2506.9287	loss_test: 2506.9314	accuracy_train: 0.5000	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 3461.2185	loss_val: 3461.7290	loss_test: 3461.2654	accuracy_train: 0.8519	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 25310.9590	loss_val: 25310.4473	loss_test: 25311.1035	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 3758.9172	loss_val: 3758.8557	loss_test: 3758.9062	accuracy_train: 0.8163	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 9	curr_val_accuracy: 0.6625	curr_test_accuracy: 0.6775
best_round: 9	best_val_accuracy: 0.6625	best_test_accuracy: 0.6775
--------------------------------------------------
round # 10		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 4991.3120	loss_val: 4991.3745	loss_test: 4991.3394	accuracy_train: 0.7467	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 6541.1729	loss_val: 6541.2295	loss_test: 6541.0327	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 24912.9863	loss_val: 24912.9043	loss_test: 24912.9824	accuracy_train: 0.8286	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 8518.7217	loss_val: 8518.7051	loss_test: 8518.7871	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 3823.8970	loss_val: 3823.9141	loss_test: 3823.9348	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1648.0887	loss_val: 1648.0819	loss_test: 1648.0927	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4198.6328	loss_val: 4198.6157	loss_test: 4198.7236	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5199.1836	loss_val: 5199.2095	loss_test: 5199.1177	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 2962.6836	loss_val: 2962.6553	loss_test: 2962.6580	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 2652.1833	loss_val: 2652.2542	loss_test: 2651.9910	accuracy_train: 0.3433	accuracy_val: 0.0000	accuracy_test: 0.4444
[client 10]	loss_train: 2903.2991	loss_val: 2903.2781	loss_test: 2903.2437	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 2698.0542	loss_val: 2697.9690	loss_test: 2698.2068	accuracy_train: 0.7722	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 2857.0898	loss_val: 2857.1545	loss_test: 2857.0991	accuracy_train: 0.6176	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 5922.3618	loss_val: 5922.3755	loss_test: 5922.3418	accuracy_train: 0.6111	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 14]	loss_train: 1785.0469	loss_val: 1784.4248	loss_test: 1784.9380	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3182.9805	loss_val: 3182.9370	loss_test: 3183.0032	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 2875.3521	loss_val: 2875.3525	loss_test: 2875.3657	accuracy_train: 0.6290	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 3816.3093	loss_val: 3816.8218	loss_test: 3816.3516	accuracy_train: 0.8519	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 29417.3262	loss_val: 29416.8301	loss_test: 29417.4824	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 4335.8711	loss_val: 4335.7964	loss_test: 4335.8569	accuracy_train: 0.7959	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 10	curr_val_accuracy: 0.6700	curr_test_accuracy: 0.6908
best_round: 10	best_val_accuracy: 0.6700	best_test_accuracy: 0.6908
--------------------------------------------------
round # 11		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5605.7710	loss_val: 5605.8389	loss_test: 5605.7988	accuracy_train: 0.7600	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 7495.9062	loss_val: 7495.9800	loss_test: 7495.7515	accuracy_train: 0.6000	accuracy_val: 0.0000	accuracy_test: 1.0000
[client 2]	loss_train: 28235.9316	loss_val: 28235.8457	loss_test: 28235.9297	accuracy_train: 0.8286	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 9719.8037	loss_val: 9719.7871	loss_test: 9719.8760	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 4425.0039	loss_val: 4425.0229	loss_test: 4425.0459	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 1891.6869	loss_val: 1891.6786	loss_test: 1891.6895	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 4808.4067	loss_val: 4808.3906	loss_test: 4808.4932	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5936.4790	loss_val: 5936.5054	loss_test: 5936.4092	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 3471.1199	loss_val: 3471.0947	loss_test: 3471.1006	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 3112.8906	loss_val: 3112.9670	loss_test: 3112.7036	accuracy_train: 0.4179	accuracy_val: 0.3750	accuracy_test: 0.5556
[client 10]	loss_train: 3316.6899	loss_val: 3316.6707	loss_test: 3316.6411	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3040.4448	loss_val: 3040.3552	loss_test: 3040.6172	accuracy_train: 0.7848	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 3305.3147	loss_val: 3305.3809	loss_test: 3305.3362	accuracy_train: 0.6176	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 7015.9292	loss_val: 7015.9355	loss_test: 7015.9121	accuracy_train: 0.7222	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 14]	loss_train: 2044.6827	loss_val: 2044.0438	loss_test: 2044.5632	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3491.9651	loss_val: 3491.9136	loss_test: 3491.9863	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3262.3611	loss_val: 3262.3489	loss_test: 3262.3662	accuracy_train: 0.7903	accuracy_val: 0.6250	accuracy_test: 0.6250
[client 17]	loss_train: 4158.3599	loss_val: 4158.8687	loss_test: 4158.3994	accuracy_train: 0.8519	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 33398.2500	loss_val: 33397.7695	loss_test: 33398.4180	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 4890.7627	loss_val: 4890.6724	loss_test: 4890.7441	accuracy_train: 0.7857	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 11	curr_val_accuracy: 0.7059	curr_test_accuracy: 0.6803
best_round: 11	best_val_accuracy: 0.7059	best_test_accuracy: 0.6803
--------------------------------------------------
round # 12		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6205.6602	loss_val: 6205.7339	loss_test: 6205.6890	accuracy_train: 0.7600	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 8450.4854	loss_val: 8450.5762	loss_test: 8450.3213	accuracy_train: 0.6667	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 31677.8848	loss_val: 31677.7949	loss_test: 31677.8867	accuracy_train: 0.8286	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 10944.4941	loss_val: 10944.4766	loss_test: 10944.5742	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 5032.1099	loss_val: 5032.1299	loss_test: 5032.1562	accuracy_train: 0.6667	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2150.8748	loss_val: 2150.8655	loss_test: 2150.8765	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 5436.8174	loss_val: 5436.8032	loss_test: 5436.8979	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6653.0322	loss_val: 6653.0601	loss_test: 6652.9614	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 4020.2083	loss_val: 4020.1875	loss_test: 4020.1934	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 3583.9480	loss_val: 3584.0281	loss_test: 3583.7717	accuracy_train: 0.5224	accuracy_val: 0.5000	accuracy_test: 0.5556
[client 10]	loss_train: 3737.5442	loss_val: 3737.5266	loss_test: 3737.5027	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3388.3391	loss_val: 3388.2451	loss_test: 3388.5327	accuracy_train: 0.7848	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 3750.3423	loss_val: 3750.4075	loss_test: 3750.3782	accuracy_train: 0.7059	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 8175.6719	loss_val: 8175.6729	loss_test: 8175.6587	accuracy_train: 0.7778	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 14]	loss_train: 2312.3630	loss_val: 2311.7109	loss_test: 2312.2424	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 3807.0007	loss_val: 3806.9414	loss_test: 3807.0232	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 3652.9736	loss_val: 3652.9512	loss_test: 3652.9729	accuracy_train: 0.9194	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 4478.5376	loss_val: 4479.0312	loss_test: 4478.5737	accuracy_train: 0.8148	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 37512.5469	loss_val: 37512.0781	loss_test: 37512.7266	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5435.8779	loss_val: 5435.7754	loss_test: 5435.8569	accuracy_train: 0.7755	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 12	curr_val_accuracy: 0.7646	curr_test_accuracy: 0.7051
best_round: 12	best_val_accuracy: 0.7646	best_test_accuracy: 0.7051
--------------------------------------------------
round # 13		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6781.5352	loss_val: 6781.6143	loss_test: 6781.5640	accuracy_train: 0.7600	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 9424.0469	loss_val: 9424.1533	loss_test: 9423.8711	accuracy_train: 0.7333	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 35082.3867	loss_val: 35082.2930	loss_test: 35082.3906	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 12222.8809	loss_val: 12222.8633	loss_test: 12222.9668	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 5615.8652	loss_val: 5615.8877	loss_test: 5615.9165	accuracy_train: 0.6790	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2424.7151	loss_val: 2424.7048	loss_test: 2424.7163	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6087.8076	loss_val: 6087.7964	loss_test: 6087.8857	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7355.7842	loss_val: 7355.8135	loss_test: 7355.7134	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 4572.8315	loss_val: 4572.8188	loss_test: 4572.8218	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 4050.4976	loss_val: 4050.5806	loss_test: 4050.3318	accuracy_train: 0.6269	accuracy_val: 0.6250	accuracy_test: 0.7778
[client 10]	loss_train: 4153.8662	loss_val: 4153.8496	loss_test: 4153.8315	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 3742.9768	loss_val: 3742.8787	loss_test: 3743.1921	accuracy_train: 0.7848	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 4202.3169	loss_val: 4202.3809	loss_test: 4202.3730	accuracy_train: 0.7647	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 9349.9619	loss_val: 9349.9570	loss_test: 9349.9580	accuracy_train: 0.8889	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2578.9871	loss_val: 2578.3218	loss_test: 2578.8696	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4105.5962	loss_val: 4105.5283	loss_test: 4105.6211	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4029.3169	loss_val: 4029.2859	loss_test: 4029.3125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 4779.5532	loss_val: 4780.0269	loss_test: 4779.5869	accuracy_train: 0.8519	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 41533.4336	loss_val: 41532.9766	loss_test: 41533.6250	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 5960.9946	loss_val: 5960.8799	loss_test: 5960.9702	accuracy_train: 0.7449	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 13	curr_val_accuracy: 0.7735	curr_test_accuracy: 0.7158
best_round: 13	best_val_accuracy: 0.7735	best_test_accuracy: 0.7158
--------------------------------------------------
round # 14		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7347.1641	loss_val: 7347.2485	loss_test: 7347.1929	accuracy_train: 0.7600	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 10318.3477	loss_val: 10318.4736	loss_test: 10318.1641	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 38617.7617	loss_val: 38617.6680	loss_test: 38617.7734	accuracy_train: 0.8857	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 13555.9238	loss_val: 13555.9072	loss_test: 13556.0156	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6171.3994	loss_val: 6171.4263	loss_test: 6171.4575	accuracy_train: 0.7037	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 2715.1907	loss_val: 2715.1799	loss_test: 2715.1909	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 6701.8335	loss_val: 6701.8252	loss_test: 6701.9116	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8028.6558	loss_val: 8028.6792	loss_test: 8028.5884	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 5122.6758	loss_val: 5122.6704	loss_test: 5122.6709	accuracy_train: 0.2083	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 4496.1494	loss_val: 4496.2334	loss_test: 4495.9951	accuracy_train: 0.7463	accuracy_val: 0.6250	accuracy_test: 0.8889
[client 10]	loss_train: 4556.9116	loss_val: 4556.8960	loss_test: 4556.8818	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4099.8042	loss_val: 4099.7031	loss_test: 4100.0410	accuracy_train: 0.7975	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 4642.0063	loss_val: 4642.0688	loss_test: 4642.0869	accuracy_train: 0.7941	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10543.5117	loss_val: 10543.5010	loss_test: 10543.5156	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 2846.5081	loss_val: 2845.8333	loss_test: 2846.3992	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4389.1631	loss_val: 4389.0884	loss_test: 4389.1948	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4399.3452	loss_val: 4399.3086	loss_test: 4399.3374	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5064.7798	loss_val: 5065.2344	loss_test: 5064.8145	accuracy_train: 0.8519	accuracy_val: 0.7500	accuracy_test: 0.7500
[client 18]	loss_train: 45377.4609	loss_val: 45377.0156	loss_test: 45377.6641	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6440.9561	loss_val: 6440.8286	loss_test: 6440.9282	accuracy_train: 0.7449	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 14	curr_val_accuracy: 0.7735	curr_test_accuracy: 0.7318
best_round: 13	best_val_accuracy: 0.7735	best_test_accuracy: 0.7158
--------------------------------------------------
round # 15		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7847.0713	loss_val: 7847.1611	loss_test: 7847.1006	accuracy_train: 0.7467	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 11107.0762	loss_val: 11107.2217	loss_test: 11106.8887	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 42169.6914	loss_val: 42169.5977	loss_test: 42169.7109	accuracy_train: 0.8857	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 14871.0859	loss_val: 14871.0684	loss_test: 14871.1826	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 6703.6733	loss_val: 6703.7070	loss_test: 6703.7373	accuracy_train: 0.7037	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3020.5115	loss_val: 3020.5010	loss_test: 3020.5117	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7290.5688	loss_val: 7290.5645	loss_test: 7290.6445	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8686.4414	loss_val: 8686.4590	loss_test: 8686.3809	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 5666.9331	loss_val: 5666.9375	loss_test: 5666.9346	accuracy_train: 0.2917	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 4939.9580	loss_val: 4940.0410	loss_test: 4939.8164	accuracy_train: 0.8507	accuracy_val: 0.7500	accuracy_test: 0.8889
[client 10]	loss_train: 4930.2930	loss_val: 4930.2783	loss_test: 4930.2681	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4446.2827	loss_val: 4446.1792	loss_test: 4446.5415	accuracy_train: 0.7975	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5065.2930	loss_val: 5065.3540	loss_test: 5065.4023	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11716.0312	loss_val: 11716.0156	loss_test: 11716.0400	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3107.8428	loss_val: 3107.1633	loss_test: 3107.7427	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4662.0728	loss_val: 4662.0029	loss_test: 4662.1143	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 4745.5063	loss_val: 4745.4658	loss_test: 4745.4961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5356.8730	loss_val: 5357.3071	loss_test: 5356.9136	accuracy_train: 0.8519	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 48961.8984	loss_val: 48961.4648	loss_test: 48962.1133	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6869.2310	loss_val: 6869.0918	loss_test: 6869.2017	accuracy_train: 0.7449	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 15	curr_val_accuracy: 0.7750	curr_test_accuracy: 0.7318
best_round: 15	best_val_accuracy: 0.7750	best_test_accuracy: 0.7318
--------------------------------------------------
round # 16		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8281.9570	loss_val: 8282.0527	loss_test: 8281.9873	accuracy_train: 0.7467	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 11839.7324	loss_val: 11839.8955	loss_test: 11839.5430	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 45761.6211	loss_val: 45761.5273	loss_test: 45761.6523	accuracy_train: 0.8857	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 16191.4932	loss_val: 16191.4775	loss_test: 16191.5967	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7200.1172	loss_val: 7200.1577	loss_test: 7200.1865	accuracy_train: 0.7284	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3336.7852	loss_val: 3336.7749	loss_test: 3336.7859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7837.8872	loss_val: 7837.8843	loss_test: 7837.9648	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9289.5205	loss_val: 9289.5342	loss_test: 9289.4658	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 6209.6704	loss_val: 6209.6851	loss_test: 6209.6772	accuracy_train: 0.3542	accuracy_val: 0.1667	accuracy_test: 0.2857
[client 9]	loss_train: 5366.7803	loss_val: 5366.8604	loss_test: 5366.6504	accuracy_train: 0.9403	accuracy_val: 0.8750	accuracy_test: 0.8889
[client 10]	loss_train: 5281.1060	loss_val: 5281.0933	loss_test: 5281.0854	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 4771.6538	loss_val: 4771.5483	loss_test: 4771.9351	accuracy_train: 0.8101	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5468.2773	loss_val: 5468.3389	loss_test: 5468.4194	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 12820.6777	loss_val: 12820.6562	loss_test: 12820.6943	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3372.7314	loss_val: 3372.0454	loss_test: 3372.6450	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 4930.5391	loss_val: 4930.4741	loss_test: 4930.5903	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 5060.9331	loss_val: 5060.8906	loss_test: 5060.9219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5615.1572	loss_val: 5615.5693	loss_test: 5615.2070	accuracy_train: 0.8519	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 52182.2344	loss_val: 52181.8164	loss_test: 52182.4609	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7254.9731	loss_val: 7254.8247	loss_test: 7254.9414	accuracy_train: 0.7347	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 16	curr_val_accuracy: 0.7839	curr_test_accuracy: 0.7242
best_round: 16	best_val_accuracy: 0.7839	best_test_accuracy: 0.7242
--------------------------------------------------
round # 17		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8626.0410	loss_val: 8626.1436	loss_test: 8626.0713	accuracy_train: 0.7467	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 12553.5244	loss_val: 12553.7051	loss_test: 12553.3340	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 49412.6641	loss_val: 49412.5742	loss_test: 49412.7070	accuracy_train: 0.8857	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 17495.8008	loss_val: 17495.7852	loss_test: 17495.9082	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7640.9351	loss_val: 7640.9829	loss_test: 7641.0103	accuracy_train: 0.7284	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3656.8762	loss_val: 3656.8667	loss_test: 3656.8774	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8320.6172	loss_val: 8320.6162	loss_test: 8320.6914	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9792.1904	loss_val: 9792.2002	loss_test: 9792.1377	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 6705.1567	loss_val: 6705.1855	loss_test: 6705.1709	accuracy_train: 0.5000	accuracy_val: 0.1667	accuracy_test: 0.4286
[client 9]	loss_train: 5756.1226	loss_val: 5756.2002	loss_test: 5756.0059	accuracy_train: 0.9701	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5602.2622	loss_val: 5602.2520	loss_test: 5602.2451	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5094.6216	loss_val: 5094.5137	loss_test: 5094.9282	accuracy_train: 0.7975	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 5840.5752	loss_val: 5840.6377	loss_test: 5840.7534	accuracy_train: 0.8235	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 13862.1670	loss_val: 13862.1377	loss_test: 13862.1924	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3634.4119	loss_val: 3633.7109	loss_test: 3634.3389	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5174.9268	loss_val: 5174.8647	loss_test: 5174.9878	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 5344.8413	loss_val: 5344.7988	loss_test: 5344.8301	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 5840.1147	loss_val: 5840.5078	loss_test: 5840.1733	accuracy_train: 0.8519	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 55128.4688	loss_val: 55128.0586	loss_test: 55128.7031	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7587.9624	loss_val: 7587.8071	loss_test: 7587.9292	accuracy_train: 0.7245	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 17	curr_val_accuracy: 0.7928	curr_test_accuracy: 0.7314
best_round: 17	best_val_accuracy: 0.7928	best_test_accuracy: 0.7314
--------------------------------------------------
round # 18		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8926.8770	loss_val: 8926.9863	loss_test: 8926.9092	accuracy_train: 0.7467	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13128.9414	loss_val: 13129.1396	loss_test: 13128.7549	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 52714.3359	loss_val: 52714.2500	loss_test: 52714.3945	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 18804.8828	loss_val: 18804.8672	loss_test: 18804.9941	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8024.3433	loss_val: 8024.3994	loss_test: 8024.4238	accuracy_train: 0.7284	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 3967.1746	loss_val: 3967.1660	loss_test: 3967.1760	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8743.1367	loss_val: 8743.1377	loss_test: 8743.2158	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10224.6445	loss_val: 10224.6582	loss_test: 10224.5879	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 7170.3232	loss_val: 7170.3687	loss_test: 7170.3447	accuracy_train: 0.5833	accuracy_val: 0.1667	accuracy_test: 0.5714
[client 9]	loss_train: 6129.6104	loss_val: 6129.6846	loss_test: 6129.5044	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 5877.5508	loss_val: 5877.5420	loss_test: 5877.5366	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5394.5151	loss_val: 5394.4077	loss_test: 5394.8467	accuracy_train: 0.7975	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 6176.9375	loss_val: 6177.0024	loss_test: 6177.1533	accuracy_train: 0.8529	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 14791.8232	loss_val: 14791.7861	loss_test: 14791.8574	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 3876.8787	loss_val: 3876.1807	loss_test: 3876.8257	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5387.5322	loss_val: 5387.4746	loss_test: 5387.6045	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 5584.9546	loss_val: 5584.9131	loss_test: 5584.9443	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6037.1802	loss_val: 6037.5483	loss_test: 6037.2490	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 57601.5625	loss_val: 57601.1641	loss_test: 57601.8086	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7885.3481	loss_val: 7885.1895	loss_test: 7885.3125	accuracy_train: 0.7347	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 18	curr_val_accuracy: 0.7928	curr_test_accuracy: 0.7469
best_round: 17	best_val_accuracy: 0.7928	best_test_accuracy: 0.7314
--------------------------------------------------
round # 19		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9175.1875	loss_val: 9175.3047	loss_test: 9175.2227	accuracy_train: 0.7467	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 13687.5215	loss_val: 13687.7354	loss_test: 13687.3418	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 55790.2148	loss_val: 55790.1289	loss_test: 55790.2891	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 20073.6914	loss_val: 20073.6758	loss_test: 20073.8066	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8345.3643	loss_val: 8345.4297	loss_test: 8345.4512	accuracy_train: 0.7407	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4266.5381	loss_val: 4266.5303	loss_test: 4266.5400	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9108.7988	loss_val: 9108.7988	loss_test: 9108.8789	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10601.8672	loss_val: 10601.8848	loss_test: 10601.7998	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 7594.1313	loss_val: 7594.1855	loss_test: 7594.1597	accuracy_train: 0.6458	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 6447.8135	loss_val: 6447.8853	loss_test: 6447.7163	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6108.0815	loss_val: 6108.0747	loss_test: 6108.0698	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5681.8809	loss_val: 5681.7720	loss_test: 5682.2378	accuracy_train: 0.7975	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 6450.2588	loss_val: 6450.3296	loss_test: 6450.5151	accuracy_train: 0.8529	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 15627.2002	loss_val: 15627.1582	loss_test: 15627.2432	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4118.7842	loss_val: 4118.0815	loss_test: 4118.7520	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5593.1699	loss_val: 5593.1206	loss_test: 5593.2583	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 5781.0151	loss_val: 5780.9746	loss_test: 5781.0059	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6225.5635	loss_val: 6225.9033	loss_test: 6225.6470	accuracy_train: 0.9630	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 59716.3477	loss_val: 59715.9648	loss_test: 59716.6133	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8127.4438	loss_val: 8127.2812	loss_test: 8127.4072	accuracy_train: 0.7041	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 19	curr_val_accuracy: 0.8101	curr_test_accuracy: 0.7469
best_round: 19	best_val_accuracy: 0.8101	best_test_accuracy: 0.7469
--------------------------------------------------
round # 20		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9368.6777	loss_val: 9368.8037	loss_test: 9368.7168	accuracy_train: 0.7733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14089.3750	loss_val: 14089.6045	loss_test: 14089.2090	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 58451.0781	loss_val: 58451.0000	loss_test: 58451.1758	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 21363.8984	loss_val: 21363.8828	loss_test: 21364.0156	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8629.6406	loss_val: 8629.7148	loss_test: 8629.7324	accuracy_train: 0.7407	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4548.8384	loss_val: 4548.8315	loss_test: 4548.8408	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9387.0586	loss_val: 9387.0566	loss_test: 9387.1494	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10888.4473	loss_val: 10888.4668	loss_test: 10888.3672	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 7987.2388	loss_val: 7987.2974	loss_test: 7987.2705	accuracy_train: 0.6667	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 6750.2021	loss_val: 6750.2720	loss_test: 6750.1113	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6317.8174	loss_val: 6317.8125	loss_test: 6317.8066	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5953.8198	loss_val: 5953.7109	loss_test: 5954.2021	accuracy_train: 0.7975	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 6669.5054	loss_val: 6669.5825	loss_test: 6669.8027	accuracy_train: 0.8529	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 16297.4795	loss_val: 16297.4316	loss_test: 16297.5312	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4322.6265	loss_val: 4321.9258	loss_test: 4322.6216	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5762.4258	loss_val: 5762.3789	loss_test: 5762.5352	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 5926.8647	loss_val: 5926.8267	loss_test: 5926.8574	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6407.8965	loss_val: 6408.2051	loss_test: 6408.0010	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 61264.2695	loss_val: 61263.8945	loss_test: 61264.5430	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8304.7842	loss_val: 8304.6182	loss_test: 8304.7461	accuracy_train: 0.7041	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 20	curr_val_accuracy: 0.8274	curr_test_accuracy: 0.7543
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 21		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9518.9531	loss_val: 9519.0889	loss_test: 9518.9971	accuracy_train: 0.7733	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14454.2373	loss_val: 14454.4863	loss_test: 14454.0850	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 60562.7305	loss_val: 60562.6562	loss_test: 60562.8477	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 22505.4082	loss_val: 22505.3945	loss_test: 22505.5273	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8855.8037	loss_val: 8855.8867	loss_test: 8855.9004	accuracy_train: 0.7654	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 4811.3213	loss_val: 4811.3149	loss_test: 4811.3242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9599.4170	loss_val: 9599.4131	loss_test: 9599.5156	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 11139.0986	loss_val: 11139.1182	loss_test: 11139.0020	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 8402.9863	loss_val: 8403.0488	loss_test: 8403.0215	accuracy_train: 0.6667	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 7029.9692	loss_val: 7030.0342	loss_test: 7029.8843	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6484.4165	loss_val: 6484.4146	loss_test: 6484.4072	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6178.3066	loss_val: 6178.1987	loss_test: 6178.7153	accuracy_train: 0.7848	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 6870.8970	loss_val: 6870.9829	loss_test: 6871.2402	accuracy_train: 0.8529	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 16851.9062	loss_val: 16851.8516	loss_test: 16851.9648	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4510.0718	loss_val: 4509.3818	loss_test: 4510.0981	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5897.8486	loss_val: 5897.8027	loss_test: 5897.9790	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 6027.5151	loss_val: 6027.4785	loss_test: 6027.5093	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6572.6650	loss_val: 6572.9429	loss_test: 6572.7930	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 62471.4570	loss_val: 62471.0938	loss_test: 62471.7422	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8443.2754	loss_val: 8443.1055	loss_test: 8443.2363	accuracy_train: 0.6939	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 21	curr_val_accuracy: 0.8187	curr_test_accuracy: 0.7469
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 22		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9616.4854	loss_val: 9616.6309	loss_test: 9616.5361	accuracy_train: 0.7867	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14690.8105	loss_val: 14691.0742	loss_test: 14690.6729	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 62324.6094	loss_val: 62324.5430	loss_test: 62324.7500	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 23662.7188	loss_val: 23662.7070	loss_test: 23662.8398	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9025.9219	loss_val: 9026.0146	loss_test: 9026.0244	accuracy_train: 0.7531	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5053.4810	loss_val: 5053.4751	loss_test: 5053.4839	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9753.7441	loss_val: 9753.7383	loss_test: 9753.8506	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 11301.5420	loss_val: 11301.5586	loss_test: 11301.4287	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 8753.6279	loss_val: 8753.6982	loss_test: 8753.6670	accuracy_train: 0.7083	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 7252.8633	loss_val: 7252.9248	loss_test: 7252.7832	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6622.5361	loss_val: 6622.5371	loss_test: 6622.5278	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6373.3843	loss_val: 6373.2798	loss_test: 6373.8203	accuracy_train: 0.7848	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 7030.9395	loss_val: 7031.0342	loss_test: 7031.3364	accuracy_train: 0.8529	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 17218.6250	loss_val: 17218.5645	loss_test: 17218.6914	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4658.8574	loss_val: 4658.1826	loss_test: 4658.9146	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5989.6035	loss_val: 5989.5625	loss_test: 5989.7529	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 6101.8179	loss_val: 6101.7827	loss_test: 6101.8130	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6713.2061	loss_val: 6713.4565	loss_test: 6713.3633	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 63088.8203	loss_val: 63088.4648	loss_test: 63089.1172	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8511.9990	loss_val: 8511.8291	loss_test: 8511.9629	accuracy_train: 0.6939	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 22	curr_val_accuracy: 0.8187	curr_test_accuracy: 0.7469
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 23		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9669.8643	loss_val: 9670.0205	loss_test: 9669.9238	accuracy_train: 0.8267	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14892.2637	loss_val: 14892.5488	loss_test: 14892.1426	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 63420.4961	loss_val: 63420.4375	loss_test: 63420.6562	accuracy_train: 0.8857	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 24719.2168	loss_val: 24719.2051	loss_test: 24719.3379	accuracy_train: 0.9833	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9135.0244	loss_val: 9135.1270	loss_test: 9135.1328	accuracy_train: 0.7531	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5268.9678	loss_val: 5268.9624	loss_test: 5268.9702	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9881.5078	loss_val: 9881.5020	loss_test: 9881.6211	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 11386.7451	loss_val: 11386.7588	loss_test: 11386.6123	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9040.8711	loss_val: 9040.9492	loss_test: 9040.9141	accuracy_train: 0.7083	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7481.6108	loss_val: 7481.6670	loss_test: 7481.5356	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6727.2300	loss_val: 6727.2334	loss_test: 6727.2222	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6528.3013	loss_val: 6528.2017	loss_test: 6528.7642	accuracy_train: 0.7848	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 7136.2212	loss_val: 7136.3271	loss_test: 7136.6797	accuracy_train: 0.8824	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 17499.2305	loss_val: 17499.1680	loss_test: 17499.3027	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4782.5762	loss_val: 4781.9165	loss_test: 4782.6660	accuracy_train: 0.5714	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6074.5103	loss_val: 6074.4751	loss_test: 6074.6821	accuracy_train: 0.5455	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 6103.8511	loss_val: 6103.8174	loss_test: 6103.8467	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6856.1870	loss_val: 6856.4204	loss_test: 6856.3716	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 63418.8281	loss_val: 63418.4844	loss_test: 63419.1367	accuracy_train: 0.8000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8519.7578	loss_val: 8519.5869	loss_test: 8519.7236	accuracy_train: 0.7143	accuracy_val: 0.8333	accuracy_test: 0.6154
curr_round: 23	curr_val_accuracy: 0.8274	curr_test_accuracy: 0.7469
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 24		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9673.0264	loss_val: 9673.1943	loss_test: 9673.0957	accuracy_train: 0.8400	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14981.5703	loss_val: 14981.8750	loss_test: 14981.4717	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 64103.3086	loss_val: 64103.2578	loss_test: 64103.4961	accuracy_train: 0.8857	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 25714.6758	loss_val: 25714.6680	loss_test: 25714.7969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9161.7178	loss_val: 9161.8330	loss_test: 9161.8320	accuracy_train: 0.7654	accuracy_val: 0.6000	accuracy_test: 0.6364
[client 5]	loss_train: 5434.5776	loss_val: 5434.5728	loss_test: 5434.5796	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9909.2451	loss_val: 9909.2383	loss_test: 9909.3662	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 11415.9463	loss_val: 11415.9590	loss_test: 11415.7949	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9316.9766	loss_val: 9317.0605	loss_test: 9317.0225	accuracy_train: 0.7083	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7661.8940	loss_val: 7661.9468	loss_test: 7661.8228	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6808.5825	loss_val: 6808.5884	loss_test: 6808.5757	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6616.7715	loss_val: 6616.6821	loss_test: 6617.2598	accuracy_train: 0.7975	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 7208.9277	loss_val: 7209.0459	loss_test: 7209.4502	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 17596.2617	loss_val: 17596.1973	loss_test: 17596.3398	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4898.7793	loss_val: 4898.1416	loss_test: 4898.9106	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6138.8994	loss_val: 6138.8696	loss_test: 6139.0981	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 6048.2949	loss_val: 6048.2622	loss_test: 6048.2910	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 6969.5132	loss_val: 6969.7266	loss_test: 6969.7290	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 63602.9336	loss_val: 63602.5977	loss_test: 63603.2500	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8464.6289	loss_val: 8464.4619	loss_test: 8464.6016	accuracy_train: 0.7143	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 24	curr_val_accuracy: 0.8199	curr_test_accuracy: 0.7549
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 25		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9618.6172	loss_val: 9618.7969	loss_test: 9618.6963	accuracy_train: 0.8400	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14958.0137	loss_val: 14958.3447	loss_test: 14957.9346	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 64525.6250	loss_val: 64525.5859	loss_test: 64525.8359	accuracy_train: 0.9143	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 26762.7090	loss_val: 26762.7031	loss_test: 26762.8281	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9173.8027	loss_val: 9173.9326	loss_test: 9173.9209	accuracy_train: 0.7778	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5576.9404	loss_val: 5576.9360	loss_test: 5576.9419	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9854.8594	loss_val: 9854.8516	loss_test: 9854.9873	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 11411.9521	loss_val: 11411.9570	loss_test: 11411.7861	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9523.6191	loss_val: 9523.7197	loss_test: 9523.6748	accuracy_train: 0.7917	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7791.2573	loss_val: 7791.3081	loss_test: 7791.1885	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6862.4868	loss_val: 6862.4961	loss_test: 6862.4810	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6698.5513	loss_val: 6698.4717	loss_test: 6699.0688	accuracy_train: 0.8228	accuracy_val: 0.9000	accuracy_test: 0.5000
[client 12]	loss_train: 7229.1357	loss_val: 7229.2686	loss_test: 7229.7261	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 17627.9434	loss_val: 17627.8770	loss_test: 17628.0273	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 4988.1421	loss_val: 4987.5298	loss_test: 4988.3218	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6149.0234	loss_val: 6149.0010	loss_test: 6149.2490	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 5957.8311	loss_val: 5957.7988	loss_test: 5957.8276	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7073.8745	loss_val: 7074.0708	loss_test: 7074.1235	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 63284.2305	loss_val: 63283.9062	loss_test: 63284.5586	accuracy_train: 0.9000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8335.6553	loss_val: 8335.4951	loss_test: 8335.6377	accuracy_train: 0.7245	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 25	curr_val_accuracy: 0.8199	curr_test_accuracy: 0.7628
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 26		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9516.2783	loss_val: 9516.4707	loss_test: 9516.3711	accuracy_train: 0.8400	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14907.2432	loss_val: 14907.5996	loss_test: 14907.1885	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 64356.8047	loss_val: 64356.7812	loss_test: 64357.0391	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 27837.0820	loss_val: 27837.0801	loss_test: 27837.1992	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9130.9141	loss_val: 9131.0654	loss_test: 9131.0332	accuracy_train: 0.7778	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5686.0371	loss_val: 5686.0327	loss_test: 5686.0381	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9757.0020	loss_val: 9756.9922	loss_test: 9757.1338	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 11323.6084	loss_val: 11323.5996	loss_test: 11323.4287	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9688.3057	loss_val: 9688.4229	loss_test: 9688.3721	accuracy_train: 0.8542	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 7925.5044	loss_val: 7925.5532	loss_test: 7925.4365	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6905.8296	loss_val: 6905.8408	loss_test: 6905.8247	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6713.6230	loss_val: 6713.5586	loss_test: 6714.1675	accuracy_train: 0.8354	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 7217.4814	loss_val: 7217.6284	loss_test: 7218.1548	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 17480.2539	loss_val: 17480.1895	loss_test: 17480.3438	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5044.2378	loss_val: 5043.6553	loss_test: 5044.4624	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6139.9849	loss_val: 6139.9692	loss_test: 6140.2344	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 5843.9053	loss_val: 5843.8740	loss_test: 5843.9014	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7179.4399	loss_val: 7179.6177	loss_test: 7179.7266	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 62758.9531	loss_val: 62758.6406	loss_test: 62759.2891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8196.3340	loss_val: 8196.1816	loss_test: 8196.3242	accuracy_train: 0.7245	accuracy_val: 0.8333	accuracy_test: 0.6923
curr_round: 26	curr_val_accuracy: 0.8115	curr_test_accuracy: 0.7628
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 27		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9359.2334	loss_val: 9359.4395	loss_test: 9359.3408	accuracy_train: 0.8400	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14849.7949	loss_val: 14850.1787	loss_test: 14849.7607	accuracy_train: 0.8000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 64063.0000	loss_val: 64062.9922	loss_test: 64063.2578	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 28873.9238	loss_val: 28873.9238	loss_test: 28874.0371	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 9064.5869	loss_val: 9064.7646	loss_test: 9064.7070	accuracy_train: 0.7778	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5772.8745	loss_val: 5772.8701	loss_test: 5772.8750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9604.0723	loss_val: 9604.0605	loss_test: 9604.2070	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 11180.5107	loss_val: 11180.4873	loss_test: 11180.3193	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9797.1230	loss_val: 9797.2627	loss_test: 9797.2061	accuracy_train: 0.8958	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8020.6118	loss_val: 8020.6597	loss_test: 8020.5454	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6938.5562	loss_val: 6938.5698	loss_test: 6938.5522	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6691.4136	loss_val: 6691.3667	loss_test: 6691.9858	accuracy_train: 0.8481	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 7159.7197	loss_val: 7159.8857	loss_test: 7160.4688	accuracy_train: 0.8824	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 17280.1074	loss_val: 17280.0430	loss_test: 17280.1992	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5091.0679	loss_val: 5090.5156	loss_test: 5091.3423	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6098.0010	loss_val: 6097.9941	loss_test: 6098.2778	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 16]	loss_train: 5711.9648	loss_val: 5711.9331	loss_test: 5711.9604	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7280.7510	loss_val: 7280.9224	loss_test: 7281.0737	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 62160.8711	loss_val: 62160.5703	loss_test: 62161.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 8045.1436	loss_val: 8044.9985	loss_test: 8045.1426	accuracy_train: 0.7245	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 27	curr_val_accuracy: 0.8115	curr_test_accuracy: 0.7708
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 28		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 9175.7793	loss_val: 9176.0000	loss_test: 9175.9023	accuracy_train: 0.8400	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14727.6738	loss_val: 14728.0801	loss_test: 14727.6631	accuracy_train: 0.8667	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 63573.0859	loss_val: 63573.0938	loss_test: 63573.3633	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 29889.1582	loss_val: 29889.1602	loss_test: 29889.2656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8977.8027	loss_val: 8978.0117	loss_test: 8977.9209	accuracy_train: 0.7778	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5826.3389	loss_val: 5826.3345	loss_test: 5826.3389	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9437.0068	loss_val: 9436.9961	loss_test: 9437.1436	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10983.5684	loss_val: 10983.5244	loss_test: 10983.3672	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9834.1240	loss_val: 9834.2930	loss_test: 9834.2295	accuracy_train: 0.9167	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8098.1562	loss_val: 8098.2036	loss_test: 8098.0898	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6952.4336	loss_val: 6952.4497	loss_test: 6952.4307	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6645.6670	loss_val: 6645.6382	loss_test: 6646.2695	accuracy_train: 0.8481	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 7075.0947	loss_val: 7075.2856	loss_test: 7075.9043	accuracy_train: 0.9118	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 16973.4922	loss_val: 16973.4297	loss_test: 16973.5898	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5133.6421	loss_val: 5133.1196	loss_test: 5133.9746	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 6052.9639	loss_val: 6052.9712	loss_test: 6053.2729	accuracy_train: 0.5909	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 16]	loss_train: 5565.4775	loss_val: 5565.4448	loss_test: 5565.4722	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7348.5273	loss_val: 7348.6899	loss_test: 7348.8950	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 61146.6016	loss_val: 61146.3164	loss_test: 61146.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7902.3032	loss_val: 7902.1675	loss_test: 7902.3120	accuracy_train: 0.7653	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 28	curr_val_accuracy: 0.8115	curr_test_accuracy: 0.7878
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 29		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8975.2119	loss_val: 8975.4492	loss_test: 8975.3525	accuracy_train: 0.8800	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14481.2939	loss_val: 14481.7266	loss_test: 14481.3047	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 62572.8867	loss_val: 62572.9141	loss_test: 62573.1797	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 30962.8223	loss_val: 30962.8262	loss_test: 30962.9238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8901.3105	loss_val: 8901.5557	loss_test: 8901.4287	accuracy_train: 0.7901	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5860.8550	loss_val: 5860.8511	loss_test: 5860.8545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9251.4648	loss_val: 9251.4561	loss_test: 9251.6006	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10750.4277	loss_val: 10750.3682	loss_test: 10750.2207	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9861.1865	loss_val: 9861.3799	loss_test: 9861.3057	accuracy_train: 0.9167	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8128.9102	loss_val: 8128.9590	loss_test: 8128.8438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6966.2422	loss_val: 6966.2607	loss_test: 6966.2397	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6580.3062	loss_val: 6580.2974	loss_test: 6580.9360	accuracy_train: 0.8481	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6970.4253	loss_val: 6970.6455	loss_test: 6971.2935	accuracy_train: 0.9118	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 16612.3047	loss_val: 16612.2441	loss_test: 16612.4062	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5148.6328	loss_val: 5148.1440	loss_test: 5149.0215	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5987.3999	loss_val: 5987.4204	loss_test: 5987.7441	accuracy_train: 0.6818	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 16]	loss_train: 5422.9375	loss_val: 5422.9038	loss_test: 5422.9316	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7391.9795	loss_val: 7392.1431	loss_test: 7392.3813	accuracy_train: 0.9259	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 59973.5508	loss_val: 59973.2734	loss_test: 59973.9062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7760.3477	loss_val: 7760.2197	loss_test: 7760.3662	accuracy_train: 0.7755	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 29	curr_val_accuracy: 0.8202	curr_test_accuracy: 0.7878
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 30		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8734.3066	loss_val: 8734.5596	loss_test: 8734.4629	accuracy_train: 0.9067	accuracy_val: 0.7000	accuracy_test: 0.9000
[client 1]	loss_train: 14192.8857	loss_val: 14193.3252	loss_test: 14192.9170	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 61787.5078	loss_val: 61787.5547	loss_test: 61787.8164	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 32218.6094	loss_val: 32218.6152	loss_test: 32218.7070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8787.8877	loss_val: 8788.1719	loss_test: 8788.0107	accuracy_train: 0.8025	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5870.6055	loss_val: 5870.6011	loss_test: 5870.6045	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9046.3369	loss_val: 9046.3301	loss_test: 9046.4727	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10503.7510	loss_val: 10503.6748	loss_test: 10503.5391	accuracy_train: 0.2381	accuracy_val: 0.2000	accuracy_test: 0.2857
[client 8]	loss_train: 9897.2480	loss_val: 9897.4600	loss_test: 9897.3789	accuracy_train: 0.9375	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 8186.8643	loss_val: 8186.9146	loss_test: 8186.7979	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6949.0601	loss_val: 6949.0820	loss_test: 6949.0591	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6459.2241	loss_val: 6459.2388	loss_test: 6459.8760	accuracy_train: 0.8481	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6831.5117	loss_val: 6831.7637	loss_test: 6832.4180	accuracy_train: 0.9412	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 16223.9209	loss_val: 16223.8643	loss_test: 16224.0273	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5207.7720	loss_val: 5207.3081	loss_test: 5208.2129	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5902.5913	loss_val: 5902.6191	loss_test: 5902.9697	accuracy_train: 0.6818	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 16]	loss_train: 5269.5112	loss_val: 5269.4756	loss_test: 5269.5044	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7431.4204	loss_val: 7431.5786	loss_test: 7431.8594	accuracy_train: 0.9630	accuracy_val: 0.5000	accuracy_test: 0.7500
[client 18]	loss_train: 58741.4766	loss_val: 58741.2109	loss_test: 58741.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7623.2544	loss_val: 7623.1328	loss_test: 7623.2817	accuracy_train: 0.7755	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 30	curr_val_accuracy: 0.8115	curr_test_accuracy: 0.7878
best_round: 20	best_val_accuracy: 0.8274	best_test_accuracy: 0.7543
--------------------------------------------------
round # 31		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8507.3232	loss_val: 8507.5918	loss_test: 8507.4922	accuracy_train: 0.9333	accuracy_val: 0.8000	accuracy_test: 0.9000
[client 1]	loss_train: 13970.0605	loss_val: 13970.5098	loss_test: 13970.1143	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 60877.4023	loss_val: 60877.4688	loss_test: 60877.7305	accuracy_train: 0.9429	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 33341.6641	loss_val: 33341.6680	loss_test: 33341.7539	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8682.2832	loss_val: 8682.6133	loss_test: 8682.4102	accuracy_train: 0.8025	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5858.6636	loss_val: 5858.6597	loss_test: 5858.6621	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8832.3779	loss_val: 8832.3740	loss_test: 8832.5117	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 10234.9209	loss_val: 10234.8330	loss_test: 10234.7041	accuracy_train: 0.2381	accuracy_val: 0.4000	accuracy_test: 0.2857
[client 8]	loss_train: 9931.1240	loss_val: 9931.3438	loss_test: 9931.2607	accuracy_train: 0.9375	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8288.4131	loss_val: 8288.4668	loss_test: 8288.3486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6941.2905	loss_val: 6941.3159	loss_test: 6941.2910	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6296.7856	loss_val: 6296.8267	loss_test: 6297.4551	accuracy_train: 0.8481	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6675.6182	loss_val: 6675.9014	loss_test: 6676.5557	accuracy_train: 0.9412	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 15792.0957	loss_val: 15792.0459	loss_test: 15792.2080	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5227.3115	loss_val: 5226.8813	loss_test: 5227.8081	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5814.4946	loss_val: 5814.5337	loss_test: 5814.9121	accuracy_train: 0.7727	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 5123.2896	loss_val: 5123.2529	loss_test: 5123.2822	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7469.2622	loss_val: 7469.4097	loss_test: 7469.7441	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 57709.5117	loss_val: 57709.2539	loss_test: 57709.8711	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7477.8589	loss_val: 7477.7534	loss_test: 7477.9048	accuracy_train: 0.7959	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 31	curr_val_accuracy: 0.8406	curr_test_accuracy: 0.7789
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 32		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8293.2188	loss_val: 8293.5068	loss_test: 8293.4033	accuracy_train: 0.9467	accuracy_val: 0.8000	accuracy_test: 0.9000
[client 1]	loss_train: 13746.5010	loss_val: 13746.9600	loss_test: 13746.5771	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 59951.6562	loss_val: 59951.7422	loss_test: 59952.0039	accuracy_train: 0.9429	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 34431.7266	loss_val: 34431.7305	loss_test: 34431.8086	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8584.4473	loss_val: 8584.8281	loss_test: 8584.5801	accuracy_train: 0.8148	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5832.1860	loss_val: 5832.1816	loss_test: 5832.1831	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8625.0273	loss_val: 8625.0244	loss_test: 8625.1602	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9933.2812	loss_val: 9933.1816	loss_test: 9933.0596	accuracy_train: 0.2381	accuracy_val: 0.4000	accuracy_test: 0.2857
[client 8]	loss_train: 9876.5156	loss_val: 9876.7588	loss_test: 9876.6768	accuracy_train: 0.9375	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8363.6123	loss_val: 8363.6689	loss_test: 8363.5488	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6921.8442	loss_val: 6921.8721	loss_test: 6921.8472	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 6121.0117	loss_val: 6121.0801	loss_test: 6121.6973	accuracy_train: 0.8608	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6509.9995	loss_val: 6510.3115	loss_test: 6510.9673	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 15419.4844	loss_val: 15419.4424	loss_test: 15419.6074	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5209.9121	loss_val: 5209.5234	loss_test: 5210.4663	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5729.3672	loss_val: 5729.4165	loss_test: 5729.8242	accuracy_train: 0.8182	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4972.8901	loss_val: 4972.8525	loss_test: 4972.8818	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7523.7935	loss_val: 7523.9321	loss_test: 7524.3169	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 56738.3594	loss_val: 56738.1094	loss_test: 56738.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7355.2544	loss_val: 7355.1641	loss_test: 7355.3179	accuracy_train: 0.8163	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 32	curr_val_accuracy: 0.8406	curr_test_accuracy: 0.7789
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 33		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 8061.0552	loss_val: 8061.3638	loss_test: 8061.2554	accuracy_train: 0.9467	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13597.7275	loss_val: 13598.1846	loss_test: 13597.8252	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 59131.1875	loss_val: 59131.2852	loss_test: 59131.5547	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 35503.9805	loss_val: 35503.9844	loss_test: 35504.0586	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8508.6084	loss_val: 8509.0518	loss_test: 8508.7471	accuracy_train: 0.8889	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5784.4302	loss_val: 5784.4258	loss_test: 5784.4263	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8412.2129	loss_val: 8412.2129	loss_test: 8412.3457	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9618.0889	loss_val: 9617.9834	loss_test: 9617.8750	accuracy_train: 0.2381	accuracy_val: 0.4000	accuracy_test: 0.2857
[client 8]	loss_train: 9870.6826	loss_val: 9870.9385	loss_test: 9870.8564	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8464.8037	loss_val: 8464.8633	loss_test: 8464.7412	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6897.7871	loss_val: 6897.8179	loss_test: 6897.7935	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5934.0190	loss_val: 5934.1167	loss_test: 5934.7197	accuracy_train: 0.8861	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6352.0137	loss_val: 6352.3545	loss_test: 6353.0044	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 15006.9629	loss_val: 15006.9316	loss_test: 15007.0947	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5197.5117	loss_val: 5197.1680	loss_test: 5198.1333	accuracy_train: 0.7143	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5642.2842	loss_val: 5642.3486	loss_test: 5642.7793	accuracy_train: 0.8636	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4828.2559	loss_val: 4828.2183	loss_test: 4828.2480	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7550.8438	loss_val: 7550.9775	loss_test: 7551.4038	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 55545.9414	loss_val: 55545.6992	loss_test: 55546.3008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7249.8672	loss_val: 7249.7881	loss_test: 7249.9463	accuracy_train: 0.8571	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 33	curr_val_accuracy: 0.8406	curr_test_accuracy: 0.7709
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 34		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7842.9697	loss_val: 7843.3003	loss_test: 7843.1841	accuracy_train: 0.9600	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13403.7510	loss_val: 13404.1982	loss_test: 13403.8701	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 58400.1211	loss_val: 58400.2266	loss_test: 58400.5156	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 36822.7305	loss_val: 36822.7344	loss_test: 36822.8008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8467.0996	loss_val: 8467.6113	loss_test: 8467.2461	accuracy_train: 0.9506	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5704.6143	loss_val: 5704.6104	loss_test: 5704.6104	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8207.0850	loss_val: 8207.0879	loss_test: 8207.2188	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 9303.3877	loss_val: 9303.2764	loss_test: 9303.1895	accuracy_train: 0.2619	accuracy_val: 0.4000	accuracy_test: 0.2857
[client 8]	loss_train: 9852.8164	loss_val: 9853.0830	loss_test: 9853.0010	accuracy_train: 0.9583	accuracy_val: 0.8333	accuracy_test: 0.5714
[client 9]	loss_train: 8580.5527	loss_val: 8580.6162	loss_test: 8580.4912	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6887.1641	loss_val: 6887.1978	loss_test: 6887.1743	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5750.2358	loss_val: 5750.3638	loss_test: 5750.9473	accuracy_train: 0.9241	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6186.6777	loss_val: 6187.0483	loss_test: 6187.6948	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 14558.6377	loss_val: 14558.6182	loss_test: 14558.7832	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5182.0786	loss_val: 5181.7759	loss_test: 5182.7681	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5525.7720	loss_val: 5525.8525	loss_test: 5526.3057	accuracy_train: 0.8636	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4682.1006	loss_val: 4682.0625	loss_test: 4682.0923	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7542.3618	loss_val: 7542.5024	loss_test: 7542.9482	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 54497.2109	loss_val: 54496.9727	loss_test: 54497.5625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7143.2920	loss_val: 7143.2329	loss_test: 7143.3911	accuracy_train: 0.8878	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 34	curr_val_accuracy: 0.8406	curr_test_accuracy: 0.7709
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 35		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7600.2280	loss_val: 7600.5815	loss_test: 7600.4556	accuracy_train: 0.9733	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13259.8750	loss_val: 13260.3115	loss_test: 13260.0117	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 57793.6641	loss_val: 57793.7812	loss_test: 57794.0781	accuracy_train: 0.9714	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 38165.9688	loss_val: 38165.9688	loss_test: 38166.0352	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 8415.3613	loss_val: 8415.9414	loss_test: 8415.5176	accuracy_train: 0.9753	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5623.1738	loss_val: 5623.1699	loss_test: 5623.1689	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8037.4414	loss_val: 8037.4482	loss_test: 8037.5776	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8992.5381	loss_val: 8992.4229	loss_test: 8992.3633	accuracy_train: 0.2857	accuracy_val: 0.4000	accuracy_test: 0.2857
[client 8]	loss_train: 9858.8320	loss_val: 9859.1016	loss_test: 9859.0215	accuracy_train: 0.9583	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 8716.4844	loss_val: 8716.5508	loss_test: 8716.4248	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6879.2783	loss_val: 6879.3140	loss_test: 6879.2910	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5587.2808	loss_val: 5587.4380	loss_test: 5588.0010	accuracy_train: 0.9367	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 6043.8252	loss_val: 6044.2231	loss_test: 6044.8628	accuracy_train: 0.9706	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 14135.6113	loss_val: 14135.6035	loss_test: 14135.7666	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5193.2383	loss_val: 5192.9736	loss_test: 5194.0210	accuracy_train: 0.8571	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5430.3906	loss_val: 5430.4858	loss_test: 5430.9653	accuracy_train: 0.9091	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4569.5015	loss_val: 4569.4634	loss_test: 4569.4927	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7525.7876	loss_val: 7525.9404	loss_test: 7526.3979	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 53673.6797	loss_val: 53673.4492	loss_test: 53674.0273	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7071.1816	loss_val: 7071.1401	loss_test: 7071.2964	accuracy_train: 0.9082	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 35	curr_val_accuracy: 0.8320	curr_test_accuracy: 0.7789
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 36		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7396.0488	loss_val: 7396.4233	loss_test: 7396.2871	accuracy_train: 0.9733	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13150.4688	loss_val: 13150.8857	loss_test: 13150.6211	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 57397.7266	loss_val: 57397.8516	loss_test: 57398.1602	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 39498.1094	loss_val: 39498.1094	loss_test: 39498.1719	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8363.0938	loss_val: 8363.7412	loss_test: 8363.2598	accuracy_train: 0.9753	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5532.3716	loss_val: 5532.3682	loss_test: 5532.3667	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7905.8267	loss_val: 7905.8384	loss_test: 7905.9673	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8736.7217	loss_val: 8736.6133	loss_test: 8736.5693	accuracy_train: 0.2857	accuracy_val: 0.4000	accuracy_test: 0.4286
[client 8]	loss_train: 9903.8613	loss_val: 9904.1289	loss_test: 9904.0527	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.7143
[client 9]	loss_train: 8887.4736	loss_val: 8887.5430	loss_test: 8887.4131	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6866.6660	loss_val: 6866.7036	loss_test: 6866.6807	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5457.2437	loss_val: 5457.4258	loss_test: 5457.9688	accuracy_train: 0.9494	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5927.0488	loss_val: 5927.4717	loss_test: 5928.1055	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13753.9238	loss_val: 13753.9277	loss_test: 13754.0918	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5187.9351	loss_val: 5187.6997	loss_test: 5188.8081	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5337.5273	loss_val: 5337.6338	loss_test: 5338.1382	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4469.1445	loss_val: 4469.1050	loss_test: 4469.1343	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7521.7588	loss_val: 7521.9346	loss_test: 7522.3809	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 52985.1602	loss_val: 52984.9336	loss_test: 52985.5000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7003.3516	loss_val: 7003.3262	loss_test: 7003.4805	accuracy_train: 0.9286	accuracy_val: 0.8333	accuracy_test: 0.8462
curr_round: 36	curr_val_accuracy: 0.8147	curr_test_accuracy: 0.8000
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 37		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7263.4106	loss_val: 7263.8057	loss_test: 7263.6626	accuracy_train: 0.9733	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13087.7236	loss_val: 13088.1133	loss_test: 13087.8906	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 56920.7656	loss_val: 56920.9062	loss_test: 56921.2188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 40869.3789	loss_val: 40869.3750	loss_test: 40869.4336	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8348.4580	loss_val: 8349.1680	loss_test: 8348.6357	accuracy_train: 0.9753	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5422.3213	loss_val: 5422.3193	loss_test: 5422.3169	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7786.1719	loss_val: 7786.1870	loss_test: 7786.3174	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8522.2979	loss_val: 8522.2070	loss_test: 8522.1631	accuracy_train: 0.2857	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 9920.5078	loss_val: 9920.7842	loss_test: 9920.7109	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 9076.3867	loss_val: 9076.4580	loss_test: 9076.3252	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6871.0532	loss_val: 6871.0928	loss_test: 6871.0688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5365.6411	loss_val: 5365.8472	loss_test: 5366.3770	accuracy_train: 0.9620	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5803.3545	loss_val: 5803.8037	loss_test: 5804.4487	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13386.8711	loss_val: 13386.8877	loss_test: 13387.0527	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5211.5874	loss_val: 5211.3755	loss_test: 5212.5327	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 15]	loss_train: 5255.1436	loss_val: 5255.2607	loss_test: 5255.7935	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4377.8862	loss_val: 4377.8447	loss_test: 4377.8745	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7505.8901	loss_val: 7506.0840	loss_test: 7506.5317	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 52417.8086	loss_val: 52417.5859	loss_test: 52418.1406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6962.8945	loss_val: 6962.8823	loss_test: 6963.0371	accuracy_train: 0.9388	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 37	curr_val_accuracy: 0.8326	curr_test_accuracy: 0.7992
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 38		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7159.1318	loss_val: 7159.5430	loss_test: 7159.3989	accuracy_train: 0.9733	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13063.0527	loss_val: 13063.4141	loss_test: 13063.2295	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 56378.4805	loss_val: 56378.6445	loss_test: 56378.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 42616.1758	loss_val: 42616.1719	loss_test: 42616.2227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8311.9277	loss_val: 8312.6973	loss_test: 8312.1172	accuracy_train: 0.9877	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5346.3467	loss_val: 5346.3457	loss_test: 5346.3418	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7689.7964	loss_val: 7689.8149	loss_test: 7689.9448	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8295.8828	loss_val: 8295.8096	loss_test: 8295.7656	accuracy_train: 0.3571	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10019.5928	loss_val: 10019.8691	loss_test: 10019.8008	accuracy_train: 0.9375	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 9282.1680	loss_val: 9282.2422	loss_test: 9282.1074	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6903.7339	loss_val: 6903.7764	loss_test: 6903.7485	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5282.3604	loss_val: 5282.5864	loss_test: 5283.1030	accuracy_train: 0.9620	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5694.9214	loss_val: 5695.3921	loss_test: 5696.0679	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 13027.5635	loss_val: 13027.5918	loss_test: 13027.7607	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5221.1895	loss_val: 5221.0034	loss_test: 5222.2319	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5178.0508	loss_val: 5178.1797	loss_test: 5178.7388	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4315.9507	loss_val: 4315.9082	loss_test: 4315.9375	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7509.0996	loss_val: 7509.3057	loss_test: 7509.7578	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 52019.5469	loss_val: 52019.3320	loss_test: 52019.8828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6954.7856	loss_val: 6954.7861	loss_test: 6954.9404	accuracy_train: 0.9490	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 38	curr_val_accuracy: 0.8326	curr_test_accuracy: 0.7949
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 39		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7160.3154	loss_val: 7160.7412	loss_test: 7160.5942	accuracy_train: 0.9733	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13003.2041	loss_val: 13003.5449	loss_test: 13003.3877	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 56007.3438	loss_val: 56007.5312	loss_test: 56007.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 44463.3164	loss_val: 44463.3086	loss_test: 44463.3594	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8247.6514	loss_val: 8248.4814	loss_test: 8247.8535	accuracy_train: 0.9877	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5274.6567	loss_val: 5274.6562	loss_test: 5274.6519	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7624.7383	loss_val: 7624.7588	loss_test: 7624.8892	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 8069.7324	loss_val: 8069.6836	loss_test: 8069.6377	accuracy_train: 0.4048	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10021.8613	loss_val: 10022.1533	loss_test: 10022.0957	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 9519.9756	loss_val: 9520.0488	loss_test: 9519.9141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 6945.6382	loss_val: 6945.6821	loss_test: 6945.6528	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5214.6987	loss_val: 5214.9385	loss_test: 5215.4482	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5595.4233	loss_val: 5595.9131	loss_test: 5596.6392	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12726.7588	loss_val: 12726.7959	loss_test: 12726.9736	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5239.8325	loss_val: 5239.6626	loss_test: 5240.9316	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5121.9395	loss_val: 5122.0791	loss_test: 5122.6606	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4262.4092	loss_val: 4262.3657	loss_test: 4262.3950	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7529.5889	loss_val: 7529.8032	loss_test: 7530.2500	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 51982.9805	loss_val: 51982.7734	loss_test: 51983.3203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6939.7832	loss_val: 6939.7959	loss_test: 6939.9517	accuracy_train: 0.9694	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 39	curr_val_accuracy: 0.8326	curr_test_accuracy: 0.7949
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 40		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7161.9141	loss_val: 7162.3589	loss_test: 7162.2036	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 12981.1162	loss_val: 12981.4316	loss_test: 12981.3027	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 1.0000
[client 2]	loss_train: 56174.6641	loss_val: 56174.8555	loss_test: 56175.1797	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 46745.2148	loss_val: 46745.2031	loss_test: 46745.2461	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8193.0693	loss_val: 8193.9619	loss_test: 8193.2852	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5213.8408	loss_val: 5213.8413	loss_test: 5213.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7576.9795	loss_val: 7577.0010	loss_test: 7577.1343	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7839.4404	loss_val: 7839.4209	loss_test: 7839.3765	accuracy_train: 0.4048	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10096.0195	loss_val: 10096.3174	loss_test: 10096.2725	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 9791.0850	loss_val: 9791.1592	loss_test: 9791.0244	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7019.5762	loss_val: 7019.6211	loss_test: 7019.5903	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5178.9248	loss_val: 5179.1802	loss_test: 5179.6851	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5535.2930	loss_val: 5535.8062	loss_test: 5536.5479	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12467.7568	loss_val: 12467.7979	loss_test: 12467.9893	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5261.8877	loss_val: 5261.7393	loss_test: 5263.1060	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5069.5103	loss_val: 5069.6562	loss_test: 5070.2661	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4224.2109	loss_val: 4224.1665	loss_test: 4224.1958	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7565.7251	loss_val: 7565.9434	loss_test: 7566.3926	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 52066.4727	loss_val: 52066.2734	loss_test: 52066.8164	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6941.0552	loss_val: 6941.0811	loss_test: 6941.2363	accuracy_train: 0.9694	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 40	curr_val_accuracy: 0.8245	curr_test_accuracy: 0.7949
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 41		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7157.5210	loss_val: 7157.9937	loss_test: 7157.8271	accuracy_train: 0.9733	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13023.2998	loss_val: 13023.5908	loss_test: 13023.4922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56429.7148	loss_val: 56429.9180	loss_test: 56430.2500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 48853.8008	loss_val: 48853.7891	loss_test: 48853.8320	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8121.7876	loss_val: 8122.7368	loss_test: 8122.0181	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5148.6465	loss_val: 5148.6479	loss_test: 5148.6411	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7554.2139	loss_val: 7554.2344	loss_test: 7554.3750	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7611.3193	loss_val: 7611.3340	loss_test: 7611.2954	accuracy_train: 0.4286	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10221.4570	loss_val: 10221.7568	loss_test: 10221.7148	accuracy_train: 0.9792	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 10105.2861	loss_val: 10105.3604	loss_test: 10105.2256	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7111.8511	loss_val: 7111.8975	loss_test: 7111.8647	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5144.7729	loss_val: 5145.0391	loss_test: 5145.5454	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5485.4048	loss_val: 5485.9351	loss_test: 5486.7217	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 12193.1162	loss_val: 12193.1611	loss_test: 12193.3672	accuracy_train: 0.9444	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5278.7393	loss_val: 5278.6074	loss_test: 5280.0747	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 5035.1152	loss_val: 5035.2656	loss_test: 5035.9019	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4202.6182	loss_val: 4202.5728	loss_test: 4202.6021	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7591.3154	loss_val: 7591.5322	loss_test: 7591.9897	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 52420.1680	loss_val: 52419.9766	loss_test: 52420.5195	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6898.4424	loss_val: 6898.5044	loss_test: 6898.6479	accuracy_train: 0.9796	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 41	curr_val_accuracy: 0.8330	curr_test_accuracy: 0.7949
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 42		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7153.4844	loss_val: 7153.9937	loss_test: 7153.8091	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13033.6055	loss_val: 13033.8916	loss_test: 13033.8018	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56666.3164	loss_val: 56666.5312	loss_test: 56666.8789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 51122.7891	loss_val: 51122.7773	loss_test: 51122.8164	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8058.3164	loss_val: 8059.3188	loss_test: 8058.5610	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5091.5371	loss_val: 5091.5391	loss_test: 5091.5312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7551.9204	loss_val: 7551.9395	loss_test: 7552.0913	accuracy_train: 0.9756	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7361.4111	loss_val: 7361.4727	loss_test: 7361.4399	accuracy_train: 0.4524	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10365.2080	loss_val: 10365.5205	loss_test: 10365.4785	accuracy_train: 0.9792	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 10415.0586	loss_val: 10415.1328	loss_test: 10414.9990	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7212.2168	loss_val: 7212.2646	loss_test: 7212.2305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5149.9546	loss_val: 5150.2295	loss_test: 5150.7437	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5449.9917	loss_val: 5450.5366	loss_test: 5451.3657	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11981.8389	loss_val: 11981.8877	loss_test: 11982.1084	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5310.2144	loss_val: 5310.0981	loss_test: 5311.6938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4999.0098	loss_val: 4999.1631	loss_test: 4999.8154	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4190.7559	loss_val: 4190.7095	loss_test: 4190.7388	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7634.3408	loss_val: 7634.5586	loss_test: 7635.0200	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 52944.0547	loss_val: 52943.8672	loss_test: 52944.4102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6867.0381	loss_val: 6867.1392	loss_test: 6867.2651	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 42	curr_val_accuracy: 0.8398	curr_test_accuracy: 0.7868
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 43		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7136.8398	loss_val: 7137.3872	loss_test: 7137.1885	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13041.8086	loss_val: 13042.1006	loss_test: 13042.0098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 56976.1914	loss_val: 56976.4062	loss_test: 56976.7773	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 53708.1328	loss_val: 53708.1172	loss_test: 53708.1523	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8031.1802	loss_val: 8032.2344	loss_test: 8031.4380	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5039.9478	loss_val: 5039.9517	loss_test: 5039.9424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7566.3594	loss_val: 7566.3779	loss_test: 7566.5391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 7137.9541	loss_val: 7138.0605	loss_test: 7138.0386	accuracy_train: 0.4762	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10334.9258	loss_val: 10335.2607	loss_test: 10335.2129	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 10727.0088	loss_val: 10727.0801	loss_test: 10726.9492	accuracy_train: 0.9851	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7330.6309	loss_val: 7330.6807	loss_test: 7330.6445	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5170.9551	loss_val: 5171.2412	loss_test: 5171.7637	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5440.7891	loss_val: 5441.3501	loss_test: 5442.2246	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11777.6787	loss_val: 11777.7285	loss_test: 11777.9668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5337.8174	loss_val: 5337.7158	loss_test: 5339.4478	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4967.0679	loss_val: 4967.2217	loss_test: 4967.8882	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4191.1826	loss_val: 4191.1357	loss_test: 4191.1650	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7683.7212	loss_val: 7683.9370	loss_test: 7684.4146	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 53543.2500	loss_val: 53543.0703	loss_test: 53543.6094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6820.8628	loss_val: 6821.0337	loss_test: 6821.1196	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 43	curr_val_accuracy: 0.8306	curr_test_accuracy: 0.7788
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 44		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7186.3921	loss_val: 7186.9941	loss_test: 7186.7705	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 12997.8877	loss_val: 12998.1787	loss_test: 12998.0889	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 2]	loss_train: 57102.9883	loss_val: 57103.1992	loss_test: 57103.5977	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 56272.1211	loss_val: 56272.1055	loss_test: 56272.1406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8020.7319	loss_val: 8021.8345	loss_test: 8021.0010	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4997.1479	loss_val: 4997.1528	loss_test: 4997.1431	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7607.7793	loss_val: 7607.7969	loss_test: 7607.9712	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6947.9976	loss_val: 6948.1504	loss_test: 6948.1401	accuracy_train: 0.5000	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10400.7227	loss_val: 10401.0684	loss_test: 10401.0176	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 11043.9814	loss_val: 11044.0479	loss_test: 11043.9219	accuracy_train: 0.9851	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7435.0513	loss_val: 7435.1025	loss_test: 7435.0659	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5200.4585	loss_val: 5200.7563	loss_test: 5201.2856	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5436.3936	loss_val: 5436.9668	loss_test: 5437.8789	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11601.4785	loss_val: 11601.5234	loss_test: 11601.7842	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5382.7993	loss_val: 5382.7109	loss_test: 5384.5845	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4944.2495	loss_val: 4944.4053	loss_test: 4945.0845	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4194.9761	loss_val: 4194.9297	loss_test: 4194.9575	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7768.5537	loss_val: 7768.7642	loss_test: 7769.2646	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 54392.4844	loss_val: 54392.3086	loss_test: 54392.8438	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6789.2881	loss_val: 6789.5347	loss_test: 6789.5713	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 44	curr_val_accuracy: 0.8306	curr_test_accuracy: 0.7788
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 45		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7228.2524	loss_val: 7228.9307	loss_test: 7228.6675	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 12979.7754	loss_val: 12980.0742	loss_test: 12979.9814	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 57138.4414	loss_val: 57138.6523	loss_test: 57139.0820	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 58422.1328	loss_val: 58422.1133	loss_test: 58422.1523	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7998.4780	loss_val: 7999.6216	loss_test: 7998.7568	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4961.0620	loss_val: 4961.0679	loss_test: 4961.0581	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7655.8071	loss_val: 7655.8247	loss_test: 7656.0093	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6789.8647	loss_val: 6790.0654	loss_test: 6790.0625	accuracy_train: 0.5952	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10444.5537	loss_val: 10444.9102	loss_test: 10444.8613	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 11340.9502	loss_val: 11341.0146	loss_test: 11340.8955	accuracy_train: 0.9851	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7530.6816	loss_val: 7530.7363	loss_test: 7530.6973	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5274.9238	loss_val: 5275.2363	loss_test: 5275.7939	accuracy_train: 0.9873	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5429.1309	loss_val: 5429.7129	loss_test: 5430.6851	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11380.6924	loss_val: 11380.7402	loss_test: 11381.0166	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5428.6865	loss_val: 5428.6079	loss_test: 5430.6064	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4934.0020	loss_val: 4934.1572	loss_test: 4934.8462	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4209.2070	loss_val: 4209.1621	loss_test: 4209.1885	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7856.1968	loss_val: 7856.3950	loss_test: 7856.9312	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 55339.9648	loss_val: 55339.7969	loss_test: 55340.3242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6764.9614	loss_val: 6765.2734	loss_test: 6765.2622	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 45	curr_val_accuracy: 0.8306	curr_test_accuracy: 0.7812
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 46		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7335.3584	loss_val: 7336.1157	loss_test: 7335.8145	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 12964.6543	loss_val: 12964.9648	loss_test: 12964.8613	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 56124.2422	loss_val: 56124.5039	loss_test: 56124.8828	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 60684.1562	loss_val: 60684.1367	loss_test: 60684.1719	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7990.2188	loss_val: 7991.4082	loss_test: 7990.5068	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4925.3115	loss_val: 4925.3188	loss_test: 4925.3096	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7696.0249	loss_val: 7696.0430	loss_test: 7696.2383	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6658.6558	loss_val: 6658.8965	loss_test: 6658.9077	accuracy_train: 0.6905	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10541.0645	loss_val: 10541.4287	loss_test: 10541.3760	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 11662.0264	loss_val: 11662.0918	loss_test: 11661.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7626.7520	loss_val: 7626.8096	loss_test: 7626.7681	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5322.2974	loss_val: 5322.6245	loss_test: 5323.1978	accuracy_train: 0.9873	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5413.5610	loss_val: 5414.1499	loss_test: 5415.1572	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11224.1504	loss_val: 11224.2002	loss_test: 11224.4863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5472.8535	loss_val: 5472.7832	loss_test: 5474.8862	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4926.1997	loss_val: 4926.3530	loss_test: 4927.0503	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4227.8896	loss_val: 4227.8467	loss_test: 4227.8701	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 7945.1680	loss_val: 7945.3604	loss_test: 7945.9243	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 56545.0195	loss_val: 56544.8555	loss_test: 56545.3750	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6734.1665	loss_val: 6734.5293	loss_test: 6734.4780	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 46	curr_val_accuracy: 0.8059	curr_test_accuracy: 0.7736
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 47		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7409.3652	loss_val: 7410.1943	loss_test: 7409.8672	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 12918.2588	loss_val: 12918.5889	loss_test: 12918.4717	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 55437.1406	loss_val: 55437.4570	loss_test: 55437.7930	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 63332.0469	loss_val: 63332.0273	loss_test: 63332.0625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7976.5581	loss_val: 7977.7832	loss_test: 7976.8564	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4910.0537	loss_val: 4910.0625	loss_test: 4910.0552	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7769.9829	loss_val: 7770.0020	loss_test: 7770.2085	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6552.9150	loss_val: 6553.1978	loss_test: 6553.2168	accuracy_train: 0.7143	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10629.5439	loss_val: 10629.9189	loss_test: 10629.8623	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 12041.3408	loss_val: 12041.4072	loss_test: 12041.3096	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7731.4907	loss_val: 7731.5513	loss_test: 7731.5068	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5389.5518	loss_val: 5389.8960	loss_test: 5390.4849	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5415.2661	loss_val: 5415.8638	loss_test: 5416.8877	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11101.5254	loss_val: 11101.5771	loss_test: 11101.8721	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5534.6582	loss_val: 5534.5942	loss_test: 5536.7964	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4927.0103	loss_val: 4927.1636	loss_test: 4927.8696	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4254.0713	loss_val: 4254.0308	loss_test: 4254.0513	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8013.2861	loss_val: 8013.4800	loss_test: 8014.0571	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 57490.9805	loss_val: 57490.8242	loss_test: 57491.3398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6746.2236	loss_val: 6746.6079	loss_test: 6746.5376	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 47	curr_val_accuracy: 0.8059	curr_test_accuracy: 0.7736
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 48		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7443.4512	loss_val: 7444.3350	loss_test: 7443.9941	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 12888.5303	loss_val: 12888.8730	loss_test: 12888.7471	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 55126.1445	loss_val: 55126.5195	loss_test: 55126.8203	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 65269.7617	loss_val: 65269.7422	loss_test: 65269.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7974.9810	loss_val: 7976.2344	loss_test: 7975.2871	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 4915.3306	loss_val: 4915.3408	loss_test: 4915.3350	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7854.5122	loss_val: 7854.5332	loss_test: 7854.7490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6451.8726	loss_val: 6452.1880	loss_test: 6452.2114	accuracy_train: 0.7857	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 10811.6973	loss_val: 10812.0840	loss_test: 10812.0137	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 12425.6143	loss_val: 12425.6797	loss_test: 12425.5889	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7822.7734	loss_val: 7822.8359	loss_test: 7822.7900	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5427.8940	loss_val: 5428.2666	loss_test: 5428.8574	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5432.3716	loss_val: 5432.9814	loss_test: 5433.9990	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10994.0518	loss_val: 10994.1055	loss_test: 10994.4092	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5589.6196	loss_val: 5589.5615	loss_test: 5591.8853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4929.4810	loss_val: 4929.6357	loss_test: 4930.3511	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4281.0156	loss_val: 4280.9785	loss_test: 4280.9961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8100.5977	loss_val: 8100.7910	loss_test: 8101.3877	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 58448.1484	loss_val: 58447.9961	loss_test: 58448.5039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6779.0869	loss_val: 6779.4473	loss_test: 6779.3911	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 48	curr_val_accuracy: 0.7984	curr_test_accuracy: 0.7736
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 49		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7287.3022	loss_val: 7288.1953	loss_test: 7287.8428	accuracy_train: 0.9733	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 12862.3027	loss_val: 12862.6611	loss_test: 12862.5264	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 54934.6445	loss_val: 54935.0469	loss_test: 54935.3320	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 67073.5078	loss_val: 67073.4844	loss_test: 67073.5234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 8002.8408	loss_val: 8004.1133	loss_test: 8003.1577	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4929.9062	loss_val: 4929.9180	loss_test: 4929.9136	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 7939.3701	loss_val: 7939.3936	loss_test: 7939.6138	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6377.7495	loss_val: 6378.0928	loss_test: 6378.1167	accuracy_train: 0.8810	accuracy_val: 0.4000	accuracy_test: 0.5714
[client 8]	loss_train: 11068.5752	loss_val: 11068.9795	loss_test: 11068.8818	accuracy_train: 0.9583	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 12814.2852	loss_val: 12814.3477	loss_test: 12814.2637	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7889.3096	loss_val: 7889.3755	loss_test: 7889.3271	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5411.8496	loss_val: 5412.2598	loss_test: 5412.8213	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5466.0698	loss_val: 5466.6938	loss_test: 5467.6763	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10853.1377	loss_val: 10853.1982	loss_test: 10853.5078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5638.7788	loss_val: 5638.7266	loss_test: 5641.1484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4927.0552	loss_val: 4927.2080	loss_test: 4927.9341	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4313.0366	loss_val: 4313.0034	loss_test: 4313.0186	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8161.2744	loss_val: 8161.4712	loss_test: 8162.0767	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 59439.0352	loss_val: 59438.8867	loss_test: 59439.3867	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6828.6362	loss_val: 6828.9600	loss_test: 6828.9312	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 49	curr_val_accuracy: 0.7898	curr_test_accuracy: 0.7657
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 50		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 7110.2456	loss_val: 7111.1240	loss_test: 7110.7705	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 12886.1895	loss_val: 12886.5537	loss_test: 12886.4150	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 54627.7656	loss_val: 54628.1680	loss_test: 54628.4609	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 3]	loss_train: 68630.3984	loss_val: 68630.3750	loss_test: 68630.4219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7973.8975	loss_val: 7975.1870	loss_test: 7974.2251	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4949.6177	loss_val: 4949.6309	loss_test: 4949.6279	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8010.6968	loss_val: 8010.7227	loss_test: 8010.9478	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6284.9214	loss_val: 6285.2886	loss_test: 6285.3159	accuracy_train: 0.9524	accuracy_val: 0.4000	accuracy_test: 0.4286
[client 8]	loss_train: 11324.4326	loss_val: 11324.8438	loss_test: 11324.7344	accuracy_train: 0.9375	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 13135.1816	loss_val: 13135.2422	loss_test: 13135.1621	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 7958.5122	loss_val: 7958.5815	loss_test: 7958.5308	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5373.7886	loss_val: 5374.2412	loss_test: 5374.7578	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5517.4600	loss_val: 5518.1021	loss_test: 5519.0049	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10783.9639	loss_val: 10784.0303	loss_test: 10784.3428	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5692.3657	loss_val: 5692.3179	loss_test: 5694.8413	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4912.8105	loss_val: 4912.9619	loss_test: 4913.6958	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4340.5483	loss_val: 4340.5181	loss_test: 4340.5303	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8217.0557	loss_val: 8217.2627	loss_test: 8217.8594	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 60468.0859	loss_val: 60467.9414	loss_test: 60468.4336	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 6907.1055	loss_val: 6907.3628	loss_test: 6907.3838	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 50	curr_val_accuracy: 0.7985	curr_test_accuracy: 0.7592
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 51		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6948.3066	loss_val: 6949.1611	loss_test: 6948.8066	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 12879.5107	loss_val: 12879.8945	loss_test: 12879.7412	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 54437.9219	loss_val: 54438.2891	loss_test: 54438.6133	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 69984.7422	loss_val: 69984.7188	loss_test: 69984.7656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7934.7266	loss_val: 7936.0391	loss_test: 7935.0620	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 4980.8091	loss_val: 4980.8228	loss_test: 4980.8218	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8100.8457	loss_val: 8100.8730	loss_test: 8101.1035	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6208.2656	loss_val: 6208.6567	loss_test: 6208.6846	accuracy_train: 0.9524	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11653.2344	loss_val: 11653.6465	loss_test: 11653.5293	accuracy_train: 0.8958	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 13379.8232	loss_val: 13379.8877	loss_test: 13379.8057	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8027.7197	loss_val: 8027.7944	loss_test: 8027.7388	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5287.6411	loss_val: 5288.1406	loss_test: 5288.5874	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5568.8408	loss_val: 5569.5010	loss_test: 5570.3359	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10736.0625	loss_val: 10736.1328	loss_test: 10736.4541	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5735.1108	loss_val: 5735.0659	loss_test: 5737.6587	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4904.5771	loss_val: 4904.7271	loss_test: 4905.4771	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4380.7729	loss_val: 4380.7466	loss_test: 4380.7568	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8269.9043	loss_val: 8270.1260	loss_test: 8270.6973	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 61330.0586	loss_val: 61329.9180	loss_test: 61330.4062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7069.8389	loss_val: 7070.0044	loss_test: 7070.0908	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 51	curr_val_accuracy: 0.8153	curr_test_accuracy: 0.7511
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 52		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6811.3579	loss_val: 6812.1851	loss_test: 6811.8354	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 12919.9082	loss_val: 12920.3115	loss_test: 12920.1406	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 54398.3398	loss_val: 54398.6758	loss_test: 54399.0312	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71215.4453	loss_val: 71215.4141	loss_test: 71215.4688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7883.9878	loss_val: 7885.3340	loss_test: 7884.3267	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5015.5049	loss_val: 5015.5190	loss_test: 5015.5195	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8191.7378	loss_val: 8191.7681	loss_test: 8192.0049	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6151.9209	loss_val: 6152.3340	loss_test: 6152.3604	accuracy_train: 0.9762	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 12146.1748	loss_val: 12146.5742	loss_test: 12146.4551	accuracy_train: 0.7500	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 13517.5762	loss_val: 13517.6465	loss_test: 13517.5605	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8082.6958	loss_val: 8082.7749	loss_test: 8082.7139	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5203.6670	loss_val: 5204.2061	loss_test: 5204.5771	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5615.0264	loss_val: 5615.6992	loss_test: 5616.5059	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10709.0645	loss_val: 10709.1406	loss_test: 10709.4668	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5778.8813	loss_val: 5778.8384	loss_test: 5781.4712	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4898.2993	loss_val: 4898.4463	loss_test: 4899.2095	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4416.1938	loss_val: 4416.1709	loss_test: 4416.1792	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8343.5830	loss_val: 8343.8066	loss_test: 8344.3906	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 62037.1133	loss_val: 62036.9766	loss_test: 62037.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7241.8413	loss_val: 7241.9365	loss_test: 7242.0635	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 52	curr_val_accuracy: 0.8234	curr_test_accuracy: 0.7517
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 53		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6725.2847	loss_val: 6726.1113	loss_test: 6725.7520	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 12910.4082	loss_val: 12910.8359	loss_test: 12910.6465	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 54437.6641	loss_val: 54437.9414	loss_test: 54438.3477	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 71990.6875	loss_val: 71990.6562	loss_test: 71990.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7822.9463	loss_val: 7824.3472	loss_test: 7823.2861	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5051.0762	loss_val: 5051.0908	loss_test: 5051.0928	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8268.7051	loss_val: 8268.7363	loss_test: 8268.9805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6110.9556	loss_val: 6111.3833	loss_test: 6111.4062	accuracy_train: 0.9762	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 12555.7969	loss_val: 12556.1865	loss_test: 12556.0723	accuracy_train: 0.7292	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 13642.2207	loss_val: 13642.2949	loss_test: 13642.2070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8117.8711	loss_val: 8117.9536	loss_test: 8117.8882	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5148.4746	loss_val: 5149.0508	loss_test: 5149.3545	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5651.6035	loss_val: 5652.2930	loss_test: 5653.0532	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10638.9092	loss_val: 10638.9932	loss_test: 10639.3174	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5827.5596	loss_val: 5827.5195	loss_test: 5830.2368	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4889.3525	loss_val: 4889.4985	loss_test: 4890.2793	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4448.9004	loss_val: 4448.8809	loss_test: 4448.8867	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8413.0059	loss_val: 8413.2373	loss_test: 8413.8193	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 62862.9805	loss_val: 62862.8477	loss_test: 62863.3242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7390.2407	loss_val: 7390.3018	loss_test: 7390.4414	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 53	curr_val_accuracy: 0.8234	curr_test_accuracy: 0.7517
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 54		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6691.6699	loss_val: 6692.5034	loss_test: 6692.1406	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 12925.7695	loss_val: 12926.2051	loss_test: 12926.0098	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 55118.8945	loss_val: 55119.1484	loss_test: 55119.5938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 72282.5547	loss_val: 72282.5234	loss_test: 72282.5938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7803.5103	loss_val: 7804.9712	loss_test: 7803.8521	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5086.1025	loss_val: 5086.1172	loss_test: 5086.1206	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8355.0400	loss_val: 8355.0742	loss_test: 8355.3242	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6073.1323	loss_val: 6073.5747	loss_test: 6073.5967	accuracy_train: 0.9762	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 12916.0078	loss_val: 12916.3955	loss_test: 12916.2715	accuracy_train: 0.7083	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 13655.7539	loss_val: 13655.8320	loss_test: 13655.7412	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8138.2075	loss_val: 8138.2925	loss_test: 8138.2246	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5113.7798	loss_val: 5114.3882	loss_test: 5114.6426	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5643.2959	loss_val: 5643.9951	loss_test: 5644.7549	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10611.0918	loss_val: 10611.1865	loss_test: 10611.5049	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5868.9209	loss_val: 5868.8838	loss_test: 5871.7007	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4871.8916	loss_val: 4872.0366	loss_test: 4872.8364	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4467.6841	loss_val: 4467.6670	loss_test: 4467.6704	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8454.2471	loss_val: 8454.4824	loss_test: 8455.0654	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 63528.6836	loss_val: 63528.5547	loss_test: 63529.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7335.6108	loss_val: 7335.6860	loss_test: 7335.8257	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 54	curr_val_accuracy: 0.8397	curr_test_accuracy: 0.7517
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 55		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6662.4424	loss_val: 6663.2896	loss_test: 6662.9116	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 12976.4775	loss_val: 12976.8916	loss_test: 12976.7168	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 55749.6836	loss_val: 55749.9180	loss_test: 55750.4023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 72767.4219	loss_val: 72767.3906	loss_test: 72767.4609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7849.7061	loss_val: 7851.2266	loss_test: 7850.0513	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5127.9673	loss_val: 5127.9814	loss_test: 5127.9863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8462.4219	loss_val: 8462.4580	loss_test: 8462.7158	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6030.1392	loss_val: 6030.5957	loss_test: 6030.6201	accuracy_train: 0.9762	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 13162.4023	loss_val: 13162.7891	loss_test: 13162.6455	accuracy_train: 0.6667	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 13696.2266	loss_val: 13696.3086	loss_test: 13696.2148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8156.3491	loss_val: 8156.4351	loss_test: 8156.3667	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5092.4663	loss_val: 5093.1030	loss_test: 5093.3174	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5636.0347	loss_val: 5636.7422	loss_test: 5637.5068	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10598.1768	loss_val: 10598.2832	loss_test: 10598.5938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5903.4971	loss_val: 5903.4624	loss_test: 5906.3574	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4870.7744	loss_val: 4870.9199	loss_test: 4871.7393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4487.7397	loss_val: 4487.7251	loss_test: 4487.7266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8527.0166	loss_val: 8527.2549	loss_test: 8527.8398	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64209.3320	loss_val: 64209.2070	loss_test: 64209.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7244.5054	loss_val: 7244.6118	loss_test: 7244.7427	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 55	curr_val_accuracy: 0.8397	curr_test_accuracy: 0.7667
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 56		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6605.3540	loss_val: 6606.2305	loss_test: 6605.8213	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13043.6973	loss_val: 13044.0781	loss_test: 13043.9316	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56120.6523	loss_val: 56120.8867	loss_test: 56121.3789	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8000
[client 3]	loss_train: 73352.1094	loss_val: 73352.0859	loss_test: 73352.1562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7883.1709	loss_val: 7884.7515	loss_test: 7883.5210	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5163.2266	loss_val: 5163.2407	loss_test: 5163.2471	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8574.5947	loss_val: 8574.6338	loss_test: 8574.8984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 6002.7739	loss_val: 6003.2407	loss_test: 6003.2700	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 13419.0625	loss_val: 13419.4482	loss_test: 13419.2900	accuracy_train: 0.6667	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 13768.6504	loss_val: 13768.7344	loss_test: 13768.6387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8154.7280	loss_val: 8154.8145	loss_test: 8154.7466	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5088.6748	loss_val: 5089.3267	loss_test: 5089.5298	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5593.9893	loss_val: 5594.6948	loss_test: 5595.5239	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10596.9004	loss_val: 10597.0146	loss_test: 10597.3193	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5933.4814	loss_val: 5933.4492	loss_test: 5936.4346	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4858.9141	loss_val: 4859.0620	loss_test: 4859.8975	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4506.4580	loss_val: 4506.4448	loss_test: 4506.4448	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8541.3145	loss_val: 8541.5615	loss_test: 8542.1211	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64927.7422	loss_val: 64927.6211	loss_test: 64928.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 19]	loss_train: 7069.8047	loss_val: 7069.9692	loss_test: 7070.0757	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 56	curr_val_accuracy: 0.8310	curr_test_accuracy: 0.7737
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 57		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6626.2891	loss_val: 6627.2183	loss_test: 6626.7690	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13102.9512	loss_val: 13103.3037	loss_test: 13103.1836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 56503.1406	loss_val: 56503.3789	loss_test: 56503.8867	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 74281.3047	loss_val: 74281.2734	loss_test: 74281.3516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7877.1406	loss_val: 7878.7769	loss_test: 7877.4976	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5192.9531	loss_val: 5192.9668	loss_test: 5192.9746	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8679.2500	loss_val: 8679.2910	loss_test: 8679.5635	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5976.2407	loss_val: 5976.7188	loss_test: 5976.7534	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 13427.8848	loss_val: 13428.2900	loss_test: 13428.1221	accuracy_train: 0.6875	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 13732.0488	loss_val: 13732.1367	loss_test: 13732.0381	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8153.8677	loss_val: 8153.9521	loss_test: 8153.8867	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5099.1665	loss_val: 5099.8271	loss_test: 5100.0415	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5556.1304	loss_val: 5556.8335	loss_test: 5557.7441	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10587.7158	loss_val: 10587.8428	loss_test: 10588.1367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5964.5781	loss_val: 5964.5479	loss_test: 5967.6050	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4854.6885	loss_val: 4854.8389	loss_test: 4855.6846	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4519.9321	loss_val: 4519.9204	loss_test: 4519.9194	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8567.9424	loss_val: 8568.1953	loss_test: 8568.7412	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65552.3828	loss_val: 65552.2656	loss_test: 65552.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6884.8809	loss_val: 6885.1416	loss_test: 6885.1997	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 57	curr_val_accuracy: 0.8395	curr_test_accuracy: 0.7626
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 58		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6590.3667	loss_val: 6591.3286	loss_test: 6590.8467	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13202.1729	loss_val: 13202.5000	loss_test: 13202.4023	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 56566.9102	loss_val: 56567.1719	loss_test: 56567.6680	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 74880.1016	loss_val: 74880.0781	loss_test: 74880.1484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7848.5483	loss_val: 7850.2197	loss_test: 7848.9106	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5222.8755	loss_val: 5222.8896	loss_test: 5222.8984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8777.5186	loss_val: 8777.5625	loss_test: 8777.8418	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5946.8555	loss_val: 5947.3433	loss_test: 5947.3877	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 13288.4600	loss_val: 13288.8945	loss_test: 13288.7119	accuracy_train: 0.7292	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 13726.3164	loss_val: 13726.4053	loss_test: 13726.3057	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8159.9224	loss_val: 8160.0039	loss_test: 8159.9414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5111.1064	loss_val: 5111.7705	loss_test: 5112.0024	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5522.7847	loss_val: 5523.4888	loss_test: 5524.4727	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10561.7158	loss_val: 10561.8516	loss_test: 10562.1367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 5993.2476	loss_val: 5993.2188	loss_test: 5996.3154	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4835.3398	loss_val: 4835.4941	loss_test: 4836.3564	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4519.9458	loss_val: 4519.9346	loss_test: 4519.9331	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8613.2930	loss_val: 8613.5439	loss_test: 8614.1035	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66150.6875	loss_val: 66150.5703	loss_test: 66151.0078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6766.9429	loss_val: 6767.2837	loss_test: 6767.2993	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 58	curr_val_accuracy: 0.8318	curr_test_accuracy: 0.7626
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 59		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6537.5659	loss_val: 6538.5483	loss_test: 6538.0405	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13274.7646	loss_val: 13275.0723	loss_test: 13274.9932	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 56640.0156	loss_val: 56640.2969	loss_test: 56640.7773	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 74968.1172	loss_val: 74968.0938	loss_test: 74968.1719	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7767.4937	loss_val: 7769.2007	loss_test: 7767.8594	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5232.1494	loss_val: 5232.1631	loss_test: 5232.1729	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8847.5967	loss_val: 8847.6426	loss_test: 8847.9316	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5922.4941	loss_val: 5922.9873	loss_test: 5923.0400	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 13003.2520	loss_val: 13003.7344	loss_test: 13003.5176	accuracy_train: 0.7708	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 13763.2227	loss_val: 13763.3105	loss_test: 13763.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8153.9941	loss_val: 8154.0723	loss_test: 8154.0132	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5131.5405	loss_val: 5132.2158	loss_test: 5132.4644	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5484.7334	loss_val: 5485.4399	loss_test: 5486.4990	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10573.2031	loss_val: 10573.3477	loss_test: 10573.6260	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6018.5259	loss_val: 6018.4980	loss_test: 6021.6450	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4828.6929	loss_val: 4828.8516	loss_test: 4829.7227	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4519.8672	loss_val: 4519.8569	loss_test: 4519.8545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8620.3730	loss_val: 8620.6260	loss_test: 8621.1816	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66638.4219	loss_val: 66638.3125	loss_test: 66638.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6729.7422	loss_val: 6730.1138	loss_test: 6730.1152	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 59	curr_val_accuracy: 0.8238	curr_test_accuracy: 0.7542
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 60		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6466.7085	loss_val: 6467.6914	loss_test: 6467.1704	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13334.8906	loss_val: 13335.1758	loss_test: 13335.1172	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 56876.8555	loss_val: 56877.1641	loss_test: 56877.6328	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 74879.7188	loss_val: 74879.7031	loss_test: 74879.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7685.2441	loss_val: 7686.9751	loss_test: 7685.6143	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7273
[client 5]	loss_train: 5252.2666	loss_val: 5252.2803	loss_test: 5252.2905	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8909.6377	loss_val: 8909.6826	loss_test: 8909.9863	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5894.5381	loss_val: 5895.0352	loss_test: 5895.0952	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 12763.5439	loss_val: 12764.0586	loss_test: 12763.8193	accuracy_train: 0.8125	accuracy_val: 0.3333	accuracy_test: 0.4286
[client 9]	loss_train: 13782.3916	loss_val: 13782.4785	loss_test: 13782.3799	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8141.9365	loss_val: 8142.0112	loss_test: 8141.9551	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5175.6553	loss_val: 5176.3389	loss_test: 5176.6221	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5439.8574	loss_val: 5440.5596	loss_test: 5441.7114	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10579.6807	loss_val: 10579.8369	loss_test: 10580.1045	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6035.8911	loss_val: 6035.8638	loss_test: 6039.0366	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4831.8218	loss_val: 4831.9854	loss_test: 4832.8735	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4523.5132	loss_val: 4523.5029	loss_test: 4523.5005	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8648.7637	loss_val: 8649.0107	loss_test: 8649.5967	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66878.2500	loss_val: 66878.1406	loss_test: 66878.5625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6727.4346	loss_val: 6727.7920	loss_test: 6727.8086	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 60	curr_val_accuracy: 0.8318	curr_test_accuracy: 0.7602
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 61		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6360.9941	loss_val: 6361.9570	loss_test: 6361.4517	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13409.8242	loss_val: 13410.0879	loss_test: 13410.0488	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 57353.2812	loss_val: 57353.6211	loss_test: 57354.0664	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 75271.6562	loss_val: 75271.6328	loss_test: 75271.7188	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7582.5259	loss_val: 7584.2822	loss_test: 7582.9033	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5257.7598	loss_val: 5257.7734	loss_test: 5257.7842	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 8955.4453	loss_val: 8955.4912	loss_test: 8955.8086	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5904.1299	loss_val: 5904.6294	loss_test: 5904.7007	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 12397.7021	loss_val: 12398.2549	loss_test: 12398.0117	accuracy_train: 0.9167	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 13759.5010	loss_val: 13759.5879	loss_test: 13759.4893	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8134.3101	loss_val: 8134.3823	loss_test: 8134.3286	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5229.2559	loss_val: 5229.9536	loss_test: 5230.2710	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5413.8267	loss_val: 5414.5259	loss_test: 5415.8125	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10589.2295	loss_val: 10589.3975	loss_test: 10589.6562	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6061.1855	loss_val: 6061.1592	loss_test: 6064.3462	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4829.4048	loss_val: 4829.5693	loss_test: 4830.4810	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 16]	loss_train: 4533.8530	loss_val: 4533.8433	loss_test: 4533.8403	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8707.7471	loss_val: 8707.9883	loss_test: 8708.6113	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67121.3828	loss_val: 67121.2734	loss_test: 67121.6875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6770.0098	loss_val: 6770.3154	loss_test: 6770.3711	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 61	curr_val_accuracy: 0.8232	curr_test_accuracy: 0.7675
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 62		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6213.7925	loss_val: 6214.7212	loss_test: 6214.2500	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13528.5166	loss_val: 13528.7568	loss_test: 13528.7432	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 57757.6719	loss_val: 57758.0273	loss_test: 57758.4688	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 75759.1875	loss_val: 75759.1719	loss_test: 75759.2578	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7464.3799	loss_val: 7466.1514	loss_test: 7464.7764	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5264.4771	loss_val: 5264.4902	loss_test: 5264.5015	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9026.3086	loss_val: 9026.3555	loss_test: 9026.6846	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5883.3579	loss_val: 5883.8594	loss_test: 5883.9409	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 12019.3203	loss_val: 12019.9004	loss_test: 12019.6777	accuracy_train: 0.9583	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 13724.0430	loss_val: 13724.1279	loss_test: 13724.0312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8134.4238	loss_val: 8134.4941	loss_test: 8134.4424	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5306.7852	loss_val: 5307.5044	loss_test: 5307.8647	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5412.1274	loss_val: 5412.8296	loss_test: 5414.1831	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10644.4414	loss_val: 10644.6172	loss_test: 10644.8721	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6099.0137	loss_val: 6098.9888	loss_test: 6102.2568	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4821.0059	loss_val: 4821.1704	loss_test: 4822.1060	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4539.5137	loss_val: 4539.5044	loss_test: 4539.5010	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8762.5020	loss_val: 8762.7422	loss_test: 8763.4004	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67383.3594	loss_val: 67383.2578	loss_test: 67383.6641	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6874.6221	loss_val: 6874.8428	loss_test: 6874.9546	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 62	curr_val_accuracy: 0.8235	curr_test_accuracy: 0.7769
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 63		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6119.5488	loss_val: 6120.4590	loss_test: 6120.0166	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13643.6191	loss_val: 13643.8379	loss_test: 13643.8477	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58289.2227	loss_val: 58289.6016	loss_test: 58290.0430	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 75996.0781	loss_val: 75996.0625	loss_test: 75996.1484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7359.8164	loss_val: 7361.5952	loss_test: 7360.2373	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5265.0308	loss_val: 5265.0439	loss_test: 5265.0552	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9079.8330	loss_val: 9079.8809	loss_test: 9080.2178	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5887.2544	loss_val: 5887.7563	loss_test: 5887.8496	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11754.4561	loss_val: 11755.0322	loss_test: 11754.8633	accuracy_train: 0.9792	accuracy_val: 0.3333	accuracy_test: 0.7143
[client 9]	loss_train: 13708.1494	loss_val: 13708.2334	loss_test: 13708.1367	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8121.3999	loss_val: 8121.4673	loss_test: 8121.4180	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5381.8721	loss_val: 5382.6138	loss_test: 5383.0132	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5405.0493	loss_val: 5405.7549	loss_test: 5407.1172	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10667.8281	loss_val: 10668.0137	loss_test: 10668.2607	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6127.0742	loss_val: 6127.0493	loss_test: 6130.3301	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4816.4658	loss_val: 4816.6284	loss_test: 4817.5903	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4556.2202	loss_val: 4556.2114	loss_test: 4556.2075	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8793.7607	loss_val: 8793.9951	loss_test: 8794.6787	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67530.9922	loss_val: 67530.8906	loss_test: 67531.2969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7080.5127	loss_val: 7080.6421	loss_test: 7080.8008	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 63	curr_val_accuracy: 0.8322	curr_test_accuracy: 0.7849
best_round: 31	best_val_accuracy: 0.8406	best_test_accuracy: 0.7789
--------------------------------------------------
round # 64		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6072.2974	loss_val: 6073.1929	loss_test: 6072.7764	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13723.4883	loss_val: 13723.6826	loss_test: 13723.7148	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58643.5508	loss_val: 58643.9414	loss_test: 58644.3828	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 76322.1797	loss_val: 76322.1641	loss_test: 76322.2500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7245.1963	loss_val: 7246.9883	loss_test: 7245.6567	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5262.7280	loss_val: 5262.7417	loss_test: 5262.7529	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9128.9326	loss_val: 9128.9824	loss_test: 9129.3262	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5885.6235	loss_val: 5886.1304	loss_test: 5886.2363	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11549.1924	loss_val: 11549.7607	loss_test: 11549.6602	accuracy_train: 0.9792	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 13648.6182	loss_val: 13648.7002	loss_test: 13648.6055	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8118.6221	loss_val: 8118.6875	loss_test: 8118.6396	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5396.6050	loss_val: 5397.3618	loss_test: 5397.7793	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5410.2773	loss_val: 5411.0000	loss_test: 5412.3262	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10688.3672	loss_val: 10688.5596	loss_test: 10688.8018	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6151.5708	loss_val: 6151.5469	loss_test: 6154.8042	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4815.9453	loss_val: 4816.1074	loss_test: 4817.0967	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4561.7949	loss_val: 4561.7866	loss_test: 4561.7822	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8856.9014	loss_val: 8857.1309	loss_test: 8857.8467	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67632.2188	loss_val: 67632.1172	loss_test: 67632.5156	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7327.9355	loss_val: 7328.0259	loss_test: 7328.1748	accuracy_train: 0.9796	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 64	curr_val_accuracy: 0.8408	curr_test_accuracy: 0.7849
best_round: 64	best_val_accuracy: 0.8408	best_test_accuracy: 0.7849
--------------------------------------------------
round # 65		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6094.0005	loss_val: 6094.9194	loss_test: 6094.5015	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13843.5693	loss_val: 13843.7461	loss_test: 13843.7979	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58838.9375	loss_val: 58839.3242	loss_test: 58839.7852	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 76346.3047	loss_val: 76346.2891	loss_test: 76346.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7187.2500	loss_val: 7189.0381	loss_test: 7187.7456	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5254.0088	loss_val: 5254.0220	loss_test: 5254.0337	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9165.5361	loss_val: 9165.5889	loss_test: 9165.9355	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5900.9077	loss_val: 5901.4185	loss_test: 5901.5347	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11356.7734	loss_val: 11357.3262	loss_test: 11357.3018	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 13630.0996	loss_val: 13630.1797	loss_test: 13630.0869	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8125.3091	loss_val: 8125.3730	loss_test: 8125.3262	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5368.8389	loss_val: 5369.6099	loss_test: 5370.0073	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.5000
[client 12]	loss_train: 5409.1011	loss_val: 5409.8418	loss_test: 5411.1030	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10717.8525	loss_val: 10718.0488	loss_test: 10718.2910	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6185.0513	loss_val: 6185.0288	loss_test: 6188.3105	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4818.5615	loss_val: 4818.7227	loss_test: 4819.7451	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4566.3882	loss_val: 4566.3804	loss_test: 4566.3760	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8891.7852	loss_val: 8892.0117	loss_test: 8892.7656	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67675.7422	loss_val: 67675.6484	loss_test: 67676.0391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7644.6929	loss_val: 7644.7637	loss_test: 7644.8789	accuracy_train: 0.9592	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 65	curr_val_accuracy: 0.8408	curr_test_accuracy: 0.7784
best_round: 64	best_val_accuracy: 0.8408	best_test_accuracy: 0.7849
--------------------------------------------------
round # 66		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6135.7070	loss_val: 6136.6406	loss_test: 6136.2329	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13887.0117	loss_val: 13887.1768	loss_test: 13887.2402	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 59036.4805	loss_val: 59036.8594	loss_test: 59037.3398	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 76468.6641	loss_val: 76468.6484	loss_test: 76468.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7137.4590	loss_val: 7139.2505	loss_test: 7137.9844	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8182
[client 5]	loss_train: 5238.4883	loss_val: 5238.5020	loss_test: 5238.5137	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9199.8955	loss_val: 9199.9512	loss_test: 9200.2988	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5894.0947	loss_val: 5894.6108	loss_test: 5894.7368	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 11133.5186	loss_val: 11134.0615	loss_test: 11134.0801	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 13569.6338	loss_val: 13569.7129	loss_test: 13569.6230	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8161.1372	loss_val: 8161.2017	loss_test: 8161.1543	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5307.1445	loss_val: 5307.9199	loss_test: 5308.2861	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5413.7236	loss_val: 5414.4829	loss_test: 5415.6875	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10739.3799	loss_val: 10739.5791	loss_test: 10739.8223	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6206.7310	loss_val: 6206.7090	loss_test: 6209.9653	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4824.6572	loss_val: 4824.8145	loss_test: 4825.8672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4563.2100	loss_val: 4563.2031	loss_test: 4563.1978	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8926.4287	loss_val: 8926.6553	loss_test: 8927.4238	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67596.2656	loss_val: 67596.1719	loss_test: 67596.5625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7954.0664	loss_val: 7954.1221	loss_test: 7954.2026	accuracy_train: 0.9388	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 66	curr_val_accuracy: 0.8150	curr_test_accuracy: 0.7858
best_round: 64	best_val_accuracy: 0.8408	best_test_accuracy: 0.7849
--------------------------------------------------
round # 67		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6168.4136	loss_val: 6169.3545	loss_test: 6168.9629	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13863.7520	loss_val: 13863.9102	loss_test: 13863.9824	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 59036.8984	loss_val: 59037.2656	loss_test: 59037.7812	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 77011.4375	loss_val: 77011.4219	loss_test: 77011.5234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7112.0615	loss_val: 7113.8770	loss_test: 7112.6123	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8182
[client 5]	loss_train: 5216.6147	loss_val: 5216.6289	loss_test: 5216.6406	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9235.8369	loss_val: 9235.8945	loss_test: 9236.2422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5908.0981	loss_val: 5908.6196	loss_test: 5908.7686	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10950.5771	loss_val: 10951.1025	loss_test: 10951.1709	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 13532.3994	loss_val: 13532.4775	loss_test: 13532.3906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8181.1001	loss_val: 8181.1650	loss_test: 8181.1162	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5285.9375	loss_val: 5286.7300	loss_test: 5287.0645	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5411.1821	loss_val: 5411.9541	loss_test: 5413.1406	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10775.4902	loss_val: 10775.6924	loss_test: 10775.9336	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6242.5674	loss_val: 6242.5459	loss_test: 6245.7969	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4835.1821	loss_val: 4835.3350	loss_test: 4836.4097	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4559.1797	loss_val: 4559.1724	loss_test: 4559.1675	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8994.4180	loss_val: 8994.6455	loss_test: 8995.4434	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67466.8203	loss_val: 67466.7266	loss_test: 67467.1094	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 8239.5996	loss_val: 8239.6514	loss_test: 8239.6953	accuracy_train: 0.9082	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 67	curr_val_accuracy: 0.8237	curr_test_accuracy: 0.7786
best_round: 64	best_val_accuracy: 0.8408	best_test_accuracy: 0.7849
--------------------------------------------------
round # 68		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6187.9629	loss_val: 6188.8926	loss_test: 6188.5244	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13854.5107	loss_val: 13854.6680	loss_test: 13854.7471	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 59000.1133	loss_val: 59000.4766	loss_test: 59001.0117	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 76584.8438	loss_val: 76584.8281	loss_test: 76584.9297	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7091.0342	loss_val: 7092.8833	loss_test: 7091.6108	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8182
[client 5]	loss_train: 5188.9224	loss_val: 5188.9370	loss_test: 5188.9487	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9295.2578	loss_val: 9295.3184	loss_test: 9295.6660	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5899.5371	loss_val: 5900.0723	loss_test: 5900.2412	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10792.0029	loss_val: 10792.5088	loss_test: 10792.6182	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 13471.9805	loss_val: 13472.0576	loss_test: 13471.9746	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8195.3965	loss_val: 8195.4609	loss_test: 8195.4111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5248.3149	loss_val: 5249.1226	loss_test: 5249.4131	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5401.8877	loss_val: 5402.6719	loss_test: 5403.8516	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10763.4629	loss_val: 10763.6660	loss_test: 10763.9111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6248.5879	loss_val: 6248.5669	loss_test: 6251.7979	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4841.5474	loss_val: 4841.6978	loss_test: 4842.8047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4547.6821	loss_val: 4547.6743	loss_test: 4547.6699	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9052.8984	loss_val: 9053.1289	loss_test: 9053.9551	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67256.1172	loss_val: 67256.0312	loss_test: 67256.4141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 8363.2842	loss_val: 8363.3389	loss_test: 8363.3652	accuracy_train: 0.8980	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 68	curr_val_accuracy: 0.8317	curr_test_accuracy: 0.7786
best_round: 64	best_val_accuracy: 0.8408	best_test_accuracy: 0.7849
--------------------------------------------------
round # 69		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6185.7046	loss_val: 6186.6128	loss_test: 6186.2803	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13787.4844	loss_val: 13787.6416	loss_test: 13787.7266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58948.2148	loss_val: 58948.5938	loss_test: 58949.1367	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 76077.8594	loss_val: 76077.8516	loss_test: 76077.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7095.1670	loss_val: 7097.0513	loss_test: 7095.7593	accuracy_train: 1.0000	accuracy_val: 0.4000	accuracy_test: 0.8182
[client 5]	loss_train: 5164.4585	loss_val: 5164.4736	loss_test: 5164.4854	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9325.0469	loss_val: 9325.1084	loss_test: 9325.4580	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5880.3145	loss_val: 5880.8662	loss_test: 5881.0576	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10743.0254	loss_val: 10743.5029	loss_test: 10743.6514	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 13483.8838	loss_val: 13483.9590	loss_test: 13483.8799	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8208.1807	loss_val: 8208.2451	loss_test: 8208.1943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5224.1694	loss_val: 5224.9922	loss_test: 5225.2480	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.5000
[client 12]	loss_train: 5382.3452	loss_val: 5383.1333	loss_test: 5384.3379	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10777.4199	loss_val: 10777.6250	loss_test: 10777.8701	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6243.1299	loss_val: 6243.1094	loss_test: 6246.3369	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4842.4873	loss_val: 4842.6362	loss_test: 4843.7700	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4533.7217	loss_val: 4533.7148	loss_test: 4533.7100	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9083.0205	loss_val: 9083.2520	loss_test: 9084.1025	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67072.9219	loss_val: 67072.8359	loss_test: 67073.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 8309.6436	loss_val: 8309.7207	loss_test: 8309.7354	accuracy_train: 0.9184	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 69	curr_val_accuracy: 0.8398	curr_test_accuracy: 0.7786
best_round: 64	best_val_accuracy: 0.8408	best_test_accuracy: 0.7849
--------------------------------------------------
round # 70		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6163.6904	loss_val: 6164.5884	loss_test: 6164.2642	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13702.8506	loss_val: 13703.0156	loss_test: 13703.0996	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 59061.2227	loss_val: 59061.6328	loss_test: 59062.1719	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 75831.8906	loss_val: 75831.8750	loss_test: 75831.9844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7105.1963	loss_val: 7107.1113	loss_test: 7105.7959	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5148.1118	loss_val: 5148.1274	loss_test: 5148.1387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9360.7832	loss_val: 9360.8457	loss_test: 9361.1943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5843.9614	loss_val: 5844.5254	loss_test: 5844.7422	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10611.6875	loss_val: 10612.1592	loss_test: 10612.3271	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 13491.5645	loss_val: 13491.6396	loss_test: 13491.5625	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8218.1377	loss_val: 8218.2021	loss_test: 8218.1504	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5187.0430	loss_val: 5187.9058	loss_test: 5188.0996	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5368.9624	loss_val: 5369.7559	loss_test: 5370.9941	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10810.4229	loss_val: 10810.6221	loss_test: 10810.8760	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6231.8564	loss_val: 6231.8369	loss_test: 6235.0728	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4835.9380	loss_val: 4836.0884	loss_test: 4837.2451	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4520.5811	loss_val: 4520.5747	loss_test: 4520.5698	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9151.7021	loss_val: 9151.9336	loss_test: 9152.8262	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67191.8594	loss_val: 67191.7734	loss_test: 67192.1484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7893.8374	loss_val: 7893.9600	loss_test: 7894.0034	accuracy_train: 0.9388	accuracy_val: 0.8333	accuracy_test: 0.8462
curr_round: 70	curr_val_accuracy: 0.8485	curr_test_accuracy: 0.7872
best_round: 70	best_val_accuracy: 0.8485	best_test_accuracy: 0.7872
--------------------------------------------------
round # 71		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6108.6118	loss_val: 6109.5132	loss_test: 6109.1807	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13641.7227	loss_val: 13641.8955	loss_test: 13641.9805	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 59177.4609	loss_val: 59177.8945	loss_test: 59178.4258	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 75677.3984	loss_val: 75677.3828	loss_test: 75677.4922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7152.8174	loss_val: 7154.7349	loss_test: 7153.4019	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5124.9775	loss_val: 5124.9932	loss_test: 5125.0039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9398.1660	loss_val: 9398.2295	loss_test: 9398.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5813.5869	loss_val: 5814.1621	loss_test: 5814.3989	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10507.4297	loss_val: 10507.9023	loss_test: 10508.0781	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 13420.7822	loss_val: 13420.8564	loss_test: 13420.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8236.5254	loss_val: 8236.5898	loss_test: 8236.5391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5168.4858	loss_val: 5169.3926	loss_test: 5169.5356	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5374.6450	loss_val: 5375.4507	loss_test: 5376.6641	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10846.5068	loss_val: 10846.7021	loss_test: 10846.9609	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6232.8442	loss_val: 6232.8252	loss_test: 6236.0708	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4837.6484	loss_val: 4837.7988	loss_test: 4838.9800	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4509.3882	loss_val: 4509.3823	loss_test: 4509.3774	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9172.2012	loss_val: 9172.4355	loss_test: 9173.3828	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67316.0000	loss_val: 67315.9141	loss_test: 67316.2891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 7499.1724	loss_val: 7499.3232	loss_test: 7499.4116	accuracy_train: 0.9796	accuracy_val: 0.9167	accuracy_test: 0.8462
curr_round: 71	curr_val_accuracy: 0.8572	curr_test_accuracy: 0.7872
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 72		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 6035.6870	loss_val: 6036.6172	loss_test: 6036.2622	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13583.5059	loss_val: 13583.6963	loss_test: 13583.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58964.6484	loss_val: 58965.0898	loss_test: 58965.6328	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 75344.5938	loss_val: 75344.5781	loss_test: 75344.6875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7210.7266	loss_val: 7212.6348	loss_test: 7211.2920	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5096.9604	loss_val: 5096.9761	loss_test: 5096.9868	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9401.7734	loss_val: 9401.8379	loss_test: 9402.1836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5784.9717	loss_val: 5785.5581	loss_test: 5785.8179	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10559.4355	loss_val: 10559.9082	loss_test: 10560.0947	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.8571
[client 9]	loss_train: 13343.7520	loss_val: 13343.8271	loss_test: 13343.7529	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8246.5635	loss_val: 8246.6289	loss_test: 8246.5771	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5152.5659	loss_val: 5153.5073	loss_test: 5153.6187	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5341.5981	loss_val: 5342.4058	loss_test: 5343.6733	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10870.1094	loss_val: 10870.2998	loss_test: 10870.5654	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6214.6270	loss_val: 6214.6079	loss_test: 6217.8232	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4835.5981	loss_val: 4835.7490	loss_test: 4836.9492	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4490.7266	loss_val: 4490.7217	loss_test: 4490.7168	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9190.3809	loss_val: 9190.6113	loss_test: 9191.6104	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67412.2344	loss_val: 67412.1562	loss_test: 67412.5312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6956.6089	loss_val: 6956.7686	loss_test: 6956.9526	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 72	curr_val_accuracy: 0.8572	curr_test_accuracy: 0.7857
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 73		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5966.2568	loss_val: 5967.2021	loss_test: 5966.8203	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13524.4727	loss_val: 13524.6855	loss_test: 13524.7529	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58946.9062	loss_val: 58947.3516	loss_test: 58947.8984	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 74747.7734	loss_val: 74747.7578	loss_test: 74747.8672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7281.3887	loss_val: 7283.3096	loss_test: 7281.9438	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5077.4692	loss_val: 5077.4849	loss_test: 5077.4951	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9488.0430	loss_val: 9488.1113	loss_test: 9488.4482	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5750.4165	loss_val: 5751.0098	loss_test: 5751.2881	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10646.3691	loss_val: 10646.8525	loss_test: 10647.0381	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 13314.4609	loss_val: 13314.5371	loss_test: 13314.4629	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8259.8369	loss_val: 8259.9023	loss_test: 8259.8516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5151.4961	loss_val: 5152.4561	loss_test: 5152.5391	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5321.4609	loss_val: 5322.2666	loss_test: 5323.5908	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10888.1299	loss_val: 10888.3232	loss_test: 10888.5869	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6218.2622	loss_val: 6218.2441	loss_test: 6221.5010	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4824.7402	loss_val: 4824.8906	loss_test: 4826.1108	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4480.7554	loss_val: 4480.7510	loss_test: 4480.7466	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9089.2539	loss_val: 9089.4971	loss_test: 9090.4600	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67478.0547	loss_val: 67477.9766	loss_test: 67478.3516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6612.7427	loss_val: 6612.9438	loss_test: 6613.1768	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 73	curr_val_accuracy: 0.8318	curr_test_accuracy: 0.7857
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 74		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5893.0317	loss_val: 5894.0049	loss_test: 5893.5947	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13434.8135	loss_val: 13435.0537	loss_test: 13435.1045	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58882.5586	loss_val: 58882.9961	loss_test: 58883.5508	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 74227.2266	loss_val: 74227.2109	loss_test: 74227.3203	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7307.9819	loss_val: 7309.9087	loss_test: 7308.5293	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5056.8208	loss_val: 5056.8374	loss_test: 5056.8472	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9621.9619	loss_val: 9622.0332	loss_test: 9622.3613	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5704.3403	loss_val: 5704.9360	loss_test: 5705.2256	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10750.6230	loss_val: 10751.1289	loss_test: 10751.2910	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 13312.4082	loss_val: 13312.4854	loss_test: 13312.4111	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8276.2402	loss_val: 8276.3066	loss_test: 8276.2549	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5164.2041	loss_val: 5165.1802	loss_test: 5165.2476	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5317.5938	loss_val: 5318.4058	loss_test: 5319.7412	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10934.7559	loss_val: 10934.9492	loss_test: 10935.2158	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6220.5737	loss_val: 6220.5562	loss_test: 6223.8428	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4820.0625	loss_val: 4820.2119	loss_test: 4821.4541	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4469.8438	loss_val: 4469.8398	loss_test: 4469.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9053.7852	loss_val: 9054.0391	loss_test: 9054.9766	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67480.7969	loss_val: 67480.7188	loss_test: 67481.0859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6464.8042	loss_val: 6465.0933	loss_test: 6465.3018	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 74	curr_val_accuracy: 0.8318	curr_test_accuracy: 0.7857
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 75		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5853.2729	loss_val: 5854.2739	loss_test: 5853.8354	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13341.5312	loss_val: 13341.7988	loss_test: 13341.8320	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 58341.5234	loss_val: 58341.9336	loss_test: 58342.5195	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 73693.2969	loss_val: 73693.2812	loss_test: 73693.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7326.0127	loss_val: 7327.9253	loss_test: 7326.5586	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5054.4380	loss_val: 5054.4551	loss_test: 5054.4639	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9773.6943	loss_val: 9773.7686	loss_test: 9774.0889	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5653.2476	loss_val: 5653.8501	loss_test: 5654.1353	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10970.1494	loss_val: 10970.6748	loss_test: 10970.8037	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 13290.7051	loss_val: 13290.7832	loss_test: 13290.7080	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8287.8975	loss_val: 8287.9648	loss_test: 8287.9141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5191.7910	loss_val: 5192.7827	loss_test: 5192.8481	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5336.0234	loss_val: 5336.8491	loss_test: 5338.1646	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10970.4385	loss_val: 10970.6328	loss_test: 10970.8994	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6237.8057	loss_val: 6237.7881	loss_test: 6241.1553	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4819.4048	loss_val: 4819.5522	loss_test: 4820.8140	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4461.6211	loss_val: 4461.6177	loss_test: 4461.6138	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9011.5889	loss_val: 9011.8506	loss_test: 9012.7832	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67187.5078	loss_val: 67187.4375	loss_test: 67187.8047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6421.0059	loss_val: 6421.3633	loss_test: 6421.5435	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 75	curr_val_accuracy: 0.8237	curr_test_accuracy: 0.7783
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 76		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5832.0659	loss_val: 5833.0884	loss_test: 5832.6270	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13283.5352	loss_val: 13283.8447	loss_test: 13283.8535	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 57862.5273	loss_val: 57862.9336	loss_test: 57863.5312	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 73410.6406	loss_val: 73410.6250	loss_test: 73410.7266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7310.4160	loss_val: 7312.3354	loss_test: 7310.9521	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5049.3115	loss_val: 5049.3296	loss_test: 5049.3374	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9897.3555	loss_val: 9897.4316	loss_test: 9897.7500	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5597.5229	loss_val: 5598.1294	loss_test: 5598.4082	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11177.1689	loss_val: 11177.7236	loss_test: 11177.8008	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 13390.3057	loss_val: 13390.3857	loss_test: 13390.3105	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8298.0527	loss_val: 8298.1211	loss_test: 8298.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5185.6084	loss_val: 5186.5986	loss_test: 5186.6587	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5386.4229	loss_val: 5387.2754	loss_test: 5388.4966	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10998.2510	loss_val: 10998.4443	loss_test: 10998.7139	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6264.4990	loss_val: 6264.4824	loss_test: 6267.8491	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4819.5376	loss_val: 4819.6875	loss_test: 4820.9634	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4452.5396	loss_val: 4452.5366	loss_test: 4452.5332	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8978.5850	loss_val: 8978.8604	loss_test: 8979.7578	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 67066.2031	loss_val: 67066.1328	loss_test: 67066.5078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6404.1890	loss_val: 6404.5879	loss_test: 6404.7549	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 76	curr_val_accuracy: 0.8238	curr_test_accuracy: 0.7628
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 77		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5812.3452	loss_val: 5813.3887	loss_test: 5812.9189	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13225.9873	loss_val: 13226.3174	loss_test: 13226.3135	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 57672.3203	loss_val: 57672.7305	loss_test: 57673.3320	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 73636.4609	loss_val: 73636.4531	loss_test: 73636.5547	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7319.2007	loss_val: 7321.1143	loss_test: 7319.7227	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5048.0776	loss_val: 5048.0962	loss_test: 5048.1035	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 9964.0176	loss_val: 9964.0957	loss_test: 9964.4180	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5553.3730	loss_val: 5553.9854	loss_test: 5554.2515	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11300.4121	loss_val: 11300.9932	loss_test: 11301.0381	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 13444.6133	loss_val: 13444.6953	loss_test: 13444.6191	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8303.2139	loss_val: 8303.2842	loss_test: 8303.2324	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5146.2524	loss_val: 5147.2305	loss_test: 5147.2744	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5427.4243	loss_val: 5428.3022	loss_test: 5429.4224	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11014.3848	loss_val: 11014.5752	loss_test: 11014.8486	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6285.4604	loss_val: 6285.4443	loss_test: 6288.8354	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4812.6108	loss_val: 4812.7588	loss_test: 4814.0396	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4451.0640	loss_val: 4451.0620	loss_test: 4451.0591	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8899.3818	loss_val: 8899.6729	loss_test: 8900.5283	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66833.1719	loss_val: 66833.1016	loss_test: 66833.4766	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6409.7349	loss_val: 6410.1616	loss_test: 6410.3149	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 77	curr_val_accuracy: 0.8151	curr_test_accuracy: 0.7628
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 78		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5802.2632	loss_val: 5803.3018	loss_test: 5802.8569	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13244.7393	loss_val: 13245.0908	loss_test: 13245.0762	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 57250.8125	loss_val: 57251.1914	loss_test: 57251.8164	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 73395.5625	loss_val: 73395.5547	loss_test: 73395.6484	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7327.1084	loss_val: 7329.0312	loss_test: 7327.6206	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5044.0747	loss_val: 5044.0938	loss_test: 5044.1011	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10015.5254	loss_val: 10015.6025	loss_test: 10015.9287	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5524.0400	loss_val: 5524.6548	loss_test: 5524.9097	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11368.9658	loss_val: 11369.5723	loss_test: 11369.5791	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 13479.8066	loss_val: 13479.8896	loss_test: 13479.8125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8331.3350	loss_val: 8331.4082	loss_test: 8331.3545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5130.2661	loss_val: 5131.2148	loss_test: 5131.2905	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5507.5537	loss_val: 5508.4722	loss_test: 5509.4268	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 11007.1523	loss_val: 11007.3369	loss_test: 11007.6211	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6301.6626	loss_val: 6301.6470	loss_test: 6305.0190	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4806.5098	loss_val: 4806.6587	loss_test: 4807.9336	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4453.0854	loss_val: 4453.0850	loss_test: 4453.0825	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8852.9219	loss_val: 8853.2227	loss_test: 8854.0518	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66919.8828	loss_val: 66919.8125	loss_test: 66920.1953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6430.7852	loss_val: 6431.2134	loss_test: 6431.3672	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 78	curr_val_accuracy: 0.8238	curr_test_accuracy: 0.7628
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 79		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5810.4800	loss_val: 5811.5176	loss_test: 5811.0913	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13213.4102	loss_val: 13213.7852	loss_test: 13213.7568	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56950.4922	loss_val: 56950.8281	loss_test: 56951.4922	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 73037.2500	loss_val: 73037.2422	loss_test: 73037.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7309.1392	loss_val: 7311.0728	loss_test: 7309.6455	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5040.1880	loss_val: 5040.2070	loss_test: 5040.2139	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10066.0742	loss_val: 10066.1523	loss_test: 10066.4785	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5496.5645	loss_val: 5497.1807	loss_test: 5497.4199	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11368.9443	loss_val: 11369.5762	loss_test: 11369.5586	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 13494.3604	loss_val: 13494.4443	loss_test: 13494.3672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8339.6729	loss_val: 8339.7480	loss_test: 8339.6914	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5112.3267	loss_val: 5113.2505	loss_test: 5113.3467	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5594.9585	loss_val: 5595.9243	loss_test: 5596.6963	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 13]	loss_train: 10987.1436	loss_val: 10987.3232	loss_test: 10987.6133	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6330.2949	loss_val: 6330.2803	loss_test: 6333.6372	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4792.9644	loss_val: 4793.1123	loss_test: 4794.3906	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4455.3657	loss_val: 4455.3657	loss_test: 4455.3638	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8722.9756	loss_val: 8723.3008	loss_test: 8724.0293	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66862.5391	loss_val: 66862.4688	loss_test: 66862.8516	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6484.6680	loss_val: 6485.0513	loss_test: 6485.2383	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 79	curr_val_accuracy: 0.7992	curr_test_accuracy: 0.7628
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 80		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5833.2285	loss_val: 5834.2461	loss_test: 5833.8452	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 1]	loss_train: 13166.3398	loss_val: 13166.7441	loss_test: 13166.6953	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56589.0977	loss_val: 56589.3945	loss_test: 56590.1055	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 72815.7266	loss_val: 72815.7109	loss_test: 72815.8125	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7255.7402	loss_val: 7257.6851	loss_test: 7256.2500	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5033.5415	loss_val: 5033.5610	loss_test: 5033.5674	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10129.0146	loss_val: 10129.0928	loss_test: 10129.4199	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5470.8652	loss_val: 5471.4805	loss_test: 5471.7070	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11410.6094	loss_val: 11411.2549	loss_test: 11411.2334	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 13626.7500	loss_val: 13626.8320	loss_test: 13626.7568	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8336.3350	loss_val: 8336.4121	loss_test: 8336.3555	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5098.1758	loss_val: 5099.0791	loss_test: 5099.1953	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5685.4717	loss_val: 5686.4775	loss_test: 5687.0776	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10982.2246	loss_val: 10982.3994	loss_test: 10982.6992	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6368.3452	loss_val: 6368.3311	loss_test: 6371.7217	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4778.5923	loss_val: 4778.7388	loss_test: 4780.0234	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4463.8315	loss_val: 4463.8330	loss_test: 4463.8311	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8633.6240	loss_val: 8633.9590	loss_test: 8634.6396	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66694.1016	loss_val: 66694.0312	loss_test: 66694.4219	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6538.1855	loss_val: 6538.5303	loss_test: 6538.7510	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 80	curr_val_accuracy: 0.7992	curr_test_accuracy: 0.7784
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 81		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5864.1123	loss_val: 5865.1226	loss_test: 5864.7412	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.8000
[client 1]	loss_train: 13131.9570	loss_val: 13132.3945	loss_test: 13132.3193	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56420.4844	loss_val: 56420.7461	loss_test: 56421.5039	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 72734.8359	loss_val: 72734.8203	loss_test: 72734.9141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8889
[client 4]	loss_train: 7186.1548	loss_val: 7188.1279	loss_test: 7186.6709	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5029.2788	loss_val: 5029.2979	loss_test: 5029.3042	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10127.1230	loss_val: 10127.2012	loss_test: 10127.5293	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8571
[client 7]	loss_train: 5466.8442	loss_val: 5467.4600	loss_test: 5467.6704	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11278.6514	loss_val: 11279.3252	loss_test: 11279.2871	accuracy_train: 1.0000	accuracy_val: 0.3333	accuracy_test: 0.5714
[client 9]	loss_train: 13689.5020	loss_val: 13689.5840	loss_test: 13689.5098	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8332.1064	loss_val: 8332.1846	loss_test: 8332.1260	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5078.3496	loss_val: 5079.2422	loss_test: 5079.3691	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5797.4307	loss_val: 5798.4751	loss_test: 5798.9072	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10962.2012	loss_val: 10962.3750	loss_test: 10962.6768	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6383.8418	loss_val: 6383.8281	loss_test: 6387.2144	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4774.4858	loss_val: 4774.6304	loss_test: 4775.9165	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4467.8818	loss_val: 4467.8843	loss_test: 4467.8823	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8557.7139	loss_val: 8558.0576	loss_test: 8558.7002	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66641.7188	loss_val: 66641.6484	loss_test: 66642.0391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6594.7520	loss_val: 6595.0649	loss_test: 6595.3159	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 81	curr_val_accuracy: 0.8072	curr_test_accuracy: 0.7784
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 82		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5898.8901	loss_val: 5899.9058	loss_test: 5899.5342	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13143.1221	loss_val: 13143.5781	loss_test: 13143.4922	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56368.3711	loss_val: 56368.6016	loss_test: 56369.4141	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6000
[client 3]	loss_train: 72853.4062	loss_val: 72853.3906	loss_test: 72853.4844	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7103.6743	loss_val: 7105.6758	loss_test: 7104.2007	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7273
[client 5]	loss_train: 5025.1138	loss_val: 5025.1318	loss_test: 5025.1387	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10149.8643	loss_val: 10149.9434	loss_test: 10150.2773	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5470.9272	loss_val: 5471.5425	loss_test: 5471.7397	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11148.0479	loss_val: 11148.7461	loss_test: 11148.7080	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 13697.1748	loss_val: 13697.2568	loss_test: 13697.1826	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8322.5947	loss_val: 8322.6748	loss_test: 8322.6143	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5051.9458	loss_val: 5052.8379	loss_test: 5052.9731	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5857.5586	loss_val: 5858.6245	loss_test: 5858.9595	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10959.3291	loss_val: 10959.5010	loss_test: 10959.8047	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6394.7407	loss_val: 6394.7275	loss_test: 6398.1543	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4768.6562	loss_val: 4768.7974	loss_test: 4770.0776	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4466.6938	loss_val: 4466.6968	loss_test: 4466.6953	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8457.7471	loss_val: 8458.1113	loss_test: 8458.6875	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66512.4531	loss_val: 66512.3828	loss_test: 66512.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6527.3687	loss_val: 6527.7280	loss_test: 6527.9766	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 82	curr_val_accuracy: 0.8316	curr_test_accuracy: 0.7791
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 83		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5910.7817	loss_val: 5911.7915	loss_test: 5911.4238	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13135.1006	loss_val: 13135.5693	loss_test: 13135.4727	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56401.3008	loss_val: 56401.7500	loss_test: 56402.3281	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 72671.8516	loss_val: 72671.8359	loss_test: 72671.9297	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7023.8398	loss_val: 7025.8667	loss_test: 7024.3813	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5013.9731	loss_val: 5013.9912	loss_test: 5013.9985	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10209.3779	loss_val: 10209.4570	loss_test: 10209.8008	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5464.3013	loss_val: 5464.9141	loss_test: 5465.1030	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11062.4961	loss_val: 11063.2012	loss_test: 11063.1738	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 13636.7256	loss_val: 13636.8096	loss_test: 13636.7334	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8303.0820	loss_val: 8303.1641	loss_test: 8303.1016	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5023.6221	loss_val: 5024.5215	loss_test: 5024.6748	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5895.2339	loss_val: 5896.3125	loss_test: 5896.5581	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10971.1953	loss_val: 10971.3643	loss_test: 10971.6709	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6396.3320	loss_val: 6396.3193	loss_test: 6399.8262	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4763.7437	loss_val: 4763.8818	loss_test: 4765.1494	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4455.3301	loss_val: 4455.3340	loss_test: 4455.3330	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8394.7900	loss_val: 8395.1680	loss_test: 8395.7129	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 66280.0391	loss_val: 66279.9688	loss_test: 66280.3594	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6457.0903	loss_val: 6457.5112	loss_test: 6457.7412	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 83	curr_val_accuracy: 0.8152	curr_test_accuracy: 0.7870
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 84		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5911.9668	loss_val: 5912.9717	loss_test: 5912.6021	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13180.2031	loss_val: 13180.7051	loss_test: 13180.5850	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 57366.2305	loss_val: 57366.9062	loss_test: 57367.3047	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 72987.2031	loss_val: 72987.1953	loss_test: 72987.2812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6941.1968	loss_val: 6943.2715	loss_test: 6941.7612	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5012.2173	loss_val: 5012.2358	loss_test: 5012.2427	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10247.5957	loss_val: 10247.6729	loss_test: 10248.0303	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5508.5718	loss_val: 5509.1836	loss_test: 5509.3633	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 11030.8193	loss_val: 11031.5195	loss_test: 11031.5244	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5714
[client 9]	loss_train: 13522.8369	loss_val: 13522.9219	loss_test: 13522.8457	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8294.9258	loss_val: 8295.0098	loss_test: 8294.9453	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5008.3540	loss_val: 5009.2783	loss_test: 5009.4326	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5908.3691	loss_val: 5909.4463	loss_test: 5909.6387	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10959.2158	loss_val: 10959.3799	loss_test: 10959.6943	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6405.5190	loss_val: 6405.5068	loss_test: 6409.0786	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4769.0537	loss_val: 4769.1914	loss_test: 4770.4473	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4454.9355	loss_val: 4454.9395	loss_test: 4454.9390	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8368.9414	loss_val: 8369.3203	loss_test: 8369.8584	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 65963.4453	loss_val: 65963.3750	loss_test: 65963.7656	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6419.0498	loss_val: 6419.5103	loss_test: 6419.7275	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 84	curr_val_accuracy: 0.8163	curr_test_accuracy: 0.7794
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 85		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5906.6899	loss_val: 5907.6973	loss_test: 5907.3276	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 1]	loss_train: 13161.7178	loss_val: 13162.2637	loss_test: 13162.1094	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 57990.7109	loss_val: 57991.5078	loss_test: 57991.8242	accuracy_train: 0.9429	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 73757.2578	loss_val: 73757.2500	loss_test: 73757.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6900.7178	loss_val: 6902.8184	loss_test: 6901.3032	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5013.4277	loss_val: 5013.4463	loss_test: 5013.4531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10268.2969	loss_val: 10268.3730	loss_test: 10268.7451	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5563.5308	loss_val: 5564.1333	loss_test: 5564.3228	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10987.4971	loss_val: 10988.1973	loss_test: 10988.2246	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.5714
[client 9]	loss_train: 13461.8799	loss_val: 13461.9668	loss_test: 13461.8887	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8277.7266	loss_val: 8277.8105	loss_test: 8277.7461	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5009.8867	loss_val: 5010.8281	loss_test: 5010.9985	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5927.7344	loss_val: 5928.8096	loss_test: 5928.9570	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10966.1436	loss_val: 10966.3086	loss_test: 10966.6211	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6419.5923	loss_val: 6419.5801	loss_test: 6423.2163	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4779.3052	loss_val: 4779.4434	loss_test: 4780.6909	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4464.8291	loss_val: 4464.8335	loss_test: 4464.8330	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8289.6514	loss_val: 8290.0615	loss_test: 8290.5361	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 65751.6719	loss_val: 65751.6016	loss_test: 65751.9922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6410.9146	loss_val: 6411.4009	loss_test: 6411.6108	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 85	curr_val_accuracy: 0.8175	curr_test_accuracy: 0.7794
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 86		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5879.8149	loss_val: 5880.8247	loss_test: 5880.4595	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 1]	loss_train: 13168.4189	loss_val: 13168.9912	loss_test: 13168.8125	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 58125.8164	loss_val: 58126.6484	loss_test: 58126.9336	accuracy_train: 0.9143	accuracy_val: 0.6000	accuracy_test: 0.2000
[client 3]	loss_train: 74077.7109	loss_val: 74077.7031	loss_test: 74077.7812	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6859.4038	loss_val: 6861.5137	loss_test: 6860.0073	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5015.9829	loss_val: 5016.0015	loss_test: 5016.0078	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10343.7354	loss_val: 10343.8115	loss_test: 10344.1982	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5622.7827	loss_val: 5623.3774	loss_test: 5623.5718	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10958.4258	loss_val: 10959.1201	loss_test: 10959.1777	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 13372.7773	loss_val: 13372.8662	loss_test: 13372.7861	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8274.1865	loss_val: 8274.2695	loss_test: 8274.2070	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5010.3262	loss_val: 5011.3066	loss_test: 5011.4678	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5907.0254	loss_val: 5908.0898	loss_test: 5908.2344	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10950.8340	loss_val: 10951.0020	loss_test: 10951.3096	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6429.8867	loss_val: 6429.8750	loss_test: 6433.5430	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4783.1836	loss_val: 4783.3228	loss_test: 4784.5693	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4478.3638	loss_val: 4478.3687	loss_test: 4478.3687	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8207.4619	loss_val: 8207.9111	loss_test: 8208.3301	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 65567.6328	loss_val: 65567.5625	loss_test: 65567.9531	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6415.6230	loss_val: 6416.1196	loss_test: 6416.3306	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 86	curr_val_accuracy: 0.8175	curr_test_accuracy: 0.7636
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 87		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5852.9844	loss_val: 5854.0078	loss_test: 5853.6450	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 1]	loss_train: 13178.0967	loss_val: 13178.6709	loss_test: 13178.4863	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 57595.4922	loss_val: 57596.3047	loss_test: 57596.5781	accuracy_train: 0.9143	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 74715.0000	loss_val: 74714.9922	loss_test: 74715.0703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6824.1064	loss_val: 6826.2266	loss_test: 6824.7271	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5008.1162	loss_val: 5008.1348	loss_test: 5008.1401	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10412.6904	loss_val: 10412.7676	loss_test: 10413.1650	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5677.2192	loss_val: 5677.8076	loss_test: 5678.0073	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10907.8457	loss_val: 10908.5410	loss_test: 10908.6074	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 13301.3740	loss_val: 13301.4648	loss_test: 13301.3848	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8244.5752	loss_val: 8244.6543	loss_test: 8244.5938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5032.2598	loss_val: 5033.2920	loss_test: 5033.4360	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5868.4707	loss_val: 5869.5234	loss_test: 5869.6836	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10960.5010	loss_val: 10960.6699	loss_test: 10960.9756	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6445.4590	loss_val: 6445.4473	loss_test: 6449.1523	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4784.4663	loss_val: 4784.6050	loss_test: 4785.8511	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4483.2124	loss_val: 4483.2173	loss_test: 4483.2178	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8182.9004	loss_val: 8183.3818	loss_test: 8183.7749	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 64826.4688	loss_val: 64826.4023	loss_test: 64826.7891	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6420.5854	loss_val: 6421.0820	loss_test: 6421.2969	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 87	curr_val_accuracy: 0.8175	curr_test_accuracy: 0.7647
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 88		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5823.6206	loss_val: 5824.6665	loss_test: 5824.2920	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.7000
[client 1]	loss_train: 13173.5791	loss_val: 13174.1445	loss_test: 13173.9629	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 57060.3008	loss_val: 57061.0742	loss_test: 57061.3516	accuracy_train: 0.9714	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 75139.4219	loss_val: 75139.4141	loss_test: 75139.4922	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6805.7490	loss_val: 6807.8774	loss_test: 6806.3872	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5001.0527	loss_val: 5001.0718	loss_test: 5001.0767	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10437.6641	loss_val: 10437.7402	loss_test: 10438.1494	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5682.4893	loss_val: 5683.0713	loss_test: 5683.2852	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10816.0537	loss_val: 10816.7432	loss_test: 10816.8193	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 13233.0234	loss_val: 13233.1152	loss_test: 13233.0342	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8233.1045	loss_val: 8233.1807	loss_test: 8233.1221	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5062.1030	loss_val: 5063.1689	loss_test: 5063.3086	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5758.7661	loss_val: 5759.7900	loss_test: 5760.0732	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10954.0254	loss_val: 10954.1992	loss_test: 10954.5000	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6474.9824	loss_val: 6474.9707	loss_test: 6478.7402	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4776.2036	loss_val: 4776.3428	loss_test: 4777.5947	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4493.1255	loss_val: 4493.1304	loss_test: 4493.1318	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8167.9995	loss_val: 8168.5093	loss_test: 8168.8843	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 64723.8633	loss_val: 64723.7969	loss_test: 64724.1836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6446.1582	loss_val: 6446.6016	loss_test: 6446.8550	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7692
curr_round: 88	curr_val_accuracy: 0.8174	curr_test_accuracy: 0.7721
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 89		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5820.4600	loss_val: 5821.5273	loss_test: 5821.1357	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.7000
[client 1]	loss_train: 13145.3975	loss_val: 13145.9424	loss_test: 13145.7725	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56536.1133	loss_val: 56536.8398	loss_test: 56537.1367	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 75430.3281	loss_val: 75430.3125	loss_test: 75430.3984	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6812.2974	loss_val: 6814.4141	loss_test: 6812.9443	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5000.9009	loss_val: 5000.9199	loss_test: 5000.9238	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10479.6855	loss_val: 10479.7627	loss_test: 10480.1816	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5685.6592	loss_val: 5686.2334	loss_test: 5686.4619	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4286
[client 8]	loss_train: 10798.4551	loss_val: 10799.1367	loss_test: 10799.2246	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 13195.5654	loss_val: 13195.6562	loss_test: 13195.5771	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8236.6436	loss_val: 8236.7158	loss_test: 8236.6592	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5086.6919	loss_val: 5087.7876	loss_test: 5087.9116	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5644.2476	loss_val: 5645.2310	loss_test: 5645.6577	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8000
[client 13]	loss_train: 10973.9766	loss_val: 10974.1572	loss_test: 10974.4492	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6502.7305	loss_val: 6502.7188	loss_test: 6506.5449	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4777.4565	loss_val: 4777.5957	loss_test: 4778.8545	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4503.8784	loss_val: 4503.8833	loss_test: 4503.8853	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8188.9844	loss_val: 8189.5078	loss_test: 8189.8848	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.5000
[client 18]	loss_train: 64488.4531	loss_val: 64488.3867	loss_test: 64488.7734	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6510.7700	loss_val: 6511.0918	loss_test: 6511.4248	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 89	curr_val_accuracy: 0.8181	curr_test_accuracy: 0.7721
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 90		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5835.3740	loss_val: 5836.4790	loss_test: 5836.0679	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13171.8945	loss_val: 13172.4219	loss_test: 13172.2637	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 56008.1094	loss_val: 56008.7578	loss_test: 56009.1016	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.4000
[client 3]	loss_train: 75345.4609	loss_val: 75345.4453	loss_test: 75345.5312	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6815.0254	loss_val: 6817.1436	loss_test: 6815.6714	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.8182
[client 5]	loss_train: 5006.9668	loss_val: 5006.9858	loss_test: 5006.9897	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10494.4756	loss_val: 10494.5518	loss_test: 10494.9795	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5676.4263	loss_val: 5676.9951	loss_test: 5677.2344	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10804.6953	loss_val: 10805.3682	loss_test: 10805.4648	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 13143.8525	loss_val: 13143.9434	loss_test: 13143.8652	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8241.0771	loss_val: 8241.1455	loss_test: 8241.0928	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5096.8677	loss_val: 5097.9800	loss_test: 5098.0815	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5549.9570	loss_val: 5550.9067	loss_test: 5551.5034	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.8000
[client 13]	loss_train: 10977.1582	loss_val: 10977.3477	loss_test: 10977.6357	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6532.3569	loss_val: 6532.3452	loss_test: 6536.1885	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4785.8848	loss_val: 4786.0249	loss_test: 4787.2935	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4508.2222	loss_val: 4508.2275	loss_test: 4508.2295	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8226.0166	loss_val: 8226.5488	loss_test: 8226.9365	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 64504.0859	loss_val: 64504.0195	loss_test: 64504.4062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6647.5059	loss_val: 6647.6846	loss_test: 6648.0923	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 90	curr_val_accuracy: 0.8175	curr_test_accuracy: 0.7713
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 91		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5846.5264	loss_val: 5847.6738	loss_test: 5847.2378	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13148.8047	loss_val: 13149.3008	loss_test: 13149.1621	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 55470.1016	loss_val: 55470.6445	loss_test: 55471.0625	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 75685.7969	loss_val: 75685.7812	loss_test: 75685.8672	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6844.2534	loss_val: 6846.3926	loss_test: 6844.8818	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5013.2852	loss_val: 5013.3047	loss_test: 5013.3081	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10463.1846	loss_val: 10463.2617	loss_test: 10463.6963	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5651.2407	loss_val: 5651.7993	loss_test: 5652.0493	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10805.0830	loss_val: 10805.7402	loss_test: 10805.8467	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 13108.6777	loss_val: 13108.7676	loss_test: 13108.6924	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8241.4473	loss_val: 8241.5127	loss_test: 8241.4629	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5099.0483	loss_val: 5100.1938	loss_test: 5100.2402	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5467.3330	loss_val: 5468.2456	loss_test: 5469.0190	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10985.0195	loss_val: 10985.2148	loss_test: 10985.4980	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6560.3569	loss_val: 6560.3452	loss_test: 6564.2305	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4790.0215	loss_val: 4790.1626	loss_test: 4791.4443	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4517.2412	loss_val: 4517.2461	loss_test: 4517.2490	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8265.6357	loss_val: 8266.1553	loss_test: 8266.5742	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 64684.5195	loss_val: 64684.4531	loss_test: 64684.8359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6729.9844	loss_val: 6730.1001	loss_test: 6730.5278	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 91	curr_val_accuracy: 0.8425	curr_test_accuracy: 0.7714
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 92		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5858.3677	loss_val: 5859.5488	loss_test: 5859.1021	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7000
[client 1]	loss_train: 13178.7637	loss_val: 13179.2070	loss_test: 13179.1094	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 55332.8555	loss_val: 55333.3047	loss_test: 55333.8047	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 75617.4688	loss_val: 75617.4531	loss_test: 75617.5391	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6863.3965	loss_val: 6865.5771	loss_test: 6864.0088	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5011.8994	loss_val: 5011.9185	loss_test: 5011.9214	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10461.2363	loss_val: 10461.3145	loss_test: 10461.7529	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5649.0288	loss_val: 5649.5869	loss_test: 5649.8467	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10815.2900	loss_val: 10815.9316	loss_test: 10816.0479	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 13044.1670	loss_val: 13044.2578	loss_test: 13044.1836	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8241.7207	loss_val: 8241.7842	loss_test: 8241.7373	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5101.7646	loss_val: 5102.9111	loss_test: 5102.9326	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5376.9058	loss_val: 5377.7803	loss_test: 5378.7710	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10975.2607	loss_val: 10975.4600	loss_test: 10975.7422	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6581.0796	loss_val: 6581.0684	loss_test: 6584.9722	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4787.3037	loss_val: 4787.4458	loss_test: 4788.7417	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4526.8496	loss_val: 4526.8545	loss_test: 4526.8574	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8310.2158	loss_val: 8310.7217	loss_test: 8311.1729	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 64576.6289	loss_val: 64576.5625	loss_test: 64576.9414	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6772.1665	loss_val: 6772.2559	loss_test: 6772.6860	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 92	curr_val_accuracy: 0.8425	curr_test_accuracy: 0.7714
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 93		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5873.0303	loss_val: 5874.2417	loss_test: 5873.7969	accuracy_train: 0.9867	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13217.5098	loss_val: 13217.9258	loss_test: 13217.8506	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 55407.3633	loss_val: 55407.7383	loss_test: 55408.3164	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 76158.1562	loss_val: 76158.1406	loss_test: 76158.2266	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6887.3574	loss_val: 6889.5952	loss_test: 6887.9639	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.8182
[client 5]	loss_train: 5018.1621	loss_val: 5018.1812	loss_test: 5018.1841	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10446.8652	loss_val: 10446.9443	loss_test: 10447.3828	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5640.4736	loss_val: 5641.0317	loss_test: 5641.3003	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10784.2334	loss_val: 10784.8672	loss_test: 10784.9541	accuracy_train: 1.0000	accuracy_val: 0.8333	accuracy_test: 0.7143
[client 9]	loss_train: 12962.3164	loss_val: 12962.4072	loss_test: 12962.3350	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8224.5264	loss_val: 8224.5859	loss_test: 8224.5410	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5089.2153	loss_val: 5090.3613	loss_test: 5090.3501	accuracy_train: 1.0000	accuracy_val: 0.7000	accuracy_test: 0.6000
[client 12]	loss_train: 5319.6392	loss_val: 5320.4834	loss_test: 5321.7080	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10948.9824	loss_val: 10949.1836	loss_test: 10949.4697	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6597.6953	loss_val: 6597.6841	loss_test: 6601.6133	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4789.7119	loss_val: 4789.8545	loss_test: 4791.1665	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4535.3281	loss_val: 4535.3330	loss_test: 4535.3359	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8384.9170	loss_val: 8385.3799	loss_test: 8385.9072	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.2500
[client 18]	loss_train: 64706.0312	loss_val: 64705.9648	loss_test: 64706.3477	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6831.2627	loss_val: 6831.3330	loss_test: 6831.7573	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 93	curr_val_accuracy: 0.8344	curr_test_accuracy: 0.7714
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 94		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5874.2344	loss_val: 5875.4868	loss_test: 5875.0381	accuracy_train: 0.9867	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13298.8809	loss_val: 13299.2559	loss_test: 13299.2168	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.6667
[client 2]	loss_train: 55477.5859	loss_val: 55477.9219	loss_test: 55478.5508	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 76107.1406	loss_val: 76107.1250	loss_test: 76107.2109	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6919.9087	loss_val: 6922.2046	loss_test: 6920.5205	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5022.0669	loss_val: 5022.0854	loss_test: 5022.0879	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10497.2510	loss_val: 10497.3320	loss_test: 10497.7666	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5645.5151	loss_val: 5646.0806	loss_test: 5646.3628	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10802.0664	loss_val: 10802.7090	loss_test: 10802.7441	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.7143
[client 9]	loss_train: 12928.1553	loss_val: 12928.2461	loss_test: 12928.1758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8227.4902	loss_val: 8227.5479	loss_test: 8227.5029	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5074.7197	loss_val: 5075.8740	loss_test: 5075.8198	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5306.8286	loss_val: 5307.6646	loss_test: 5309.0537	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10942.1826	loss_val: 10942.3877	loss_test: 10942.6709	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6596.6577	loss_val: 6596.6465	loss_test: 6600.6304	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4787.9253	loss_val: 4788.0688	loss_test: 4789.3823	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4537.8931	loss_val: 4537.8979	loss_test: 4537.9004	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8480.0781	loss_val: 8480.4912	loss_test: 8481.1064	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.2500
[client 18]	loss_train: 64692.0312	loss_val: 64691.9648	loss_test: 64692.3477	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6881.3286	loss_val: 6881.3911	loss_test: 6881.8052	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8462
curr_round: 94	curr_val_accuracy: 0.8248	curr_test_accuracy: 0.7716
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 95		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5877.9644	loss_val: 5879.2632	loss_test: 5878.8096	accuracy_train: 0.9867	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13389.1396	loss_val: 13389.4775	loss_test: 13389.4688	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 55608.9961	loss_val: 55609.3008	loss_test: 55609.9766	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 76272.5234	loss_val: 76272.5078	loss_test: 76272.5938	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6946.7637	loss_val: 6949.1196	loss_test: 6947.3926	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5021.5049	loss_val: 5021.5234	loss_test: 5021.5254	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10530.1846	loss_val: 10530.2686	loss_test: 10530.7031	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5664.6597	loss_val: 5665.2383	loss_test: 5665.5278	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10808.9512	loss_val: 10809.6006	loss_test: 10809.5840	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12876.4795	loss_val: 12876.5693	loss_test: 12876.5020	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8219.1436	loss_val: 8219.1982	loss_test: 8219.1543	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5064.9282	loss_val: 5066.1079	loss_test: 5065.9995	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5303.3628	loss_val: 5304.2002	loss_test: 5305.7090	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10909.2139	loss_val: 10909.4189	loss_test: 10909.7061	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6589.5503	loss_val: 6589.5396	loss_test: 6593.5122	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4787.9663	loss_val: 4788.1108	loss_test: 4789.4233	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4536.1958	loss_val: 4536.2002	loss_test: 4536.2021	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8592.1348	loss_val: 8592.5029	loss_test: 8593.2246	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64979.1875	loss_val: 64979.1172	loss_test: 64979.5039	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6849.4326	loss_val: 6849.4966	loss_test: 6849.9136	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.8462
curr_round: 95	curr_val_accuracy: 0.8333	curr_test_accuracy: 0.7864
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 96		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5864.4995	loss_val: 5865.8237	loss_test: 5865.3730	accuracy_train: 0.9867	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13424.3135	loss_val: 13424.6162	loss_test: 13424.6377	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 55759.3867	loss_val: 55759.6719	loss_test: 55760.3789	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 76902.3594	loss_val: 76902.3438	loss_test: 76902.4297	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6950.9165	loss_val: 6953.3525	loss_test: 6951.5669	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5021.9028	loss_val: 5021.9214	loss_test: 5021.9233	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10545.4775	loss_val: 10545.5615	loss_test: 10545.9961	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5692.3828	loss_val: 5692.9736	loss_test: 5693.2725	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10767.7734	loss_val: 10768.4395	loss_test: 10768.3672	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12837.7695	loss_val: 12837.8584	loss_test: 12837.7949	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8206.8301	loss_val: 8206.8838	loss_test: 8206.8398	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5067.7061	loss_val: 5068.9014	loss_test: 5068.7588	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5294.1821	loss_val: 5295.0171	loss_test: 5296.6147	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10861.3418	loss_val: 10861.5479	loss_test: 10861.8389	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6582.2139	loss_val: 6582.2031	loss_test: 6586.1948	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4780.1362	loss_val: 4780.2817	loss_test: 4781.5840	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4534.4355	loss_val: 4534.4399	loss_test: 4534.4419	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8699.6055	loss_val: 8699.9424	loss_test: 8700.7676	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64974.2695	loss_val: 64974.1992	loss_test: 64974.5859	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6771.2100	loss_val: 6771.2808	loss_test: 6771.7056	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 96	curr_val_accuracy: 0.8333	curr_test_accuracy: 0.7700
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 97		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5831.2700	loss_val: 5832.6069	loss_test: 5832.1621	accuracy_train: 0.9733	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13542.0625	loss_val: 13542.3262	loss_test: 13542.3818	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 55798.7891	loss_val: 55799.0703	loss_test: 55799.7891	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 77129.4453	loss_val: 77129.4297	loss_test: 77129.5156	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6965.0146	loss_val: 6967.5176	loss_test: 6965.6865	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5022.2725	loss_val: 5022.2900	loss_test: 5022.2930	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10522.3936	loss_val: 10522.4775	loss_test: 10522.9102	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5714.0234	loss_val: 5714.6250	loss_test: 5714.9380	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10807.2344	loss_val: 10807.9170	loss_test: 10807.8086	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12764.0332	loss_val: 12764.1211	loss_test: 12764.0605	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8204.6045	loss_val: 8204.6572	loss_test: 8204.6143	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5076.4932	loss_val: 5077.6836	loss_test: 5077.5420	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5000
[client 12]	loss_train: 5297.6011	loss_val: 5298.4370	loss_test: 5300.0962	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10855.4355	loss_val: 10855.6494	loss_test: 10855.9385	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6554.2749	loss_val: 6554.2637	loss_test: 6558.2173	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4767.8906	loss_val: 4768.0386	loss_test: 4769.3384	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4533.0332	loss_val: 4533.0371	loss_test: 4533.0386	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8811.9170	loss_val: 8812.2266	loss_test: 8813.1553	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64917.2578	loss_val: 64917.1875	loss_test: 64917.5703	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6671.3672	loss_val: 6671.4541	loss_test: 6671.8862	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7692
curr_round: 97	curr_val_accuracy: 0.8333	curr_test_accuracy: 0.7700
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 98		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5788.4482	loss_val: 5789.7632	loss_test: 5789.3408	accuracy_train: 0.9867	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13632.2178	loss_val: 13632.4600	loss_test: 13632.5342	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 55897.0078	loss_val: 55897.2891	loss_test: 55898.0156	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 77678.5547	loss_val: 77678.5391	loss_test: 77678.6250	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 6975.8916	loss_val: 6978.4287	loss_test: 6976.5830	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5024.6558	loss_val: 5024.6729	loss_test: 5024.6758	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10532.7451	loss_val: 10532.8311	loss_test: 10533.2627	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5721.6729	loss_val: 5722.2803	loss_test: 5722.5986	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10798.8398	loss_val: 10799.5342	loss_test: 10799.4082	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12592.7246	loss_val: 12592.8076	loss_test: 12592.7520	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8215.5547	loss_val: 8215.6055	loss_test: 8215.5635	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5099.6963	loss_val: 5100.8911	loss_test: 5100.7515	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5303.0273	loss_val: 5303.8726	loss_test: 5305.5581	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10865.3428	loss_val: 10865.5645	loss_test: 10865.8506	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6558.9375	loss_val: 6558.9268	loss_test: 6562.8408	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4776.3062	loss_val: 4776.4541	loss_test: 4777.7544	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4534.9268	loss_val: 4534.9307	loss_test: 4534.9321	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 8926.9150	loss_val: 8927.2051	loss_test: 8928.2246	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64877.4336	loss_val: 64877.3633	loss_test: 64877.7461	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6602.7271	loss_val: 6602.8438	loss_test: 6603.2754	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 98	curr_val_accuracy: 0.8246	curr_test_accuracy: 0.7784
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
round # 99		sampled_clients: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[client 0]	loss_train: 5708.7480	loss_val: 5709.9658	loss_test: 5709.5957	accuracy_train: 1.0000	accuracy_val: 0.5000	accuracy_test: 0.7000
[client 1]	loss_train: 13708.8574	loss_val: 13709.0791	loss_test: 13709.1719	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.6667
[client 2]	loss_train: 55903.4648	loss_val: 55903.7578	loss_test: 55904.4805	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 3]	loss_train: 78151.5078	loss_val: 78151.4922	loss_test: 78151.5781	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 4]	loss_train: 7001.1362	loss_val: 7003.6592	loss_test: 7001.8242	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.7273
[client 5]	loss_train: 5034.4536	loss_val: 5034.4702	loss_test: 5034.4731	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 6]	loss_train: 10587.2197	loss_val: 10587.3096	loss_test: 10587.7393	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7143
[client 7]	loss_train: 5708.4512	loss_val: 5709.0630	loss_test: 5709.3838	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.5714
[client 8]	loss_train: 10785.4287	loss_val: 10786.1357	loss_test: 10786.0107	accuracy_train: 1.0000	accuracy_val: 0.6667	accuracy_test: 0.8571
[client 9]	loss_train: 12528.3799	loss_val: 12528.4561	loss_test: 12528.4062	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 10]	loss_train: 8231.7607	loss_val: 8231.8105	loss_test: 8231.7686	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 11]	loss_train: 5118.3525	loss_val: 5119.5513	loss_test: 5119.4185	accuracy_train: 1.0000	accuracy_val: 0.6000	accuracy_test: 0.6000
[client 12]	loss_train: 5308.1147	loss_val: 5308.9663	loss_test: 5310.6489	accuracy_train: 1.0000	accuracy_val: 0.8000	accuracy_test: 0.6000
[client 13]	loss_train: 10834.3096	loss_val: 10834.5391	loss_test: 10834.8193	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.7500
[client 14]	loss_train: 6563.5850	loss_val: 6563.5742	loss_test: 6567.4443	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.0000
[client 15]	loss_train: 4788.3540	loss_val: 4788.5010	loss_test: 4789.8018	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 0.5000
[client 16]	loss_train: 4538.2412	loss_val: 4538.2451	loss_test: 4538.2461	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 17]	loss_train: 9059.1338	loss_val: 9059.4023	loss_test: 9060.5010	accuracy_train: 1.0000	accuracy_val: 0.7500	accuracy_test: 0.5000
[client 18]	loss_train: 64825.8828	loss_val: 64825.8086	loss_test: 64826.1875	accuracy_train: 1.0000	accuracy_val: 1.0000	accuracy_test: 1.0000
[client 19]	loss_train: 6497.0239	loss_val: 6497.2271	loss_test: 6497.6216	accuracy_train: 1.0000	accuracy_val: 0.9167	accuracy_test: 0.7692
curr_round: 99	curr_val_accuracy: 0.8246	curr_test_accuracy: 0.7784
best_round: 71	best_val_accuracy: 0.8572	best_test_accuracy: 0.7872
--------------------------------------------------
